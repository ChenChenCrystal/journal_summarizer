# arXiv cs.AI Summary â€“ 2025-09-15

## My Favorite Streamer is an LLM: Discovering, Bonding, and Co-Creating in AI VTuber Fandom
**URL:** https://arxiv.org/abs/2509.10427

**Abstract:** AI VTubers, where the performer is not human but algorithmically generated, introduce a new context for fandom. While human VTubers have been substantially studied for their cultural appeal, parasocial dynamics, and community economies, little is known about how audiences engage with their AI counterparts. To address this gap, we present a qualitative study of Neuro-sama, the most prominent AI VTuber. Our findings show that engagement is anchored in active co-creation: audiences are drawn by the AI's unpredictable yet entertaining interactions, cement loyalty through collective emotional events that trigger anthropomorphic projection, and sustain attachment via the AI's consistent persona. Financial support emerges not as a reward for performance but as a participatory mechanism for shaping livestream content, establishing a resilient fan economy built on ongoing interaction. These dynamics reveal how AI Vtuber fandom reshapes fan-creator relationships and offer implications for designing transparent and sustainable AI-mediated communities.

**AI Summary:** This research explores how audiences engage with AI VTubers, specifically focusing on Neuro-sama, the most prominent AI VTuber. The study finds that engagement with AI VTubers is rooted in active co-creation, with audiences drawn to the AI's unpredictable interactions and forming emotional attachments through collective events. Financial support from fans is seen as a way to shape livestream content, highlighting the unique dynamics of AI VTuber fandom and offering insights for designing sustainable AI-mediated communities.

---

## The Language of Approval: Identifying the Drivers of Positive Feedback Online
**URL:** https://arxiv.org/abs/2509.10370

**Abstract:** Positive feedback via likes and awards is central to online governance, yet which attributes of users' posts elicit rewards -- and how these vary across authors and communities -- remains unclear. To examine this, we combine quasi-experimental causal inference with predictive modeling on 11M posts from 100 subreddits. We identify linguistic patterns and stylistic attributes causally linked to rewards, controlling for author reputation, timing, and community context. For example, overtly complicated language, tentative style, and toxicity reduce rewards. We use our set of curated features to train models that can detect highly-upvoted posts with high AUC. Our audit of community guidelines highlights a ``policy-practice gap'' -- most rules focus primarily on civility and formatting requirements, with little emphasis on the attributes identified to drive positive feedback. These results inform the design of community guidelines, support interfaces that teach users how to craft desirable contributions, and moderation workflows that emphasize positive reinforcement over purely punitive enforcement.

**AI Summary:** This research examines the linguistic patterns and stylistic attributes that drive positive feedback online, using a combination of causal inference and predictive modeling on 11 million posts from 100 subreddits. The study finds that attributes such as complicated language, tentative style, and toxicity reduce rewards, and that community guidelines often do not focus on these key drivers of positive feedback. The results have implications for designing community guidelines, teaching users how to create desirable contributions, and emphasizing positive reinforcement in moderation workflows.

---

## Who Decides How Knowing Becomes Doing? Redistributing Authority in Human-AI Music Co-Creation
**URL:** https://arxiv.org/abs/2509.10331

**Abstract:** In the era of human-AI co-creation, the maxim "knowing is easy, doing is hard" is redefined. AI has the potential to ease execution, yet the essence of "hard" lies in who governs the translation from knowing to doing. Mainstream tools often centralize interpretive authority and homogenize expression, suppressing marginal voices. To address these challenges, we introduce the first systematic framework for redistributing authority in the knowing-doing cycle, built on three principles, namely contestability, agency, and plurality. Through interactive studies with 180 music practitioners, complemented by in-depth interviews, we demonstrate that these principles reshape human-AI authority relations and reactivate human creative expression. The findings establish a new paradigm for critical computing and human-AI co-creation that advances from critique to practice.

**AI Summary:** This research explores the dynamics of authority in human-AI music co-creation, emphasizing the importance of who governs the translation from knowledge to action. The study introduces a framework based on contestability, agency, and plurality to redistribute authority and promote diverse creative expression. Through interactive studies with music practitioners, the research demonstrates that these principles can reshape human-AI authority relations and enhance creative outcomes, offering a new paradigm for critical computing and human-AI collaboration.

---

## MusicScaffold: Bridging Machine Efficiency and Human Growth in Adolescent Creative Education through Generative AI
**URL:** https://arxiv.org/abs/2509.10327

**Abstract:** Adolescence is marked by strong creative impulses but limited strategies for structured expression, often leading to frustration or disengagement. While generative AI lowers technical barriers and delivers efficient outputs, its role in fostering adolescents' expressive growth has been overlooked. We propose MusicScaffold, the first adolescent-centered framework that repositions AI as a guide, coach, and partner, making expressive strategies transparent and learnable, and supporting autonomy. In a four-week study with middle school students (ages 12--14), MusicScaffold enhanced cognitive specificity, behavioral self-regulation, and affective confidence in music creation. By reframing generative AI as a scaffold rather than a generator, this work bridges the machine efficiency of generative systems with human growth in adolescent creative education.

**AI Summary:** The study introduces MusicScaffold, a framework that uses generative AI to guide and support middle school students in music creation, enhancing cognitive specificity, behavioral self-regulation, and affective confidence. By repositioning AI as a scaffold rather than a generator, the research shows how AI can facilitate structured expression and foster creative growth in adolescents, bridging the gap between machine efficiency and human development in creative education.

---

## Understanding Expert Exploration in EHR Visualization Tools: The ParcoursVis Use Case
**URL:** https://arxiv.org/abs/2509.10081

**Abstract:** We introduce our ongoing work toward an insight-based evaluation methodology aimed at understanding practitioners' mental models when exploring medical data. It is based on ParcoursVis, a Progressive Visual Analytics system designed to visualize event sequences derived from Electronic Health Records at scale (millions of patients, billions of events), developed in collaboration with the Emergency Departments of 16 Parisian hospitals and with the French Social Security. Building on prior usability validation, our current evaluation focuses on the insights generated by expert users and aims to better understand the exploration strategies they employ when engaging with exploration visualization tools. We describe our system and outline our evaluation protocol, analysis strategy, and preliminary findings. Building on this approach and our pilot results, we contribute a design protocol for conducting insight-based studies under real-world constraints, including the availability of health practitioners whom we were fortunate to interview. Our findings highlight a loop, where the use of the system helps refine data variables identification and the system itself. We aim to shed light on generated insights, to highlight the utility of exploratory tools in health data analysis contexts.

**AI Summary:** The research focuses on understanding how expert users explore medical data using the ParcoursVis visualization system. The study involves collaboration with multiple hospitals and the French Social Security to analyze event sequences from Electronic Health Records. The findings suggest that the system helps refine data variables identification and the system itself, highlighting the importance of exploratory tools in health data analysis.

---

## From customer survey feedback to software improvements: Leveraging the full potential of data
**URL:** https://arxiv.org/abs/2509.10064

**Abstract:** Converting customer survey feedback data into usable insights has always been a great challenge for large software enterprises. Despite the improvements on this field, a major obstacle often remains when drawing the right conclusions out of the data and channeling them into the software development process. In this paper we present a practical end-to-end approach of how to extract useful information out of a data set and leverage the information to drive change. We describe how to choose the right metrics to measure, gather appropriate feedback from customer end-users, analyze the data by leveraging methods from inferential statistics, make the data transparent, and finally drive change with the results. Furthermore, we present an example of a UX prototype dashboard that can be used to communicate the analyses to stakeholders within the company.

**AI Summary:** This research paper addresses the challenge of converting customer survey feedback into actionable insights for software development. The authors propose an end-to-end approach that involves choosing the right metrics, gathering feedback, analyzing data using inferential statistics, and driving change based on the results. They also provide an example of a UX prototype dashboard for communicating the analyses to stakeholders. This research is significant as it offers a practical method for leveraging customer feedback data to improve software development processes in large enterprises.

---

## Inclusive by design: Developing Barrier-Free Authentication for Blind and Low Vision Users through the ALIAS Project
**URL:** https://arxiv.org/abs/2509.10043

**Abstract:** Authentication is the cornerstone of information security in our daily lives. However, disabled users such as Blind and Low-Vision (BLV) ones are left behind in digital services due to the lack of accessibility. According to the World Health Organization, 36 million people are blind worldwide. It is estimated that there will be 115 million by 2050, due to the ageing of the population. Yet accessing digital services has become increasingly essential. At the same time, cyber threats targeting individuals have also increased strongly in the last few years. The ALIAS project addresses the need for accessible digital authentication solutions for BLV users facing challenges with digital technology. Security systems can inhibit access for these individuals as they become more complex. This project aims to create a barrier-free authentication system based on cognitive ergonomics and user experience (UX) design methods specifically for BLV users. This paper presents an overview of current research in this area. We also identify research gaps, and finally, we present our project's methodology and approach. First, we will build a knowledge base on the digital practices and cognitive models of BLV users during authentication. This information will support the development of prototypes, which will be tested and refined through two iterations before finalizing the operational version.

**AI Summary:** The ALIAS project aims to develop a barrier-free authentication system for Blind and Low-Vision (BLV) users to improve their access to digital services. With an increasing number of blind individuals worldwide and growing cyber threats, the need for accessible authentication solutions is more critical than ever. The project will focus on cognitive ergonomics and user experience design to create prototypes that will be tested and refined to meet the unique needs of BLV users.

---

## A Framework for AI-Supported Mediation in Community-based Online Collaboration
**URL:** https://arxiv.org/abs/2509.10015

**Abstract:** Online spaces involve diverse communities engaging in various forms of collaboration, which naturally give rise to discussions, some of which inevitably escalate into conflict or disputes. To address such situations, AI has primarily been used for moderation. While moderation systems are important because they help maintain order, common moderation strategies of removing or suppressing content and users rarely address the underlying disagreements or the substantive content of disputes. Mediation, by contrast, fosters understanding, reduces emotional tension, and facilitates consensus through guided negotiation. Mediation not only enhances the quality of collaborative decisions but also strengthens relationships among group members. For this reason, we argue for shifting focus toward AI-supported mediation. In this work, we propose an information-focused framework for AI-supported mediation designed for community-based collaboration. Within this framework, we hypothesize that AI must acquire and reason over three key types of information: content, culture, and people.

**AI Summary:** This research proposes a framework for AI-supported mediation in online communities to address conflicts and disputes that arise during collaboration. The study argues that moderation systems that focus on removing or suppressing content do not address underlying disagreements, while mediation can foster understanding and consensus among group members. The framework suggests that AI should acquire and reason over information related to content, culture, and people to effectively support mediation in online collaboration.

---

## Beyond the Silence: How Men Navigate Infertility Through Digital Communities and Data Sharing
**URL:** https://arxiv.org/abs/2509.10003

**Abstract:** Men experiencing infertility face unique challenges navigating Traditional Masculinity Ideologies that discourage emotional expression and help-seeking. This study examines how Reddit's r/maleinfertility community helps overcome these barriers through digital support networks. Using topic modeling (115 topics), network analysis (11 micro-communities), and time-lagged regression on 11,095 posts and 79,503 comments from 8,644 users, we found the community functions as a hybrid space: informal diagnostic hub, therapeutic commons, and governed institution. Medical advice dominates discourse (63.3\%), while emotional support (7.4\%) and moderation (29.2\%) create essential infrastructure. Sustained engagement correlates with actionable guidance and affiliation language, not emotional processing. Network analysis revealed structurally cohesive but topically diverse clusters without echo chamber characteristics. Cross-posters (20\% of users) who bridge r/maleinfertility and the gender-mixed r/infertility community serve as navigators and mentors, transferring knowledge between spaces. These findings inform trauma-informed design for stigmatized health communities, highlighting role-aware systems and navigation support.

**AI Summary:** This study explores how the Reddit community r/maleinfertility provides a supportive space for men facing infertility, overcoming traditional masculinity ideologies that discourage emotional expression. The community functions as a hybrid space, offering medical advice, emotional support, and moderation. The findings suggest that sustained engagement is linked to actionable guidance and affiliation language, rather than emotional processing, and cross-posters play a crucial role in transferring knowledge between different online communities. This research has implications for designing trauma-informed support systems for stigmatized health communities.

---

## Immersive Invaders: Privacy Threats from Deceptive Design in Virtual Reality Games and Applications
**URL:** https://arxiv.org/abs/2509.09916

**Abstract:** Virtual Reality (VR) technologies offer immersive experiences but collect substantial user data. While deceptive design is well-studied in 2D platforms, little is known about its manifestation in VR environments and its impact on user privacy. This research investigates deceptive designs in privacy communication and interaction mechanisms of 12 top-rated VR games and applications through autoethnographic evaluation of the applications and thematic analysis of privacy policies. We found that while many deceptive designs rely on 2D interfaces, some VR-unique features, while not directly enabling deception, amplified data disclosure behaviors, and obscured actual data practices. Convoluted privacy policies and manipulative consent practices further hinder comprehension and increase privacy risks. We also observed privacy-preserving design strategies and protective considerations in VR privacy policies. We offer recommendations for ethical VR design that balance immersive experiences with strong privacy protections, guiding researchers, designers, and policymakers to improve privacy in VR environments.

**AI Summary:** This research explores the presence of deceptive design in privacy communication and interaction mechanisms in VR games and applications. The study found that while some deceptive designs in VR rely on 2D interfaces, unique VR features can amplify data disclosure behaviors and obscure actual data practices. The research highlights the importance of ethical VR design to balance immersive experiences with strong privacy protections, offering recommendations for researchers, designers, and policymakers to improve privacy in VR environments.

---

## Seeing Identity in Data: Can Anthropographics Uncover Racial Homophily in Emotional Responses?
**URL:** https://arxiv.org/abs/2509.09910

**Abstract:** Racial homophily refers to the tendency of individuals to associate with others of the same racial or ethnic background. A recent study found no evidence of racial homophily in responses to mass shooting data visualizations. To increase the likelihood of detecting an effect, we redesigned the experiment by replacing bar charts with anthropographics and expanding the sample size. In a crowdsourced study (N=720), we showed participants a pictograph of mass shooting victims in the United States, with victims from one of three racial groups (Hispanic, Black, or White) highlighted. Each participant was assigned a visualization highlighting either their own racial group or a different racial group, allowing us to assess the influence of racial concordance on changes in affect (emotion). We found that, across all conditions, racial concordance had a modest but significant effect on changes in affect, with participants experiencing greater negative affect change when viewing visualizations highlighting their own race. This study provides initial evidence that racial homophily can emerge in responses to data visualizations, particularly when using anthropographics.

**AI Summary:** This study explored the impact of racial homophily on emotional responses to data visualizations of mass shooting victims using anthropographics. The results showed a modest but significant effect of racial concordance on changes in affect, with participants experiencing greater negative affect when viewing visualizations highlighting their own race. This suggests that racial homophily can influence emotional responses to data visualizations, highlighting the importance of considering race in data representation.

---

## Climate Data for Power Systems Applications: Lessons in Reusing Wildfire Smoke Data for Solar PV Studies
**URL:** https://arxiv.org/abs/2509.09888

**Abstract:** Data reuse is using data for a purpose distinct from its original intent. As data sharing becomes more prevalent in science, enabling effective data reuse is increasingly important. In this paper, we present a power systems case study of data repurposing for enabling data reuse. We define data repurposing as the process of transforming data to fit a new research purpose. In our case study, we repurpose a geospatial wildfire smoke forecast dataset into a historical dataset. We analyze its efficacy toward analyzing wildfire smoke impact on solar photovoltaic energy production. We also provide documentation and interactive demos for using the repurposed dataset. We identify key enablers of data reuse including metadata standardization, contextual documentation, and communication between data creators and reusers. We also identify obstacles to data reuse such as risk of misinterpretation and barriers to efficient data access. Through an iterative approach to data repurposing, we demonstrate how leveraging and expanding knowledge transfer infrastructures like online documentation, interactive visualizations, and data streaming directly address these obstacles. The findings facilitate big data use from other domains for power systems applications and grid resiliency.

**AI Summary:** This research paper explores the concept of data reuse in the context of power systems applications, specifically focusing on repurposing wildfire smoke data for solar PV studies. The study highlights the importance of data repurposing in enabling effective data reuse, and identifies key enablers and obstacles in the process. Through their case study, the researchers demonstrate how leveraging knowledge transfer infrastructures can facilitate the use of big data from other domains for power systems applications and grid resiliency.

---

## Vibe Check: Understanding the Effects of LLM-Based Conversational Agents' Personality and Alignment on User Perceptions in Goal-Oriented Tasks
**URL:** https://arxiv.org/abs/2509.09870

**Abstract:** Large language models (LLMs) enable conversational agents (CAs) to express distinctive personalities, raising new questions about how such designs shape user perceptions. This study investigates how personality expression levels and user-agent personality alignment influence perceptions in goal-oriented tasks. In a between-subjects experiment (N=150), participants completed travel planning with CAs exhibiting low, medium, or high expression across the Big Five traits, controlled via our novel Trait Modulation Keys framework. Results revealed an inverted-U relationship: medium expression produced the most positive evaluations across Intelligence, Enjoyment, Anthropomorphism, Intention to Adopt, Trust, and Likeability, significantly outperforming both extremes. Personality alignment further enhanced outcomes, with Extraversion and Emotional Stability emerging as the most influential traits. Cluster analysis identified three distinct compatibility profiles, with "Well-Aligned" users reporting substantially positive perceptions. These findings demonstrate that personality expression and strategic trait alignment constitute optimal design targets for CA personality, offering design implications as LLM-based CAs become increasingly prevalent.

**AI Summary:** This study examines how the personality expression levels and alignment of conversational agents (CAs) based on large language models (LLMs) impact user perceptions during goal-oriented tasks. Results show that CAs with medium personality expression levels across the Big Five traits received the most positive evaluations, outperforming both low and high expression levels. Additionally, personality alignment between users and CAs, particularly in traits like Extraversion and Emotional Stability, significantly enhanced user perceptions, highlighting the importance of strategic trait alignment in designing LLM-based CAs.

---

## Designing and Evaluating AI Margin Notes in Document Reader Software
**URL:** https://arxiv.org/abs/2509.09840

**Abstract:** AI capabilities for document reader software are usually presented in separate chat interfaces. We explore integrating AI into document comments, a concept we formalize as AI margin notes. Three design parameters characterize this approach: margin notes are integrated with the text while chat interfaces are not; selecting text for a margin note can be automated through AI or manual; and the generation of a margin note can involve AI to various degrees. Two experiments investigate integration and selection automation, with results showing participants prefer integrated AI margin notes and manual selection. A third experiment explores human and AI involvement through six alternative techniques. Techniques with less AI involvement resulted in more psychological ownership, but faster and less effortful designs are generally preferred. Surprisingly, the degree of AI involvement had no measurable effect on reading comprehension. Our work shows that AI margin notes are desirable and contributes implications for their design.

**AI Summary:** This research explores the concept of AI margin notes in document reader software as an alternative to traditional chat interfaces. The study found that participants preferred integrated AI margin notes with manual text selection, and that the degree of AI involvement did not significantly impact reading comprehension. The findings suggest that AI margin notes are a desirable feature in document reader software and provide insights for their design and implementation.

---

## Merging Bodies, Dividing Conflict: Body-Swapping in Mixed Reality Increases Closeness Yet Weakens the Joint Simon Effect
**URL:** https://arxiv.org/abs/2509.09815

**Abstract:** Mixed Reality (MR) presents novel opportunities to investigate how individuals perceive themselves and others during shared, augmented experiences within a common physical environment. Previous research has demonstrated that users can embody avatars in MR, temporarily extending their sense of self. However, there has been limited exploration of body-swapping, a condition in which two individuals simultaneously inhabit each other's avatars, and its potential effects on social interaction in immersive environments. To address this gap, we adapted the Joint Simon Task (JST), a well-established implicit paradigm, to examine how body-swapping influences the cognitive and perceptual boundaries between self and other. Our results indicate that body-swapping led participants to experience themselves and their partner as functioning like a single, unified system, as in two bodies operating as one agent. This suggests possible cognitive and perceptual changes that go beyond simple collaboration. Our findings have significant implications for the design of MR systems intended to support collaboration, empathy, social learning, and therapeutic interventions through shared embodiment.

**AI Summary:** This research explores the effects of body-swapping in mixed reality on social interaction and cognitive boundaries between self and others. The study found that body-swapping led participants to perceive themselves and their partner as a unified system, impacting collaboration and perception. These findings have important implications for the design of mixed reality systems aimed at enhancing collaboration, empathy, social learning, and therapeutic interventions through shared embodiment.

---

## RFSeek and Ye Shall Find
**URL:** https://arxiv.org/abs/2509.10216

**Abstract:** Requests for Comments (RFCs) are extensive specification documents for network protocols, but their prose-based format and their considerable length often impede precise operational understanding. We present RFSeek, an interactive tool that automatically extracts visual summaries of protocol logic from RFCs. RFSeek leverages large language models (LLMs) to generate provenance-linked, explorable diagrams, surfacing both official state machines and additional logic found only in the RFC text. Compared to existing RFC visualizations, RFSeek's visual summaries are more transparent and easier to audit against their textual source. We showcase the tool's potential through a series of use cases, including guided knowledge extraction and semantic diffing, applied to protocols such as TCP, QUIC, PPTP, and DCCP.
In practice, RFSeek not only reconstructs the RFC diagrams included in some specifications, but, more interestingly, also uncovers important logic such as nodes or edges described in the text but missing from those diagrams. RFSeek further derives new visualization diagrams for complex RFCs, with QUIC as a representative case. Our approach, which we term \emph{Summary Visualization}, highlights a promising direction: combining LLMs with formal, user-customized visualizations to enhance protocol comprehension and support robust implementations.

**AI Summary:** The research introduces RFSeek, an interactive tool that automatically extracts visual summaries of network protocol logic from RFCs using large language models. RFSeek not only reconstructs existing RFC diagrams but also uncovers additional important logic described in the text. This approach, termed "Summary Visualization," shows promise in enhancing protocol comprehension and supporting robust implementations by combining LLMs with user-customized visualizations.

---

## Multi-Intent Recognition in Dialogue Understanding: A Comparison Between Smaller Open-Source LLMs
**URL:** https://arxiv.org/abs/2509.10010

**Abstract:** In this paper, we provide an extensive analysis of multi-label intent classification using Large Language Models (LLMs) that are open-source, publicly available, and can be run in consumer hardware. We use the MultiWOZ 2.1 dataset, a benchmark in the dialogue system domain, to investigate the efficacy of three popular open-source pre-trained LLMs, namely LLama2-7B-hf, Mistral-7B-v0.1, and Yi-6B. We perform the classification task in a few-shot setup, giving 20 examples in the prompt with some instructions. Our approach focuses on the differences in performance of these models across several performance metrics by methodically assessing these models on multi-label intent classification tasks. Additionally, we compare the performance of the instruction-based fine-tuning approach with supervised learning using the smaller transformer model BertForSequenceClassification as a baseline. To evaluate the performance of the models, we use evaluation metrics like accuracy, precision, and recall as well as micro, macro, and weighted F1 score. We also report the inference time, VRAM requirements, etc. The Mistral-7B-v0.1 outperforms two other generative models on 11 intent classes out of 14 in terms of F-Score, with a weighted average of 0.50. It also has relatively lower Humming Loss and higher Jaccard Similarity, making it the winning model in the few-shot setting. We find BERT based supervised classifier having superior performance compared to the best performing few-shot generative LLM. The study provides a framework for small open-source LLMs in detecting complex multi-intent dialogues, enhancing the Natural Language Understanding aspect of task-oriented chatbots.

**AI Summary:** This research paper compares the performance of three open-source Large Language Models (LLMs) in multi-label intent classification tasks using the MultiWOZ 2.1 dataset. The study finds that the Mistral-7B-v0.1 model outperforms the other models in terms of F-Score, Humming Loss, and Jaccard Similarity in a few-shot setup. Additionally, the study highlights the effectiveness of using smaller transformer models like BertForSequenceClassification for supervised learning in dialogue understanding tasks, providing insights for improving task-oriented chatbots' Natural Language Understanding capabilities.

---

## Using the Pepper Robot to Support Sign Language Communication
**URL:** https://arxiv.org/abs/2509.09889

**Abstract:** Social robots are increasingly experimented in public and assistive settings, but their accessibility for Deaf users remains quite underexplored. Italian Sign Language (LIS) is a fully-fledged natural language that relies on complex manual and non-manual components. Enabling robots to communicate using LIS could foster more inclusive human robot interaction, especially in social environments such as hospitals, airports, or educational settings. This study investigates whether a commercial social robot, Pepper, can produce intelligible LIS signs and short signed LIS sentences. With the help of a Deaf student and his interpreter, an expert in LIS, we co-designed and implemented 52 LIS signs on Pepper using either manual animation techniques or a MATLAB based inverse kinematics solver. We conducted a exploratory user study involving 12 participants proficient in LIS, both Deaf and hearing. Participants completed a questionnaire featuring 15 single-choice video-based sign recognition tasks and 2 open-ended questions on short signed sentences. Results shows that the majority of isolated signs were recognized correctly, although full sentence recognition was significantly lower due to Pepper's limited articulation and temporal constraints. Our findings demonstrate that even commercially available social robots like Pepper can perform a subset of LIS signs intelligibly, offering some opportunities for a more inclusive interaction design. Future developments should address multi-modal enhancements (e.g., screen-based support or expressive avatars) and involve Deaf users in participatory design to refine robot expressivity and usability.

**AI Summary:** This study explores the use of the Pepper robot to communicate in Italian Sign Language (LIS) in order to enhance human-robot interaction in social settings. Through a co-design process with a Deaf student and an expert in LIS, 52 LIS signs were implemented on Pepper, with the majority of isolated signs being recognized correctly by participants. However, full sentence recognition was lower due to Pepper's limitations, suggesting the need for multi-modal enhancements and involving Deaf users in the design process for improved usability and expressivity.

---

## SoilSound: Smartphone-based Soil Moisture Estimation
**URL:** https://arxiv.org/abs/2509.09823

**Abstract:** Soil moisture monitoring is essential for agriculture and environmental management, yet existing methods require either invasive probes disturbing the soil or specialized equipment, limiting access to the public. We present SoilSound, an ubiquitous accessible smartphone-based acoustic sensing system that can measure soil moisture without disturbing the soil. We leverage the built-in speaker and microphone to perform a vertical scan mechanism to accurately measure moisture without any calibration. Unlike existing work that use transmissive properties, we propose an alternate model for acoustic reflections in soil based on the surface roughness effect to enable moisture sensing without disturbing the soil. The system works by sending acoustic chirps towards the soil and recording the reflections during a vertical scan, which are then processed and fed to a convolutional neural network for on-device soil moisture estimation with negligible computational, memory, or power overhead. We evaluated the system by training with curated soils in boxes in the lab and testing in the outdoor fields and show that SoilSound achieves a mean absolute error (MAE) of 2.39% across 10 different locations. Overall, the evaluation shows that SoilSound can accurately track soil moisture levels ranging from 15.9% to 34.0% across multiple soil types, environments, and users; without requiring any calibration or disturbing the soil, enabling widespread moisture monitoring for home gardeners, urban farmers, citizen scientists, and agricultural communities in resource-limited settings.

**AI Summary:** The research introduces SoilSound, a smartphone-based acoustic sensing system that can accurately measure soil moisture without disturbing the soil. By leveraging the built-in speaker and microphone, the system uses a vertical scan mechanism and surface roughness effect to estimate soil moisture levels. The system achieved a mean absolute error of 2.39% across different locations and soil types, demonstrating its potential for widespread use in agriculture and environmental management without the need for specialized equipment or invasive probes.

---

## Distinguishing Startle from Surprise Events Based on Physiological Signals
**URL:** https://arxiv.org/abs/2509.09799

**Abstract:** Unexpected events can impair attention and delay decision-making, posing serious safety risks in high-risk environments such as aviation. In particular, reactions like startle and surprise can impact pilot performance in different ways, yet are often hard to distinguish in practice. Existing research has largely studied these reactions separately, with limited focus on their combined effects or how to differentiate them using physiological data. In this work, we address this gap by distinguishing between startle and surprise events based on physiological signals using machine learning and multi-modal fusion strategies. Our results demonstrate that these events can be reliably predicted, achieving a highest mean accuracy of 85.7% with SVM and Late Fusion. To further validate the robustness of our model, we extended the evaluation to include a baseline condition, successfully differentiating between Startle, Surprise, and Baseline states with a highest mean accuracy of 74.9% with XGBoost and Late Fusion.

**AI Summary:** This research focuses on distinguishing between startle and surprise events based on physiological signals to improve safety in high-risk environments like aviation. By using machine learning and multi-modal fusion strategies, the study shows that these events can be accurately predicted, with a highest mean accuracy of 85.7% for distinguishing between startle and surprise events. The results demonstrate the potential for using physiological data to differentiate between these reactions and improve decision-making in critical situations.

---

## Creativity Benchmark: A benchmark for marketing creativity for LLM models
**URL:** https://arxiv.org/abs/2509.09702

**Abstract:** We introduce Creativity Benchmark, an evaluation framework for large language models (LLMs) in marketing creativity. The benchmark covers 100 brands (12 categories) and three prompt types (Insights, Ideas, Wild Ideas). Human pairwise preferences from 678 practising creatives over 11,012 anonymised comparisons, analysed with Bradley-Terry models, show tightly clustered performance with no model dominating across brands or prompt types: the top-bottom spread is $\Delta\theta \approx 0.45$, which implies a head-to-head win probability of $0.61$; the highest-rated model beats the lowest only about $61\%$ of the time. We also analyse model diversity using cosine distances to capture intra- and inter-model variation and sensitivity to prompt reframing. Comparing three LLM-as-judge setups with human rankings reveals weak, inconsistent correlations and judge-specific biases, underscoring that automated judges cannot substitute for human evaluation. Conventional creativity tests also transfer only partially to brand-constrained tasks. Overall, the results highlight the need for expert human evaluation and diversity-aware workflows.

**AI Summary:** The study introduces a benchmark for evaluating the marketing creativity of large language models (LLMs) using 100 brands and three types of prompts. The results show that no single model consistently outperforms others across brands or prompt types, with a head-to-head win probability of 61%. The research emphasizes the importance of expert human evaluation and diversity-aware workflows in assessing creativity, as automated judges and conventional creativity tests only partially transfer to brand-constrained tasks.

---

## Explaining the Reputational Risks of AI-Mediated Communication: Messages Labeled as AI-Assisted Are Viewed as Less Diagnostic of the Sender's Moral Character
**URL:** https://arxiv.org/abs/2509.09645

**Abstract:** When someone sends us a thoughtful message, we naturally form judgments about their character. But what happens when that message carries a label indicating it was written with the help of AI? This paper investigates how the appearance of AI assistance affects our perceptions of message senders. Adding nuance to previous research, through two studies (N=399) featuring vignette scenarios, we find that AI-assistance labels don't necessarily make people view senders negatively. Rather, they dampen the strength of character signals in communication. We show that when someone sends a warmth-signalling message (like thanking or apologizing) without AI help, people more strongly categorize the sender as warm. At the same time, when someone sends a coldness-signalling message (like bragging or blaming) without assistance, people more confidently categorize them as cold. Interestingly, AI labels weaken both these associations: An AI-assisted apology makes the sender appear less warm than if they had written it themselves, and an AI-assisted blame makes the sender appear less cold than if they had composed it independently. This supports our signal diagnosticity explanation: messages labeled as AI-assisted are viewed as less diagnostic than messages which seem unassisted. We discuss how our findings shed light on the causal origins of previously reported observations in AI-Mediated Communication.

**AI Summary:** This research explores how the perception of message senders is influenced when their messages are labeled as AI-assisted. The findings suggest that AI labels dampen the strength of character signals in communication, with AI-assisted messages being viewed as less diagnostic of the sender's moral character. This has implications for understanding reputational risks in AI-mediated communication and sheds light on the causal origins of previous observations in this field.

---

## Cognitive Affordances in Visualization: Related Constructs, Design Factors, and Framework
**URL:** https://arxiv.org/abs/2509.09510

**Abstract:** Classically, affordance research investigates how the shape of objects communicates actions to potential users. Cognitive affordances, a subset of this research, characterize how the design of objects influences cognitive actions, such as information processing. Within visualization, cognitive affordances inform how graphs' design decisions communicate information to their readers. Although several related concepts exist in visualization, a formal translation of affordance theory to visualization is still lacking. In this paper, we review and translate affordance theory to visualization by formalizing how cognitive affordances operate within a visualization context. We also review common methods and terms, and compare related constructs to cognitive affordances in visualization. Based on a synthesis of research from psychology, human computer interaction, and visualization, we propose a framework of cognitive affordances in visualization that enumerates design decisions and reader characteristics that influence a visualization's hierarchy of communicated information. Finally, we demonstrate how this framework can guide the evaluation and redesign of visualizations.

**AI Summary:** This research paper explores the concept of cognitive affordances in visualization, focusing on how design decisions in graphs influence information processing by readers. The study reviews related constructs in visualization and proposes a framework that formalizes how cognitive affordances operate within this context. By synthesizing research from psychology, human-computer interaction, and visualization, the framework aims to guide the evaluation and redesign of visualizations to enhance their effectiveness in communicating information to users.

---

## Changing the Paradigm from Dynamic Queries to LLM-generated SQL Queries with Human Intervention
**URL:** https://arxiv.org/abs/2509.09461

**Abstract:** We propose leveraging Large Language Models (LLMs) as an interaction layer for medical visualization systems. In domains like healthcare, where users must navigate high-dimensional, coded, and heterogeneous datasets, LLM-generated queries enable expert medical users to express complex analytical intents in natural language. These intents are then translated into editable and executable queries, replacing the dynamic query interfaces used by traditional visualization systems built around sliders, check boxes, and drop-downs. This interaction model reduces visual clutter and eliminates the need for users to memorize field names or system codes, supporting fluid exploration, with the drawback of not exposing all the filtering criteria. We also reintroduce dynamic queries on demand to better support interactive exploration. We posit that medical users are trained to know the possible filtering options but challenged to remember the details of the attribute names and code values. We demonstrate this paradigm in ParcoursVis, our scalable EventFlow-inspired patient care pathway visualization system powered by the French National Health Data System, one of the largest health data repositories in the world.

**AI Summary:** This research proposes using Large Language Models (LLMs) to generate SQL queries for medical visualization systems, allowing expert users to express complex analytical intents in natural language. This approach eliminates the need for traditional dynamic query interfaces and supports fluid exploration of high-dimensional healthcare datasets. The study demonstrates the effectiveness of this paradigm in ParcoursVis, a patient care pathway visualization system, showcasing the potential of LLM-generated queries with human intervention in navigating large and heterogeneous healthcare datasets.

---

## Real-Time Kinematic Positioning and Optical See-Through Head-Mounted Display for Outdoor Tracking: Hybrid System and Preliminary Assessment
**URL:** https://arxiv.org/abs/2509.09412

**Abstract:** This paper presents an outdoor tracking system using Real-Time Kinematic (RTK) positioning and Optical See-Through Head Mounted Display(s) (OST-HMD(s)) in urban areas where the accurate tracking of objects is critical and where displaying occluded information is important for safety reasons. The approach presented here replaces 2D screens/tablets and offers distinct advantages, particularly in scenarios demanding hands-free operation. The integration of RTK, which provides centimeter-level accuracy of tracked objects, with OST-HMD represents a promising solution for outdoor applications. This paper provides valuable insights into leveraging the combined potential of RTK and OST-HMD for outdoor tracking tasks from the perspectives of systems integration, performance optimization, and usability. The main contributions of this paper are: \textbf{1)} a system for seamlessly merging RTK systems with OST-HMD to enable relatively precise and intuitive outdoor tracking, \textbf{2)} an approach to determine a global location to achieve the position relative to the world, \textbf{3)} an approach referred to as 'semi-dynamic' for system assessment. Moreover, we offer insights into several relevant future research topics aimed at improving the OST-HMD and RTK hybrid system for outdoor tracking.

**AI Summary:** This research paper introduces a hybrid outdoor tracking system that combines Real-Time Kinematic (RTK) positioning with Optical See-Through Head-Mounted Displays (OST-HMDs) for accurate object tracking in urban areas. The integration of RTK and OST-HMDs offers centimeter-level accuracy and hands-free operation, making it a promising solution for outdoor applications. The paper provides insights into the system integration, performance optimization, and usability of the hybrid system, as well as suggests future research directions for improving outdoor tracking with RTK and OST-HMDs.

---

## Smart Device Development for Gait Monitoring: Multimodal Feedback in an Interactive Foot Orthosis, Walking Aid, and Mobile Application
**URL:** https://arxiv.org/abs/2509.09359

**Abstract:** Smart assistive technologies such as sensor-based footwear and walking aids offer promising opportunities to support rehabilitation through real-time feedback and patient-centered monitoring. However, most orthotic devices remain passive and lack integrated sensing or feedback functionalities, while existing research often focuses on isolated prototypes rather than cohesive, interactive systems. In this work, we present the design and implementation of a novel modular sensor system that combines a smart foot orthosis with an instrumented forearm crutch. The system integrates plantar pressure and motion sensing, vibrotactile feedback, and wireless communication via a smartphone application. We conducted an experimental user study with eight participants to validate the feasibility of the smart foot orthosis for mobile gait detection, explore the potential of haptic feedback for user interaction, and assess the usability of the accompanying mobile health application. Our work contributes to the field of smart assistive technology in rehabilitation and prevention by demonstrating a functional and comprehensive system. We further discuss system limitations, outline potential application scenarios, and provide recommendations for future development and clinical integration.

**AI Summary:** This research focuses on the development of a smart foot orthosis and forearm crutch system that integrates plantar pressure and motion sensing, vibrotactile feedback, and wireless communication through a smartphone application. The study conducted with eight participants validated the feasibility of the system for mobile gait detection and explored the potential of haptic feedback for user interaction. The findings suggest that this comprehensive system has the potential to support rehabilitation and prevention efforts in the field of smart assistive technology.

---

## Proactive AI Adoption can be Threatening: When Help Backfires
**URL:** https://arxiv.org/abs/2509.09309

**Abstract:** Artificial intelligence (AI) assistants are increasingly embedded in workplace tools, raising the question of how initiative-taking shapes adoption. Prior work highlights trust and expectation mismatches as barriers, but the underlying psychological mechanisms remain unclear. Drawing on self-affirmation and social exchange theories, we theorize that unsolicited help elicits self-threat, reducing willingness to accept assistance, likelihood of future use, and performance expectancy. We report two vignette-based experiments (Study~1: $N=761$; Study~2: $N=571$, preregistered). Study~1 compared anticipatory and reactive help provided by an AI vs. a human, while Study~2 distinguished between \emph{offering} (suggesting help) and \emph{providing} (acting automatically). In Study 1, AI help was more threatening than human help. Across both studies, anticipatory help increased perceived threat and reduced adoption outcomes. Our findings identify self-threat as a mechanism explaining why proactive AI features may backfire and suggest design implications for AI initiative.

**AI Summary:** This research explores the impact of proactive AI assistance in the workplace, finding that unsolicited help from AI can lead to feelings of self-threat, reducing willingness to accept assistance and future use of the technology. The study compared AI and human assistance, finding that AI help was more threatening. These findings have implications for the design of AI systems and suggest that proactive features may backfire if not carefully implemented.

---

## The Impact of Device Type, Data Practices, and Use Case Scenarios on Privacy Concerns about Eye-tracked Augmented Reality in the United States and Germany
**URL:** https://arxiv.org/abs/2509.09285

**Abstract:** Augmented reality technology will likely be prevalent with more affordable head-mounted displays. Integrating novel interaction modalities such as eye trackers into head-mounted displays could lead to collecting vast amounts of biometric data, which may allow inference of sensitive user attributes like health status or sexual preference, posing privacy issues. While previous works broadly examined privacy concerns about augmented reality, ours is the first to extensively explore privacy concerns on behavioral data, particularly eye tracking in augmented reality. We crowdsourced four survey studies in the United States (n1 = 48, n2 = 525) and Germany (n3 = 48, n4 = 525) to understand the impact of user attributes, augmented reality devices, use cases, data practices, and country on privacy concerns. Our findings indicate that participants are generally concerned about privacy when they know what inferences can be made based on the collected data. Despite the more prominent use of smartphones in daily life than augmented reality glasses, we found no indications of differing privacy concerns depending on the device type. In addition, our participants are more comfortable when a particular use case benefits them and less comfortable when other humans can consume their data. Furthermore, participants in the United States are less concerned about their privacy than those in Germany. Based on our findings, we provide several recommendations to practitioners and policymakers for privacy-aware augmented reality.

**AI Summary:** This research explores privacy concerns surrounding eye-tracked augmented reality technology in the United States and Germany. The study found that participants are most concerned about privacy when they understand the potential inferences that can be made from collected data. Interestingly, there was no significant difference in privacy concerns between smartphone and augmented reality device users, and participants were more comfortable with data collection when it directly benefited them. The findings suggest the need for privacy-aware practices in the development and implementation of augmented reality technology.

---

## Flip Co-op: Cooperative Takeovers in Shared Autonomy
**URL:** https://arxiv.org/abs/2509.09281

**Abstract:** Shared autonomy requires principled mechanisms for allocating and transferring control between a human and an autonomous agent. Existing approaches often rely on blending control inputs between human and autonomous agent or switching rules, which lack theoretical guarantees. This paper develops a game-theoretic framework for modeling cooperative takeover in shared autonomy. We formulate the switching interaction as a dynamic game in which authority is embedded directly into the system dynamics, resulting in Nash equilibrium(NE)-based strategies rather than ad hoc switching rules. We establish the existence and characterization of NE in the space of pure takeover strategies under stochastic human intent. For the class of linear-quadratic systems, we derive closed-form recursions for takeover strategies and saddle-point value functions, providing analytical insight and efficient computation of cooperative takeover policies. We further introduce a bimatrix potential game reformulation to address scenarios where human and autonomy utilities are not perfectly aligned, yielding a unifying potential function that preserves tractability while capturing intent deviations. The framework is applied to a vehicle trajectory tracking problem, demonstrating how equilibrium takeover strategies adapt across straight and curved path segments. The results highlight the trade-off between human adaptability and autonomous efficiency and illustrate the practical benefits of grounding shared autonomy in cooperative game theory.

**AI Summary:** This research paper introduces a game-theoretic framework for modeling cooperative takeovers in shared autonomy, addressing the need for principled mechanisms for control allocation between humans and autonomous agents. The framework establishes Nash equilibrium-based strategies for takeover in dynamic games, providing analytical insight and efficient computation for cooperative takeover policies. The study demonstrates the adaptability of equilibrium takeover strategies in a vehicle trajectory tracking problem, highlighting the trade-off between human adaptability and autonomous efficiency in shared autonomy systems.

---

## Sensible Agent: A Framework for Unobtrusive Interaction with Proactive AR Agents
**URL:** https://arxiv.org/abs/2509.09255

**Abstract:** Proactive AR agents promise context-aware assistance, but their interactions often rely on explicit voice prompts or responses, which can be disruptive or socially awkward. We introduce Sensible Agent, a framework designed for unobtrusive interaction with these proactive agents. Sensible Agent dynamically adapts both "what" assistance to offer and, crucially, "how" to deliver it, based on real-time multimodal context sensing. Informed by an expert workshop (n=12) and a data annotation study (n=40), the framework leverages egocentric cameras, multimodal sensing, and Large Multimodal Models (LMMs) to infer context and suggest appropriate actions delivered via minimally intrusive interaction modes. We demonstrate our prototype on an XR headset through a user study (n=10) in both AR and VR scenarios. Results indicate that Sensible Agent significantly reduces perceived interaction effort compared to voice-prompted baseline, while maintaining high usability and achieving higher preference.

**AI Summary:** The study introduces the Sensible Agent framework, which aims to enable unobtrusive interaction with proactive AR agents by dynamically adapting assistance based on real-time context sensing. Through the use of egocentric cameras, multimodal sensing, and Large Multimodal Models, the framework suggests appropriate actions in a minimally intrusive manner. User studies show that the Sensible Agent significantly reduces perceived interaction effort compared to traditional voice prompts, while maintaining high usability and user preference.

---

## User Exploration and Exploitation Behavior Under the Influence of Real-time Interactions in Live Streaming Environments
**URL:** https://arxiv.org/abs/2509.09138

**Abstract:** Live streaming platforms offer a distinctive way for users and content creators to interact with each other through real-time communication. While research on user behavior in online platforms has explored how users discover their favorite content from creators and engage with them, the role of real-time features remains unclear. There are open questions as to what commonalities and differences exist in users' relationships with live streaming platforms compared to traditional on-demand style platforms. To understand this, we employ the concept of Exploration/Exploitation (E/E) and analyze a large-scale dataset from a live streaming platform over two years. Our results indicate that even on live streaming platforms, users exhibit E/E behavior but experience a longer exploration period. We also identify external factors, such as circadian rhythms, that influence E/E dynamics and user loyalty. The presented study emphasizes the importance of balancing E/E in online platform design, especially for live streaming platforms, providing implications that suggest design strategies for platform developers and content creators to facilitate timely engagement and retention.

**AI Summary:** This research explores user behavior in live streaming platforms, focusing on the concept of Exploration/Exploitation (E/E). The study finds that users exhibit E/E behavior on live streaming platforms, but with a longer exploration period compared to traditional on-demand platforms. External factors, such as circadian rhythms, also influence user loyalty and engagement on these platforms. The findings suggest the importance of balancing E/E in platform design to enhance user engagement and retention in live streaming environments.

---

## Content Moderation Futures
**URL:** https://arxiv.org/abs/2509.09076

**Abstract:** This study examines the failures and possibilities of contemporary social media governance through the lived experiences of various content moderation professionals. Drawing on participatory design workshops with 33 practitioners in both the technology industry and broader civil society, this research identifies significant structural misalignments between corporate incentives and public interests. While experts agree that successful content moderation is principled, consistent, contextual, proactive, transparent, and accountable, current technology companies fail to achieve these goals, due in part to exploitative labor practices, chronic underinvestment in user safety, and pressures of global scale. I argue that successful governance is undermined by the pursuit of technological novelty and rapid growth, resulting in platforms that necessarily prioritize innovation and expansion over public trust and safety. To counter this dynamic, I revisit the computational history of care work, to motivate present-day solidarity amongst platform governance workers and inspire systemic change.

**AI Summary:** This research explores the challenges and opportunities in content moderation on social media platforms by analyzing the experiences of content moderation professionals. The study highlights the disconnect between corporate interests and public needs, pointing out issues such as exploitative labor practices and lack of investment in user safety. The research emphasizes the importance of principled, consistent, contextual, proactive, transparent, and accountable content moderation practices to build public trust and safety on social media platforms.

---

## Digital Iran Reloaded: Gamer Mitigation Tactics of IRI Information Controls
**URL:** https://arxiv.org/abs/2509.09063

**Abstract:** Internet censorship in the Islamic Republic of Iran restricts access to global platforms and services, forcing users to rely on circumvention technologies such as VPNs, proxies, and tunneling tools. This report presents findings from a mixed-methods study of 660 Iranian internet users, with a focus on gamers as a digitally literate and socially networked community. Survey data are combined with network measurements of latency and VPN performance to identify both technical and social strategies of circumvention. Results show that while younger users report higher confidence with circumvention, peer networks, rather than formal training, are the strongest predictors of resilience. Gaming communities, particularly those active on platforms such as Discord and Telegram, serve as hubs for sharing tactics and lowering barriers to adoption. These findings extend existing work on usable security and censorship circumvention by highlighting the intersection of infrastructural conditions and social learning. The study concludes with design and policy implications for developers, researchers, and funders working on digital rights and information controls.

**AI Summary:** This research study examines how internet censorship in Iran has led to the use of circumvention technologies by users, particularly gamers, to access global platforms. The study found that younger users are more confident in using circumvention tools, and peer networks play a significant role in fostering resilience against censorship. Gaming communities serve as important hubs for sharing tactics and lowering barriers to adoption of circumvention technologies, highlighting the importance of social learning in overcoming information controls. The findings have implications for developers, researchers, and policymakers working on digital rights and information controls.

---

## Extended Version: It Should Be Easy but... New Users Experiences and Challenges with Secret Management Tools
**URL:** https://arxiv.org/abs/2509.09036

**Abstract:** Software developers face risks of leaking their software secrets, such as API keys or passwords, which can result in significant harm. Secret management tools (SMTs), such as HashiCorp Vault Secrets or Infisical, are highly recommended by industry, academia, and security guidelines to manage secrets securely. SMTs are designed to help developers secure their secrets in a central location, yet secrets leaks are still commonplace, and developers report difficulty in learning how to setup and use SMTs. While SMTs typically come with publicly available help resources (e.g., tool documentation and interfaces), it is unclear if these actually help developers learn to effectively use SMTs. Without usable help resources that onboards developers, quick adoption and effective use of SMTs may be unrealistic. In a qualitative two-step study, we observed 21 new users in person while they used SMTs to perform two secret management tasks: secret storage and access, then secret injection. We interviewed participants after each task to identify their challenges and experiences using SMTs, with the assistance of help resources. While our study sample is narrow, it serves as a reasonable proxy for new developers who are likely to adopt SMTs early in their careers. We found that even in a laboratory setting where new users found tool functionality, interface flexibility helpful, they still experienced increased difficulty to effectively use SMTs to securely remediate a hard-coded secret when they felt tool documentation was insufficient and it motivated participants to deviate from official tool documentation to access secondary sources or attempt workaround methods. Specific challenges reported by participants were tool documentation content quality, navigation difficulties with both tool documentation and web interfaces for finding helpful content, and supportive tool features.

**AI Summary:** The research focuses on the challenges faced by new users in effectively using secret management tools (SMTs) to secure software secrets. Despite the availability of help resources, developers still struggle with setting up and using SMTs, leading to potential security risks. The study highlights the importance of user-friendly help resources and the need for improvements in tool documentation and interface design to facilitate quick adoption and effective use of SMTs by developers.

---

## YouthSafe: A Youth-Centric Safety Benchmark and Safeguard Model for Large Language Models
**URL:** https://arxiv.org/abs/2509.08997

**Abstract:** Large Language Models (LLMs) are increasingly used by teenagers and young adults in everyday life, ranging from emotional support and creative expression to educational assistance. However, their unique vulnerabilities and risk profiles remain under-examined in current safety benchmarks and moderation systems, leaving this population disproportionately exposed to harm. In this work, we present Youth AI Risk (YAIR), the first benchmark dataset designed to evaluate and improve the safety of youth LLM interactions. YAIR consists of 12,449 annotated conversation snippets spanning 78 fine grained risk types, grounded in a taxonomy of youth specific harms such as grooming, boundary violation, identity confusion, and emotional overreliance. We systematically evaluate widely adopted moderation models on YAIR and find that existing approaches substantially underperform in detecting youth centered risks, often missing contextually subtle yet developmentally harmful interactions. To address these gaps, we introduce YouthSafe, a real-time risk detection model optimized for youth GenAI contexts. YouthSafe significantly outperforms prior systems across multiple metrics on risk detection and classification, offering a concrete step toward safer and more developmentally appropriate AI interactions for young users.

**AI Summary:** This research introduces Youth AI Risk (YAIR), a benchmark dataset designed to evaluate and improve the safety of youth interactions with Large Language Models (LLMs). The study found that existing moderation models underperform in detecting youth-centered risks, leading to potential harm for young users. The development of YouthSafe, a real-time risk detection model optimized for youth interactions, significantly outperformed prior systems and offers a step towards safer and more developmentally appropriate AI interactions for teenagers and young adults.

---

## Characterizing Multimodal Interaction in Visualization Authoring Tools
**URL:** https://arxiv.org/abs/2509.08953

**Abstract:** Multimodal interaction has been increasingly considered in designing visualization authoring tools. However, multimodal interaction has a broad meaning in visualization authoring, according to our literature review. Although some previous studies compare different authoring tools, a comprehensive overview of the diverse characteristics of multimodal interaction in visualization authoring tools is still missing. This paper seeks to offer a systematic perspective on how multimodal interaction is integrated within visualization authoring tools. Such an overview can enhance understanding of current practices, highlight distinguishing features among tools, and help identify future research directions, guiding designers in developing more accessible and effective authoring systems. We review 20 visualization authoring tools that incorporate multimodal interaction and characterize how multimodal interaction is applied in these tools. Based on the review results, we discuss design implications and future directions.

**AI Summary:** This research paper explores the integration of multimodal interaction in visualization authoring tools, highlighting the diverse characteristics and applications of this technology. By reviewing 20 visualization authoring tools, the study offers insights into current practices and design implications for future research and development. The findings aim to enhance understanding, identify distinguishing features, and guide designers in creating more accessible and effective authoring systems.

---

## A Contextual Bandits Approach for Personalization of Hand Gesture Recognition
**URL:** https://arxiv.org/abs/2509.08915

**Abstract:** In human-computer interaction applications like hand gesture recognition, supervised learning models are often trained on a large population of users to achieve high task accuracy. However, due to individual variability in sensor signals and user behavior, static models may not provide optimal performance for all users. Personalizing pretrained models via calibration--collecting labeled data from each user--can improve performance but introduces user friction and struggles with limited data. To overcome these issues, we propose a calibrationless longitudinal personalization method: a contextual multi-arm bandit (MAB) algorithm combined with a pretrained neural network for gesture recognition. This reinforcement-learning-style approach enables personalization using binary reward signals, either user-provided or inferred by the system.
We validated this method in a user study. Participants wore a surface electromyography (sEMG) device and played multiple rounds of a 2-D navigation game using six hand gestures. In the session, they completed a baseline round and then a round with our algorithm; in the second session, they played another round with our algorithm. Our approach led to a significant reduction in users' average false negative rate by 0.113 from the initial to the final round, with further decreases between sessions. Average precision also trended upward (by 0.139) from the start to end of a round, continuing in the next session. Notably, some users who could not complete the game with the baseline model succeeded with our contextual MAB model. In summary, our

**AI Summary:** The research proposes a calibrationless longitudinal personalization method using a contextual multi-arm bandit algorithm combined with a pretrained neural network for hand gesture recognition. This approach improves performance for individual users without the need for collecting labeled data from each user, leading to a significant reduction in false negative rates and an increase in precision. The study demonstrates the effectiveness of the method in improving user performance in a 2-D navigation game using hand gestures, with some users who struggled with a baseline model succeeding with the proposed approach.

---

## CryptoGuard: An AI-Based Cryptojacking Detection Dashboard Prototype
**URL:** https://arxiv.org/abs/2509.09638

**Abstract:** With the widespread adoption of cryptocurrencies, cryptojacking has become a significant security threat to crypto wallet users. This paper presents a front-end prototype of an AI-powered security dashboard, namely, CryptoGuard. Developed through a user-centered design process, the prototype was constructed as a high-fidelity, click-through model from Figma mockups to simulate key user interactions. It is designed to assist users in monitoring their login and transaction activity, identifying any suspicious behavior, and enabling them to take action directly within the wallet interface. The dashboard is designed for a general audience, prioritizing an intuitive user experience for non-technical individuals. Although its AI functionality is conceptual, the prototype demonstrates features like visual alerts and reporting. This work is positioned explicitly as a design concept, bridging cryptojacking detection research with human-centered interface design. This paper also demonstrates how usability heuristics can directly inform a tool's ability to support rapid and confident decision-making under real-world threats. This paper argues that practical security tools require not only robust backend functionality but also a user-centric design that communicates risk and empowers users to take meaningful action.

**AI Summary:** The paper presents a prototype of an AI-powered security dashboard called CryptoGuard to detect cryptojacking threats for crypto wallet users. The prototype focuses on user-centered design, providing visual alerts and reporting to assist users in monitoring and identifying suspicious activity within their wallets. The research highlights the importance of combining robust backend functionality with a user-centric design to empower users to make informed decisions and take action against security threats.

---

## Personality-Enhanced Social Recommendations in SAMI: Exploring the Role of Personality Detection in Matchmaking
**URL:** https://arxiv.org/abs/2509.09583

**Abstract:** Social connection is a vital part of learning, yet online course environments present barriers to the organic formation of social groups. SAMI offers one solution by facilitating student connections, but its effectiveness is constrained by an incomplete Theory of Mind, limiting its ability to create an effective mental model of a student. One facet of this is its inability to intuit personality, which may influence the relevance of its recommendations. To explore this, we propose a personality detection model utilizing GPTs zero-shot capability to infer Big-Five personality traits from forum introduction posts, often encouraged in online courses. We benchmark its performance against established models, demonstrating its efficacy in this task. Furthermore, we integrate this model into SAMIs entity-based matchmaking system, enabling personality-informed social recommendations. Initial integration suggests personality traits can complement existing matching factors, though additional evaluation is required to determine their full impact on student engagement and match quality.

**AI Summary:** The research explores the role of personality detection in improving social recommendations in online learning environments. By utilizing a personality detection model to infer Big-Five personality traits from forum introduction posts, the study demonstrates the efficacy of this approach in enhancing SAMI's matchmaking system. Initial results suggest that incorporating personality traits into social recommendations can improve student engagement and match quality, highlighting the potential impact of personality-enhanced recommendations in facilitating social connections in online courses.

---

## Incorporating AI Incident Reporting into Telecommunications Law and Policy: Insights from India
**URL:** https://arxiv.org/abs/2509.09508

**Abstract:** The integration of artificial intelligence (AI) into telecommunications infrastructure introduces novel risks, such as algorithmic bias and unpredictable system behavior, that fall outside the scope of traditional cybersecurity and data protection frameworks. This paper introduces a precise definition and a detailed typology of telecommunications AI incidents, establishing them as a distinct category of risk that extends beyond conventional cybersecurity and data protection breaches. It argues for their recognition as a distinct regulatory concern. Using India as a case study for jurisdictions that lack a horizontal AI law, the paper analyzes the country's key digital regulations. The analysis reveals that India's existing legal instruments, including the Telecommunications Act, 2023, the CERT-In Rules, and the Digital Personal Data Protection Act, 2023, focus on cybersecurity and data breaches, creating a significant regulatory gap for AI-specific operational incidents, such as performance degradation and algorithmic bias. The paper also examines structural barriers to disclosure and the limitations of existing AI incident repositories. Based on these findings, the paper proposes targeted policy recommendations centered on integrating AI incident reporting into India's existing telecom governance. Key proposals include mandating reporting for high-risk AI failures, designating an existing government body as a nodal agency to manage incident data, and developing standardized reporting frameworks. These recommendations aim to enhance regulatory clarity and strengthen long-term resilience, offering a pragmatic and replicable blueprint for other nations seeking to govern AI risks within their existing sectoral frameworks.

**AI Summary:** This paper highlights the need to incorporate AI incident reporting into telecommunications law and policy, as the integration of AI into telecommunications infrastructure introduces novel risks that traditional frameworks do not cover. Using India as a case study, the paper identifies a regulatory gap in existing laws that focus on cybersecurity and data breaches but do not address AI-specific operational incidents. The paper proposes policy recommendations to address this gap, such as mandating reporting for high-risk AI failures and developing standardized reporting frameworks, to enhance regulatory clarity and strengthen resilience in governing AI risks within existing sectoral frameworks.

---

## Measuring Implicit Spatial Coordination in Teams: Effects on Collective Intelligence and Performance
**URL:** https://arxiv.org/abs/2509.09314

**Abstract:** Coordinated teamwork is essential in fast-paced decision-making environments that require dynamic adaptation, often without an opportunity for explicit communication. Although implicit coordination has been extensively considered in the existing literature, the majority of work has focused on co-located, synchronous teamwork (such as sports teams) or, in distributed teams, primarily on coordination of knowledge work. However, many teams (firefighters, military, law enforcement, emergency response) must coordinate their movements in physical space without the benefit of visual cues or extensive explicit communication. This paper investigates how three dimensions of spatial coordination, namely exploration diversity, movement specialization, and adaptive spatial proximity, influence team performance in a collaborative online search and rescue task where explicit communication is restricted and team members rely on movement patterns to infer others' intentions and coordinate actions. Our metrics capture the relational aspects of teamwork by measuring spatial proximity, distribution patterns, and alignment of movements within shared environments. We analyze data from 34 four-person teams (136 participants) assigned to specialized roles in a search and rescue task. Results show that spatial specialization positively predicts performance, while adaptive spatial proximity exhibits a marginal inverted U-shaped relationship, suggesting moderate levels of adaptation are optimal. Furthermore, the temporal dynamics of these metrics differentiate high- from low-performing teams over time. These findings provide insights into implicit spatial coordination in role-based teamwork and highlight the importance of balanced adaptive strategies, with implications for training and AI-assisted team support systems.

**AI Summary:** This research explores how implicit spatial coordination, specifically exploration diversity, movement specialization, and adaptive spatial proximity, impacts team performance in a collaborative online search and rescue task. The study found that spatial specialization positively correlates with performance, while adaptive spatial proximity shows an optimal inverted U-shaped relationship. The findings offer insights into the importance of balanced adaptive strategies in role-based teamwork, with implications for training and AI-assisted team support systems.

---

## Understanding Economic Tradeoffs Between Human and AI Agents in Bargaining Games
**URL:** https://arxiv.org/abs/2509.09071

**Abstract:** Coordination tasks traditionally performed by humans are increasingly being delegated to autonomous agents. As this pattern progresses, it becomes critical to evaluate not only these agents' performance but also the processes through which they negotiate in dynamic, multi-agent environments. Furthermore, different agents exhibit distinct advantages: traditional statistical agents, such as Bayesian models, may excel under well-specified conditions, whereas large language models (LLMs) can generalize across contexts. In this work, we compare humans (N = 216), LLMs (GPT-4o, Gemini 1.5 Pro), and Bayesian agents in a dynamic negotiation setting that enables direct, identical-condition comparisons across populations, capturing both outcomes and behavioral dynamics. Bayesian agents extract the highest surplus through aggressive optimization, at the cost of frequent trade rejections. Humans and LLMs can achieve similar overall surplus, but through distinct behaviors: LLMs favor conservative, concessionary trades with few rejections, while humans employ more strategic, risk-taking, and fairness-oriented behaviors. Thus, we find that performance parity -- a common benchmark in agent evaluation -- can conceal fundamental differences in process and alignment, which are critical for practical deployment in real-world coordination tasks.

**AI Summary:** This research compares the performance and negotiation processes of humans, large language models (LLMs), and Bayesian agents in dynamic bargaining games. While Bayesian agents extract the highest surplus through aggressive optimization, they face frequent trade rejections. Humans and LLMs achieve similar overall surplus through different behaviors, with LLMs favoring conservative trades and humans using more strategic and fairness-oriented approaches. The study highlights the importance of understanding the tradeoffs between human and AI agents in negotiation tasks for practical deployment in real-world coordination scenarios.

---

## Towards Trustworthy AI: Characterizing User-Reported Risks across LLMs "In the Wild"
**URL:** https://arxiv.org/abs/2509.08912

**Abstract:** While Large Language Models (LLMs) are rapidly integrating into daily life, research on their risks often remains lab-based and disconnected from the problems users encounter "in the wild." While recent HCI research has begun to explore these user-facing risks, it typically concentrates on a singular LLM chatbot like ChatGPT or an isolated risk like privacy. To gain a holistic understanding of multi-risk across LLM chatbots, we analyze online discussions on Reddit around seven major LLM chatbots through the U.S. NIST's AI Risk Management Framework. We find that user-reported risks are unevenly distributed and platform-specific. While "Valid and Reliable" risk is the most frequently mentioned, each product also exhibits a unique "risk fingerprint;" for instance, user discussions associate GPT more with "Safe" and "Fair" issues, Gemini with "Privacy," and Claude with "Secure and Resilient" risks. Furthermore, the nature of these risks differs by their prevalence: less frequent risks like "Explainability" and "Privacy" manifest as nuanced user trade-offs, more common ones like "Fairness" are experienced as direct personal harms. Our findings reveal gaps between risks reported by system-centered studies and by users, highlighting the need for user-centered approaches that support users in their daily use of LLM chatbots.

**AI Summary:** This research examines user-reported risks associated with Large Language Models (LLMs) in real-world settings, analyzing discussions on Reddit about seven major LLM chatbots. The study finds that user-reported risks are unevenly distributed and platform-specific, with each chatbot exhibiting a unique "risk fingerprint." The findings suggest a need for user-centered approaches to address the gaps between risks reported by system-centered studies and those experienced by users in their daily interactions with LLM chatbots.

---

## Investigating Student Interaction Patterns with Large Language Model-Powered Course Assistants in Computer Science Courses
**URL:** https://arxiv.org/abs/2509.08862

**Abstract:** Providing students with flexible and timely academic support is a challenge at most colleges and universities, leaving many students without help outside scheduled hours. Large language models (LLMs) are promising for bridging this gap, but interactions between students and LLMs are rarely overseen by educators. We developed and studied an LLM-powered course assistant deployed across multiple computer science courses to characterize real-world use and understand pedagogical implications. By Spring 2024, our system had been deployed to approximately 2,000 students across six courses at three institutions. Analysis of the interaction data shows that usage remains strong in the evenings and nights and is higher in introductory courses, indicating that our system helps address temporal support gaps and novice learner needs. We sampled 200 conversations per course for manual annotation: most sampled responses were judged correct and helpful, with a small share unhelpful or erroneous; few responses included dedicated examples. We also examined an inquiry-based learning strategy: only around 11% of sampled conversations contained LLM-generated follow-up questions, which were often ignored by students in advanced courses. A Bloom's taxonomy analysis reveals that current LLM capabilities are limited in generating higher-order cognitive questions. These patterns suggest opportunities for pedagogically oriented LLM-based educational systems and greater educator involvement in configuring prompts, content, and policies.

**AI Summary:** This research investigates the use of Large Language Models (LLMs) as course assistants in computer science courses to provide flexible academic support to students. The study found that the LLM-powered system was effective in addressing temporal support gaps and beginner learner needs, with most responses being judged correct and helpful. However, there is room for improvement in generating higher-order cognitive questions and incorporating educator input to enhance the pedagogical effectiveness of LLM-based educational systems.

---

## A Systematic Mapping Study on Chatbots in Programming Education
**URL:** https://arxiv.org/abs/2509.08857

**Abstract:** Educational chatbots have gained prominence as support tools for teaching programming, particularly in introductory learning contexts. This paper presents a Systematic Mapping Study (SMS) that investigated how such agents have been developed and applied in programming education. From an initial set of 3,216 publications, 54 studies were selected and analyzed based on five research subquestions, addressing chatbot types, programming languages used, educational content covered, interaction models, and application contexts. The results reveal a predominance of chatbots designed for Python instruction, focusing on fundamental programming concepts, and employing a wide variety of pedagogical approaches and technological architectures. In addition to identifying trends and gaps in the literature, this study provides insights to inform the development of new educational tools for programming instruction.

**AI Summary:** This systematic mapping study examined the development and application of chatbots in programming education, focusing on 54 selected studies out of 3,216 publications. The results showed a prevalence of chatbots designed for teaching Python and covering fundamental programming concepts, with a variety of pedagogical approaches and technological architectures. The study highlights trends and gaps in the literature, providing insights for the development of new educational tools for programming instruction.

---

## Augmenting speech transcripts of VR recordings with gaze, pointing, and visual context for multimodal coreference resolution
**URL:** https://arxiv.org/abs/2509.08689

**Abstract:** Understanding transcripts of immersive multimodal conversations is challenging because speakers frequently rely on visual context and non-verbal cues, such as gestures and visual attention, which are not captured in speech alone. This lack of information makes coreferences resolution-the task of linking ambiguous expressions like ``it'' or ``there'' to their intended referents-particularly challenging. In this paper we present a system that augments VR speech transcript with eye-tracking laser pointing data, and scene metadata to generate textual descriptions of non-verbal communication and the corresponding objects of interest. To evaluate the system, we collected gaze, gesture, and voice data from 12 participants (6 pairs) engaged in an open-ended design critique of a 3D model of an apartment. Our results show a 26.5\% improvement in coreference resolution accuracy by a GPT model when using our multimodal transcript compared to a speech-only baseline.

**AI Summary:** This research focuses on improving coreference resolution in speech transcripts of VR recordings by incorporating non-verbal cues such as gaze, pointing, and visual context. The study found that augmenting speech transcripts with these additional modalities led to a significant improvement in coreference resolution accuracy, with a 26.5% increase compared to using speech-only data. This work highlights the importance of considering multimodal information in understanding immersive conversations and demonstrates the potential for enhancing AI systems with non-verbal communication cues.

---

## Visual Analysis of Time-Dependent Observables in Cell Signaling Simulations
**URL:** https://arxiv.org/abs/2509.08589

**Abstract:** The ability of a cell to communicate with its environment is essential for key cellular functions like replication, metabolism, or cell fate decisions. The involved molecular mechanisms are highly dynamic and difficult to capture experimentally. Simulation studies offer a valuable means for exploring and predicting how cell signaling processes unfold. We present a design study on the visual analysis of such studies to support 1) modelers in calibrating model parameters such that the simulated signal responses over time reflect reference behavior from cell biology research and 2) cell biologists in exploring the influence of receptor trafficking on the efficiency of signal transmission within the cell. We embed time series plots into parallel coordinates to enable a simultaneous analysis of model parameters and temporal outputs. A usage scenario illustrates how our approach assists with typical tasks such as assessing the plausibility of temporal outputs or their sensitivity across model configurations.

**AI Summary:** This research focuses on using visual analysis to study cell signaling simulations, which are crucial for understanding cellular functions. The study aims to help modelers calibrate parameters and assist cell biologists in exploring the impact of receptor trafficking on signal transmission efficiency within cells. By embedding time series plots into parallel coordinates, researchers can analyze model parameters and temporal outputs simultaneously, aiding in tasks such as assessing the plausibility of outputs and sensitivity across different model configurations.

---

## Acceptability of AI Assistants for Privacy: Perceptions of Experts and Users on Personalized Privacy Assistants
**URL:** https://arxiv.org/abs/2509.08554

**Abstract:** Individuals increasingly face an overwhelming number of tasks and decisions. To cope with the new reality, there is growing research interest in developing intelligent agents that can effectively assist people across various aspects of daily life in a tailored manner, with privacy emerging as a particular area of application. Artificial intelligence (AI) assistants for privacy, such as personalized privacy assistants (PPAs), have the potential to automatically execute privacy decisions based on users' pre-defined privacy preferences, sparing them the mental effort and time usually spent on each privacy decision. This helps ensure that, even when users feel overwhelmed or resigned about privacy, the decisions made by PPAs still align with their true preferences and best interests. While research has explored possible designs of such agents, user and expert perspectives on the acceptability of such AI-driven solutions remain largely unexplored. In this study, we conducted five focus groups with domain experts (n = 11) and potential users (n = 26) to uncover key themes shaping the acceptance of PPAs. Factors influencing the acceptability of AI assistants for privacy include design elements (such as information sources used by the agent), external conditions (such as regulation and literacy education), and systemic conditions (e.g., public or market providers and the need to avoid monopoly) to PPAs. These findings provide theoretical extensions to technology acceptance models measuring PPAs, insights on design, and policy implications for PPAs, as well as broader implications for the design of AI assistants.

**AI Summary:** This research explores the acceptability of AI assistants for privacy, specifically personalized privacy assistants (PPAs), which can make privacy decisions based on users' preferences. The study found that factors such as design elements, external conditions like regulation and literacy education, and systemic conditions like public or market providers influence the acceptance of PPAs. The findings provide insights for the design and policy implications of AI assistants for privacy, as well as broader implications for the design of AI assistants in general.

---

## Embedding Empathy into Visual Analytics: A Framework for Person-Centred Dementia Care
**URL:** https://arxiv.org/abs/2509.08548

**Abstract:** Dementia care requires healthcare professionals to balance a patient's medical needs with a deep understanding of their personal needs, preferences, and emotional cues. However, current digital tools prioritise quantitative metrics over empathetic engagement,limiting caregivers ability to develop a deeper personal understanding of their patients. This paper presents an empathy centred visualisation framework, developed through a design study, to address this gap. The framework integrates established principles of person centred care with empathy mapping methodologies to encourage deeper engagement. Our methodology provides a structured approach to designing for indirect end users, patients whose experience is shaped by a tool they may not directly interact with. To validate the framework, we conducted evaluations with healthcare professinals, including usability testing of a working prototype and a User Experience Questionnaire study. Results suggest the feasibility of the framework, with participants highlighting its potential to support a more personal and empathetic relationship between medical staff and patients. The work starts to explore how empathy could be systematically embedded into visualisation design, as we contribute to ongoing efforts in the data visualisation community to support human centred, interpretable, and ethically aligned clinical care, addressing the urgent need to improve dementia patients experiences in hospital settings.

**AI Summary:** This research paper introduces an empathy-centered visualisation framework for dementia care, aiming to bridge the gap between medical needs and personal preferences of patients. The framework integrates person-centered care principles and empathy mapping methodologies to encourage deeper engagement and understanding. Evaluation results suggest that the framework has the potential to support a more personal and empathetic relationship between medical staff and patients, contributing to the ongoing efforts in data visualization to improve dementia patients' experiences in hospital settings.

---

## Formal verification for robo-advisors: Irrelevant for subjective end-user trust, yet decisive for investment behavior?
**URL:** https://arxiv.org/abs/2509.08540

**Abstract:** This online-vignette study investigates the impact of certification and verification as measures for quality assurance of AI on trust and use of a robo-advisor. Confronting 520 participants with an imaginary situation where they were using an online banking service to invest their inherited money, we formed 4 experimental groups. EG1 achieved no further information of their robo-advisor, while EG2 was informed that their robo-advisor was certified by a reliable agency for unbiased processes, and EG3 was presented with a formally verified robo-advisor that was proven to consider their investment preferences. A control group was presented a remote certified human financial advisor. All groups had to decide on how much of their 10,000 euros they would give to their advisor to autonomously invest for them and report on trust and perceived dependability. A second manipulation happened afterwards, confronting participants with either a successful or failed investment. Overall, our results show that the level of quality assurance of the advisor had surprisingly near to no effect of any of our outcome variables, except for people's perception of their own mental model of the advisor. Descriptively, differences between investments show that seem to favor a verified advisor with a median investment of 65,000 euros (vs. 50,000). Success or failure information, though influences only partially by advisor quality, has been perceived as a more important clue for advisor trustworthiness, leading to substantially different trust and dependability ratings. The study shows the importance of thoroughly investigating not only trust, but also trusting behavior with objective measures. It also underlines the need for future research on formal verification, that might be the gold standard in proving AI mathematically, but seems not to take full effect as a cue for trustworthiness for end-users.

**AI Summary:** This study examined the impact of certification and verification on trust and investment behavior in robo-advisors. The results showed that the level of quality assurance of the advisor had little effect on trust and dependability, except for influencing participants' perception of the advisor's mental model. While a formally verified robo-advisor was favored in terms of investment decisions, success or failure of investments had a greater impact on trustworthiness. The study highlights the importance of investigating both trust and trusting behavior with objective measures and suggests that formal verification may not be as influential for end-user trust as previously thought.

---

