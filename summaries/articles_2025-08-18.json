[
  {
    "title": "Grab-n-Go: On-the-Go Microgesture Recognition with Objects in Hand",
    "abstract": "As computing devices become increasingly integrated into daily life, there is a growing need for intuitive, always-available interaction methods, even when users' hands are occupied. In this paper, we introduce Grab-n-Go, the first wearable device that leverages active acoustic sensing to recognize subtle hand microgestures while holding various objects. Unlike prior systems that focus solely on free-hand gestures or basic hand-object activity recognition, Grab-n-Go simultaneously captures information about hand microgestures, grasping poses, and object geometries using a single wristband, enabling the recognition of fine-grained hand movements occurring within activities involving occupied hands. A deep learning framework processes these complex signals to identify 30 distinct microgestures, with 6 microgestures for each of the 5 grasping poses. In a user study with 10 participants and 25 everyday objects, Grab-n-Go achieved an average recognition accuracy of 92.0%. A follow-up study further validated Grab-n-Go's robustness against 10 more challenging, deformable objects. These results underscore the potential of Grab-n-Go to provide seamless, unobtrusive interactions without requiring modifications to existing objects. The complete dataset, comprising data from 18 participants performing 30 microgestures with 35 distinct objects, is publicly available at this https URL with the DOI: this https URL.",
    "url": "https://arxiv.org/abs/2508.11620",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces Grab-n-Go, a wearable device that uses active acoustic sensing to recognize hand microgestures while holding objects. The device can identify 30 distinct microgestures with an average accuracy of 92.0%, making it a promising tool for intuitive interaction methods in daily life without the need for modifications to existing objects. The study demonstrates the device's effectiveness in recognizing fine-grained hand movements and grasping poses, highlighting its potential for seamless and unobtrusive interactions."
  },
  {
    "title": "Adaptive Cardio Load Targets for Improving Fitness and Performance",
    "abstract": "Cardio Load, introduced by Google in 2024, is a measure of cardiovascular work (also known as training load) resulting from all the user's activities across the day. It is based on heart rate reserve and captures both activity intensity and duration. Thanks to feedback from users and internal research, we introduce adaptive and personalized targets which will be set weekly. This feature will be available in the Public Preview of the Fitbit app after September 2025. This white paper provides a comprehensive overview of Cardio Load (CL) and how weekly CL targets are established, with examples shown to illustrate the effect of varying CL on the weekly target. We compare Cardio Load and Active Zone Minutes (AZMs), highlighting their distinct purposes, i.e. AZMs for health guidelines and CL for performance measurement. We highlight that CL is accumulated both during active workouts and incidental daily activities, so users are able top-up their CL score with small bouts of activity across the day.",
    "url": "https://arxiv.org/abs/2508.11613",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces Cardio Load (CL) as a measure of cardiovascular work based on heart rate reserve, capturing both activity intensity and duration. The study presents adaptive and personalized weekly CL targets, which will be available in the Fitbit app after September 2025. CL is shown to be a valuable tool for improving fitness and performance, with the ability for users to accumulate their CL score throughout the day through both active workouts and daily activities."
  },
  {
    "title": "Grand Challenge: Mediating Between Confirmatory and Exploratory Research Cultures in Health Sciences and Visual Analytics",
    "abstract": "Collaboration between health science and visual analytics research is often hindered by different, sometimes incompatible approaches to research design. Health science often follows hypothesis-driven protocols, registered in advance, and focuses on reproducibility and risk mitigation. Visual analytics, in contrast, relies on iterative data exploration, prioritizing insight generation and analytic refinement through user interaction. These differences create challenges in interdisciplinary projects, including misaligned terminology, unrealistic expectations about data readiness, divergent validation norms, or conflicting explainability requirements. To address these persistent tensions, we identify seven research needs and actions: (1) guidelines for broader community adoption, (2) agreement on quality and validation benchmarks, (3) frameworks for aligning research tasks, (4) integrated workflows combining confirmatory and exploratory stages, (5) tools for harmonizing terminology across disciplines, (6) dedicated bridging roles for transdisciplinary work, and (7) cultural adaptation and mutual recognition. We organize these needs in a framework with three areas: culture, standards, and processes. They can constitute a research agenda for developing reliable, reproducible, and clinically relevant data-centric methods.",
    "url": "https://arxiv.org/abs/2508.11544",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research highlights the challenges in collaboration between health science and visual analytics due to differences in research approaches. The study identifies seven research needs and actions to bridge the gap, including guidelines for broader adoption, agreement on quality benchmarks, and integrated workflows combining confirmatory and exploratory stages. By addressing these challenges, the research aims to develop reliable, reproducible, and clinically relevant data-centric methods in interdisciplinary projects."
  },
  {
    "title": "ReachVox: Clutter-free Reachability Visualization for Robot Motion Planning in Virtual Reality",
    "abstract": "Human-Robot-Collaboration can enhance workflows by leveraging the mutual strengths of human operators and robots. Planning and understanding robot movements remain major challenges in this domain. This problem is prevalent in dynamic environments that might need constant robot motion path adaptation. In this paper, we investigate whether a minimalistic encoding of the reachability of a point near an object of interest, which we call ReachVox, can aid the collaboration between a remote operator and a robotic arm in VR. Through a user study (n=20), we indicate the strength of the visualization relative to a point-based reachability check-up.",
    "url": "https://arxiv.org/abs/2508.11426",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research explores the use of a clutter-free reachability visualization tool called ReachVox to aid in human-robot collaboration for robot motion planning in virtual reality. The study suggests that ReachVox can effectively assist remote operators in understanding and adapting robot movements in dynamic environments, as demonstrated through a user study comparing it to a point-based reachability check-up. This research highlights the potential of minimalist visualization tools in enhancing workflows and collaboration between human operators and robots in complex environments."
  },
  {
    "title": "Towards Embodied Conversational Agents for Reducing Oral Exam Anxiety in Extended Reality",
    "abstract": "Oral examinations are a prevalent but psychologically demanding form of assessment in higher education. Many students experience intense anxiety, which can impair cognitive performance and hinder academic success. This position paper explores the potential of embodied conversational agents (ECAs) in extended reality (XR) environments to support students preparing for oral exams. We propose a system concept that integrates photorealistic ECAs with real-time capable large language models (LLMs) to enable psychologically safe, adaptive, and repeatable rehearsal of oral examination scenarios. We also discuss the potential benefits and challenges of such an envisioned system.",
    "url": "https://arxiv.org/abs/2508.11412",
    "journal": "arXiv cs.HC",
    "ai_summary": "This position paper discusses the potential of using embodied conversational agents (ECAs) in extended reality (XR) environments to help students reduce anxiety and improve performance during oral examinations in higher education. The proposed system concept integrates photorealistic ECAs with large language models (LLMs) to provide students with psychologically safe, adaptive, and repeatable rehearsal of oral exam scenarios. The research highlights the benefits of this system in supporting students' preparation for oral exams, while also addressing potential challenges in implementing such technology."
  },
  {
    "title": "FACET:Teacher-Centred LLM-Based Multi-Agent Systems-Towards Personalized Educational Worksheets",
    "abstract": "The increasing heterogeneity of student populations poses significant challenges for teachers, particularly in mathematics education, where cognitive, motivational, and emotional differences strongly influence learning outcomes. While AI-driven personalization tools have emerged, most remain performance-focused, offering limited support for teachers and neglecting broader pedagogical needs. This paper presents the FACET framework, a teacher-facing, large language model (LLM)-based multi-agent system designed to generate individualized classroom materials that integrate both cognitive and motivational dimensions of learner profiles. The framework comprises three specialized agents: (1) learner agents that simulate diverse profiles incorporating topic proficiency and intrinsic motivation, (2) a teacher agent that adapts instructional content according to didactical principles, and (3) an evaluator agent that provides automated quality assurance. We tested the system using authentic grade 8 mathematics curriculum content and evaluated its feasibility through a) automated agent-based assessment of output quality and b) exploratory feedback from K-12 in-service teachers. Results from ten internal evaluations highlighted high stability and alignment between generated materials and learner profiles, and teacher feedback particularly highlighted structure and suitability of tasks. The findings demonstrate the potential of multi-agent LLM architectures to provide scalable, context-aware personalization in heterogeneous classroom settings, and outline directions for extending the framework to richer learner profiles and real-world classroom trials.",
    "url": "https://arxiv.org/abs/2508.11401",
    "journal": "arXiv cs.HC",
    "ai_summary": "The FACET framework is a teacher-facing AI system that uses large language models to generate personalized educational materials for students based on their cognitive and motivational profiles. The system, comprised of learner, teacher, and evaluator agents, was tested with grade 8 mathematics curriculum content and received positive feedback from in-service teachers for its alignment with learner profiles and task suitability. This research highlights the potential of multi-agent LLM architectures to provide scalable and context-aware personalization in diverse classroom settings, with implications for future extensions and real-world trials."
  },
  {
    "title": "Trustworthy AI Psychotherapy: Multi-Agent LLM Workflow for Counseling and Explainable Mental Disorder Diagnosis",
    "abstract": "LLM-based agents have emerged as transformative tools capable of executing complex tasks through iterative planning and action, achieving significant advancements in understanding and addressing user needs. Yet, their effectiveness remains limited in specialized domains such as mental health diagnosis, where they underperform compared to general applications. Current approaches to integrating diagnostic capabilities into LLMs rely on scarce, highly sensitive mental health datasets, which are challenging to acquire. These methods also fail to emulate clinicians' proactive inquiry skills, lack multi-turn conversational comprehension, and struggle to align outputs with expert clinical reasoning. To address these gaps, we propose DSM5AgentFlow, the first LLM-based agent workflow designed to autonomously generate DSM-5 Level-1 diagnostic questionnaires. By simulating therapist-client dialogues with specific client profiles, the framework delivers transparent, step-by-step disorder predictions, producing explainable and trustworthy results. This workflow serves as a complementary tool for mental health diagnosis, ensuring adherence to ethical and legal standards. Through comprehensive experiments, we evaluate leading LLMs across three critical dimensions: conversational realism, diagnostic accuracy, and explainability. Our datasets and implementations are fully open-sourced.",
    "url": "https://arxiv.org/abs/2508.11398",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research proposes a new workflow, DSM5AgentFlow, that utilizes LLM-based agents to autonomously generate DSM-5 Level-1 diagnostic questionnaires for mental health diagnosis. The framework simulates therapist-client dialogues and produces transparent disorder predictions, addressing the limitations of current approaches in specialized domains such as mental health. Through comprehensive experiments, the study evaluates leading LLMs in terms of conversational realism, diagnostic accuracy, and explainability, providing a trustworthy and explainable tool for mental health diagnosis that adheres to ethical and legal standards."
  },
  {
    "title": "Towards Smart Workplaces: Understanding Mood-Influencing Factors of the Physical Workspace in Collaborative Group Settings",
    "abstract": "Group mood plays a crucial role in shaping workspace experiences, influencing group dynamics, team performance, and creativity. The perceived group mood depends on many, often subconscious, aspects such as individual emotional states or group life, which make it challenging to maintain a positive atmosphere. Intelligent technology could support mood regulation in physical office environments, for example, as adaptive ambient lighting for mood regulation. However, little is known about the relationship between the physical workspace and group mood dynamics. To address this knowledge gap, we conducted a qualitative user study (N=8 workgroups and overall 26 participants) to explore how the physical workspace shapes group mood experiences and investigate employees' perspectives on intelligent mood-aware technologies. Our findings reveal key factors influencing group mood, and participants' expectations for supportive technology to preserve privacy and autonomy. Our work highlights the potential of adaptive and responsive workspaces while also emphasizing the need for human-centered, technology-driven interventions that benefit group well-being.",
    "url": "https://arxiv.org/abs/2508.11335",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the impact of physical workspace on group mood in collaborative settings and the potential for intelligent technology to regulate mood. The study found that various factors, such as individual emotional states and group dynamics, influence group mood, and participants expressed interest in technology that could support mood regulation while preserving privacy and autonomy. The findings suggest the potential for adaptive workspaces to enhance group well-being through human-centered, technology-driven interventions."
  },
  {
    "title": "The User-first Approach to AI Ethics: Preferences for Ethical Principles in AI Systems across Cultures and Contexts",
    "abstract": "As AI systems increasingly permeate everyday life, designers and developers face mounting pressure to balance innovation with ethical design choices. To date, the operationalisation of AI ethics has predominantly depended on frameworks that prescribe which ethical principles should be embedded within AI systems. However, the extent to which users value these principles remains largely unexplored in the existing literature. In a discrete choice experiment conducted in four countries, we quantify user preferences for 11 ethical principles. Our findings indicate that, while users generally prioritise privacy, justice & fairness, and transparency, their preferences exhibit significant variation based on culture and application context. Latent class analysis further revealed four distinct user cohorts, the largest of which is ethically disengaged and defers to regulatory oversight. Our findings offer (1) empirical evidence of uneven user prioritisation of AI ethics principles, (2) actionable guidance for operationalising ethics tailored to culture and context, (3) support for the development of robust regulatory mechanisms, and (4) a foundation for advancing a user-centred approach to AI ethics, motivated independently from abstract moral theory.",
    "url": "https://arxiv.org/abs/2508.11327",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores user preferences for ethical principles in AI systems across different cultures and contexts. The study found that users generally prioritize privacy, justice & fairness, and transparency, but preferences vary based on culture and application context. The findings suggest the need for tailored approaches to operationalizing ethics in AI systems, support for robust regulatory mechanisms, and a user-centered approach to AI ethics."
  },
  {
    "title": "Outpace Reality: A Novel Augmented-Walking Technique for Virtual Reality Games",
    "abstract": "The size of most virtual environments exceeds the tracking space available for physical walking. One solution to this disparity is to extend the available walking range by augmenting users' actual movements. However, the resulting increase in visual flow can easily cause cybersickness. Therefore, we present a novel augmented-walking approach for virtual reality games. Our core concept is a virtual tunnel that spans the entire travel distance when viewed from the outside. However, its interior is only a fraction as long, allowing users to cover the distance by real walking. Whereas the tunnel hides the visual flow from the applied movement acceleration, windows on the tunnel's walls still reveal the actual expedited motion. Our evaluation reveals that our approach avoids cybersickness while enhancing physical activity and preserving presence. We finish our paper with a discussion of the design considerations and limitations of our proposed locomotion technique.",
    "url": "https://arxiv.org/abs/2508.11314",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces a novel augmented-walking technique for virtual reality games to address the issue of limited physical walking space in virtual environments. The approach involves using a virtual tunnel that visually extends the walking distance while allowing users to cover the distance by real walking. The study shows that this technique reduces cybersickness, increases physical activity, and maintains a sense of presence in the virtual environment."
  },
  {
    "title": "GulliVR: A Walking-Oriented Technique for Navigation in Virtual Reality Games Based on Virtual Body Resizing",
    "abstract": "Virtual reality games are often centered around our feeling of \"being there\". That presence can be significantly enhanced by supporting physical walking. Although modern virtual reality systems enable room-scale motions, the size of our living rooms is not enough to explore vast virtual environments. Developers bypass that limitation by adding virtual navigation such as teleportation. Although such techniques are intended (or designed) to extend but not replace natural walking, what we often observe are nonmoving players beaming to a location that is one real step ahead. Our navigation metaphor emphasizes physical walking by promoting players into giants on demand to cover large distances. In contrast to flying, our technique proportionally increases the modeled eye distance, preventing cybersickness and creating the feeling of being in a miniature world. Our evaluations underpin a significantly increased presence and walking distance compared to the teleportation approach. Finally, we derive a set of game design implications related to the integration of our technique.",
    "url": "https://arxiv.org/abs/2508.11304",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces a new navigation technique, GulliVR, for virtual reality games that focuses on physical walking to enhance the feeling of presence in the virtual environment. By allowing players to become giants on demand, the technique enables them to cover large distances while maintaining a sense of immersion and preventing cybersickness. Evaluations show increased presence and walking distance compared to traditional teleportation methods, providing valuable insights for game developers on integrating the new technique into their games."
  },
  {
    "title": "Is General-Purpose AI Reasoning Sensitive to Data-Induced Cognitive Biases? Dynamic Benchmarking on Typical Software Engineering Dilemmas",
    "abstract": "Human cognitive biases in software engineering can lead to costly errors. While general-purpose AI (GPAI) systems may help mitigate these biases due to their non-human nature, their training on human-generated data raises a critical question: Do GPAI systems themselves exhibit cognitive biases?\nTo investigate this, we present the first dynamic benchmarking framework to evaluate data-induced cognitive biases in GPAI within software engineering workflows. Starting with a seed set of 16 hand-crafted realistic tasks, each featuring one of 8 cognitive biases (e.g., anchoring, framing) and corresponding unbiased variants, we test whether bias-inducing linguistic cues unrelated to task logic can lead GPAI systems from correct to incorrect conclusions.\nTo scale the benchmark and ensure realism, we develop an on-demand augmentation pipeline relying on GPAI systems to generate task variants that preserve bias-inducing cues while varying surface details. This pipeline ensures correctness (88--99% on average, according to human evaluation), promotes diversity, and controls reasoning complexity by leveraging Prolog-based reasoning and LLM-as-a-judge validation. It also verifies that the embedded biases are both harmful and undetectable by logic-based, unbiased reasoners.\nWe evaluate leading GPAI systems (GPT, LLaMA, DeepSeek) and find a consistent tendency to rely on shallow linguistic heuristics over deep reasoning. All systems exhibit cognitive biases (ranging from 5.9% to 35% across types), with bias sensitivity increasing sharply with task complexity (up to 49%), highlighting critical risks in real-world software engineering deployments.",
    "url": "https://arxiv.org/abs/2508.11278",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research investigates whether general-purpose AI (GPAI) systems trained on human-generated data exhibit cognitive biases in software engineering workflows. The study develops a dynamic benchmarking framework to evaluate bias-inducing linguistic cues in GPAI systems, finding that leading systems tend to rely on shallow linguistic heuristics over deep reasoning. The findings suggest that GPAI systems exhibit cognitive biases (ranging from 5.9% to 35% across types), with sensitivity increasing with task complexity, highlighting potential risks in real-world software engineering deployments."
  },
  {
    "title": "From Misunderstandings to Learning Opportunities: Leveraging Generative AI in Discussion Forums to Support Student Learning",
    "abstract": "In the contemporary educational landscape, particularly in large classroom settings, discussion forums have become a crucial tool for promoting interaction and addressing student queries. These forums foster a collaborative learning environment where students engage with both the teaching team and their peers. However, the sheer volume of content generated in these forums poses two significant interconnected challenges: How can we effectively identify common misunderstandings that arise in student discussions? And once identified, how can instructors use these insights to address them effectively? This paper explores the approach to integrating large language models (LLMs) and Retrieval-Augmented Generation (RAG) to tackle these challenges. We then demonstrate the approach Misunderstanding to Mastery (M2M) with authentic data from three computer science courses, involving 1355 students with 2878 unique posts, followed by an evaluation with five instructors teaching these courses. Results show that instructors found the approach promising and valuable for teaching, effectively identifying misunderstandings and generating actionable insights. Instructors highlighted the need for more fine-grained groupings, clearer metrics, validation of the created resources, and ethical considerations around data anonymity.",
    "url": "https://arxiv.org/abs/2508.11150",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of large language models and Retrieval-Augmented Generation to identify and address common misunderstandings in student discussion forums. The approach, Misunderstanding to Mastery (M2M), was tested in three computer science courses with positive feedback from instructors who found it valuable for teaching. The results suggest that leveraging generative AI in discussion forums can help instructors effectively identify and address student misunderstandings, with room for further refinement and consideration of ethical implications."
  },
  {
    "title": "Toward Needs-Conscious Design: Co-Designing a Human-Centered Framework for AI-Mediated Communication",
    "abstract": "We introduce Needs-Conscious Design, a human-centered framework for AI-mediated communication that builds on the principles of Nonviolent Communication (NVC). We conducted an interview study with N=14 certified NVC trainers and a diary study and co-design with N=13 lay users of online communication technologies to understand how NVC might inform design that centers human relationships. We define three pillars of Needs-Conscious Design: Intentionality, Presence, and Receptiveness to Needs. Drawing on participant co-designs, we provide design concepts and illustrative examples for each of these pillars. We further describe a problematic emergent property of AI-mediated communication identified by participants, which we call Empathy Fog, and which is characterized by uncertainty over how much empathy, attention, and effort a user has actually invested via an AI-facilitated online interaction. Finally, because even well-intentioned designs may alter user behavior and process emotional data, we provide guiding questions for consentful Needs-Conscious Design, applying an affirmative consent framework used in social media contexts. Needs-Conscious Design offers a foundation for leveraging AI to facilitate human connection, rather than replacing or obscuring it.",
    "url": "https://arxiv.org/abs/2508.11149",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces Needs-Conscious Design, a framework for AI-mediated communication based on Nonviolent Communication principles. Through interviews and co-design studies, the researchers identified three pillars of Needs-Conscious Design: Intentionality, Presence, and Receptiveness to Needs. They also discovered a problematic emergent property called Empathy Fog, which highlights uncertainty in AI-facilitated interactions. The study emphasizes the importance of consentful design in leveraging AI to enhance human connection rather than replacing it."
  },
  {
    "title": "DriveSimQuest: A VR Driving Simulator and Research Platform on Meta Quest with Unity",
    "abstract": "Using head-mounted Virtual Reality (VR) displays to simulate driving is critical to studying driving behavior and designing driver assistance systems. But existing VR driving simulators are often limited to tracking only eye movements. The bulky outside-in tracking setup and Unreal-based architecture also present significant engineering challenges for interaction researchers and practitioners. We present DriveSimQuest, a VR driving simulator and research platform built on the Meta Quest Pro and Unity, capable of capturing rich behavioral signals such as gaze, facial expressions, hand activities, and full-body gestures in real-time. DriveSimQuest offers a preliminary, easy-to-deploy platform that supports researchers and practitioners in studying drivers' affective states and behaviors, and in designing future context-aware driving assistance systems.",
    "url": "https://arxiv.org/abs/2508.11072",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces DriveSimQuest, a VR driving simulator and research platform on Meta Quest Pro and Unity that allows for capturing rich behavioral signals such as gaze, facial expressions, hand activities, and full-body gestures in real-time. This platform addresses limitations of existing VR driving simulators by providing a more comprehensive and easy-to-deploy tool for studying drivers' affective states and behaviors, as well as designing context-aware driving assistance systems."
  },
  {
    "title": "Human-in-the-Loop Systems for Adaptive Learning Using Generative AI",
    "abstract": "A Human-in-the-Loop (HITL) approach leverages generative AI to enhance personalized learning by directly integrating student feedback into AI-generated solutions. Students critique and modify AI responses using predefined feedback tags, fostering deeper engagement and understanding. This empowers students to actively shape their learning, with AI serving as an adaptive partner. The system uses a tagging technique and prompt engineering to personalize content, informing a Retrieval-Augmented Generation (RAG) system to retrieve relevant educational material and adjust explanations in real time. This builds on existing research in adaptive learning, demonstrating how student-driven feedback loops can modify AI-generated responses for improved student retention and engagement, particularly in STEM education. Preliminary findings from a study with STEM students indicate improved learning outcomes and confidence compared to traditional AI tools. This work highlights AI's potential to create dynamic, feedback-driven, and personalized learning environments through iterative refinement.",
    "url": "https://arxiv.org/abs/2508.11062",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of Human-in-the-Loop systems with generative AI to enhance personalized learning by incorporating student feedback into AI-generated solutions. By allowing students to critique and modify AI responses using predefined tags, the system empowers students to actively shape their learning experience. The study shows promising results in improving student retention and engagement in STEM education, indicating the potential of AI to create dynamic and personalized learning environments through iterative refinement."
  },
  {
    "title": "Stories and Systems: Educational Interactive Storytelling to Teach Media Literacy and Systemic Thinking",
    "abstract": "This paper explores how Interactive Digital Narratives (IDNs) can support learners in developing the critical literacies needed to address complex societal challenges, so-called wicked problems, such as climate change, pandemics, and social inequality. While digital technologies offer broad access to narratives and data, they also contribute to misinformation and the oversimplification of interconnected issues. IDNs enable learners to navigate nonlinear, interactive stories, fostering deeper understanding and engagement. We introduce Systemic Learning IDNs: interactive narrative experiences explicitly designed to help learners explore and reflect on complex systems and interdependencies. To guide their creation and use, we propose the CLASS framework, a structured model that integrates systems thinking, design thinking, and storytelling. This transdisciplinary approach supports learners in developing curiosity, critical thinking, and collaborative problem-solving. Focusing on the classroom context, we apply CLASS to two cases, one commercial narrative simulation and one educational prototype, offering a comparative analysis and practical recommendations for future design and implementation. By combining narrative, systems mapping, and participatory design, this paper highlights how IDNs can become powerful tools for transformative, systems-oriented learning in an increasingly complex world.",
    "url": "https://arxiv.org/abs/2508.11059",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores how Interactive Digital Narratives (IDNs) can help learners develop critical literacies to address complex societal challenges like climate change and social inequality. The study introduces Systemic Learning IDNs, interactive narratives designed to help learners understand complex systems and interdependencies. The proposed CLASS framework integrates systems thinking, design thinking, and storytelling to support learners in developing critical thinking and collaborative problem-solving skills in the classroom. This research demonstrates the potential of IDNs as effective tools for transformative, systems-oriented learning in a complex world."
  },
  {
    "title": "AI That Helps Us Help Each Other: A Proactive System for Scaffolding Mentor-Novice Collaboration in Entrepreneurship Coaching",
    "abstract": "Entrepreneurship requires navigating open-ended, ill-defined problems: identifying risks, challenging assumptions, and making strategic decisions under deep uncertainty. Novice founders often struggle with these metacognitive demands, while mentors face limited time and visibility to provide tailored support. We present a human-AI coaching system that combines a domain-specific cognitive model of entrepreneurial risk with a large language model (LLM) to proactively scaffold both novice and mentor thinking. The system proactively poses diagnostic questions that challenge novices' thinking and helps both novices and mentors plan for more focused and emotionally attuned meetings. Critically, mentors can inspect and modify the underlying cognitive model, shaping the logic of the system to reflect their evolving needs. Through an exploratory field deployment, we found that using the system supported novice metacognition, helped mentors plan emotionally attuned strategies, and improved meeting depth, intentionality, and focus--while also surfaced key tensions around trust, misdiagnosis, and expectations of AI. We contribute design principles for proactive AI systems that scaffold metacognition and human-human collaboration in complex, ill-defined domains, offering implications for similar domains like healthcare, education, and knowledge work.",
    "url": "https://arxiv.org/abs/2508.11052",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research presents a human-AI coaching system designed to support novice founders and mentors in entrepreneurship coaching by proactively posing diagnostic questions and scaffolding metacognitive thinking. The system improves meeting depth, intentionality, and focus, while allowing mentors to modify the underlying cognitive model to meet their evolving needs. The study highlights the potential of proactive AI systems in complex, ill-defined domains like entrepreneurship, with implications for other fields such as healthcare, education, and knowledge work."
  },
  {
    "title": "Families' Vision of Generative AI Agents for Household Safety Against Digital and Physical Threats",
    "abstract": "As families face increasingly complex safety challenges in digital and physical environments, generative AI (GenAI) presents new opportunities to support household safety through multiple specialized AI agents. Through a two-phase qualitative study consisting of individual interviews and collaborative sessions with 13 parent-child dyads, we explored families' conceptualizations of GenAI and their envisioned use of AI agents in daily family life. Our findings reveal that families preferred to distribute safety-related support across multiple AI agents, each embodying a familiar caregiving role: a household manager coordinating routine tasks and mitigating risks such as digital fraud and home accidents; a private tutor providing personalized educational support, including safety education; and a family therapist offering emotional support to address sensitive safety issues such as cyberbullying and digital harassment. Families emphasized the need for agent-specific privacy boundaries, recognized generational differences in trust toward AI agents, and stressed the importance of maintaining open family communication alongside the assistance of AI agents. Based on these findings, we propose a multi-agent system design featuring four privacy-preserving principles: memory segregation, conversational consent, selective data sharing, and progressive memory management to help balance safety, privacy, and autonomy within family contexts.",
    "url": "https://arxiv.org/abs/2508.11030",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores families' perspectives on using generative AI agents for household safety against digital and physical threats. Findings suggest that families prefer multiple specialized AI agents, each embodying a familiar caregiving role, to address various safety concerns. The study highlights the importance of privacy boundaries, trust in AI agents, and maintaining open family communication while utilizing AI technology for safety in the home."
  },
  {
    "title": "GhostObjects: Instructing Robots by Manipulating Spatially Aligned Virtual Twins in Augmented Reality",
    "abstract": "Robots are increasingly capable of autonomous operations, yet human interaction remains essential for issuing personalized instructions. Instead of directly controlling robots through Programming by Demonstration (PbD) or teleoperation, we propose giving instructions by interacting with GhostObjects-world-aligned, life-size virtual twins of physical objects-in augmented reality (AR). By direct manipulation of GhostObjects, users can precisely specify physical goals and spatial parameters, with features including real-world lasso selection of multiple objects and snapping back to default positions, enabling tasks beyond simple pick-and-place.",
    "url": "https://arxiv.org/abs/2508.11022",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces the concept of GhostObjects, which are virtual twins of physical objects that can be manipulated in augmented reality to instruct robots. By interacting with GhostObjects, users can give precise instructions to robots without the need for direct control through Programming by Demonstration or teleoperation. This method allows for more personalized and detailed task instructions, expanding the capabilities of robots beyond simple pick-and-place tasks."
  },
  {
    "title": "Human-AI collaboration or obedient and often clueless AI in instruct, serve, repeat dynamics?",
    "abstract": "While research on human-AI collaboration exists, it mainly examined language learning and used traditional counting methods with little attention to evolution and dynamics of collaboration on cognitively demanding tasks. This study examines human-AI interactions while solving a complex problem. Student-AI interactions were qualitatively coded and analyzed with transition network analysis, sequence analysis and partial correlation networks as well as comparison of frequencies using chi-square and Person-residual shaded Mosaic plots to map interaction patterns, their evolution, and their relationship to problem complexity and student performance. Findings reveal a dominant Instructive pattern with interactions characterized by iterative ordering rather than collaborative negotiation. Oftentimes, students engaged in long threads that showed misalignment between their prompts and AI output that exemplified a lack of synergy that challenges the prevailing assumptions about LLMs as collaborative partners. We also found no significant correlations between assignment complexity, prompt length, and student grades suggesting a lack of cognitive depth, or effect of problem difficulty. Our study indicates that the current LLMs, optimized for instruction-following rather than cognitive partnership, compound their capability to act as cognitively stimulating or aligned collaborators. Implications for designing AI systems that prioritize cognitive alignment and collaboration are discussed.",
    "url": "https://arxiv.org/abs/2508.10919",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study examines human-AI interactions in solving complex problems and finds that interactions are often characterized by instructive patterns rather than collaborative negotiation. The findings suggest that current AI systems are optimized for instruction-following rather than cognitive partnership, leading to a lack of cognitive depth and alignment in collaboration. The study highlights the need for designing AI systems that prioritize cognitive alignment and collaboration to enhance human-AI interactions."
  },
  {
    "title": "Managing the unexpected: Operator behavioural data and its value in predicting correct alarm responses",
    "abstract": "Data from psychophysiological measures can offer new insight into control room operators' behaviour, cognition, and mental workload status. This can be particularly helpful when combined with appraisal of capacity to respond to possible critical plant conditions (i.e. critical alarms response scenarios). However, wearable physiological measurement tools such as eye tracking and EEG caps can be perceived as intrusive and not suitable for usage in daily operations. Therefore, this article examines the potential of using real-time data from process and operator-system interactions during abnormal scenarios that can be recorded and retrieved from the distributed control system's historian or process log, and their capacity to provide insight into operator behavior and predict their response outcomes, without intruding on daily tasks. Data for this study were obtained from a design of experiment using a formaldehyde production plant simulator and four human-in-the-loop experimental support configurations. A comparison between the different configurations in terms of both behaviour and performance is presented in this paper. A step-wise logistic regression and a Bayesian network models were used to achieve this objective. The results identified some predictive metrics and the paper discuss their value as precursor or predictor of overall system performance in alarm response scenarios. Knowledge of relevant and predictive behavioural metrics accessible in real time can better equip decision-makers to predict outcomes and provide timely support measures for operators.",
    "url": "https://arxiv.org/abs/2508.10917",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of real-time data from process and operator-system interactions to predict correct alarm responses by control room operators without intruding on their daily tasks. The study used data from a formaldehyde production plant simulator and different experimental support configurations to identify predictive metrics for operator behavior and performance during alarm response scenarios. The results highlight the value of using predictive behavioral metrics to better equip decision-makers in predicting outcomes and providing timely support measures for operators."
  },
  {
    "title": "Multimodal Quantitative Measures for Multiparty Behaviour Evaluation",
    "abstract": "Digital humans are emerging as autonomous agents in multiparty interactions, yet existing evaluation metrics largely ignore contextual coordination dynamics. We introduce a unified, intervention-driven framework for objective assessment of multiparty social behaviour in skeletal motion data, spanning three complementary dimensions: (1) synchrony via Cross-Recurrence Quantification Analysis, (2) temporal alignment via Multiscale Empirical Mode Decompositionbased Beat Consistency, and (3) structural similarity via Soft Dynamic Time Warping. We validate metric sensitivity through three theory-driven perturbations -- gesture kinematic dampening, uniform speech-gesture delays, and prosodic pitch-variance reduction-applied to $\\approx 145$ 30-second thin slices of group interactions from the DnD dataset. Mixed-effects analyses reveal predictable, joint-independent shifts: dampening increases CRQA determinism and reduces beat consistency, delays weaken cross-participant coupling, and pitch flattening elevates F0 Soft-DTW costs. A complementary perception study ($N=27$) compares judgments of full-video and skeleton-only renderings to quantify representation effects. Our three measures deliver orthogonal insights into spatial structure, timing alignment, and behavioural variability. Thereby forming a robust toolkit for evaluating and refining socially intelligent agents. Code available on \\href{this https URL}{GitHub}.",
    "url": "https://arxiv.org/abs/2508.10916",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces a framework for evaluating multiparty social behavior in digital humans using three quantitative measures: synchrony, temporal alignment, and structural similarity. The study validates the sensitivity of these metrics through perturbations in gesture kinematics, speech-gesture delays, and prosodic pitch variance. The findings show predictable shifts in behavior and offer a robust toolkit for assessing and improving socially intelligent agents in interactive environments."
  },
  {
    "title": "Generation and Evaluation in the Human Invention Process through the Lens of Game Design",
    "abstract": "The human ability to learn rules and solve problems has been a central concern of cognitive science research since the field's earliest days. But we do not just follow rules and solve problems given to us by others: we modify those rules, create new problems, and set new goals and tasks for ourselves and others. Arguably, even more than rule following and problem solving, human intelligence is about creatively breaking and stretching the rules, changing the game, and inventing new problems worth thinking about. Creating a good rule or a good problem depends not just on the ideas one can think up but on how one evaluates such proposals. Here, we study invention through the lens of game design. We focus particularly on the early stages of novice, \"everyday\" game creation, where the stakes are low. We draw on a dataset of over 450 human created games, created by participants who saw an initial seed set of two-player grid-based strategy games. We consider two different cognitive mechanisms that may be at work during the early processes of intuitive game invention: an associative proposal based on previous games one has seen and compute-bounded model-based evaluation that an everyday game creator may use to refine their initial draft proposals. In our preliminary work, we conduct a model-based analysis of how people invented new games based on prior experience and find that generated games are best described by a model which incorporates model-based estimates of game quality at a population level. Our work points to how human invention is based not only on what people propose, but how they evaluate and offers a computational toolkit to scale empirical studies of model-based simulation in open-ended human innovation.",
    "url": "https://arxiv.org/abs/2508.10914",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the human ability to invent new games through the lens of game design, focusing on the early stages of novice game creation. The study analyzes over 450 human-created games and identifies two cognitive mechanisms involved in the process: associative proposal based on previous games and model-based evaluation to refine initial proposals. The findings suggest that human invention is not only about generating ideas, but also about evaluating and refining them, providing insights into how people create and innovate in open-ended scenarios."
  },
  {
    "title": "Uncovering Latent Connections in Indigenous Heritage: Semantic Pipelines for Cultural Preservation in Brazil",
    "abstract": "Indigenous communities face ongoing challenges in preserving their cultural heritage, particularly in the face of systemic marginalization and urban development. In Brazil, the Museu Nacional dos Povos Indigenas through the Tainacan platform hosts the country's largest online collection of Indigenous objects and iconographies, providing a critical resource for cultural engagement. Using publicly available data from this repository, we present a data-driven initiative that applies artificial intelligence to enhance accessibility, interpretation, and exploration. We develop two semantic pipelines: a visual pipeline that models image-based similarity and a textual pipeline that captures semantic relationships from item descriptions. These embedding spaces are projected into two dimensions and integrated into an interactive visualization tool we also developed. In addition to similarity-based navigation, users can explore the collection through temporal and geographic lenses, enabling both semantic and contextualized perspectives. The system supports curatorial tasks, aids public engagement, and reveals latent connections within the collection. This work demonstrates how AI can ethically contribute to cultural preservation practices.",
    "url": "https://arxiv.org/abs/2508.10911",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on using artificial intelligence to enhance accessibility and exploration of Indigenous cultural heritage in Brazil through the Museu Nacional dos Povos Indigenas. By developing visual and textual semantic pipelines, the researchers were able to create an interactive visualization tool that allows users to navigate the collection based on similarity, temporal, and geographic perspectives. This AI-driven initiative not only supports curatorial tasks and public engagement but also uncovers latent connections within the collection, demonstrating the ethical contribution of AI to cultural preservation practices."
  },
  {
    "title": "Designing for Engaging Communication Between Parents and Young Adult Children Through Shared Music Experiences",
    "abstract": "This paper aims to foster social interaction between parents and young adult children living apart via music. Our approach transforms their music-listening moment into an opportunity to listen to the other's favorite songs and enrich interaction in their daily lives. To this end, we explore the current practice and needs of parent-child communication and the experience and perception of music-mediated interaction. Based on the findings, we developed DJ-Fam, a mobile application that enables parents and children to listen to their favorite songs and use them as conversation starters to foster parent-child interaction. From our deployment study with seven families over four weeks in South Korea, we show the potential of DJ-Fam to influence parent-child interaction and their mutual understanding and relationship positively. Specifically, DJ-Fam considerably increases the frequency of communication and diversifies the communication channels and topics, all of which are satisfactory to the participants.",
    "url": "https://arxiv.org/abs/2508.10907",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research explores using music as a tool to facilitate communication between parents and young adult children living apart. The development of the DJ-Fam mobile application allows parents and children to share and discuss their favorite songs, leading to increased frequency and diversity of communication. The study conducted in South Korea shows that DJ-Fam positively impacts parent-child interaction and relationship, highlighting the potential of music-mediated communication in enhancing family connections."
  },
  {
    "title": "How do Data Journalists Design Maps to Tell Stories?",
    "abstract": "Maps are essential to news media as they provide a familiar way to convey spatial context and present engaging narratives. However, the design of journalistic maps may be challenging, as editorial teams need to balance multiple aspects, such as aesthetics, the audience's expected data literacy, tight publication deadlines, and the team's technical skills. Data journalists often come from multiple areas and lack a cartography, data visualization, and data science background, limiting their competence in creating maps. While previous studies have examined spatial visualizations in data stories, this research seeks to gain a deeper understanding of the map design process employed by news outlets. To achieve this, we strive to answer two specific research questions: what is the design space of journalistic maps? and how do editorial teams produce journalistic map articles? To answer the first one, we collected and analyzed a large corpus of 462 journalistic maps used in news articles from five major news outlets published over three months. As a result, we created a design space comprised of eight dimensions that involved both properties describing the articles' aspects and the visual/interactive features of maps. We approach the second research question via semi-structured interviews with four data journalists who create data-driven articles daily. Through these interviews, we identified the most common design rationales made by editorial teams and potential gaps in current practices. We also collected the practitioners' feedback on our design space to externally validate it. With these results, we aim to provide researchers and journalists with empirical data to design and study journalistic maps.",
    "url": "https://arxiv.org/abs/2508.10903",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores how data journalists design maps to tell stories in news media. The study analyzes a large corpus of 462 journalistic maps from major news outlets and identifies eight dimensions in the design space of these maps. Through interviews with data journalists, common design rationales and potential gaps in current practices are identified, providing empirical data to help researchers and journalists create and study journalistic maps effectively."
  },
  {
    "title": "Inclusion Arena: An Open Platform for Evaluating Large Foundation Models with Real-World Apps",
    "abstract": "Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) have ushered in a new era of AI capabilities, demonstrating near-human-level performance across diverse scenarios. While numerous benchmarks (e.g., MMLU) and leaderboards (e.g., Chatbot Arena) have been proposed to help evolve the development of LLMs and MLLMs, most rely on static datasets or crowdsourced general-domain prompts, often falling short of reflecting performance in real-world applications. To bridge this critical gap, we present Inclusion Arena, a live leaderboard that ranks models based on human feedback collected directly from AI-powered applications. Our platform integrates pairwise model comparisons into natural user interactions, ensuring evaluations reflect practical usage scenarios. For robust model ranking, we employ the Bradley-Terry model augmented with two key innovations: (1) Placement Matches, a cold-start mechanism to quickly estimate initial ratings for newly integrated models, and (2) Proximity Sampling, an intelligent comparison strategy that prioritizes battles between models of similar capabilities to maximize information gain and enhance rating stability. Extensive empirical analyses and simulations demonstrate that Inclusion Arena yields reliable and stable rankings, exhibits higher data transitivity compared to general crowdsourced datasets, and significantly mitigates the risk of malicious manipulation. By fostering an open alliance between foundation models and real-world applications, Inclusion Arena aims to accelerate the development of LLMs and MLLMs truly optimized for practical, user-centric deployments. The platform is publicly accessible at this https URL.",
    "url": "https://arxiv.org/abs/2508.11452",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces Inclusion Arena, a live leaderboard for evaluating large language models and multimodal large language models based on human feedback from AI-powered applications. The platform uses pairwise model comparisons in natural user interactions to rank models, incorporating innovative techniques like Placement Matches and Proximity Sampling for robust and stable rankings. The findings show that Inclusion Arena provides reliable rankings, enhances data transitivity, and reduces the risk of manipulation, ultimately aiming to accelerate the development of AI models optimized for real-world applications."
  },
  {
    "title": "An Exploratory Study on Crack Detection in Concrete through Human-Robot Collaboration",
    "abstract": "Structural inspection in nuclear facilities is vital for maintaining operational safety and integrity. Traditional methods of manual inspection pose significant challenges, including safety risks, high cognitive demands, and potential inaccuracies due to human limitations. Recent advancements in Artificial Intelligence (AI) and robotic technologies have opened new possibilities for safer, more efficient, and accurate inspection methodologies. Specifically, Human-Robot Collaboration (HRC), leveraging robotic platforms equipped with advanced detection algorithms, promises significant improvements in inspection outcomes and reductions in human workload. This study explores the effectiveness of AI-assisted visual crack detection integrated into a mobile Jackal robot platform. The experiment results indicate that HRC enhances inspection accuracy and reduces operator workload, resulting in potential superior performance outcomes compared to traditional manual methods.",
    "url": "https://arxiv.org/abs/2508.11404",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores the use of AI-assisted visual crack detection in concrete through Human-Robot Collaboration (HRC) using a mobile Jackal robot platform. The results show that HRC enhances inspection accuracy and reduces operator workload, suggesting potential superior performance outcomes compared to traditional manual methods. This research highlights the significance of AI and robotic technologies in improving safety, efficiency, and accuracy in structural inspections in nuclear facilities."
  },
  {
    "title": "CRAFT-GUI: Curriculum-Reinforced Agent For GUI Tasks",
    "abstract": "As autonomous agents become adept at understanding and interacting with graphical user interface (GUI) environments, a new era of automated task execution is emerging. Recent studies have demonstrated that Reinforcement Learning (RL) can effectively enhance agents' performance in dynamic interactive GUI environments. However, these methods face two key limitations: (1) they overlook the significant variation in difficulty across different GUI tasks by treating the entire training data as a uniform set, which hampers the agent's ability to adapt its learning process; and (2) most approaches collapse task-specific nuances into a single, coarse reward, leaving the agent with a uniform signal that yields inefficient policy updates. To address these limitations, we propose CRAFT-GUI, a curriculum learning framework based on Group Relative Policy Optimization (GRPO) that explicitly accounts for the varying difficulty across trajectories. To enable more fine-grained policy optimization, we design a reward function that combines simple rule-based signals with model-judged evaluation, providing richer and more nuanced feedback during training. Experimental results demonstrate that our method achieves significant improvements over previous state-of-the-art approaches, outperforming them by 5.6% on public benchmarks Android Control and 10.3% on our internal online benchmarks, respectively. These findings empirically validate the effectiveness of integrating reinforcement learning with curriculum learning in GUI interaction tasks.",
    "url": "https://arxiv.org/abs/2508.11360",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces CRAFT-GUI, a curriculum learning framework that addresses the limitations of current reinforcement learning methods in GUI tasks. By considering the varying difficulty across different tasks and designing a reward function that provides more nuanced feedback, CRAFT-GUI achieves significant improvements over previous state-of-the-art approaches. The findings demonstrate the effectiveness of integrating reinforcement learning with curriculum learning in GUI interaction tasks, paving the way for more efficient and adaptive automated task execution in dynamic interactive GUI environments."
  },
  {
    "title": "UWB-PostureGuard: A Privacy-Preserving RF Sensing System for Continuous Ergonomic Sitting Posture Monitoring",
    "abstract": "Improper sitting posture during prolonged computer use has become a significant public health concern. Traditional posture monitoring solutions face substantial barriers, including privacy concerns with camera-based systems and user discomfort with wearable sensors. This paper presents UWB-PostureGuard, a privacy-preserving ultra-wideband (UWB) sensing system that advances mobile technologies for preventive health management through continuous, contactless monitoring of ergonomic sitting posture. Our system leverages commercial UWB devices, utilizing comprehensive feature engineering to extract multiple ergonomic sitting posture features. We develop PoseGBDT to effectively capture temporal dependencies in posture patterns, addressing limitations of traditional frame-wise classification approaches. Extensive real-world evaluation across 10 participants and 19 distinct postures demonstrates exceptional performance, achieving 99.11% accuracy while maintaining robustness against environmental variables such as clothing thickness, additional devices, and furniture configurations. Our system provides a scalable, privacy-preserving mobile health solution on existing platforms for proactive ergonomic management, improving quality of life at low costs.",
    "url": "https://arxiv.org/abs/2508.11115",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research paper introduces UWB-PostureGuard, a privacy-preserving RF sensing system that monitors ergonomic sitting posture continuously without the need for cameras or wearable sensors. The system utilizes UWB technology and advanced feature engineering to achieve high accuracy in identifying sitting postures, even in real-world settings with various environmental variables. The findings suggest that UWB-PostureGuard could be a scalable and cost-effective solution for proactive ergonomic management, addressing public health concerns related to prolonged computer use."
  },
  {
    "title": "Utilizing Vision-Language Models as Action Models for Intent Recognition and Assistance",
    "abstract": "Human-robot collaboration requires robots to quickly infer user intent, provide transparent reasoning, and assist users in achieving their goals. Our recent work introduced GUIDER, our framework for inferring navigation and manipulation intents. We propose augmenting GUIDER with a vision-language model (VLM) and a text-only language model (LLM) to form a semantic prior that filters objects and locations based on the mission prompt. A vision pipeline (YOLO for object detection and the Segment Anything Model for instance segmentation) feeds candidate object crops into the VLM, which scores their relevance given an operator prompt; in addition, the list of detected object labels is ranked by a text-only LLM. These scores weight the existing navigation and manipulation layers of GUIDER, selecting context-relevant targets while suppressing unrelated objects. Once the combined belief exceeds a threshold, autonomy changes occur, enabling the robot to navigate to the desired area and retrieve the desired object, while adapting to any changes in the operator's intent. Future work will evaluate the system on Isaac Sim using a Franka Emika arm on a Ridgeback base, with a focus on real-time assistance.",
    "url": "https://arxiv.org/abs/2508.11093",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces a framework called GUIDER for inferring navigation and manipulation intents in human-robot collaboration. By augmenting GUIDER with a vision-language model and a text-only language model, the system can filter objects and locations based on the mission prompt, enabling the robot to select context-relevant targets and suppress unrelated objects. The proposed system allows for quick inference of user intent, transparent reasoning, and assistance in achieving goals, with potential applications in real-time assistance scenarios."
  },
  {
    "title": "Not There Yet: Evaluating Vision Language Models in Simulating the Visual Perception of People with Low Vision",
    "abstract": "Advances in vision language models (VLMs) have enabled the simulation of general human behavior through their reasoning and problem solving capabilities. However, prior research has not investigated such simulation capabilities in the accessibility domain. In this paper, we evaluate the extent to which VLMs can simulate the vision perception of low vision individuals when interpreting images. We first compile a benchmark dataset through a survey study with 40 low vision participants, collecting their brief and detailed vision information and both open-ended and multiple-choice image perception and recognition responses to up to 25 images. Using these responses, we construct prompts for VLMs (GPT-4o) to create simulated agents of each participant, varying the included information on vision information and example image responses. We evaluate the agreement between VLM-generated responses and participants' original answers. Our results indicate that VLMs tend to infer beyond the specified vision ability when given minimal prompts, resulting in low agreement (0.59). The agreement between the agent' and participants' responses remains low when only either the vision information (0.59) or example image responses (0.59) are provided, whereas a combination of both significantly increase the agreement (0.70, p < 0.0001). Notably, a single example combining both open-ended and multiple-choice responses, offers significant performance improvements over either alone (p < 0.0001), while additional examples provided minimal benefits (p > 0.05).",
    "url": "https://arxiv.org/abs/2508.10972",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research evaluates the ability of vision language models (VLMs) to simulate the visual perception of individuals with low vision when interpreting images. The study found that VLMs tend to infer beyond the specified vision ability when given minimal prompts, resulting in low agreement with participants' original answers. However, providing a combination of vision information and example image responses significantly increased the agreement between VLM-generated responses and participants' answers, highlighting the importance of including both types of information in simulations of low vision perception."
  },
  {
    "title": "Topological Structure Description for Artcode Detection Using the Shape of Orientation Histogram",
    "abstract": "The increasing ubiquity of smartphones and resurgence of VR/AR techniques, it is expected that our everyday environment may soon be decorating with objects connecting with virtual elements. Alerting to the presence of these objects is therefore the first step for motivating follow-up further inspection and triggering digital material attached to the objects. This work studies a special kind of these objects -- Artcodes -- a human-meaningful and machine-readable decorative markers that camouflage themselves with freeform appearance by encoding information into their topology. We formulate this problem of recongising the presence of Artcodes as Artcode proposal detection, a distinct computer vision task that classifies topologically similar but geometrically and semantically different objects as a same class. To deal with this problem, we propose a new feature descriptor, called the shape of orientation histogram, to describe the generic topological structure of an Artcode. We collect datasets and conduct comprehensive experiments to evaluate the performance of the Artcode detection proposer built upon this new feature vector. Our experimental results show the feasibility of the proposed feature vector for representing topological structures and the effectiveness of the system for detecting Artcode proposals. Although this work is an initial attempt to develop a feature-based system for detecting topological objects like Artcodes, it would open up new interaction opportunities and spark potential applications of topological object detection.",
    "url": "https://arxiv.org/abs/2508.10942",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on detecting Artcodes, which are markers that encode information into their topology and blend into their surroundings. The study introduces a new feature descriptor, the shape of orientation histogram, to represent the topological structure of Artcodes. Experimental results demonstrate the effectiveness of this feature descriptor in detecting Artcode proposals, suggesting potential applications for topological object detection in interactive environments."
  },
  {
    "title": "Privacy Enhancement for Gaze Data Using a Noise-Infused Autoencoder",
    "abstract": "We present a privacy-enhancing mechanism for gaze signals using a latent-noise autoencoder that prevents users from being re-identified across play sessions without their consent, while retaining the usability of the data for benign tasks. We evaluate privacy-utility trade-offs across biometric identification and gaze prediction tasks, showing that our approach significantly reduces biometric identifiability with minimal utility degradation. Unlike prior methods in this direction, our framework retains physiologically plausible gaze patterns suitable for downstream use, which produces favorable privacy-utility trade-off. This work advances privacy in gaze-based systems by providing a usable and effective mechanism for protecting sensitive gaze data.",
    "url": "https://arxiv.org/abs/2508.10918",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces a privacy-enhancing mechanism for gaze data using a noise-infused autoencoder, which prevents re-identification of users across play sessions without their consent. The study demonstrates that this approach significantly reduces biometric identifiability while maintaining usability for benign tasks, improving privacy-utility trade-offs in gaze-based systems. Unlike previous methods, this framework retains physiologically plausible gaze patterns, making it a valuable tool for protecting sensitive gaze data in a usable and effective manner."
  },
  {
    "title": "\"I Want My Chart to Be Just for Me\": Community-Engaged Design to Support Outpatient Healthcare for Resettled Communities",
    "abstract": "Individuals resettled in a new environment often face challenges in accessing adequate healthcare services, particularly within the complex processes of outpatient clinic care. Cultural differences, language barriers, and low socioeconomic status contribute to these difficulties. While previous studies have identified barriers and proposed technology-mediated solutions for resettled populations, many focus on addressing deficits rather than building on the strengths these communities already possess, which limits the sustainability and relevance of these solutions in everyday life. We conducted two community-based participatory design workshops with 30 Hmong community members in a large metropolitan area in the US. Through this process, we identified four types of assets the community has gradually developed, including intergenerational support for health management and storytelling-based communication practices that facilitate relatable and culturally grounded interactions. We show how participatory design workshops can foster asset-based approaches, and discuss design implications for technologies that leverage patients' existing strengths to support their health management during outpatient visits.",
    "url": "https://arxiv.org/abs/2508.10757",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the challenges faced by resettled communities in accessing outpatient healthcare services and emphasizes the importance of building on the strengths of these communities rather than focusing solely on deficits. Through community-based design workshops with Hmong community members, the study identified existing assets such as intergenerational support for health management and storytelling-based communication practices. The findings suggest that leveraging these strengths through technology can improve the healthcare experience for resettled populations during outpatient visits."
  },
  {
    "title": "Visualization of Electronic Health Record Sequences at Scale",
    "abstract": "We present ParcoursVis, a Progressive Visual Analytics tool designed to explore electronic health record sequences of patients at scale. Existing tools process and aggregate the whole dataset upfront before showing the visualization, taking a time proportional to the data size. Therefore, to remain interactive, existing tools are limited to data sizes that can be processed in under a few seconds to meet the latency constraints of human attention. To overcome this limitation and scale to larger sizes, ParcoursVis relies on a progressive algorithm that quickly shows an approximate initial result of the aggregation, visualized as an Icicle tree, and improves it iteratively, updating the visualization until the whole computation is done. With its architecture, ParcoursVis remains interactive while visualizing the sequences of tens of millions of patients, each described with thousands of events; three to five orders of magnitude more than similar systems. Managing large datasets allows for exploring rare medical conditions or unexpected patient pathways, contributing to improving treatments. We describe the algorithms we use and our evaluation concerning their scalability, convergence, and stability. We also report on a set of guidelines to support visualization designers in developing scalable progressive systems. ParcoursVis already allows practitioners to perform analyses on two large real medical datasets. Our prototype is open-source.",
    "url": "https://arxiv.org/abs/2508.10700",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces ParcoursVis, a Progressive Visual Analytics tool that can explore electronic health record sequences of patients at a large scale. By utilizing a progressive algorithm, ParcoursVis can visualize sequences of tens of millions of patients with thousands of events, allowing for the exploration of rare medical conditions and unexpected patient pathways. The tool's scalability and interactivity make it a valuable resource for improving treatments and supporting visualization designers in developing scalable progressive systems."
  },
  {
    "title": "Gaze-Based Indicators of Driver Cognitive Distraction: Effects of Different Traffic Conditions and Adaptive Cruise Control Use",
    "abstract": "In this simulator study, we investigate how gaze parameters reflect driver cognitive distraction under varying traffic conditions and adaptive cruise control (ACC) use. Participants completed six driving scenarios that combined two levels of cognitive distraction (with/without mental calculations) and three levels of driving environment complexity. Throughout the experiment, participants were free to activate or deactivate an ACC. We analyzed two gaze-based indicators of driver cognitive distraction: the percent road center, and the gaze dispersions (horizontal and vertical). Our results show that vertical gaze dispersion increases with traffic complexity, while ACC use leads to gaze concentration toward the road center. Cognitive distraction reduces road center gaze and increases vertical dispersion. Complementary analyses revealed that these observations actually arise mainly between mental calculations, while periods of mental calculations are characterized by a temporary increase in gaze concentration.",
    "url": "https://arxiv.org/abs/2508.10624",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study examines how gaze parameters can indicate driver cognitive distraction in different traffic conditions and when using adaptive cruise control (ACC). The results show that vertical gaze dispersion increases with traffic complexity, ACC use leads to gaze concentration towards the road center, and cognitive distraction decreases road center gaze and increases vertical dispersion. The study also found that periods of mental calculations result in temporary increases in gaze concentration. These findings highlight the importance of considering gaze-based indicators in assessing driver distraction and the impact of ACC on driver behavior."
  },
  {
    "title": "Are Electrodermal Activity-Based Indicators of Driver Cognitive Distraction Robust to Varying Traffic Conditions and Adaptive Cruise Control Use?",
    "abstract": "In this simulator study, we investigate whether and how electrodermal activity (EDA) reflects driver cognitive distraction under varying traffic conditions and adaptive cruise control (ACC) use. Participants drove in six scenarios, combining two levels of cognitive distraction (presence/absence of a mental calculation task) and three levels of driving environment complexity (different traffic conditions). Throughout the experiment, they were free to activate or deactivate ACC (ACC use, two levels). We analyzed three EDA-based indicators of cognitive distraction: SCL (mean skin conductance level), SCR amplitude (mean amplitude of skin conductance responses), and SCR rate (rate of skin conductance responses). Results indicate that all three indicators were significantly influenced by cognitive distraction and ACC use, while environment complexity influenced SCL and SCR amplitude, but not SCR rate. These findings suggest that EDA-based indicators reflect variations in drivers' mental workload due not only to cognitive distraction, but also to driving environment and automation use.",
    "url": "https://arxiv.org/abs/2508.10620",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study examined how electrodermal activity (EDA) can indicate driver cognitive distraction in varying traffic conditions and with adaptive cruise control (ACC) use. The results showed that EDA-based indicators such as mean skin conductance level, skin conductance response amplitude, and skin conductance response rate were significantly affected by cognitive distraction and ACC use. Additionally, the complexity of the driving environment also influenced EDA indicators, suggesting that EDA can reflect changes in mental workload due to distractions, driving conditions, and automation use."
  },
  {
    "title": "DEV: A Driver-Environment-Vehicle Closed-Loop Framework for Risk-Aware Adaptive Automation of Driving",
    "abstract": "The increasing integration of automation in vehicles aims to enhance both safety and comfort, but it also introduces new risks, including driver disengagement, reduced situation awareness, and mode confusion. In this work, we propose the DEV framework, a closed-loop framework for risk-aware adaptive driving automation that captures the dynamic interplay between the driver, the environment, and the vehicle. The framework promotes to continuously adjusting the operational level of automation based on a risk management strategy. The real-time risk assessment supports smoother transitions and effective cooperation between the driver and the automation system. Furthermore, we introduce a nomenclature of indexes corresponding to each core component, namely driver involvement, environment complexity, and vehicle engagement, and discuss how their interaction influences driving risk. The DEV framework offers a comprehensive perspective to align multidisciplinary research efforts and guide the development of dynamic, risk-aware driving automation systems.",
    "url": "https://arxiv.org/abs/2508.10618",
    "journal": "arXiv cs.HC",
    "ai_summary": "The DEV framework is proposed as a closed-loop system for risk-aware adaptive driving automation, taking into account the dynamic interaction between the driver, environment, and vehicle. By continuously adjusting the level of automation based on a risk management strategy, the framework aims to improve driver-automation cooperation and reduce risks such as disengagement and reduced situation awareness. The introduction of indexes for driver involvement, environment complexity, and vehicle engagement provides a comprehensive perspective for developing dynamic, risk-aware driving automation systems."
  },
  {
    "title": "Differential Physiological Responses to Proxemic and Facial Threats in Virtual Avatar Interactions",
    "abstract": "Proxemics, the study of spatial behavior, is fundamental to social interaction and increasingly relevant for virtual reality (VR) applications. While previous research has established that users respond to personal space violations in VR similarly as in real-world settings, phase-specific physiological responses and the modulating effects of facial expressions remain understudied. We investigated physiological and subjective responses to personal space violations by virtual avatars, to understand how threatening facial expressions and interaction phases (approach vs. standing) influence these responses. Sixteen participants experienced a 2x2 factorial design manipulating Personal Space (intrusion vs. respect) and Facial Expression (neutral vs. angry) while we recorded skin conductance response (SCR), heart rate variability (HRV), and discomfort ratings. Personal space boundaries were individually calibrated using a stop-distance procedure. Results show that SCR responses are significantly higher during the standing phase compared to the approach phase when personal space was violated, indicating that prolonged proximity within personal space boundaries is more physiologically arousing than the approach itself. Angry facial expressions significantly reduced HRV, reflecting decreased parasympathetic activity, and increased discomfort ratings, but did not amplify SCR responses. These findings demonstrate that different physiological modalities capture distinct aspects of proxemic responses: SCR primarily reflects spatial boundary violations, while HRV responds to facial threat cues. Our results provide insights for developing comprehensive multi-modal assessments of social behavior in virtual environments and inform the design of more realistic avatar interactions.",
    "url": "https://arxiv.org/abs/2508.10586",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores how individuals respond physiologically to personal space violations by virtual avatars, focusing on the effects of facial expressions and interaction phases. The study found that prolonged proximity within personal space boundaries is more physiologically arousing than the approach itself, with angry facial expressions reducing heart rate variability and increasing discomfort ratings. These findings suggest that different physiological responses capture distinct aspects of proxemic responses, providing insights for developing more realistic avatar interactions in virtual environments."
  },
  {
    "title": "Reproducible Physiological Features in Affective Computing: A Preliminary Analysis on Arousal Modeling",
    "abstract": "In Affective Computing, a key challenge lies in reliably linking subjective emotional experiences with objective physiological markers. This preliminary study addresses the issue of reproducibility by identifying physiological features from cardiovascular and electrodermal signals that are associated with continuous self-reports of arousal levels. Using the Continuously Annotated Signal of Emotion dataset, we analyzed 164 features extracted from cardiac and electrodermal signals of 30 participants exposed to short emotion-evoking videos. Feature selection was performed using the Terminating-Random Experiments (T-Rex) method, which performs variable selection systematically controlling a user-defined target False Discovery Rate. Remarkably, among all candidate features, only two electrodermal-derived features exhibited reproducible and statistically significant associations with arousal, achieving a 100\\% confirmation rate. These results highlight the necessity of rigorous reproducibility assessments in physiological features selection, an aspect often overlooked in Affective Computing. Our approach is particularly promising for applications in safety-critical environments requiring trustworthy and reliable white box models, such as mental disorder recognition and human-robot interaction systems.",
    "url": "https://arxiv.org/abs/2508.10561",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study focuses on identifying physiological features that are consistently associated with self-reported arousal levels in affective computing. Using a dataset of participants exposed to emotion-evoking videos, the researchers found that only two electrodermal-derived features showed reproducible and statistically significant associations with arousal. This highlights the importance of rigorous reproducibility assessments in selecting physiological features for applications in safety-critical environments like mental disorder recognition and human-robot interaction systems."
  },
  {
    "title": "Stress Detection from Multimodal Wearable Sensor Data",
    "abstract": "Human-Computer Interaction (HCI) is a multi-modal, interdisciplinary field focused on designing, studying, and improving the interactions between people and computer systems. This involves the design of systems that can recognize, interpret, and respond to human emotions or stress. Developing systems to monitor and react to stressful events can help prevent severe health implications caused by long-term stress exposure. Currently, the publicly available datasets and standardized protocols for data collection in this domain are limited. Therefore, we introduce a multi-modal dataset intended for wearable affective computing research, specifically the development of automated stress recognition systems. We systematically review the publicly available datasets recorded in controlled laboratory settings. Based on a proposed framework for the standardization of stress experiments and data collection, we collect physiological and motion signals from wearable devices (e.g., electrodermal activity, photoplethysmography, three-axis accelerometer). During the experimental protocol, we differentiate between the following four affective/activity states: neutral, physical, cognitive stress, and socio-evaluative stress. These different phases are meticulously labeled, allowing for detailed analysis and reconstruction of each experiment. Meta-data such as body positions, locations, and rest phases are included as further annotations. In addition, we collect psychological self-assessments after each stressor to evaluate subjects' affective states. The contributions of this paper are twofold: 1) a novel multi-modal, publicly available dataset for automated stress recognition, and 2) a benchmark for stress detection with 89\\% in a binary classification (baseline vs. stress) and 82\\% in a multi-class classification (baseline vs. stress vs. physical exercise).",
    "url": "https://arxiv.org/abs/2508.10468",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on developing automated stress recognition systems using multi-modal wearable sensor data. The study introduces a new dataset for affective computing research, with detailed annotations and standardized protocols for stress experiments. The results show promising accuracy rates in stress detection, highlighting the significance of this work in preventing health implications caused by long-term stress exposure."
  },
  {
    "title": "MCP2OSC: Parametric Control by Natural Language",
    "abstract": "Text prompts enable intuitive content creation but may fall short in achieving high precision for intricate tasks; knob or slider controls offer precise adjustments at the cost of increased complexity. To address the gap between knobs and prompts, a new MCP (Model Context Protocol) server and a unique set of prompt design criteria are presented to enable exploring parametric OSC (OpenSoundControl) control by natural language prompts. Demonstrated by 14 practical QA examples with best practices and the generalized prompt templates, this study finds Claude integrated with the MCP2OSC server effective in generating OSC messages by natural language, interpreting, searching, and visualizing OSC messages, validating and debugging OSC messages, and managing OSC address patterns. MCP2OSC enhances human-machine collaboration by leveraging LLM (Large Language Model) to handle intricate OSC development tasks, and by empowering human creativity with an intuitive language interface featuring flexible precision controls: a prompt-based OSC tool. This study provides a novel perspective on the creative MCP application at the network protocol level by utilizing LLM's strength in directly processing and generating human-readable OSC messages. The results suggest its potential for a LLM-based universal control mechanism for multimedia devices.",
    "url": "https://arxiv.org/abs/2508.10414",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces MCP2OSC, a system that allows for parametric control through natural language prompts, bridging the gap between intuitive text prompts and precise knob or slider controls. The study demonstrates the effectiveness of MCP2OSC in generating and managing OSC messages, validating and debugging OSC messages, and managing OSC address patterns, enhancing human-machine collaboration and empowering creativity. The results suggest the potential for MCP2OSC to serve as a universal control mechanism for multimedia devices, utilizing LLM's strength in processing and generating human-readable OSC messages."
  },
  {
    "title": "\"Here Comes the Makeup Tutorial You Asked For!\": Exploring Communication Strategies and Viewer Engagement in Beauty Videos on Rednote",
    "abstract": "More and more people, especially females, create and view beauty videos covering topics like makeup tutorials and vlogs on social media platforms. Understanding the communication strategies that creators use in these videos and how they affect viewers' engagement can help spread beauty knowledge. By coding 352 beauty videos in Rednote, this study presents a comprehensive taxonomy of communication strategies used by the creators, such as using home as the video background and displaying makeup effects when starting the narrative at the beginning. We further label and computationally classify six categories of comments that reveal viewers' engagement with beauty videos. The regression analyses reveal the effects of beauty video communication strategies on viewers' engagement; for example, calling viewers to take action at the end tends to attract more comments that debate the product's efficacy. We discuss insights into fostering the creation of beauty videos and the communication of beauty knowledge.",
    "url": "https://arxiv.org/abs/2508.10364",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the communication strategies used by creators in beauty videos on Rednote and how they impact viewer engagement. By analyzing 352 videos, the study identifies key strategies such as using home backgrounds and displaying makeup effects at the beginning. The findings suggest that certain strategies, like prompting viewers to take action, can increase engagement and discussion among viewers, providing insights for creators looking to enhance their beauty videos and knowledge communication."
  },
  {
    "title": "Mental Effort Estimation in Motion Exploration and Concept Generation Design Tasks using Inter-Band Relative Power Difference of EEG",
    "abstract": "Conceptual design is a cognitively complex task, especially in the engineering design of products having relative motion between components. Designers prefer sketching as a medium for conceptual design and use gestures and annotations to represent such relative motion. Literature suggests that static representations of motion in sketches may not achieve the intended functionality when realised, because it primarily depends on the designers' mental capabilities for motion simulation. Thus, it is important to understand the cognitive phenomena when designers are exploring concepts of articulated products. The current work is an attempt to understand design neurocognition by categorising the tasks and measuring the mental effort involved in these tasks using EEG. The analysis is intended to validate design intervention tools to support the conceptual design involving motion exploration. A novel EEG-based metric, inter-Band Relative Power Difference (inter-BRPD), is introduced to quantify mental effort. A design experiment is conducted with 32 participants, where they have to perform one control task and 2 focus tasks corresponding to the motion exploration task (MET) and the concept generation task (CGT), respectively. EEG data is recorded during the 3 tasks, cleaned, processed and analysed using the MNE library in Python. It is observed from the results that inter-BRPD captures the essence of mental effort with half the number of conventionally used parameters. The reliability and efficacy of the inter-BRPD metric are also statistically validated against literature-based cognitive metrics. With these new insights, the study opens up possibilities for creating support for conceptual design and its evaluation.",
    "url": "https://arxiv.org/abs/2508.10353",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research aims to understand the cognitive processes involved in conceptual design tasks, specifically focusing on motion exploration and concept generation. Using EEG data and a novel metric called inter-Band Relative Power Difference (inter-BRPD), the study found that mental effort can be accurately quantified with fewer parameters. The results suggest that this new metric could be a valuable tool for supporting conceptual design tasks and evaluating design interventions in the future."
  },
  {
    "title": "Beyond Self-Regulated Learning Processes: Unveiling Hidden Tactics in Generative AI-Assisted Writing",
    "abstract": "The integration of Generative AI (GenAI) into education is reshaping how students learn, making self-regulated learning (SRL) - the ability to plan, monitor, and adapt one's learning - more important than ever. To support learners in these new contexts, it is essential to understand how SRL unfolds during interaction with GenAI tools. Learning analytics offers powerful techniques for analyzing digital trace data to infer SRL behaviors. However, existing approaches often assume SRL processes are linear, segmented, and non-overlapping-assumptions that overlook the dynamic, recursive, and non-linear nature of real-world learning. We address this by conceptualizing SRL as a layered system: observable learning patterns reflect hidden tactics (short, purposeful action states), which combine into broader SRL strategies. Using Hidden Markov Models (HMMs), we analyzed trace data from higher education students engaged in GenAI-assisted academic writing. We identified three distinct groups of learners, each characterized by different SRL strategies. These groups showed significant differences in performance, indicating that students' use of different SRL strategies in GenAI-assisted writing led to varying task outcomes. Our findings advance the methodological toolkit for modeling SRL and inform the design of adaptive learning technologies that more effectively support learners in GenAI-enhanced educational environments.",
    "url": "https://arxiv.org/abs/2508.10310",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the interaction between students and Generative AI tools in education, emphasizing the importance of understanding self-regulated learning (SRL) processes in this context. By analyzing digital trace data using Hidden Markov Models (HMMs), the study identifies different SRL strategies used by students in GenAI-assisted academic writing, leading to varying task outcomes. These findings contribute to the development of adaptive learning technologies that can better support learners in GenAI-enhanced educational environments."
  },
  {
    "title": "Artificial Emotion: A Survey of Theories and Debates on Realising Emotion in Artificial Intelligence",
    "abstract": "Affective Computing (AC) has enabled Artificial Intelligence (AI) systems to recognise, interpret, and respond to human emotions - a capability also known as Artificial Emotional Intelligence (AEI). It is increasingly seen as an important component of Artificial General Intelligence (AGI). We discuss whether in order to peruse this goal, AI benefits from moving beyond emotion recognition and synthesis to develop internal emotion-like states, which we term as Artificial Emotion (AE). This shift potentially allows AI to benefit from the paradigm of `inner emotions' in ways we - as humans - do. Although recent research shows early signs that AI systems may exhibit AE-like behaviours, a clear framework for how emotions can be realised in AI remains underexplored. In this paper, we discuss potential advantages of AE in AI, review current manifestations of AE in machine learning systems, examine emotion-modulated architectures, and summarise mechanisms for modelling and integrating AE into future AI. We also explore the ethical implications and safety risks associated with `emotional' AGI, while concluding with our opinion on how AE could be beneficial in the future.",
    "url": "https://arxiv.org/abs/2508.10286",
    "journal": "arXiv cs.HC",
    "ai_summary": "The abstract discusses the concept of Artificial Emotion (AE) in Artificial Intelligence (AI) systems, which goes beyond emotion recognition and synthesis to develop internal emotion-like states. The paper explores the potential advantages of AE in AI, reviews current manifestations of AE in machine learning systems, and discusses the ethical implications and safety risks associated with 'emotional' AGI. The authors conclude with their opinion on how AE could be beneficial in the future of AI research."
  },
  {
    "title": "Facilitating Longitudinal Interaction Studies of AI Systems",
    "abstract": "UIST researchers develop tools to address user challenges. However, user interactions with AI evolve over time through learning, adaptation, and repurposing, making one time evaluations insufficient. Capturing these dynamics requires longer-term studies, but challenges in deployment, evaluation design, and data collection have made such longitudinal research difficult to implement. Our workshop aims to tackle these challenges and prepare researchers with practical strategies for longitudinal studies. The workshop includes a keynote, panel discussions, and interactive breakout groups for discussion and hands-on protocol design and tool prototyping sessions. We seek to foster a community around longitudinal system research and promote it as a more embraced method for designing, building, and evaluating UIST tools.",
    "url": "https://arxiv.org/abs/2508.10252",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research abstract discusses the importance of conducting longitudinal studies to understand how user interactions with AI systems evolve over time. The researchers aim to address challenges in deployment, evaluation design, and data collection to facilitate longer-term studies. The workshop aims to provide practical strategies for researchers to conduct longitudinal research and promote it as a valuable method for designing and evaluating UIST tools."
  },
  {
    "title": "Personalized Real-time Jargon Support for Online Meetings",
    "abstract": "Effective interdisciplinary communication is frequently hindered by domain-specific jargon. To explore the jargon barriers in-depth, we conducted a formative diary study with 16 professionals, revealing critical limitations in current jargon-management strategies during workplace meetings. Based on these insights, we designed ParseJargon, an interactive LLM-powered system providing real-time personalized jargon identification and explanations tailored to users' individual backgrounds. A controlled experiment comparing ParseJargon against baseline (no support) and general-purpose (non-personalized) conditions demonstrated that personalized jargon support significantly enhanced participants' comprehension, engagement, and appreciation of colleagues' work, whereas general-purpose support negatively affected engagement. A follow-up field study validated ParseJargon's usability and practical value in real-time meetings, highlighting both opportunities and limitations for real-world deployment. Our findings contribute insights into designing personalized jargon support tools, with implications for broader interdisciplinary and educational applications.",
    "url": "https://arxiv.org/abs/2508.10239",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the barriers to effective communication caused by domain-specific jargon in workplace meetings. The study found that personalized jargon support, provided by the ParseJargon system, significantly improved participants' comprehension, engagement, and appreciation of colleagues' work compared to no support or general-purpose support. The findings suggest the potential for personalized jargon support tools to enhance interdisciplinary communication in various settings."
  }
]