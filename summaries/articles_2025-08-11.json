[
  {
    "title": "Non-programmers Assessing AI-Generated Code: A Case Study of Business Users Analyzing Data",
    "abstract": "Non-technical end-users increasingly rely on AI code generation to perform technical tasks like data analysis. However, large language models (LLMs) remain unreliable, and it is unclear whether end-users can effectively identify model errors $\\unicode{x2014}$ especially in realistic and domain-specific scenarios. We surveyed marketing and sales professionals to assess their ability to critically evaluate LLM-generated analyses of marketing data. Participants were shown natural language explanations of the AI's code, repeatedly informed the AI often makes mistakes, and explicitly prompted to identify them. Yet, participants frequently failed to detect critical flaws that could compromise decision-making, many of which required no technical knowledge to recognize. To investigate why, we reformatted AI responses into clearly delineated steps and provided alternative approaches for each decision to support critical evaluation. While these changes had a positive effect, participants often struggled to reason through the AI's steps and alternatives. Our findings suggest that business professionals cannot reliably verify AI-generated data analyses on their own and explore reasons why to inform future designs. As non-programmers adopt code-generating AI for technical tasks, unreliable AI and insufficient human oversight poses risks of unsafe or low-quality decisions.",
    "url": "https://arxiv.org/abs/2508.06484",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research study focused on non-technical end-users' ability to assess AI-generated code for data analysis tasks. The study found that participants, mainly marketing and sales professionals, struggled to identify critical errors in AI-generated analyses, even when explicitly prompted to do so. The findings suggest that non-programmers may have difficulty verifying the accuracy of AI-generated data analyses on their own, highlighting the importance of human oversight in ensuring the quality and safety of decisions made using AI-generated code."
  },
  {
    "title": "Zombitron: towards a toolbox for repurposing obsolete smartphones into new interactive systems",
    "abstract": "This article explores the possibilities of reusing obsolete smartphones and tablets to build new interactive systems. Taking the case of a musical instrument, I present my research into the design of a controller made from various of these obsolete smartphones. From the diagnostic stage to the creation of a new autonomous electronic object, I document the process, the barriers and the levers encountered. Based on these explorations and discussions with two professional musicians, I provide several insights into the software and hardware aspects, with a view to continuing this work, towards the creation of an open-source toolkit enabling anyone to build new interactive systems with old devices. I discuss the implication of how a high-level web-based approach could allow designers to enter the black box and foster permacomputing using smartphones.",
    "url": "https://arxiv.org/abs/2508.06354",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores repurposing obsolete smartphones and tablets to create new interactive systems, focusing on designing a musical instrument controller using these devices. The study documents the process of creating a new electronic object from obsolete smartphones, highlighting barriers and potential solutions. The research aims to develop an open-source toolkit for building interactive systems with old devices, emphasizing the potential for permacomputing using smartphones."
  },
  {
    "title": "Emoji Reactions on Telegram Often Reflect Social Approval Over Emotional Resonance",
    "abstract": "Emoji reactions are a frequently used feature of messaging platforms. Prior work mainly interpreted emojis as indicators of emotional resonance or user sentiment. However, emoji reactions may instead reflect broader social dynamics. Here, we investigate the communicative function of emoji reactions on Telegram by analyzing the relationship between the emotional and rhetorical content of messages and the emoji reactions they receive. We collect and analyze over 650k Telegram messages that received at least one emoji reaction. We annotate each message with sentiment, emotion, persuasion strategy, and speech act labels, and infer the sentiment and emotion of emoji reactions using both lexicons and large languages. We find a systematic mismatch between message sentiment and reaction sentiment, with positive reactions dominating even when the message is neutral or negative. We show that this pattern remains consistent across rhetorical strategies and emotional tones, suggesting that emoji reactions may signal a degree of social approval rather than reflecting emotional resonance. Finally, we shed light on the communicative strategies that predict greater emoji engagement. These findings have methodological implications for sentiment analysis, as interpreting emoji reactions as direct proxies for emotional response may be misleading.",
    "url": "https://arxiv.org/abs/2508.06349",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research examines the use of emoji reactions on Telegram and finds that they often reflect social approval rather than emotional resonance. The study analyzes over 650k messages and shows a mismatch between the sentiment of the message and the sentiment of the emoji reactions, with positive reactions dominating even in neutral or negative messages. The findings suggest that emoji reactions may serve as a signal of social approval and have implications for sentiment analysis in interpreting emoji reactions."
  },
  {
    "title": "Automatic Semantic Alignment of Flow Pattern Representations for Exploration with Large Language Models",
    "abstract": "Explorative flow visualization allows domain experts to analyze complex flow structures by interactively investigating flow patterns. However, traditional visual interfaces often rely on specialized graphical representations and interactions, which require additional effort to learn and use. Natural language interaction offers a more intuitive alternative, but teaching machines to recognize diverse scientific concepts and extract corresponding structures from flow data poses a significant challenge. In this paper, we introduce an automated framework that aligns flow pattern representations with the semantic space of large language models (LLMs), eliminating the need for manual labeling. Our approach encodes streamline segments using a denoising autoencoder and maps the generated flow pattern representations to LLM embeddings via a projector layer. This alignment empowers semantic matching between textual embeddings and flow representations through an attention mechanism, enabling the extraction of corresponding flow patterns based on textual descriptions. To enhance accessibility, we develop an interactive interface that allows users to query and visualize flow structures using natural language. Through case studies, we demonstrate the effectiveness of our framework in enabling intuitive and intelligent flow exploration.",
    "url": "https://arxiv.org/abs/2508.06300",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces an automated framework that aligns flow pattern representations with the semantic space of large language models, eliminating the need for manual labeling. By encoding streamline segments using a denoising autoencoder and mapping them to LLM embeddings, the framework enables semantic matching between textual descriptions and flow representations, facilitating intuitive and intelligent flow exploration through natural language interaction. Case studies demonstrate the effectiveness of this approach in enabling domain experts to analyze complex flow structures more easily and efficiently."
  },
  {
    "title": "A Multimodal Framework for Understanding Collaborative Design Processes",
    "abstract": "An essential task in analyzing collaborative design processes, such as those that are part of workshops in design studies, is identifying design outcomes and understanding how the collaboration between participants formed the results and led to decision-making. However, findings are typically restricted to a consolidated textual form based on notes from interviews or observations. A challenge arises from integrating different sources of observations, leading to large amounts and heterogeneity of collected data. To address this challenge we propose a practical, modular, and adaptable framework of workshop setup, multimodal data acquisition, AI-based artifact extraction, and visual analysis. Our interactive visual analysis system, reCAPit, allows the flexible combination of different modalities, including video, audio, notes, or gaze, to analyze and communicate important workshop findings. A multimodal streamgraph displays activity and attention in the working area, temporally aligned topic cards summarize participants' discussions, and drill-down techniques allow inspecting raw data of included sources. As part of our research, we conducted six workshops across different themes ranging from social science research on urban planning to a design study on band-practice visualization. The latter two are examined in detail and described as case studies. Further, we present considerations for planning workshops and challenges that we derive from our own experience and the interviews we conducted with workshop experts. Our research extends existing methodology of collaborative design workshops by promoting data-rich acquisition of multimodal observations, combined AI-based extraction and interactive visual analysis, and transparent dissemination of results.",
    "url": "https://arxiv.org/abs/2508.06117",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research presents a multimodal framework, reCAPit, for analyzing collaborative design processes in workshops, integrating different sources of observations like video, audio, notes, and gaze data. The framework includes AI-based artifact extraction and interactive visual analysis tools to effectively summarize and communicate important workshop findings. Case studies on urban planning and band-practice visualization workshops demonstrate the effectiveness of the framework in enhancing the methodology of collaborative design workshops and promoting transparent dissemination of results."
  },
  {
    "title": "ThematicPlane: Bridging Tacit User Intent and Latent Spaces for Image Generation",
    "abstract": "Generative AI has made image creation more accessible, yet aligning outputs with nuanced creative intent remains challenging, particularly for non-experts. Existing tools often require users to externalize ideas through prompts or references, limiting fluid exploration. We introduce ThematicPlane, a system that enables users to navigate and manipulate high-level semantic concepts (e.g., mood, style, or narrative tone) within an interactive thematic design plane. This interface bridges the gap between tacit creative intent and system control. In our exploratory study (N=6), participants engaged in divergent and convergent creative modes, often embracing unexpected results as inspiration or iteration cues. While they grounded their exploration in familiar themes, differing expectations of how themes mapped to outputs revealed a need for more explainable controls. Overall, ThematicPlane fosters expressive, iterative workflows and highlights new directions for intuitive, semantics-driven interaction in generative design tools.",
    "url": "https://arxiv.org/abs/2508.06065",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces ThematicPlane, a system that allows users to manipulate high-level semantic concepts for image generation, bridging the gap between creative intent and system control. The study found that participants engaged in both divergent and convergent creative modes, often finding unexpected results inspiring or useful for iteration. The system fosters expressive and iterative workflows, suggesting new directions for intuitive, semantics-driven interaction in generative design tools."
  },
  {
    "title": "RAGTrace: Understanding and Refining Retrieval-Generation Dynamics in Retrieval-Augmented Generation",
    "abstract": "Retrieval-Augmented Generation (RAG) systems have emerged as a promising solution to enhance large language models (LLMs) by integrating external knowledge retrieval with generative capabilities. While significant advancements have been made in improving retrieval accuracy and response quality, a critical challenge remains that the internal knowledge integration and retrieval-generation interactions in RAG workflows are largely opaque. This paper introduces RAGTrace, an interactive evaluation system designed to analyze retrieval and generation dynamics in RAG-based workflows. Informed by a comprehensive literature review and expert interviews, the system supports a multi-level analysis approach, ranging from high-level performance evaluation to fine-grained examination of retrieval relevance, generation fidelity, and cross-component interactions. Unlike conventional evaluation practices that focus on isolated retrieval or generation quality assessments, RAGTrace enables an integrated exploration of retrieval-generation relationships, allowing users to trace knowledge sources and identify potential failure cases. The system's workflow allows users to build, evaluate, and iterate on retrieval processes tailored to their specific domains of interest. The effectiveness of the system is demonstrated through case studies and expert evaluations on real-world RAG applications.",
    "url": "https://arxiv.org/abs/2508.06056",
    "journal": "arXiv cs.HC",
    "ai_summary": "The paper introduces RAGTrace, an interactive evaluation system that allows for the analysis of retrieval and generation dynamics in Retrieval-Augmented Generation (RAG) workflows. Unlike traditional evaluation methods that focus on isolated retrieval or generation quality, RAGTrace enables a comprehensive exploration of retrieval-generation relationships, facilitating the identification of potential failure cases. The system's effectiveness is demonstrated through case studies and expert evaluations on real-world RAG applications, showcasing its potential to improve the integration of external knowledge retrieval with generative capabilities in large language models."
  },
  {
    "title": "Hand by Hand: LLM Driving EMS Assistant for Operational Skill Learning",
    "abstract": "Operational skill learning, inherently physical and reliant on hands-on practice and kinesthetic feedback, has yet to be effectively replicated in large language model (LLM)-supported training. Current LLM training assistants primarily generate customized textual feedback, neglecting the crucial kinesthetic modality. This gap derives from the textual and uncertain nature of LLMs, compounded by concerns on user acceptance of LLM driven body control. To bridge this gap and realize the potential of collaborative human-LLM action, this work explores human experience of LLM driven kinesthetic assistance. Specifically, we introduced an \"Align-Analyze-Adjust\" strategy and developed FlightAxis, a tool that integrates LLM with Electrical Muscle Stimulation (EMS) for flight skill acquisition, a representative operational skill domain. FlightAxis learns flight skills from manuals and guides forearm movements during simulated flight tasks. Our results demonstrate high user acceptance of LLM-mediated body control and significantly reduced task completion times. Crucially, trainees reported that this kinesthetic assistance enhanced their awareness of operation flaws and fostered increased engagement in the training process, rather than relieving perceived load. This work demonstrated the potential of kinesthetic LLM training in operational skill acquisition.",
    "url": "https://arxiv.org/abs/2508.06000",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of large language models (LLMs) combined with Electrical Muscle Stimulation (EMS) to assist in operational skill learning, specifically in the domain of flight skills. The study found that integrating LLMs with EMS significantly reduced task completion times, increased user engagement, and improved awareness of operational flaws during training. This work highlights the potential of using kinesthetic assistance in LLM-driven training for operational skill acquisition."
  },
  {
    "title": "It's a Complete Haystack: Understanding Dependency Management Needs in Computer-Aided Design",
    "abstract": "In today's landscape, hardware development teams face increasing demands for better quality products, greater innovation, and shorter manufacturing lead times. Despite the need for more efficient and effective processes, hardware designers continue to struggle with a lack of awareness of design changes and other collaborators' actions, a persistent issue in decades of CSCW research. One significant and unaddressed challenge is understanding and managing dependencies between 3D CAD (computer-aided design) models, especially when products can contain thousands of interconnected components. In this two-phase formative study, we explore designers' pain points of CAD dependency management through a thematic analysis of 100 online forum discussions and semi-structured interviews with 10 designers. We identify nine key challenges related to the traceability, navigation, and consistency of CAD dependencies, that harm the effective coordination of hardware development teams. To address these challenges, we propose design goals and necessary features to enhance hardware designers' awareness and management of dependencies, ultimately with the goal of improving collaborative workflows.",
    "url": "https://arxiv.org/abs/2508.05940",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research study focuses on the challenges faced by hardware designers in managing dependencies between 3D CAD models, which can hinder the coordination of hardware development teams. Through analysis of online forum discussions and interviews, nine key challenges related to traceability, navigation, and consistency of CAD dependencies were identified. The study proposes design goals and features to improve designers' awareness and management of dependencies, aiming to enhance collaborative workflows in hardware development."
  },
  {
    "title": "ASLSL: Adaptive shared latent structure learning with incomplete multi-modal physiological data for multi-dimensional emotional feature selection",
    "abstract": "Recently, multi-modal physiological signals based emotion recognition has garnered increasing attention in the field of brain-computer interfaces. Nevertheness, the associated multi-modal physiological features are often high-dimensional and inevitably include irrelevant, redundant, and noisy representation, which can easily lead to overfitting, poor performance, and high computational complexity in emotion classifiers. Feature selection has been widely applied to address these challenges. However, previous studies generally assumed that multi-modal physiological data are complete, whereas in reality, the data are often incomplete due to the openness of the acquisition and operational environment. For example, a part of samples are available in several modalities but not in others. To address this issue, we propose a novel method for incomplete multi-modal physiological signal feature selection called adaptive shared latent structure learning (ASLSL). Based on the property that similar features share similar emotional labels, ASLSL employs adaptive shared latent structure learning to explore a common latent space shared for incomplete multi-modal physiological signals and multi-dimensional emotional labels, thereby mitigating the impact of missing information and mining consensus information. Two most popular multi-modal physiological emotion datasets (DEAP and DREAMER) with multi-dimensional emotional labels were utilized to compare the performance between compare ASLSL and seventeen feature selection methods. Comprehensive experimental results on these datasets demonstrate the effectiveness of ASLSL.",
    "url": "https://arxiv.org/abs/2508.05934",
    "journal": "arXiv cs.HC",
    "ai_summary": "The abstract discusses the challenges of high-dimensional and incomplete multi-modal physiological data in emotion recognition, leading to overfitting and poor performance in classifiers. The proposed method, ASLSL, utilizes adaptive shared latent structure learning to select features from incomplete data, improving the performance of emotion classifiers by exploring a common latent space shared between physiological signals and emotional labels. Experimental results on two popular datasets show the effectiveness of ASLSL compared to other feature selection methods."
  },
  {
    "title": "REFS: Robust EEG feature selection with missing multi-dimensional annotation for emotion recognition",
    "abstract": "The affective brain-computer interface is a crucial technology for affective interaction and emotional intelligence, emerging as a significant area of research in the human-computer interaction. Compared to single-type features, multi-type EEG features provide a multi-level representation for analyzing multi-dimensional emotions. However, the high dimensionality of multi-type EEG features, combined with the relatively small number of high-quality EEG samples, poses challenges such as classifier overfitting and suboptimal real-time performance in multi-dimensional emotion recognition. Moreover, practical applications of affective brain-computer interface frequently encounters partial absence of multi-dimensional emotional labels due to the open nature of the acquisition environment, and ambiguity and variability in individual emotion perception. To address these challenges, this study proposes a novel EEG feature selection method for missing multi-dimensional emotion recognition. The method leverages adaptive orthogonal non-negative matrix factorization to reconstruct the multi-dimensional emotional label space through second-order and higher-order correlations, which could reduce the negative impact of missing values and outliers on label reconstruction. Simultaneously, it employs least squares regression with graph-based manifold learning regularization and global feature redundancy minimization regularization to enable EEG feature subset selection despite missing information, ultimately achieving robust EEG-based multi-dimensional emotion recognition. Simulation experiments on three widely used multi-dimensional emotional datasets, DREAMER, DEAP and HDED, reveal that the proposed method outperforms thirteen advanced feature selection methods in terms of robustness for EEG emotional feature selection.",
    "url": "https://arxiv.org/abs/2508.05933",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on developing a robust EEG feature selection method for emotion recognition in the affective brain-computer interface. The study addresses challenges such as classifier overfitting and suboptimal real-time performance by leveraging adaptive orthogonal non-negative matrix factorization and least squares regression with graph-based manifold learning regularization. The proposed method outperforms thirteen advanced feature selection methods in terms of robustness for EEG emotional feature selection, showcasing its potential for improving multi-dimensional emotion recognition in practical applications."
  },
  {
    "title": "Do Ethical AI Principles Matter to Users? A Large-Scale Analysis of User Sentiment and Satisfaction",
    "abstract": "As AI systems become increasingly embedded in organizational workflows and consumer applications, ethical principles such as fairness, transparency, and robustness have been widely endorsed in policy and industry guidelines. However, there is still scarce empirical evidence on whether these principles are recognized, valued, or impactful from the perspective of users. This study investigates the link between ethical AI and user satisfaction by analyzing over 100,000 user reviews of AI products from G2. Using transformer-based language models, we measure sentiment across seven ethical dimensions defined by the EU Ethics Guidelines for Trustworthy AI. Our findings show that all seven dimensions are positively associated with user satisfaction. Yet, this relationship varies systematically across user and product types. Technical users and reviewers of AI development platforms more frequently discuss system-level concerns (e.g., transparency, data governance), while non-technical users and reviewers of end-user applications emphasize human-centric dimensions (e.g., human agency, societal well-being). Moreover, the association between ethical AI and user satisfaction is significantly stronger for non-technical users and end-user applications across all dimensions. Our results highlight the importance of ethical AI design from users' perspectives and underscore the need to account for contextual differences across user roles and product types.",
    "url": "https://arxiv.org/abs/2508.05913",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores the relationship between ethical AI principles and user satisfaction by analyzing over 100,000 user reviews of AI products. The findings indicate that ethical dimensions such as fairness, transparency, and robustness are positively associated with user satisfaction, with variations based on user and product types. Non-technical users and reviewers of end-user applications place more emphasis on human-centric dimensions, suggesting the significance of ethical AI design from users' perspectives and the importance of considering contextual differences across user roles and product types."
  },
  {
    "title": "Modeling Interactive Narrative Systems: A Formal Approach",
    "abstract": "Interactive Narrative Systems (INS) have revolutionized digital experiences by empowering users to actively shape their stories, diverging from traditional passive storytelling. However, the field faces challenges due to fragmented research efforts and diverse system representations. This paper introduces a formal representation framework for INS, inspired by diverse approaches from the state of the art. By providing a consistent vocabulary and modeling structure, the framework facilitates the analysis, the description and comparison of INS properties. Experimental validations on the \"Little Red Riding Hood\" scenario highlight the usefulness of the proposed formalism and its impact on improving the evaluation of INS. This work aims to foster collaboration and coherence within the INS research community by proposing a methodology for formally representing these systems.",
    "url": "https://arxiv.org/abs/2508.05653",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper introduces a formal representation framework for Interactive Narrative Systems (INS) to address challenges in fragmented research efforts and diverse system representations. The framework aims to provide a consistent vocabulary and modeling structure to facilitate analysis, description, and comparison of INS properties. Experimental validations on the \"Little Red Riding Hood\" scenario demonstrate the usefulness of the proposed formalism in improving the evaluation of INS, with the overall goal of fostering collaboration and coherence within the INS research community."
  },
  {
    "title": "A Humanoid Social Robot as a Teaching Assistant in the Classroom",
    "abstract": "Although innovation and the support of new technologies are much needed to ease the burden on the education system, social robots in schools to help teachers with educational tasks are rare. Child-Robot Interaction (CRI) could support teachers and add an embodied social component to modern multi-modal and multi-sensory learning environments already in use. The social robot Pepper, connected to the Large Language Model (LLM) ChatGPT, was used in a high school classroom to teach new learning content to groups of students. I tested the technical possibilities with the robot on site and asked the students about their acceptance and perceived usefulness of teaching with the help of a social robot. All participants felt that the robot's presentation of the learning material was appropriate or at least partially appropriate and that its use made sense.",
    "url": "https://arxiv.org/abs/2508.05646",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of a social robot, Pepper, connected to a language model, ChatGPT, as a teaching assistant in a high school classroom. The study found that students generally accepted the robot's presentation of learning material and found its use to be useful. This suggests that humanoid social robots could potentially support teachers and enhance the educational experience in modern learning environments."
  },
  {
    "title": "Automated Visualization Makeovers with LLMs",
    "abstract": "Making a good graphic that accurately and efficiently conveys the desired message to the audience is both an art and a science, typically not taught in the data science curriculum. Visualisation makeovers are exercises where the community exchange feedback to improve charts and data visualizations. Can multi-modal large language models (LLMs) emulate this task? Given a plot in the form of an image file, or the code used to generate it, an LLM, primed with a list of visualization best practices, is employed to semi-automatically generate constructive criticism to produce a better plot. Our system is centred around prompt engineering of a pre-trained model, relying on a combination of userspecified guidelines and any latent knowledge of data visualization practices that might lie within an LLMs training corpus. Unlike other works, the focus is not on generating valid visualization scripts from raw data or prompts, but on educating the user how to improve their existing data visualizations according to an interpretation of best practices. A quantitative evaluation is performed to measure the sensitivity of the LLM agent to various plotting issues across different chart types. We make the tool available as a simple self-hosted applet with an accessible Web interface.",
    "url": "https://arxiv.org/abs/2508.05637",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of multi-modal large language models (LLMs) to provide constructive criticism and improve data visualizations through automated visualization makeovers. The system is designed to educate users on best practices for creating effective visualizations, rather than generating new visualization scripts. The tool is available as a self-hosted applet with a user-friendly web interface, offering a valuable resource for improving data visualization skills."
  },
  {
    "title": "Improved Dysarthric Speech to Text Conversion via TTS Personalization",
    "abstract": "We present a case study on developing a customized speech-to-text system for a Hungarian speaker with severe dysarthria. State-of-the-art automatic speech recognition (ASR) models struggle with zero-shot transcription of dysarthric speech, yielding high error rates. To improve performance with limited real dysarthric data, we fine-tune an ASR model using synthetic speech generated via a personalized text-to-speech (TTS) system. We introduce a method for generating synthetic dysarthric speech with controlled severity by leveraging premorbidity recordings of the given speaker and speaker embedding interpolation, enabling ASR fine-tuning on a continuum of impairments. Fine-tuning on both real and synthetic dysarthric speech reduces the character error rate (CER) from 36-51% (zero-shot) to 7.3%. Our monolingual FastConformer_Hu ASR model significantly outperforms Whisper-turbo when fine-tuned on the same data, and the inclusion of synthetic speech contributes to an 18% relative CER reduction. These results highlight the potential of personalized ASR systems for improving accessibility for individuals with severe speech impairments.",
    "url": "https://arxiv.org/abs/2508.06391",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research focuses on improving speech-to-text conversion for individuals with severe dysarthria by developing a personalized system using synthetic speech generated through a text-to-speech system. By fine-tuning an ASR model on both real and synthetic dysarthric speech, the character error rate is significantly reduced, showcasing the potential of personalized ASR systems to enhance accessibility for individuals with speech impairments. The study highlights the importance of utilizing personalized approaches to improve the performance of ASR models for individuals with severe speech impairments."
  },
  {
    "title": "From Explainable to Explanatory Artificial Intelligence: Toward a New Paradigm for Human-Centered Explanations through Generative AI",
    "abstract": "Current explainable AI (XAI) approaches prioritize algorithmic transparency and present explanations in abstract, non-adaptive formats that often fail to support meaningful end-user understanding. This paper introduces \"Explanatory AI\" as a complementary paradigm that leverages generative AI capabilities to serve as explanatory partners for human understanding rather than providers of algorithmic transparency. While XAI reveals algorithmic decision processes for model validation, Explanatory AI addresses contextual reasoning to support human decision-making in sociotechnical contexts. We develop a definition and systematic eight-dimensional conceptual model distinguishing Explanatory AI through narrative communication, adaptive personalization, and progressive disclosure principles. Empirical validation through Rapid Contextual Design methodology with healthcare professionals demonstrates that users consistently prefer context-sensitive, multimodal explanations over technical transparency. Our findings reveal the practical urgency for AI systems designed for human comprehension rather than algorithmic introspection, establishing a comprehensive research agenda for advancing user-centered AI explanation approaches across diverse domains and cultural contexts.",
    "url": "https://arxiv.org/abs/2508.06352",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces the concept of \"Explanatory AI\" as a new paradigm that focuses on providing context-sensitive, multimodal explanations to support human decision-making, rather than just algorithmic transparency. The study demonstrates that healthcare professionals prefer explanations that are personalized, adaptive, and presented in a narrative format. This shift towards human-centered explanations highlights the importance of designing AI systems that prioritize user comprehension over algorithmic introspection, and sets a research agenda for advancing user-centered explanation approaches in various domains and cultural contexts."
  },
  {
    "title": "Unsupervised Partner Design Enables Robust Ad-hoc Teamwork",
    "abstract": "We introduce Unsupervised Partner Design (UPD) - a population-free, multi-agent reinforcement learning framework for robust ad-hoc teamwork that adaptively generates training partners without requiring pretrained partners or manual parameter tuning. UPD constructs diverse partners by stochastically mixing an ego agent's policy with biased random behaviours and scores them using a variance-based learnability metric that prioritises partners near the ego agent's current learning frontier. We show that UPD can be integrated with unsupervised environment design, resulting in the first method enabling fully unsupervised curricula over both level and partner distributions in a cooperative setting. Through extensive evaluations on Overcooked-AI and the Overcooked Generalisation Challenge, we demonstrate that this dynamic partner curriculum is highly effective: UPD consistently outperforms both population-based and population-free baselines as well as ablations. In a user study, we further show that UPD achieves higher returns than all baselines and was perceived as significantly more adaptive, more human-like, a better collaborator, and less frustrating.",
    "url": "https://arxiv.org/abs/2508.06336",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces Unsupervised Partner Design (UPD), a framework for generating training partners in multi-agent reinforcement learning without the need for pretrained partners or manual tuning. UPD constructs diverse partners by mixing an ego agent's policy with random behaviors and prioritizes partners near the ego agent's learning frontier. The study demonstrates that UPD outperforms other baselines in ad-hoc teamwork scenarios, showing higher returns and being perceived as more adaptive, human-like, and collaborative in a user study."
  },
  {
    "title": "EmoAugNet: A Signal-Augmented Hybrid CNN-LSTM Framework for Speech Emotion Recognition",
    "abstract": "Recognizing emotional signals in speech has a significant impact on enhancing the effectiveness of human-computer interaction (HCI). This study introduces EmoAugNet, a hybrid deep learning framework, that incorporates Long Short-Term Memory (LSTM) layers with one-dimensional Convolutional Neural Networks (1D-CNN) to enable reliable Speech Emotion Recognition (SER). The quality and variety of the features that are taken from speech signals have a significant impact on how well SER systems perform. A comprehensive speech data augmentation strategy was used to combine both traditional methods, such as noise addition, pitch shifting, and time stretching, with a novel combination-based augmentation pipeline to enhance generalization and reduce overfitting. Each audio sample was transformed into a high-dimensional feature vector using root mean square energy (RMSE), Mel-frequency Cepstral Coefficient (MFCC), and zero-crossing rate (ZCR). Our model with ReLU activation has a weighted accuracy of 95.78\\% and unweighted accuracy of 92.52\\% on the IEMOCAP dataset and, with ELU activation, has a weighted accuracy of 96.75\\% and unweighted accuracy of 91.28\\%. On the RAVDESS dataset, we get a weighted accuracy of 94.53\\% and 94.98\\% unweighted accuracy for ReLU activation and 93.72\\% weighted accuracy and 94.64\\% unweighted accuracy for ELU activation. These results highlight EmoAugNet's effectiveness in improving the robustness and performance of SER systems through integated data augmentation and hybrid modeling.",
    "url": "https://arxiv.org/abs/2508.06321",
    "journal": "arXiv cs.HC",
    "ai_summary": "The study introduces EmoAugNet, a hybrid deep learning framework that combines LSTM layers with 1D-CNN for Speech Emotion Recognition (SER). The model achieved high accuracy rates on the IEMOCAP and RAVDESS datasets, showcasing the effectiveness of EmoAugNet in improving the robustness and performance of SER systems through integrated data augmentation and hybrid modeling. These findings are significant for enhancing human-computer interaction by accurately recognizing emotional signals in speech."
  },
  {
    "title": "EICAP: Deep Dive in Assessment and Enhancement of Large Language Models in Emotional Intelligence through Multi-Turn Conversations",
    "abstract": "Emotional Intelligence (EI) is a critical yet underexplored dimension in the development of human-aligned LLMs. To address this gap, we introduce a unified, psychologically grounded four-layer taxonomy of EI tailored for large language models (LLMs), encompassing emotional tracking, cause inference, appraisal, and emotionally appropriate response generation. Building on this framework, we present EICAP-Bench, a novel MCQ style multi-turn benchmark designed to evaluate EI capabilities in open-source LLMs across diverse linguistic and cultural contexts. We evaluate six LLMs: LLaMA3 (8B), LLaMA3-Instruct, Gemma (9B), Gemma-Instruct, Qwen2.5 (7B), and Qwen2.5-Instruct on EmoCap-Bench, identifying Qwen2.5-Instruct as the strongest baseline. To assess the potential for enhancing EI capabilities, we fine-tune both Qwen2.5-Base and Qwen2.5-Instruct using LoRA adapters on UltraChat (UC), a large-scale, instruction-tuned dialogue dataset, in both English and Arabic. Our statistical analysis reveals that among the five EI layers, only the Appraisal layer shows significant improvement through UC-based fine-tuning. These findings highlight the limitations of existing pretraining and instruction-tuning paradigms in equipping LLMs with deeper emotional reasoning and underscore the need for targeted data and modeling strategies for comprehensive EI alignment.",
    "url": "https://arxiv.org/abs/2508.06196",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces a taxonomy of Emotional Intelligence (EI) tailored for large language models (LLMs) and presents a benchmark to evaluate EI capabilities in LLMs across diverse contexts. The study evaluates six LLMs and finds that Qwen2.5-Instruct performs the best as a baseline. Fine-tuning on a dialogue dataset shows significant improvement in the Appraisal layer of EI, indicating the need for targeted data and modeling strategies for comprehensive EI alignment in LLMs."
  },
  {
    "title": "Pragmatics beyond humans: meaning, communication, and LLMs",
    "abstract": "The paper reconceptualizes pragmatics not as a subordinate, third dimension of meaning, but as a dynamic interface through which language operates as a socially embedded tool for action. With the emergence of large language models (LLMs) in communicative contexts, this understanding needs to be further refined and methodologically reconsidered. The first section challenges the traditional semiotic trichotomy, arguing that connectionist LLM architectures destabilize established hierarchies of meaning, and proposes the Human-Machine Communication (HMC) framework as a more suitable alternative. The second section examines the tension between human-centred pragmatic theories and the machine-centred nature of LLMs. While traditional, Gricean-inspired pragmatics continue to dominate, it relies on human-specific assumptions ill-suited to predictive systems like LLMs. Probabilistic pragmatics, particularly the Rational Speech Act framework, offers a more compatible teleology by focusing on optimization rather than truth-evaluation. The third section addresses the issue of substitutionalism in three forms - generalizing, linguistic, and communicative - highlighting the anthropomorphic biases that distort LLM evaluation and obscure the role of human communicative subjects. Finally, the paper introduces the concept of context frustration to describe the paradox of increased contextual input paired with a collapse in contextual understanding, emphasizing how users are compelled to co-construct pragmatic conditions both for the model and themselves. These arguments suggest that pragmatic theory may need to be adjusted or expanded to better account for communication involving generative AI.",
    "url": "https://arxiv.org/abs/2508.06167",
    "journal": "arXiv cs.HC",
    "ai_summary": "This paper challenges traditional views of pragmatics, arguing that it is a dynamic interface through which language operates as a tool for action. It discusses the tension between human-centric pragmatic theories and machine-centric LLMs, proposing a new framework called Human-Machine Communication. The paper also introduces the concept of context frustration to describe the challenges of communication with generative AI, suggesting that pragmatic theory may need to be adjusted to better account for this type of interaction."
  },
  {
    "title": "Exploring Interactive Simulation of Grass Display Color Characteristic Based on Real-World Conditions",
    "abstract": "Recent research has focused on incorporating media into living environments via color-controlled materials and image display. In particular, grass-based displays have drawn attention as landscape-friendly interactive interfaces. To develop the grass display, it is important to obtain the grass color change characteristics that depend on the real environment. However, conventional methods require experiments on actual equipment every time the lighting or viewpoint changes, which is time-consuming and costly. Although research has begun on simulating grass colors, this approach still faces significant issues as it takes many hours for a single measurement. In this paper, we explore an interactive simulation of a grass display color change characteristic based on real-world conditions in a virtual environment. We evaluated our method's accuracy by simulating grass color characteristics across multiple viewpoints and environments, and then compared the results against prior work. The results indicated that our method tended to simulate the grass color characteristics similar to the actual characteristics and showed the potential to do so more quickly and with comparable accuracy to the previous study.",
    "url": "https://arxiv.org/abs/2508.06086",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores an interactive simulation of grass display color characteristics based on real-world conditions in a virtual environment. The study found that their method was able to accurately simulate grass color changes across different viewpoints and environments, showing potential for a quicker and more cost-effective approach compared to previous methods. This research is significant as it could lead to the development of landscape-friendly interactive interfaces that can adapt to various lighting and viewpoint conditions."
  },
  {
    "title": "Learning by Teaching: Engaging Students as Instructors of Large Language Models in Computer Science Education",
    "abstract": "While Large Language Models (LLMs) are often used as virtual tutors in computer science (CS) education, this approach can foster passive learning and over-reliance. This paper presents a novel pedagogical paradigm that inverts this model: students act as instructors who must teach an LLM to solve problems. To facilitate this, we developed strategies for designing questions with engineered knowledge gaps that only a student can bridge, and we introduce Socrates, a system for deploying this method with minimal overhead. We evaluated our approach in an undergraduate course and found that this active-learning method led to statistically significant improvements in student performance compared to historical cohorts. Our work demonstrates a practical, cost-effective framework for using LLMs to deepen student engagement and mastery.",
    "url": "https://arxiv.org/abs/2508.05979",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores a new teaching approach in computer science education where students act as instructors to teach Large Language Models (LLMs) to solve problems. By designing questions with knowledge gaps that only students can bridge, this active-learning method led to significant improvements in student performance compared to traditional teaching methods. The study demonstrates a practical and cost-effective way to use LLMs to enhance student engagement and mastery in computer science education."
  },
  {
    "title": "Bionic Vision as Neuroadaptive XR: Closed-Loop Perceptual Interfaces for Neurotechnology",
    "abstract": "Visual neuroprostheses are commonly framed as technologies to restore natural sight to people who are blind. In practice, they create a novel mode of perception shaped by sparse, distorted, and unstable input. They resemble early extended reality (XR) headsets more than natural vision, streaming video from a head-mounted camera to a neural \"display\" with under 1000 pixels, limited field of view, low refresh rates, and nonlinear spatial mappings. No amount of resolution alone will make this experience natural. This paper proposes a reframing: bionic vision as neuroadaptive XR. Rather than replicating natural sight, the goal is to co-adapt brain and device through a bidirectional interface that responds to neural constraints, behavioral goals, and cognitive state. By comparing traditional XR, current implants, and proposed neuroadaptive systems, it introduces a new design space for inclusive, brain-aware computing. It concludes with research provocations spanning encoding, evaluation, learning, and ethics, and invites the XR community to help shape the future of sensory augmentation.",
    "url": "https://arxiv.org/abs/2508.05963",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research paper discusses how visual neuroprostheses, designed to restore sight to the blind, actually create a unique mode of perception that differs from natural vision. It suggests reframing bionic vision as neuroadaptive extended reality (XR) to co-adapt the brain and device through a bidirectional interface. This new design approach aims to address the limitations of current implants and traditional XR technology, offering a more inclusive and brain-aware computing experience for sensory augmentation."
  },
  {
    "title": "Social and Telepresence Robots for Accessibility and Inclusion in Small Museums",
    "abstract": "There are still many museums that present accessibility barriers, particularly regarding perceptual, cultural, and cognitive aspects. This is especially evident in low-density population areas. The aim of the ROBSO-PM project is to improve the accessibility of small museums through the use of social robots and social telepresence robots, focusing on three museums as case studies: the Museum of the Holy Shroud in Turin, a small but globally known institution, and two lesser known mountain museums: the Museum of the Champlas du Col Carnival and the Pragelato Museum of Alpine Peoples' Costumes and Traditions. The project explores two main applications for robots: as guides supporting inclusive visits for foreign or disabled visitors, and as telepresence tools allowing people with limited mobility to access museums remotely. From a research perspective, key topics include storytelling, robot personality, empathy, personalization, and, in the case of telepresence, collaboration between the robot and the person, with clearly defined roles and autonomy.",
    "url": "https://arxiv.org/abs/2508.05946",
    "journal": "arXiv cs.HC",
    "ai_summary": "The ROBSO-PM project aims to improve accessibility in small museums through the use of social robots and telepresence robots, focusing on three case study museums. The research explores the use of robots as guides for inclusive visits and as telepresence tools for remote access for individuals with limited mobility. Key topics include storytelling, robot personality, empathy, personalization, and collaboration between the robot and the person."
  },
  {
    "title": "Towards Transparent Ethical AI: A Roadmap for Trustworthy Robotic Systems",
    "abstract": "As artificial intelligence (AI) and robotics increasingly permeate society, ensuring the ethical behavior of these systems has become paramount. This paper contends that transparency in AI decision-making processes is fundamental to developing trustworthy and ethically aligned robotic systems. We explore how transparency facilitates accountability, enables informed consent, and supports the debugging of ethical algorithms. The paper outlines technical, ethical, and practical challenges in implementing transparency and proposes novel approaches to enhance it, including standardized metrics, explainable AI techniques, and user-friendly interfaces. This paper introduces a framework that connects technical implementation with ethical considerations in robotic systems, focusing on the specific challenges of achieving transparency in dynamic, real-world contexts. We analyze how prioritizing transparency can impact public trust, regulatory policies, and avenues for future research. By positioning transparency as a fundamental element in ethical AI system design, we aim to add to the ongoing discussion on responsible AI and robotics, providing direction for future advancements in this vital field.",
    "url": "https://arxiv.org/abs/2508.05846",
    "journal": "arXiv cs.HC",
    "ai_summary": "This paper emphasizes the importance of transparency in AI decision-making processes for developing trustworthy and ethically aligned robotic systems. The authors discuss how transparency can enhance accountability, enable informed consent, and support the debugging of ethical algorithms. They propose novel approaches, such as standardized metrics and explainable AI techniques, to improve transparency in dynamic, real-world contexts, ultimately aiming to impact public trust, regulatory policies, and future research in responsible AI and robotics."
  },
  {
    "title": "AI-Guided Exploration of Large-Scale Codebases",
    "abstract": "Understanding large-scale, complex software systems is a major challenge for developers, who spend a significant portion of their time on program comprehension. Traditional tools such as static visualizations and reverse engineering techniques provide structural insights but often lack interactivity, adaptability, and integration with contextual information. Recent advancements in large language models (LLMs) offer new opportunities to enhance code exploration workflows, yet their lack of grounding and integration with structured views limits their effectiveness. This work introduces a hybrid approach that integrates deterministic reverse engineering with LLM-guided, intent-aware visual exploration. The proposed system combines UML-based visualization, dynamic user interfaces, historical context, and collaborative features into an adaptive tool for code comprehension. By interpreting user queries and interaction patterns, the LLM helps developers navigate and understand complex codebases more effectively. A prototype implementation for Java demonstrates the feasibility of this approach. Future work includes empirical evaluation, scaling to polyglot systems, and exploring GUI-driven LLM interaction models. This research lays the groundwork for intelligent, interactive environments that align with developer cognition and collaborative workflows.",
    "url": "https://arxiv.org/abs/2508.05799",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores a hybrid approach that combines deterministic reverse engineering with large language models (LLMs) to enhance code exploration workflows for developers. The proposed system integrates UML-based visualization, dynamic user interfaces, historical context, and collaborative features to help developers navigate and understand complex codebases more effectively. The prototype implementation for Java demonstrates the feasibility of this approach, laying the groundwork for intelligent, interactive environments that align with developer cognition and collaborative workflows."
  },
  {
    "title": "Discrepancy-Aware Contrastive Adaptation in Medical Time Series Analysis",
    "abstract": "In medical time series disease diagnosis, two key challenges are identified. First, the high annotation cost of medical data leads to overfitting in models trained on label-limited, single-center datasets. To address this, we propose incorporating external data from related tasks and leveraging AE-GAN to extract prior knowledge, providing valuable references for downstream tasks. Second, many existing studies employ contrastive learning to derive more generalized medical sequence representations for diagnostic tasks, usually relying on manually designed diverse positive and negative sample pairs. However, these approaches are complex, lack generalizability, and fail to adaptively capture disease-specific features across different conditions. To overcome this, we introduce LMCF (Learnable Multi-views Contrastive Framework), a framework that integrates a multi-head attention mechanism and adaptively learns representations from different views through inter-view and intra-view contrastive learning strategies. Additionally, the pre-trained AE-GAN is used to reconstruct discrepancies in the target data as disease probabilities, which are then integrated into the contrastive learning process. Experiments on three target datasets demonstrate that our method consistently outperforms other seven baselines, highlighting its significant impact on healthcare applications such as the diagnosis of myocardial infarction, Alzheimer's disease, and Parkinson's disease. We release the source code at xxxxx.",
    "url": "https://arxiv.org/abs/2508.05572",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research addresses challenges in medical time series disease diagnosis, including overfitting due to limited labeled data and the lack of adaptive capture of disease-specific features. The proposed LMCF framework integrates multi-head attention and contrastive learning to improve the generalizability of medical sequence representations. Experiments show that the method outperforms seven baselines in diagnosing diseases like myocardial infarction, Alzheimer's, and Parkinson's, showcasing its potential impact on healthcare applications."
  },
  {
    "title": "Towards Human-Centric Evaluation of Interaction-Aware Automated Vehicle Controllers: A Framework and Case Study",
    "abstract": "As automated vehicles (AVs) increasingly integrate into mixed-traffic environments, evaluating their interaction with human-driven vehicles (HDVs) becomes critical. In most research focused on developing new AV control algorithms (controllers), the performance of these algorithms is assessed solely based on performance metrics such as collision avoidance or lane-keeping efficiency, while largely overlooking the human-centred dimensions of interaction with HDVs. This paper proposes a structured evaluation framework that addresses this gap by incorporating metrics grounded in the human-robot interaction literature. The framework spans four key domains: a) interaction effect, b) interaction perception, c) interaction effort, and d) interaction ability. These domains capture both the performance of the AV and its impact on human drivers around it. To demonstrate the utility of the framework, we apply it to a case study evaluating how a state-of-the-art AV controller interacts with human drivers in a merging scenario in a driving simulator. Measuring HDV-HDV interactions as a baseline, this study included one representative metric per domain: a) perceived safety, b) subjective ratings, specifically how participants perceived the other vehicle's driving behaviour (e.g., aggressiveness or predictability) , c) driver workload, and d) merging success. The results showed that incorporating metrics covering all four domains in the evaluation of AV controllers can illuminate critical differences in driver experience when interacting with AVs. This highlights the need for a more comprehensive evaluation approach. Our framework offers researchers, developers, and policymakers a systematic method for assessing AV behaviour beyond technical performance, fostering the development of AVs that are not only functionally capable but also understandable, acceptable, and safe from a human perspective.",
    "url": "https://arxiv.org/abs/2508.05497",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper introduces a structured evaluation framework for assessing the interaction between automated vehicles (AVs) and human-driven vehicles (HDVs) based on human-centric metrics. The framework includes four key domains: interaction effect, perception, effort, and ability, which capture both the performance of the AV and its impact on human drivers. By applying the framework to a case study on a merging scenario in a driving simulator, the study found that incorporating these human-centric metrics can reveal critical differences in driver experience when interacting with AVs, emphasizing the importance of a more comprehensive evaluation approach for AV controllers."
  },
  {
    "title": "Implementation and Application of Multi-Format 3D Data Integration in a Cross-Device Commercial Metaverse Platform",
    "abstract": "Traditionally, specialized 3D design data, such as BIM and CAD, have been accessible only to a select group of experts, creating significant barriers that prevent general users from participating in decision-making processes. This paper provides a systematic overview of practical insights for utilizing 3D data in industrial and architectural domains by presenting implementation cases of the industrial metaverse on Cluster, a commercial cross-device metaverse platform. This paper analyzes the characteristics and constraints of major data formats in the industrial and architectural fields and organizes integration workflows for the metaverse. Through application cases utilizing 3D data across multiple domains, we present practical examples of collaborative decision-making support enabled by the fusion of metaverse and digital twin technologies. Specifically, we demonstrate that multi-device access and simultaneous multi-user participation capabilities foster democratic environments in the industrial metaverse, which are challenging to achieve with conventional, expert-dependent systems.",
    "url": "https://arxiv.org/abs/2508.05332",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the integration of specialized 3D design data in a commercial metaverse platform, Cluster, to enable general users to participate in decision-making processes in industrial and architectural domains. The study highlights the importance of multi-format 3D data integration and showcases how collaborative decision-making support can be enhanced through the fusion of metaverse and digital twin technologies. The findings suggest that the platform's multi-device access and multi-user participation capabilities create democratic environments in the industrial metaverse, overcoming barriers associated with expert-dependent systems."
  },
  {
    "title": "Critical Design Strategy: a Method for Heuristically Evaluating Visualisation Designs",
    "abstract": "We present the Critical Design Strategy (CDS) - a structured method designed to facilitate the examination of visualisation designs through reflection and critical thought. The CDS helps designers think critically and make informed improvements using heuristic evaluation. When developing a visual tool or pioneering a novel visualisation approach, identifying areas for enhancement can be challenging. Critical thinking is particularly crucial for visualisation designers and tool developers, especially those new to the field, such as studying visualisation in higher education. The CDS consists of three stages across six perspectives: Stage 1 captures the essence of the idea by assigning an indicative title and selecting five adjectives (from twenty options) to form initial impressions of the design. Stage 2 involves an in-depth critique using 30 heuristic questions spanning six key perspectives - user, environment, interface, components, design, and visual marks. Stage 3 focuses on synthesising insights, reflecting on design decisions, and determining the next steps forward. We introduce the CDS and explore its use across three visualisation modules in both undergraduate and postgraduate courses. Our longstanding experience with the CDS has allowed us to refine and develop it over time: from its initial creation through workshops in 2017/18 to improvements in wording and the development of two applications by 2020, followed by the expansion of support notes and refinement of heuristics through 2023; while using it in our teaching each year. This sustained use allows us to reflect on its practical application and offer guidance on how others can incorporate it into their own work.",
    "url": "https://arxiv.org/abs/2508.05325",
    "journal": "arXiv cs.HC",
    "ai_summary": "The Critical Design Strategy (CDS) is a method that helps visualisation designers critically evaluate their designs through reflection and heuristic evaluation. It consists of three stages and six key perspectives, allowing designers to identify areas for improvement and make informed decisions. The CDS has been refined and developed over time through practical application in undergraduate and postgraduate courses, offering guidance for others to incorporate it into their work."
  },
  {
    "title": "A Methodological Framework and Questionnaire for Investigating Perceived Algorithmic Fairness",
    "abstract": "This study explores perceptions of fairness in algorithmic decision-making among users in Bangladesh through a comprehensive mixed-methods approach. By integrating quantitative survey data with qualitative interview insights, we examine how cultural, social, and contextual factors influence users' understanding of fairness, transparency, and accountability in AI systems. Our findings reveal nuanced attitudes toward human oversight, explanation mechanisms, and contestability, highlighting the importance of culturally aware design principles for equitable and trustworthy algorithmic systems. These insights contribute to ongoing discussions on algorithmic fairness by foregrounding perspectives from a non-Western context, thus broadening the global dialogue on ethical AI deployment.",
    "url": "https://arxiv.org/abs/2508.05281",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study investigates perceptions of algorithmic fairness in Bangladesh through a mixed-methods approach, revealing how cultural and contextual factors impact users' views on fairness, transparency, and accountability in AI systems. The findings emphasize the significance of culturally aware design principles for creating equitable and trustworthy algorithmic systems, shedding light on the importance of human oversight, explanation mechanisms, and contestability. This research contributes to the global discussion on ethical AI deployment by incorporating perspectives from a non-Western context."
  },
  {
    "title": "Driver Assistant: Persuading Drivers to Adjust Secondary Tasks Using Large Language Models",
    "abstract": "Level 3 automated driving systems allows drivers to engage in secondary tasks while diminishing their perception of risk. In the event of an emergency necessitating driver intervention, the system will alert the driver with a limited window for reaction and imposing a substantial cognitive burden. To address this challenge, this study employs a Large Language Model (LLM) to assist drivers in maintaining an appropriate attention on road conditions through a \"humanized\" persuasive advice. Our tool leverages the road conditions encountered by Level 3 systems as triggers, proactively steering driver behavior via both visual and auditory routes. Empirical study indicates that our tool is effective in sustaining driver attention with reduced cognitive load and coordinating secondary tasks with takeover behavior. Our work provides insights into the potential of using LLMs to support drivers during multi-task automated driving.",
    "url": "https://arxiv.org/abs/2508.05238",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of Large Language Models (LLMs) to assist drivers in maintaining attention on road conditions while engaging in secondary tasks in Level 3 automated driving systems. The study found that the tool effectively sustained driver attention, reduced cognitive load, and coordinated secondary tasks with takeover behavior. This work highlights the potential of LLMs in supporting drivers during multi-task automated driving scenarios."
  },
  {
    "title": "FDC-Net: Rethinking the association between EEG artifact removal and multi-dimensional affective computing",
    "abstract": "Electroencephalogram (EEG)-based emotion recognition holds significant value in affective computing and brain-computer interfaces. However, in practical applications, EEG recordings are susceptible to the effects of various physiological artifacts. Current approaches typically treat denoising and emotion recognition as independent tasks using cascaded architectures, which not only leads to error accumulation, but also fails to exploit potential synergies between these tasks. Moreover, conventional EEG-based emotion recognition models often rely on the idealized assumption of \"perfectly denoised data\", lacking a systematic design for noise robustness. To address these challenges, a novel framework that deeply couples denoising and emotion recognition tasks is proposed for end-to-end noise-robust emotion recognition, termed as Feedback-Driven Collaborative Network for Denoising-Classification Nexus (FDC-Net). Our primary innovation lies in establishing a dynamic collaborative mechanism between artifact removal and emotion recognition through: (1) bidirectional gradient propagation with joint optimization strategies; (2) a gated attention mechanism integrated with frequency-adaptive Transformer using learnable band-position encoding. Two most popular EEG-based emotion datasets (DEAP and DREAMER) with multi-dimensional emotional labels were employed to compare the artifact removal and emotion recognition performance between ASLSL and nine state-of-the-art methods. In terms of the denoising task, FDC-Net obtains a maximum correlation coefficient (CC) value of 96.30% on DEAP and a maximum CC value of 90.31% on DREAMER. In terms of the emotion recognition task under physiological artifact interference, FDC-Net achieves emotion recognition accuracies of 82.3+7.1% on DEAP and 88.1+0.8% on DREAMER.",
    "url": "https://arxiv.org/abs/2508.05231",
    "journal": "arXiv cs.HC",
    "ai_summary": "The study introduces a novel framework, FDC-Net, that integrates EEG artifact removal and emotion recognition tasks to improve noise-robust emotion recognition. By coupling denoising and emotion recognition tasks, the model achieves high correlation coefficients for artifact removal and high emotion recognition accuracies on popular EEG-based emotion datasets. The findings suggest that the proposed approach outperforms existing methods by effectively addressing the challenges of noise interference in EEG recordings for affective computing applications."
  },
  {
    "title": "ADSEL: Adaptive dual self-expression learning for EEG feature selection via incomplete multi-dimensional emotional tagging",
    "abstract": "EEG based multi-dimension emotion recognition has attracted substantial research interest in human computer interfaces. However, the high dimensionality of EEG features, coupled with limited sample sizes, frequently leads to classifier overfitting and high computational complexity. Feature selection constitutes a critical strategy for mitigating these challenges. Most existing EEG feature selection methods assume complete multi-dimensional emotion labels. In practice, open acquisition environment, and the inherent subjectivity of emotion perception often result in incomplete label data, which can compromise model generalization. Additionally, existing feature selection methods for handling incomplete multi-dimensional labels primarily focus on correlations among various dimensions during label recovery, neglecting the correlation between samples in the label space and their interaction with various dimensions. To address these issues, we propose a novel incomplete multi-dimensional feature selection algorithm for EEG-based emotion recognition. The proposed method integrates an adaptive dual self-expression learning (ADSEL) with least squares regression. ADSEL establishes a bidirectional pathway between sample-level and dimension-level self-expression learning processes within the label space. It could facilitate the cross-sharing of learned information between these processes, enabling the simultaneous exploitation of effective information across both samples and dimensions for label reconstruction. Consequently, ADSEL could enhances label recovery accuracy and effectively identifies the optimal EEG feature subset for multi-dimensional emotion recognition.",
    "url": "https://arxiv.org/abs/2508.05229",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research focuses on developing a novel feature selection algorithm, ADSEL, for EEG-based emotion recognition in scenarios where multi-dimensional emotion labels are incomplete. The proposed method integrates adaptive dual self-expression learning with least squares regression to improve label recovery accuracy and identify optimal EEG feature subsets for emotion recognition. By establishing a bidirectional pathway between sample-level and dimension-level self-expression learning processes, ADSEL allows for more effective information sharing and exploitation across both samples and dimensions, ultimately enhancing model generalization and performance."
  },
  {
    "title": "CWEFS: Brain volume conduction effects inspired channel-wise EEG feature selection for multi-dimensional emotion recognition",
    "abstract": "Due to the intracranial volume conduction effects, high-dimensional multi-channel electroencephalography (EEG) features often contain substantial redundant and irrelevant information. This issue not only hinders the extraction of discriminative emotional representations but also compromises the real-time performance. Feature selection has been established as an effective approach to address the challenges while enhancing the transparency and interpretability of emotion recognition models. However, existing EEG feature selection research overlooks the influence of latent EEG feature structures on emotional label correlations and assumes uniform importance across various channels, directly limiting the precise construction of EEG feature selection models for multi-dimensional affective computing. To address these limitations, a novel channel-wise EEG feature selection (CWEFS) method is proposed for multi-dimensional emotion recognition. Specifically, inspired by brain volume conduction effects, CWEFS integrates EEG emotional feature selection into a shared latent structure model designed to construct a consensus latent space across diverse EEG channels. To preserve the local geometric structure, this consensus space is further integrated with the latent semantic analysis of multi-dimensional emotional labels. Additionally, CWEFS incorporates adaptive channel-weight learning to automatically determine the significance of different EEG channels in the emotional feature selection task. The effectiveness of CWEFS was validated using three popular EEG datasets with multi-dimensional emotional labels. Comprehensive experimental results, compared against nineteen feature selection methods, demonstrate that the EEG feature subsets chosen by CWEFS achieve optimal emotion recognition performance across six evaluation metrics.",
    "url": "https://arxiv.org/abs/2508.05228",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces a novel channel-wise EEG feature selection method, CWEFS, for multi-dimensional emotion recognition, addressing the issue of redundant and irrelevant information in high-dimensional EEG features. The method integrates EEG emotional feature selection into a shared latent structure model, considering the influence of latent EEG feature structures on emotional label correlations and determining the significance of different EEG channels. Experimental results show that CWEFS outperforms nineteen other feature selection methods in achieving optimal emotion recognition performance across six evaluation metrics, highlighting its effectiveness in enhancing the transparency and interpretability of emotion recognition models."
  },
  {
    "title": "AI Conversational Tutors in Foreign Language Learning: A Mixed-Methods Evaluation Study",
    "abstract": "This paper focuses on AI tutors in foreign language learning, a field of application of AI tutors with great development, especially during the last years, when great advances in natural language understanding and processing in real time, have been achieved. These tutors attempt to address needs for improving language skills (speaking, or communicative competence, understanding). In this paper, a mixed-methos empirical study on the use of different kinds of state-of-the-art AI tutors for language learning is reported. This study involves a user experience evaluation of typical such tools, with special focus in their conversation functionality and an evaluation of their quality, based on chat transcripts. This study can help establish criteria for assessing the quality of such systems and inform the design of future tools, including concerns about data privacy and secure handling of learner information.",
    "url": "https://arxiv.org/abs/2508.05156",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper evaluates the effectiveness of AI conversational tutors in foreign language learning, highlighting the recent advancements in natural language understanding and processing. The study focuses on improving language skills such as speaking and communicative competence through the use of state-of-the-art AI tutors. The findings from this mixed-methods evaluation study can help establish criteria for assessing the quality of AI language learning systems and inform the design of future tools, addressing concerns about data privacy and secure handling of learner information."
  },
  {
    "title": "Metacognition and self-regulated learning in manipulative robotic problem-solving task",
    "abstract": "Metacognition is an important aspect in creative problem solving (CPS) and through this chapter we analyse the meta-reasoning aspects applied in the different processes of monitoring the progress of learners' reasoning and CPS activities. Meta-reasoning monitors the way that problem-solving processes advance and regulate time and efforts towards a solution. In the context of an ill-defined problem, exploration is required to develop a better-defined problem space and advance towards the solution space. The way learners engage in exploration and exploitations is regulated by the meta-reasoning within the CPS activity. The objective of this chapter is to examine and identify the CPS process with educational robots through a metacognitive and interactionist approach. This chapter presents a case study, where, to solve a problem, a participant had to explore a set of robot cubes to develop the technological knowledge associated with each single component of the system, but also conceptualize a system-level behaviour of the cubes when they are assembled. The chapter presents the emergence of knowledge through the metacognitive regulation of the process of exploration and exploitation of prior knowledge and emergent knowledge until finding a solution",
    "url": "https://arxiv.org/abs/2508.05112",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the role of metacognition in creative problem solving with educational robots, specifically focusing on how learners monitor and regulate their reasoning and problem-solving processes. The study found that meta-reasoning plays a crucial role in guiding learners through exploration and exploitation of knowledge in order to advance towards a solution. The findings highlight the importance of metacognitive regulation in the learning process and how it can enhance problem-solving skills when working with manipulative robotic tasks."
  },
  {
    "title": "SparseEMG: Computational Design of Sparse EMG Layouts for Sensing Gestures",
    "abstract": "Gesture recognition with electromyography (EMG) is a complex problem influenced by gesture sets, electrode count and placement, and machine learning parameters (e.g., features, classifiers). Most existing toolkits focus on streamlining model development but overlook the impact of electrode selection on classification accuracy. In this work, we present the first data-driven analysis of how electrode selection and classifier choice affect both accuracy and sparsity. Through a systematic evaluation of 28 combinations (4 selection schemes, 7 classifiers), across six datasets, we identify an approach that minimizes electrode count without compromising accuracy. The results show that Permutation Importance (selection scheme) with Random Forest (classifier) reduces the number of electrodes by 53.5\\%. Based on these findings, we introduce SparseEMG, a design tool that generates sparse electrode layouts based on user-selected gesture sets, electrode constraints, and ML parameters while also predicting classification performance. SparseEMG supports 50+ unique gestures and is validated in three real-world applications using different hardware setups. Results from our multi-dataset evaluation show that the layouts generated from the SparseEMG design tool are transferable across users with only minimal variation in gesture recognition performance.",
    "url": "https://arxiv.org/abs/2508.05098",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the impact of electrode selection and classifier choice on gesture recognition accuracy using electromyography (EMG). The study identifies an approach that minimizes electrode count without compromising accuracy, reducing the number of electrodes by 53.5%. The findings lead to the development of SparseEMG, a design tool that generates sparse electrode layouts for gesture recognition with high accuracy and transferability across users."
  },
  {
    "title": "A Desktop-Centric Design Space for Direct Object Examination and Visualization in Mixed-Reality Environments",
    "abstract": "Mixed reality (MR) environments are bound to become ubiquitous as MR technology becomes lighter, higher resolution, more affordable, and overall becomes a seamless extension of our current work and living spaces. For research scientists and clinicians focused on understanding 3D phenomena or patient pathologies within the context of the larger human anatomy, that means a necessary evolution of their workstations currently only utilizing 2D interfaces for everyday communication, logistics and data analysis. MR technologies bring forth immersive 3D representations coexisting in our natural spaces, while allowing for richer interconnected information displays, where 3D representations greatly aid in the detailed understanding of physical structures, spatial relationships, and 3D contextualization of 2D measurements, projections, abstractions, and other data details. We present a breakdown of the different interaction zones and modalities into a design space that best accommodates the creation of applications for users engaged through MR technologies in precise object-centric data analysis within the ergonomic confines of their desktop physical spaces.",
    "url": "https://arxiv.org/abs/2508.05088",
    "journal": "arXiv cs.HC",
    "ai_summary": "The abstract discusses the potential of mixed reality (MR) environments in enhancing the understanding of 3D phenomena and patient pathologies within the context of human anatomy. The research focuses on the evolution of workstations to accommodate immersive 3D representations and interconnected information displays, allowing for detailed understanding of physical structures and spatial relationships. The study presents a design space for creating applications that facilitate precise object-centric data analysis through MR technologies within the ergonomic constraints of desktop physical spaces."
  },
  {
    "title": "Accessibility Beyond Accommodations: A Systematic Redesign of Introduction to Computer Science for Students with Visual Impairments",
    "abstract": "Computer science education has evolved extensively; however, systemic barriers still prevent students with visual impairments from fully participating. While existing research has developed specialized programming tools and assistive technologies, these solutions remain fragmented and often require complex technical infrastructure, which limits their classroom implementation. Current approaches treat accessibility as individual accommodations rather than integral curriculum design, creating gaps in holistic educational support. This paper presents a comprehensive framework for redesigning introductory computer science curricula to provide equitable learning experiences for students with visual impairments without requiring specialized technical infrastructure. The framework outlines five key components that together contribute a systematic approach to curriculum accessibility: accessible learning resources with pre-distributed materials and tactile diagrams, in-class learning kits with hands-on demonstrations, structured support systems with dedicated teaching assistance, an online tool repository, and psychosocial support for classroom participation. Unlike existing tool-focused solutions, this framework addresses both technical and pedagogical dimensions of inclusive education while emphasizing practical implementation in standard university settings. The design is grounded in universal design principles and validated through expert consultation with accessibility specialists and disability services professionals, establishing foundations for future empirical evaluation of learning outcomes and student engagement while serving as a template for broader institutional adoption.",
    "url": "https://arxiv.org/abs/2508.05056",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper presents a systematic framework for redesigning computer science curricula to make them more accessible for students with visual impairments. The framework includes components such as accessible learning resources, in-class learning kits, structured support systems, an online tool repository, and psychosocial support. Unlike existing solutions that focus on individual accommodations, this framework addresses both technical and pedagogical aspects of inclusive education, with the potential to be implemented in standard university settings and serve as a template for broader institutional adoption."
  },
  {
    "title": "Human-AI Schema Discovery and Application for Creative Problem Solving",
    "abstract": "Humans often rely on underlying structural patterns-schemas-to create, whether by writing stories, designing software, or composing music. Schemas help organize ideas and guide exploration, but they are often difficult to discover and apply, especially in complex or unfamiliar domains. My Ph.D. research develops a framework for human-AI schema discovery and application to support creative problem solving. I design systems that support users in sensemaking over examples to abstract schemas, and in operationalizing schemas into human-AI co-creative workflows for application. This research offers insights into how schema-guided interaction can make implicit knowledge more accessible and actionable, advancing more transparent and collaborative human-AI systems.",
    "url": "https://arxiv.org/abs/2508.05045",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on the development of a framework for human-AI schema discovery and application to enhance creative problem solving. The study aims to support users in identifying and utilizing underlying structural patterns (schemas) to organize ideas and guide exploration in complex or unfamiliar domains. The findings suggest that schema-guided interaction can make implicit knowledge more accessible and actionable, leading to more transparent and collaborative human-AI systems."
  },
  {
    "title": "Situated Epistemic Infrastructures: A Diagnostic Framework for Post-Coherence Knowledge",
    "abstract": "Large Language Models (LLMs) such as ChatGPT have rendered visible the fragility of contemporary knowledge infrastructures by simulating coherence while bypassing traditional modes of citation, authority, and validation. This paper introduces the Situated Epistemic Infrastructures (SEI) framework as a diagnostic tool for analyzing how knowledge becomes authoritative across hybrid human-machine systems under post-coherence conditions. Rather than relying on stable scholarly domains or bounded communities of practice, SEI traces how credibility is mediated across institutional, computational, and temporal arrangements. Integrating insights from infrastructure studies, platform theory, and epistemology, the framework foregrounds coordination over classification, emphasizing the need for anticipatory and adaptive models of epistemic stewardship. The paper contributes to debates on AI governance, knowledge production, and the ethical design of information systems by offering a robust alternative to representationalist models of scholarly communication.",
    "url": "https://arxiv.org/abs/2508.04995",
    "journal": "arXiv cs.HC",
    "ai_summary": "This paper introduces the Situated Epistemic Infrastructures (SEI) framework as a tool for analyzing how knowledge is established as authoritative in hybrid human-machine systems in a post-coherence world. The framework emphasizes the importance of coordination over classification and highlights the need for anticipatory and adaptive models of epistemic stewardship. By integrating insights from infrastructure studies, platform theory, and epistemology, the SEI framework offers a robust alternative to traditional models of scholarly communication and contributes to discussions on AI governance, knowledge production, and ethical information system design."
  },
  {
    "title": "Toward Supporting Narrative-Driven Data Exploration: Barriers and Design Opportunities",
    "abstract": "Analysts increasingly explore data through evolving, narrative-driven inquiries, moving beyond static dashboards and predefined metrics as their questions deepen and shift. As these explorations progress, insights often become dispersed across views, making it challenging to maintain context or clarify how conclusions arise. Through a formative study with 48 participants, we identify key barriers that hinder narrative-driven exploration, including difficulty maintaining context across views, tracing reasoning paths, and externalizing evolving interpretations. Our findings surface design opportunities to support narrative-driven analysis better.",
    "url": "https://arxiv.org/abs/2508.04920",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores how analysts are shifting towards narrative-driven data exploration beyond static dashboards. The study identifies barriers such as maintaining context across views and tracing reasoning paths, making it challenging to clarify how conclusions arise. The findings suggest design opportunities to better support narrative-driven analysis and improve the exploration of data for deeper insights."
  },
  {
    "title": "Root Cause Analysis Training for Healthcare Professionals With AI-Powered Virtual Simulation: A Proof-of-Concept",
    "abstract": "Root Cause Analysis (RCA) is a critical tool for investigating adverse events in healthcare and improving patient safety. However, existing RCA training programs are often limited by high resource demands, leading to insufficient training and inconsistent implementation. To address this challenge, we present an AI-powered 3D simulation game that helps healthcare professionals develop RCA skills through interactive, immersive simulations. This approach offers a cost-effective, scalable, and accessible alternative to traditional training. The prototype simulates an RCA investigation following a death in the ICU, where learners interview five virtual avatars representing ICU team members to investigate the incident and complete a written report. The system enables natural, life-like interactions with avatars via large language models (LLMs), emotional text-to-speech, and AI-powered animations. An additional LLM component provides formative and summative feedback to support continual improvement. We conclude by outlining plans to empirically evaluate the system's efficacy.",
    "url": "https://arxiv.org/abs/2508.04904",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study introduces an AI-powered 3D simulation game to help healthcare professionals improve their Root Cause Analysis (RCA) skills in investigating adverse events and enhancing patient safety. The virtual simulation offers a cost-effective and scalable alternative to traditional training programs, allowing learners to interact with virtual avatars representing ICU team members and complete a written report on an RCA investigation following a death in the ICU. The system utilizes large language models, emotional text-to-speech, and AI-powered animations to provide natural interactions and feedback, with plans for further empirical evaluation of its effectiveness."
  },
  {
    "title": "Learning AI Auditing: A Case Study of Teenagers Auditing a Generative AI Model",
    "abstract": "This study investigates how high school-aged youth engage in algorithm auditing to identify and understand biases in artificial intelligence and machine learning (AI/ML) tools they encounter daily. With AI/ML technologies being increasingly integrated into young people's lives, there is an urgent need to equip teenagers with AI literacies that build both technical knowledge and awareness of social impacts. Algorithm audits (also called AI audits) have traditionally been employed by experts to assess potential harmful biases, but recent research suggests that non-expert users can also participate productively in auditing. We conducted a two-week participatory design workshop with 14 teenagers (ages 14-15), where they audited the generative AI model behind TikTok's Effect House, a tool for creating interactive TikTok filters. We present a case study describing how teenagers approached the audit, from deciding what to audit to analyzing data using diverse strategies and communicating their results. Our findings show that participants were engaged and creative throughout the activities, independently raising and exploring new considerations, such as age-related biases, that are uncommon in professional audits. We drew on our expertise in algorithm auditing to triangulate their findings as a way to examine if the workshop supported participants to reach coherent conclusions in their audit. Although the resulting number of changes in race, gender, and age representation uncovered by the teens were slightly different from ours, we reached similar conclusions. This study highlights the potential for auditing to inspire learning activities to foster AI literacies, empower teenagers to critically examine AI systems, and contribute fresh perspectives to the study of algorithmic harms.",
    "url": "https://arxiv.org/abs/2508.04902",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research study involved teenagers participating in algorithm auditing to identify biases in AI models used in everyday technology like TikTok filters. The findings show that teenagers were able to engage creatively in the audit process, independently exploring new considerations such as age-related biases. The study suggests that involving non-expert users, like teenagers, in AI auditing can inspire learning activities to develop AI literacy and empower young people to critically examine AI systems for potential biases."
  },
  {
    "title": "An Implementation of a Visual Stepper in the GRASP Programming System",
    "abstract": "The direct purpose of this paper - as its title suggests - is to present how the visual evaluator extension is implemented in the GRASP programming system. The indirect purpose is to provide a tutorial around the design of GRASP, and in particular - around the architecture of its extension mechanism. Neither GRASP nor its extension mechanisms are, at the moment of writing this paper, final or complete, and we are certain that some details of the solutions described in here will change even before the first release. What will not change, though, is the set of problems that need to be solved in order to build a system with capabilities similar to those of GRASP. We believe that these problems might be of interest to the Scheme community.",
    "url": "https://arxiv.org/abs/2508.04859",
    "journal": "arXiv cs.HC",
    "ai_summary": "This paper discusses the implementation of a visual evaluator extension in the GRASP programming system, aiming to provide insight into the design and architecture of GRASP and its extension mechanisms. The authors acknowledge that the system is not yet final or complete, but highlight the ongoing need to address key challenges in building a system with similar capabilities. The findings suggest that the problems encountered in developing GRASP may be of interest to the Scheme community."
  },
  {
    "title": "Charts-of-Thought: Enhancing LLM Visualization Literacy Through Structured Data Extraction",
    "abstract": "This paper evaluates the visualization literacy of modern Large Language Models (LLMs) and introduces a novel prompting technique called Charts-of-Thought. We tested three state-of-the-art LLMs (Claude-3.7-sonnet, GPT-4.5 preview, and Gemini-2.0-pro) on the Visualization Literacy Assessment Test (VLAT) using standard prompts and our structured approach. The Charts-of-Thought method guides LLMs through a systematic data extraction, verification, and analysis process before answering visualization questions. Our results show Claude-3.7-sonnet achieved a score of 50.17 using this method, far exceeding the human baseline of 28.82. This approach improved performance across all models, with score increases of 21.8% for GPT-4.5, 9.4% for Gemini-2.0, and 13.5% for Claude-3.7 compared to standard prompting. The performance gains were consistent across original and modified VLAT charts, with Claude correctly answering 100% of questions for several chart types that previously challenged LLMs. Our study reveals that modern multimodal LLMs can surpass human performance on visualization literacy tasks when given the proper analytical framework. These findings establish a new benchmark for LLM visualization literacy and demonstrate the importance of structured prompting strategies for complex visual interpretation tasks. Beyond improving LLM visualization literacy, Charts-of-Thought could also enhance the accessibility of visualizations, potentially benefiting individuals with visual impairments or lower visualization literacy.",
    "url": "https://arxiv.org/abs/2508.04842",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research evaluates the visualization literacy of Large Language Models (LLMs) and introduces a new prompting technique called Charts-of-Thought. The study shows that using this method significantly improves the performance of LLMs on visualization tasks, surpassing human baseline scores and demonstrating the importance of structured prompting for complex visual interpretation. These findings set a new benchmark for LLM visualization literacy and suggest potential benefits for individuals with visual impairments or lower visualization literacy."
  },
  {
    "title": "At a Glance to Your Fingertips: Enabling Direct Manipulation of Distant Objects Through SightWarp",
    "abstract": "In 3D user interfaces, reaching out to grab and manipulate something works great until it is out of reach. Indirect techniques like gaze and pinch offer an alternative for distant interaction, but do not provide the same immediacy or proprioceptive feedback as direct gestures. To support direct gestures for faraway objects, we introduce SightWarp, an interaction technique that exploits eye-hand coordination to seamlessly summon object proxies to the user's fingertips. The idea is that after looking at a distant object, users either shift their gaze to the hand or move their hand into view-triggering the creation of a scaled near-space proxy of the object and its surrounding context. The proxy remains active until the eye-hand pattern is released. The key benefit is that users always have an option to immediately operate on the distant object through a natural, direct hand gesture. Through a user study of a 3D object docking task, we show that users can easily employ SightWarp, and that subsequent direct manipulation improves performance over gaze and pinch. Application examples illustrate its utility for 6DOF manipulation, overview-and-detail navigation, and world-in-miniature interaction. Our work contributes to expressive and flexible object interactions across near and far spaces.",
    "url": "https://arxiv.org/abs/2508.04821",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces SightWarp, an interaction technique that allows users to manipulate distant objects through direct gestures by summoning object proxies to their fingertips. This method improves performance over indirect techniques like gaze and pinch, providing users with a more natural and immediate way to interact with objects in 3D space. The study demonstrates the effectiveness of SightWarp for tasks such as 6DOF manipulation and world-in-miniature interaction, highlighting its potential for enhancing object interactions across near and far spaces."
  },
  {
    "title": "Evaluating the Impact of LLM-guided Reflection on Learning Outcomes with Interactive AI-Generated Educational Podcasts",
    "abstract": "This study examined whether embedding LLM-guided reflection prompts in an interactive AI-generated podcast improved learning and user experience compared to a version without prompts. Thirty-six undergraduates participated, and while learning outcomes were similar across conditions, reflection prompts reduced perceived attractiveness, highlighting a call for more research on reflective interactivity design.",
    "url": "https://arxiv.org/abs/2508.04787",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study investigated the impact of LLM-guided reflection prompts in interactive AI-generated podcasts on learning outcomes and user experience. While learning outcomes did not differ significantly between the two versions, the presence of reflection prompts decreased perceived attractiveness, suggesting the need for further research on designing reflective interactivity in educational podcasts."
  }
]