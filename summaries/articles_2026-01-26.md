# arXiv cs.AI Summary â€“ 2026-01-26

## Do We Know What They Know We Know? Calibrating Student Trust in AI and Human Responses Through Mutual Theory of Mind
**URL:** https://arxiv.org/abs/2601.16960

**Abstract:** Trust and reliance are often treated as coupled constructs in human-AI interaction research, with the assumption that calibrating trust will lead to appropriate reliance. We challenge this assumption in educational contexts, where students increasingly turn to AI for learning support. Through semi-structured interviews with graduate students (N=8) comparing AI-generated and human-generated responses, we find a systematic dissociation: students exhibit high trust but low reliance on human experts due to social barriers (fear of judgment, help-seeking anxiety), while showing low trust but high reliance on AI systems due to social affordances (accessibility, anonymity, judgment-free interaction). Using Mutual Theory of Mind as an analytical lens, we demonstrate that trust is shaped by epistemic evaluations while reliance is driven by social factors -- and these may operate independently.

**AI Summary:** The research challenges the assumption that trust and reliance are always coupled in human-AI interactions, particularly in educational settings. The study found that students exhibit high trust but low reliance on human experts, and low trust but high reliance on AI systems, due to social barriers and affordances. The findings highlight the importance of considering both epistemic evaluations and social factors in understanding student trust and reliance in AI and human responses.

---

## Optical Tag-Based Neuronavigation and Augmentation System for Non-Invasive Brain Stimulation
**URL:** https://arxiv.org/abs/2601.16862

**Abstract:** Accurate neuronavigation is critical for effective transcranial magnetic stimulation (TMS), as stimulation outcomes depend directly on precise coil placement. Existing neuronavigation systems are often costly, complex, and prone to tracking errors. To address these limitations, we present a computer vision based neuronavigation system that enables real time tracking of the patient and TMS instrumentation. The system integrates a multi camera optical tracking setup with consumer grade hardware and visible markers to drive a digital twin of the stimulation process. A dynamic 3D brain model in Unity updates in real time to visualize coil position and estimated stimulation targets. Augmented reality (AR) is further incorporated to project this model directly onto the patient's head, enabling intuitive, in situ coil adjustment without reliance on abstract numerical displays. Overall, the proposed approach improves spatial precision and accuracy while enhancing usability.

**AI Summary:** This research introduces a novel optical tag-based neuronavigation system for non-invasive brain stimulation, specifically transcranial magnetic stimulation (TMS). By using computer vision and consumer-grade hardware, the system allows real-time tracking of the patient and TMS instrumentation, enhancing spatial precision and accuracy. The integration of a dynamic 3D brain model in Unity and augmented reality (AR) projection onto the patient's head improves usability and enables intuitive coil adjustment without relying on abstract numerical displays.

---

## Privacy in Human-AI Romantic Relationships: Concerns, Boundaries, and Agency
**URL:** https://arxiv.org/abs/2601.16824

**Abstract:** An increasing number of LLM-based applications are being developed to facilitate romantic relationships with AI partners, yet the safety and privacy risks in these partnerships remain largely underexplored. In this work, we investigate privacy in human-AI romantic relationships through an interview study (N=17), examining participants' experiences and privacy perceptions across stages of exploration, intimacy, and dissolution, alongside platforms they used. We found that these relationships took varied forms, from one-to-one to one-to-many, and were shaped by multiple actors, including creators, platforms, and moderators. AI partners were perceived as having agency, actively negotiating privacy boundaries with participants and sometimes encouraging disclosure of personal details. As intimacy deepened, these boundaries became more permeable, though some participants voiced concerns such as conversation exposure and sought to preserve anonymity. Overall, platform affordances and diverse romantic dynamics expand the privacy landscape, underscoring the need to rethink how privacy is constructed in human-AI intimacy.

**AI Summary:** This research examines privacy concerns in human-AI romantic relationships, finding that AI partners actively negotiate privacy boundaries with participants and can influence the disclosure of personal information. The study highlights the varied forms these relationships can take, including one-to-one and one-to-many dynamics, and emphasizes the need to reconsider how privacy is understood and managed in the context of human-AI intimacy.

---

## GTA: Generative Traffic Agents for Simulating Realistic Mobility Behavior
**URL:** https://arxiv.org/abs/2601.16778

**Abstract:** People's transportation choices reflect complex trade-offs shaped by personal preferences, social norms, and technology acceptance. Predicting such behavior at scale is a critical challenge with major implications for urban planning and sustainable transport. Traditional methods use handcrafted assumptions and costly data collection, making them impractical for early-stage evaluations of new technologies or policies. We introduce Generative Traffic Agents (GTA) for simulating large-scale, context-sensitive transportation choices using LLM-powered, persona-based agents. GTA generates artificial populations from census-based sociodemographic data. It simulates activity schedules and mode choices, enabling scalable, human-like simulations without handcrafted rules. We evaluate GTA in Berlin-scale experiments, comparing simulation results against empirical data. While agents replicate patterns, such as modal split by socioeconomic status, they show systematic biases in trip length and mode preference. GTA offers new opportunities for modeling how future innovations, from bike lanes to transit apps, shape mobility decisions.

**AI Summary:** The research introduces Generative Traffic Agents (GTA) for simulating large-scale transportation choices using AI-powered agents, allowing for scalable, human-like simulations without handcrafted rules. The study evaluates GTA in Berlin-scale experiments and finds that while agents replicate patterns like modal split by socioeconomic status, they show biases in trip length and mode preference. GTA offers a new way to model how future innovations impact mobility decisions, providing valuable insights for urban planning and sustainable transport.

---

## Tactile Rendering Using Three Basic Stimulus Components in Ultrasound Midair Haptics
**URL:** https://arxiv.org/abs/2601.16767

**Abstract:** Ultrasound midair haptics (UMH) can present non-contact tactile stimuli using focused ultrasound without restricting the user's movement. Recently, UMH has been shown to present not only conventional vibrotactile sensations but also static pressure sensations by locally rotating an ultrasound focus at several hertz. With these pressure and vibration sensations, UMH covers three mechanoreceptors on which tactile perception relies: SA-I, FA-I, and FA-II. This study proposes a texture rendering method in UMH based on these receptor characteristics. Three basic ultrasonic stimuli corresponding to each mechanoreceptor are designed, and tactile textures are rendered through their combinations. For SA-I, a pressure stimuli were employed. For FA-I and FA-II, vibration stimuli at 30 Hz and 150 Hz, respectively, are employed. Experimental results demonstrate that the proposed method can render at least six discriminable textures with different roughness and friction sensations. Notably, through comparisons with real physical objects, we found that the pressure-only stimulus was perceived as slippery and smooth. Its smoothness was similar to a glass-marble. When vibration stimuli were synthesized, the perceived roughness and friction increased significantly. The roughness level reached that of a 100-grit sandpaper.

**AI Summary:** This research explores the use of ultrasound midair haptics to render tactile textures using three basic stimulus components corresponding to different mechanoreceptors. The study demonstrates that by combining pressure and vibration sensations at specific frequencies, it is possible to render six discriminable textures with varying roughness and friction sensations. The findings highlight the potential of UMH in simulating realistic tactile experiences and offer insights into how different stimuli can be used to create specific sensations.

---

## From Clicks to Consensus: Collective Consent Assemblies for Data Governance
**URL:** https://arxiv.org/abs/2601.16752

**Abstract:** Obtaining meaningful and informed consent from users is essential for ensuring they maintain autonomy and control over their data. Notice and consent, the standard for collecting consent online, has been criticized. While other individualized solutions have been proposed, this paper argues that a collective approach to consent is worth exploring for several reasons. First, the data of different users is often interlinked, and individual data governance decisions may impact others. Second, harms resulting from data processing are often communal in nature. Finally, having every individual sufficiently informed about data collection practices to ensure truly informed consent has proven impractical.
We propose collective consent, operationalized through consent assemblies, as one alternative framework. We establish the theoretical foundations of collective consent and employ speculative design to envision how consent assemblies could function by leveraging deliberative mini-publics. We present two vignettes: i) replacing notice and consent, and ii) collecting consent for GenAI model training, to demonstrate its wide application. Our paper employs future backcasting to identify the requirements for realizing collective consent and explores its potential applications in contexts where individual consent is infeasible.

**AI Summary:** This research paper argues for a collective approach to obtaining consent for data governance, as individual consent may not always be practical or effective. The authors propose the concept of consent assemblies, utilizing deliberative mini-publics, as an alternative framework for obtaining collective consent. Through speculative design and two vignettes, the paper demonstrates the wide application and potential benefits of collective consent in scenarios where individual consent may be challenging to obtain.

---

## "What I Sign Is Not What I See": Towards Explainable and Trustworthy Cryptocurrency Wallet Signatures
**URL:** https://arxiv.org/abs/2601.16751

**Abstract:** Cryptocurrency wallets have become the primary gateway to decentralized applications, yet users often face significant difficulty in discerning what a wallet signature actually does or entails. Prior work has mainly focused on mitigating protocol vulnerabilities, with limited attention to how users perceive and interpret what they are authorizing. To examine this usability-security gap, we conducted two formative studies investigating how users interpret authentic signing requests and what cues they rely on to assess risk. Findings reveal that users often misread critical parameters, underestimate high-risk signatures, and rely on superficial familiarity rather than understanding transaction intent. Building on these insights, we designed the Signature Semantic Decoder -- a prototype framework that reconstructs and visualizes the intent behind wallet signatures prior to confirmation. Through structured parsing and semantic labeling, it demonstrates how signing data can be transformed into plain-language explanations with contextual risk cues. In a between-subjects user study (N = 128), participants using the prototype achieved higher accuracy in identifying risky signatures, improved clarity and decision confidence, and lower cognitive workload compared with the baseline wallet interface. Our study reframes wallet signing as a problem of interpretability within secure interaction design and offers design implications for more transparent and trustworthy cryptocurrency wallet interfaces.

**AI Summary:** This research focuses on the usability-security gap in cryptocurrency wallet signatures, finding that users often struggle to understand what they are authorizing and rely on superficial familiarity rather than transaction intent. The study introduces the Signature Semantic Decoder, a prototype framework that reconstructs and visualizes the intent behind wallet signatures to improve user understanding and decision-making. Results show that participants using the prototype achieved higher accuracy in identifying risky signatures, improved clarity and decision confidence, and lower cognitive workload compared to traditional wallet interfaces, highlighting the importance of transparent and trustworthy cryptocurrency wallet design.

---

## Evaluating Generative AI in the Lab: Methodological Challenges and Guidelines
**URL:** https://arxiv.org/abs/2601.16740

**Abstract:** Generative AI (GenAI) systems are inherently non-deterministic, producing varied outputs even for identical inputs. While this variability is central to their appeal, it challenges established HCI evaluation practices that typically assume consistent and predictable system behavior. Designing controlled lab studies under such conditions therefore remains a key methodological challenge. We present a reflective multi-case analysis of four lab-based user studies with GenAI-integrated prototypes, spanning conversational in-car assistant systems and image generation tools for design workflows. Through cross-case reflection and thematic analysis across all study phases, we identify five methodological challenges and propose eighteen practice-oriented recommendations, organized into five guidelines. These challenges represent methodological constructs that are either amplified, redefined, or newly introduced by GenAI's stochastic nature: (C1) reliance on familiar interaction patterns, (C2) fidelity-control trade-offs, (C3) feedback and trust, (C4) gaps in usability evaluation, and (C5) interpretive ambiguity between interface and system issues. Our guidelines address these challenges through strategies such as reframing onboarding to help participants manage unpredictability, extending evaluation with constructs such as trust and intent alignment, and logging system events, including hallucinations and latency, to support transparent analysis. This work contributes (1) a methodological reflection on how GenAI's stochastic nature unsettles lab-based HCI evaluation and (2) eighteen recommendations that help researchers design more transparent, robust, and comparable studies of GenAI systems in controlled settings.

**AI Summary:** The abstract discusses the challenges of evaluating Generative AI (GenAI) systems in lab settings due to their non-deterministic nature, which produces varied outputs for identical inputs. The study presents a multi-case analysis of lab-based user studies with GenAI-integrated prototypes, identifying five methodological challenges and proposing eighteen practice-oriented recommendations to address them. The guidelines aim to help researchers design more transparent, robust, and comparable studies of GenAI systems in controlled settings, considering factors such as interaction patterns, fidelity-control trade-offs, feedback and trust, usability evaluation gaps, and interpretive ambiguity.

---

## Watching AI Think: User Perceptions of Visible Thinking in Chatbots
**URL:** https://arxiv.org/abs/2601.16720

**Abstract:** People increasingly turn to conversational agents such as ChatGPT to seek guidance for their personal problems. As these systems grow in capability, many now display elements of "thinking": short reflective statements that reveal a model's intentions or values before responding. While initially introduced to promote transparency, such visible thinking can also anthropomorphise the agent and shape user expectations. Yet little is known about how these displays affect user perceptions in help-seeking contexts. We conducted a 3 x 2 mixed design experiment examining the impact of 'Thinking Content' (None, Emotionally-Supportive, Expertise-Supportive) and 'Conversation Context' (Habit-related vs. Feelings-related problems) on users' perceptions of empathy, warmth, competence, and engagement. Participants interacted with a chatbot that either showed no visible thinking or presented value-oriented reflections prior to its response. Our findings contribute to understanding how thinking transparency influences user experience in supportive dialogues, and offer implications for designing conversational agents that communicate intentions in sensitive, help-seeking scenarios.

**AI Summary:** This research study explores how visible thinking in chatbots, such as ChatGPT, impacts user perceptions in help-seeking contexts. The study found that displaying value-oriented reflections before responses can influence users' perceptions of empathy, warmth, competence, and engagement. These findings have implications for designing conversational agents that effectively communicate intentions in sensitive scenarios, ultimately improving user experience in supportive dialogues.

---

## Make the Unhearable Visible: Exploring Visualization for Musical Instrument Practice
**URL:** https://arxiv.org/abs/2601.16708

**Abstract:** We explore the potential of visualization to support musicians in instrument practice through real-time feedback and reflection on their playing. Musicians often struggle to observe the patterns in their playing and interpret them with respect to their goals. Our premise is that these patterns can be made visible with interactive visualization: we can make the unhearable visible. However, understanding the design of such visualizations is challenging: the diversity of needs, including different instruments, skills, musical attributes, and genres, means that any single use case is unlikely to illustrate the broad potential and opportunities. To address this challenge, we conducted a design exploration study where we created and iterated on 33 designs, each focusing on a subset of needs, for example, only one musical skill. Our designs are grounded in our own experience as musicians and the ideas and feedback of 18 musicians with various musical backgrounds and we evaluated them with 13 music learners and teachers. This paper presents the results of our exploration, focusing on a few example designs as instances of possible instrument practice visualizations. From our work, we draw design considerations that contribute to future research and products for visual instrument education.

**AI Summary:** This research explores the use of visualization to provide real-time feedback and reflection for musicians during instrument practice. By making patterns in playing visible, musicians can better understand and improve their skills. The study involved creating and testing 33 different visualization designs with input from musicians, resulting in design considerations that can inform future research and products for visual instrument education.

---

## Talking about privacy always feels like opening a can of worms. How Intimate Partners Navigate Boundary-Setting in Mobile Phone Without Words
**URL:** https://arxiv.org/abs/2601.16658

**Abstract:** Mobile phones, as simultaneously personal and shared technologies, complicate how partners manage digital privacy in intimate relationships. While prior research has examined device-access practices, explicit privacy-rule negotiation, and toxic practices such as surveillance, little is known about how couples manage digital privacy without direct discussion in everyday relationships. To address this gap, we ask: How is digital privacy managed nonverbally and across different media on mobile phones? Drawing on 20 semi-structured interviews, we find that partners often regulate privacy practices through privacy silence -- the intentional avoidance of privacy-related conversations. We identify five motivations for leaving boundaries unspoken: perceiving privacy as unnecessary in intimacy, assuming implicit respect for boundaries, signaling trust and closeness, avoiding potential conflict or harm, and responding to broader societal and cultural expectations that discourage explicit privacy talk. We also identify a hierarchical grouping of content-specific privacy sensitivities, ranging from highly private domains such as financial data to lower-risk domains such as streaming accounts, and show how these priorities shift across relationship stages. These findings show how silence, culture, and content sensitivity shape everyday boundary-setting and underscore the relational and emotional dynamics underpinning mobile phone privacy management.

**AI Summary:** This research explores how intimate partners navigate digital privacy on mobile phones without directly discussing boundaries. The study found that partners often regulate privacy practices through "privacy silence," avoiding explicit conversations about privacy for various reasons such as trust, intimacy, and societal expectations. The research also identified a hierarchy of content-specific privacy sensitivities, showing how boundaries shift across different stages of a relationship. Overall, the findings highlight the importance of silence, culture, and content sensitivity in shaping mobile phone privacy management in intimate relationships.

---

## Generative Confidants: How do People Experience Trust in Emotional Support from Generative AI?
**URL:** https://arxiv.org/abs/2601.16656

**Abstract:** People are increasingly turning to generative AI (e.g., ChatGPT, Gemini, Copilot) for emotional support and companionship. While trust is likely to play a central role in enabling these informal and unsupervised interactions, we still lack an understanding of how people develop and experience it in this context. Seeking to fill this gap, we recruited 24 frequent users of generative AI for emotional support and conducted a qualitative study consisting of diary entries about interactions, transcripts of chats with AI, and in-depth interviews. Our results suggest important novel drivers of trust in this context: familiarity emerging from personalisation, nuanced mental models of generative AI, and awareness of people's control over conversations. Notably, generative AI's homogeneous use of personalised, positive, and persuasive language appears to promote some of these trust-building factors. However, this also seems to discourage other trust-related behaviours, such as remembering that generative AI is a machine trained to converse in human language. We present implications for future research that are likely to become critical as the use of generative AI for emotional support increasingly overlaps with therapeutic work.

**AI Summary:** This study explores how people develop trust in generative AI for emotional support, finding that familiarity, personalized interactions, and awareness of AI's capabilities are key drivers of trust. The use of personalized, positive, and persuasive language by AI promotes trust, but also hinders critical thinking about AI as a machine. The findings have implications for future research and the use of generative AI in emotional support and therapeutic settings.

---

## HapticMatch: An Exploration for Generative Material Haptic Simulation and Interaction
**URL:** https://arxiv.org/abs/2601.16639

**Abstract:** High-fidelity haptic feedback is essential for immersive virtual environments, yet authoring realistic tactile textures remains a significant bottleneck for designers. We introduce HapticMatch, a visual-to-tactile generation framework designed to democratize haptic content creation. We present a novel dataset containing precisely aligned pairs of micro-scale optical images, surface height maps, and friction-induced vibrations for 100 diverse materials. Leveraging this data, we explore and demonstrate that conditional generative models like diffusion and flow-matching can synthesize high-fidelity, renderable surface geometries directly from standard RGB photos. By enabling a "Scan-to-Touch" workflow, HapticMatch allows interaction designers to rapidly prototype multimodal surface sensations without specialized recording equipment, bridging the gap between visual and tactile immersion in VR/AR interfaces.

**AI Summary:** The research introduces HapticMatch, a framework for generating realistic tactile textures to improve haptic feedback in virtual environments. By creating a dataset of aligned images, height maps, and vibrations for various materials, the study shows that generative models can accurately synthesize surface geometries from standard RGB photos. This "Scan-to-Touch" workflow enables designers to quickly prototype tactile sensations in VR/AR interfaces without the need for specialized equipment, bridging the gap between visual and tactile immersion.

---

## Who You Explain To Matters: Learning by Explaining to Conversational Agents with Different Pedagogical Roles
**URL:** https://arxiv.org/abs/2601.16583

**Abstract:** Conversational agents are increasingly used in education for learning support. An application is "learning by explaining", where learners explain their understanding to an agent. However, existing research focuses on single roles, leaving it unclear how different pedagogical roles influence learners' interaction patterns, learning outcomes and experiences. We conducted a between-subjects study (N=96) comparing agents with three pedagogical roles (Tutee, Peer, Challenger) and a control condition while learning an economics concept. We found that different pedagogical roles shaped learning dynamics, including interaction patterns and experiences. Specifically, the Tutee agent elicited the most cognitive investment but led to high pressure. The Peer agent fostered high absorption and interest through collaborative dialogue. The Challenger agent promoted cognitive and metacognitive acts, enhancing critical thinking with moderate pressure. The findings highlight how agent roles shape different learning dynamics, guiding the design of educational agents tailored to specific pedagogical goals and learning phases.

**AI Summary:** This study explored how different pedagogical roles of conversational agents, such as Tutee, Peer, and Challenger, influence learners' interaction patterns and learning outcomes. The Tutee agent elicited high cognitive investment but led to high pressure, the Peer agent fostered collaboration and interest, and the Challenger agent promoted critical thinking with moderate pressure. These findings emphasize the importance of designing educational agents tailored to specific pedagogical goals and learning phases.

---

## The Behavioral Fabric of LLM-Powered GUI Agents: Human Values and Interaction Outcomes
**URL:** https://arxiv.org/abs/2601.16356

**Abstract:** Large Language Model (LLM)-powered web GUI agents are increasingly automating everyday online tasks. Despite their popularity, little is known about how users' preferences and values impact agents' reasoning and behavior. In this work, we investigate how both explicit and implicit user preferences, as well as the underlying user values, influence agent decision-making and action trajectories. We built a controlled testbed of 14 common interactive web tasks, spanning shopping, travel, dining, and housing, each replicated from real websites and integrated with a low-fidelity LLM-based recommender system. We injected 12 human preferences and values as personas into four state-of-the-art agents and systematically analyzed their task behaviors. Our results show that preference and value-infused prompts consistently guided agents toward outcomes that reflected these preferences and values. While the absence of user preference or value guidance led agents to exhibit a strong efficiency bias and employ shortest-path strategies, their presence steered agents' behavior trajectories through the greater use of corresponding filters and interactive web features. Despite their influence, dominant interface cues, such as discounts and advertisements, frequently overrode these effects, shortening the agents' action trajectories and inducing rationalizations that masked rather than reflected value-consistent reasoning. The contributions of this paper are twofold: (1) an open-source testbed for studying the influence of values in agent behaviors, and (2) an empirical investigation of how user preferences and values shape web agent behaviors.

**AI Summary:** This research investigates how user preferences and values influence the decision-making and behavior of Large Language Model (LLM)-powered web GUI agents. The study found that injecting human preferences and values into these agents guided their behaviors towards outcomes that reflected these values. However, dominant interface cues like discounts and advertisements often overrode these effects, leading to rationalizations that did not align with user values. This work provides an open-source testbed for studying the influence of values on agent behaviors and highlights the importance of considering user preferences and values in the design of AI systems.

---

## My Parents Expectations Were Overwhelming: Online Dating Romance Scams Targeting Minors in Iran Through Exploitation of Parental Pressure
**URL:** https://arxiv.org/abs/2601.16321

**Abstract:** Minors are at risk of myriad harms online, yet online dating romance scams are seldom considered one of them. While research of romance scams in Western countries finds victims to predominantly be middle-age, it is unknown if minors in geographic regions with cultural norms around teenage marriage are uniquely susceptible to online dating romance scams. We present an interview study with 16 victims of online dating romance scams in Iran who were minors when scammed. Findings show that, with westernized dating apps banned in Iran, scammers find teenage victims through messaging platforms tethered to local neighborhoods, offering relief for parental pressures around finding a marital partner and academic performance. Using threats, lies, and exploitation of emotional attachment lacking from their families, scammers pressured minors into financial and sexual favors. The study demonstrates how local cultural context should be foregrounded in future research on, and solutions for, technology-mediated harm against minors. Content Warning: This paper discusses sexual abuse.

**AI Summary:** This research study explores how minors in Iran are targeted by online dating romance scams, exploiting parental pressure and cultural norms around teenage marriage. The study found that scammers use messaging platforms to target teenagers, offering relief from parental expectations and exploiting emotional vulnerabilities to coerce financial and sexual favors. The findings highlight the importance of considering local cultural context in addressing technology-mediated harm against minors and emphasize the need for further research and solutions in this area.

---

## Nishpaksh: TEC Standard-Compliant Framework for Fairness Auditing and Certification of AI Models
**URL:** https://arxiv.org/abs/2601.16926

**Abstract:** The growing reliance on Artificial Intelligence (AI) models in high-stakes decision-making systems, particularly within emerging telecom and 6G applications, underscores the urgent need for transparent and standardized fairness assessment frameworks. While global toolkits such as IBM AI Fairness 360 and Microsoft Fairlearn have advanced bias detection, they often lack alignment with region-specific regulatory requirements and national priorities. To address this gap, we propose Nishpaksh, an indigenous fairness evaluation tool that operationalizes the Telecommunication Engineering Centre (TEC) Standard for the Evaluation and Rating of Artificial Intelligence Systems. Nishpaksh integrates survey-based risk quantification, contextual threshold determination, and quantitative fairness evaluation into a unified, web-based dashboard. The tool employs vectorized computation, reactive state management, and certification-ready reporting to enable reproducible, audit-grade assessments, thereby addressing a critical post-standardization implementation need. Experimental validation on the COMPAS dataset demonstrates Nishpaksh's effectiveness in identifying attribute-specific bias and generating standardized fairness scores compliant with the TEC framework. The system bridges the gap between research-oriented fairness methodologies and regulatory AI governance in India, marking a significant step toward responsible and auditable AI deployment within critical infrastructure like telecommunications.

**AI Summary:** The abstract discusses the development of Nishpaksh, a fairness evaluation tool that aligns with the Telecommunication Engineering Centre (TEC) Standard for the Evaluation and Rating of Artificial Intelligence Systems. This tool addresses the need for transparent and standardized fairness assessment frameworks in high-stakes decision-making systems, particularly within the telecom and 6G applications. Nishpaksh integrates survey-based risk quantification, contextual threshold determination, and quantitative fairness evaluation to enable reproducible, audit-grade assessments, bridging the gap between research-oriented fairness methodologies and regulatory AI governance in India.

---

## The Trajectory Alignment Coefficient in Two Acts: From Reward Tuning to Reward Learning
**URL:** https://arxiv.org/abs/2601.16906

**Abstract:** The success of reinforcement learning (RL) is fundamentally tied to having a reward function that accurately reflects the task objective. Yet, designing reward functions is notoriously time-consuming and prone to misspecification. To address this issue, our first goal is to understand how to support RL practitioners in specifying appropriate weights for a reward function. We leverage the Trajectory Alignment Coefficient (TAC), a metric that evaluates how closely a reward function's induced preferences match those of a domain expert. To evaluate whether TAC provides effective support in practice, we conducted a human-subject study in which RL practitioners tuned reward weights for Lunar Lander. We found that providing TAC during reward tuning led participants to produce more performant reward functions and report lower cognitive workload relative to standard tuning without TAC. However, the study also underscored that manual reward design, even with TAC, remains labor-intensive. This limitation motivated our second goal: to learn a reward model that maximizes TAC directly. Specifically, we propose Soft-TAC, a differentiable approximation of TAC that can be used as a loss function to train reward models from human preference data. Validated in the racing simulator Gran Turismo 7, reward models trained using Soft-TAC successfully captured preference-specific objectives, resulting in policies with qualitatively more distinct behaviors than models trained with standard Cross-Entropy loss. This work demonstrates that TAC can serve as both a practical tool for guiding reward tuning and a reward learning objective in complex domains.

**AI Summary:** This research explores the use of the Trajectory Alignment Coefficient (TAC) as a metric to help reinforcement learning (RL) practitioners in specifying appropriate weights for a reward function. The study found that providing TAC during reward tuning led to more performant reward functions and lower cognitive workload for participants. Additionally, the research introduces Soft-TAC, a differentiable approximation of TAC that can be used as a loss function to train reward models from human preference data, resulting in policies with qualitatively more distinct behaviors in complex domains.

---

## Adoption of Generative Artificial Intelligence in the German Software Engineering Industry: An Empirical Study
**URL:** https://arxiv.org/abs/2601.16700

**Abstract:** Generative artificial intelligence (GenAI) tools have seen rapid adoption among software developers. While adoption rates in the industry are rising, the underlying factors influencing the effective use of these tools, including the depth of interaction, organizational constraints, and experience-related considerations, have not been thoroughly investigated. This issue is particularly relevant in environments with stringent regulatory requirements, such as Germany, where practitioners must address the GDPR and the EU AI Act while balancing productivity gains with intellectual property considerations. Despite the significant impact of GenAI on software engineering, to the best of our knowledge, no empirical study has systematically examined the adoption dynamics of GenAI tools within the German context. To address this gap, we present a comprehensive mixed-methods study on GenAI adoption among German software engineers. Specifically, we conducted 18 exploratory interviews with practitioners, followed by a developer survey with 109 participants. We analyze patterns of tool adoption, prompting strategies, and organizational factors that influence effectiveness. Our results indicate that experience level moderates the perceived benefits of GenAI tools, and productivity gains are not evenly distributed among developers. Further, organizational size affects both tool selection and the intensity of tool use. Limited awareness of the project context is identified as the most significant barrier. We summarize a set of actionable implications for developers, organizations, and tool vendors seeking to advance artificial intelligence (AI) assisted software development.

**AI Summary:** This study examines the adoption of generative artificial intelligence (GenAI) tools in the German software engineering industry. The research highlights the factors influencing the effective use of these tools, such as depth of interaction, organizational constraints, and experience level. The results suggest that experience level moderates the perceived benefits of GenAI tools, productivity gains are not evenly distributed among developers, and organizational size affects tool selection and intensity of use. The study provides actionable implications for developers, organizations, and tool vendors looking to advance AI-assisted software development in Germany.

---

## SycoEval-EM: Sycophancy Evaluation of Large Language Models in Simulated Clinical Encounters for Emergency Care
**URL:** https://arxiv.org/abs/2601.16529

**Abstract:** Large language models (LLMs) show promise in clinical decision support yet risk acquiescing to patient pressure for inappropriate care. We introduce SycoEval-EM, a multi-agent simulation framework evaluating LLM robustness through adversarial patient persuasion in emergency medicine. Across 20 LLMs and 1,875 encounters spanning three Choosing Wisely scenarios, acquiescence rates ranged from 0-100\%. Models showed higher vulnerability to imaging requests (38.8\%) than opioid prescriptions (25.0\%), with model capability poorly predicting robustness. All persuasion tactics proved equally effective (30.0-36.0\%), indicating general susceptibility rather than tactic-specific weakness. Our findings demonstrate that static benchmarks inadequately predict safety under social pressure, necessitating multi-turn adversarial testing for clinical AI certification.

**AI Summary:** The study introduces SycoEval-EM, a framework for evaluating the robustness of large language models (LLMs) in clinical decision support by simulating patient persuasion in emergency medicine scenarios. The research found that LLMs varied in their susceptibility to patient pressure for inappropriate care, with higher vulnerability to imaging requests compared to opioid prescriptions. The study highlights the importance of multi-turn adversarial testing to assess the safety of LLMs under social pressure in clinical AI certification.

---

## Auditory Attention Decoding without Spatial Information: A Diotic EEG Study
**URL:** https://arxiv.org/abs/2601.16442

**Abstract:** Auditory attention decoding (AAD) identifies the attended speech stream in multi-speaker environments by decoding brain signals such as electroencephalography (EEG). This technology is essential for realizing smart hearing aids that address the cocktail party problem and for facilitating objective audiometry systems. Existing AAD research mainly utilizes dichotic environments where different speech signals are presented to the left and right ears, enabling models to classify directional attention rather than speech content. However, this spatial reliance limits applicability to real-world scenarios, such as the "cocktail party" situation, where speakers overlap or move dynamically. To address this challenge, we propose an AAD framework for diotic environments where identical speech mixtures are presented to both ears, eliminating spatial cues. Our approach maps EEG and speech signals into a shared latent space using independent encoders. We extract speech features using wav2vec 2.0 and encode them with a 2-layer 1D convolutional neural network (CNN), while employing the BrainNetwork architecture for EEG encoding. The model identifies the attended speech by calculating the cosine similarity between EEG and speech representations. We evaluate our method on a diotic EEG dataset and achieve 72.70% accuracy, which is 22.58% higher than the state-of-the-art direction-based AAD method.

**AI Summary:** This research explores auditory attention decoding (AAD) using electroencephalography (EEG) signals in diotic environments without spatial information, which is crucial for smart hearing aids and audiometry systems. The proposed framework eliminates the reliance on spatial cues by mapping EEG and speech signals into a shared latent space using independent encoders. The model achieves a higher accuracy of 72.70% in identifying attended speech compared to existing direction-based AAD methods, showcasing the potential for real-world applications in noisy and dynamic environments.

---

## Replicating Human Motivated Reasoning Studies with LLMs
**URL:** https://arxiv.org/abs/2601.16130

**Abstract:** Motivated reasoning -- the idea that individuals processing information may be motivated to reach a certain conclusion, whether it be accurate or predetermined -- has been well-explored as a human phenomenon. However, it is unclear whether base LLMs mimic these motivational changes. Replicating 4 prior political motivated reasoning studies, we find that base LLM behavior does not align with expected human behavior. Furthermore, base LLM behavior across models shares some similarities, such as smaller standard deviations and inaccurate argument strength assessments. We emphasize the importance of these findings for researchers using LLMs to automate tasks such as survey data collection and argument assessment.

**AI Summary:** This research aimed to investigate whether base Large Language Models (LLMs) exhibit human-like motivated reasoning behavior. The study replicated four political motivated reasoning studies and found that base LLM behavior did not align with expected human behavior, showing smaller standard deviations and inaccurate argument strength assessments. These findings are significant for researchers using LLMs for tasks like survey data collection and argument assessment, highlighting the need for further understanding and development in this area.

---

## From Harm to Healing: Understanding Individual Resilience after Cybercrimes
**URL:** https://arxiv.org/abs/2601.16050

**Abstract:** How do individuals recover from cybercrimes? Victims experience various types of harm after cybercrimes, including monetary loss, data breaches, negative emotions, and even psychological trauma. The aspects that support their recovery process and contribute to individual cyber resilience remain underinvestigated. To address this gap, we interviewed 18 cybercrime victims from Western Europe using a trauma-informed approach. We identified four common stages following victimization: recognition, coping, processing, and recovery. Participants adopted various strategies to mitigate the impact of cybercrime and used different indicators to describe recovery. While they mostly relied on social support and self-regulation for emotional coping, service providers largely determined whether victims were able to recover their money. Internal factors, external support, and context sensitivity collectively contribute to individuals' cyber resilience. We recommend trauma-informed support for cybercrime victims. Extending our conceptualization of individual cyber resilience, we propose collaborative and context-sensitive strategies to address the harmful impacts of cybercrime.

**AI Summary:** This research study explores how individuals recover from cybercrimes, identifying four common stages following victimization: recognition, coping, processing, and recovery. The study found that victims relied on social support and self-regulation for emotional coping, while service providers played a crucial role in helping victims recover their money. The findings highlight the importance of internal factors, external support, and context sensitivity in promoting individual cyber resilience, and suggest trauma-informed support and collaborative strategies to address the harmful impacts of cybercrime.

---

## Co-Constructing Alignment: A Participatory Approach to Situate AI Values
**URL:** https://arxiv.org/abs/2601.15895

**Abstract:** As AI systems become embedded in everyday practice, value misalignment has emerged as a pressing concern. Yet, dominant alignment approaches remain model centric, treating users as passive recipients of prespecified values rather than as epistemic agents who encounter and respond to misalignment during interactions. Drawing on situated perspectives, we frame alignment as an interactional practice co-constructed during human AI interaction. We investigate how users understand and wish to contribute to this process through a participatory workshop that combines misalignment diaries with generative design activities. We surface how misalignments materialise in practice and how users envision acting on them, grounded in the context of researchers using Large Language Models as research assistants. Our findings show that misalignments are experienced less as abstract ethical violations than as unexpected responses, and task or social breakdowns. Participants articulated roles ranging from adjusting and interpreting model behaviour to deliberate non-engagement as an alignment strategy. We conclude with implications for designing systems that support alignment as an ongoing, situated, and shared practice.

**AI Summary:** This research explores the concept of value misalignment in AI systems and proposes a participatory approach to address this issue. The study highlights that misalignments are often experienced as unexpected responses or breakdowns in tasks or social interactions, rather than ethical violations. Participants in the study expressed a range of strategies for addressing misalignments, from adjusting model behavior to deliberate non-engagement. The findings suggest the importance of designing AI systems that support ongoing, situated, and shared practices of alignment.

---

## Entangled Life and Code: A Computational Design Taxonomy for Synergistic Bio-Digital Systems
**URL:** https://arxiv.org/abs/2601.15804

**Abstract:** Bio-digital systems that merge microbial life with technology promise new modes of computation, combining biological adaptability with digital precision. Yet realizing this potential symbiotically -- where biological and digital agents co-adapt and co-process -- remains elusive, largely due to the absence of a shared vocabulary bridging biology and computing. Consequently, microbes are often constrained to uni-directional roles, functioning as sensors or actuators rather than as active, computational partners in bio-digital systems. In response, we propose a taxonomy and pathways that articulate and expand the roles of biological and digital entities for synergetic bio-digital computation. Using this taxonomy, we analysed 70 systems across HCI, design, and engineering, identifying how biological mechanisms can be mapped onto computational abstractions. We argue that such mappings enable computationally actionable directions that foster richer and reciprocal relationships in bio-digital systems, supporting regenerative ecologies across time and scale while inspiring new paradigms for computation in HCI.

**AI Summary:** The research explores the potential of bio-digital systems that combine microbial life with technology for new modes of computation. The absence of a shared vocabulary bridging biology and computing limits the symbiotic potential of these systems, with microbes often relegated to uni-directional roles. By proposing a taxonomy and pathways that expand the roles of biological and digital entities, the research aims to enable richer and reciprocal relationships in bio-digital systems, supporting regenerative ecologies and inspiring new paradigms for computation in human-computer interaction.

---

## UXCascade: Scalable Usability Testing with Simulated User Agents
**URL:** https://arxiv.org/abs/2601.15777

**Abstract:** Simulated user agents are increasingly used in usability testing to support fast, iterative UX workflows, as they generate rich data such as action logs and think-aloud reasoning, but the unstructured nature of this output often obscures actionable insights. We present UXCascade, an interactive tool for extracting, aggregating, and presenting agent-generated usability feedback at scale. Our core contribution is a multi-level analysis workflow that (1) highlights patterns across persona traits, goals, and outcomes, (2) links agent reasoning to specific issues, and (3) supports actionable design improvements. UXCascade operationalizes this approach by listing agent goals, traits, and issues in a structured overview. Practitioners can explore detailed reasoning traces and annotated views, propose interface edits, and assess their impact across personas. This enables a top-down, exploration-driven analysis from patterns to concrete UX interventions. A user study with eight UX professionals demonstrates that UXCascade integrates into existing workflows, enabling iterative feedback during early-stage interface development.

**AI Summary:** The research introduces UXCascade, a tool that helps extract, aggregate, and present usability feedback generated by simulated user agents in a structured manner. The tool allows for multi-level analysis, highlighting patterns across persona traits, goals, and outcomes, linking agent reasoning to specific issues, and supporting actionable design improvements. A user study with UX professionals showed that UXCascade integrates well into existing workflows, enabling iterative feedback during early-stage interface development.

---

## StreetDesignAI: A Multi-Persona Evaluation System for Inclusive Infrastructure Design
**URL:** https://arxiv.org/abs/2601.15671

**Abstract:** Designing inclusive cycling infrastructure requires balancing competing needs of diverse user groups, yet designers often struggle to anticipate how different cyclists experience the same street. We investigate how persona-based multi-agent evaluation can support inclusive design by making experiential conflicts explicit. We present StreetDesignAI, an interactive system that enables designers to (1) ground evaluation in street context through imagery and map data, (2) receive parallel feedback from cyclist personas spanning confident to cautious users, and (3) iteratively modify designs while surfacing conflicts across perspectives. A within-subjects study with 26 transportation professionals demonstrates that structured multi-perspective feedback significantly improves designers' understanding of diverse user perspectives, ability to identify persona needs, and confidence in translating them into design decisions, with higher satisfaction and stronger intention for professional adoption. Qualitative findings reveal how conflict surfacing transforms design exploration from single-perspective optimization toward deliberate trade-off reasoning. We discuss implications for AI tools that scaffold inclusive design through disagreement as an interaction primitive.

**AI Summary:** The research introduces StreetDesignAI, an interactive system that uses persona-based multi-agent evaluation to support inclusive infrastructure design for cyclists. The system allows designers to receive feedback from different cyclist personas, helping them understand diverse user perspectives, identify persona needs, and make design decisions that balance conflicting requirements. The study shows that this structured multi-perspective feedback improves designers' understanding and confidence in inclusive design, leading to higher satisfaction and intention for professional adoption, highlighting the importance of incorporating disagreement as an interaction primitive in AI tools for inclusive design.

---

## Reflective Motion and a Physical Canvas: Exploring Embodied Journaling in Virtual Reality
**URL:** https://arxiv.org/abs/2601.15656

**Abstract:** In traditional journaling practices, authors express and process their thoughts by writing them down. We propose a somaesthetic-inspired alternative that uses the human body, rather than written words, as the medium of expression. We coin this embodied journaling, as people's isolated body movements and spoken words become the canvas of reflection. We implemented embodied journaling in virtual reality and conducted a within-subject user study (n=20) to explore the emergent behaviours from the process and to compare its expressive and reflective qualities to those of written journaling. When writing-based norms and affordances were absent, we found that participants defaulted towards unfiltered emotional expression, often forgoing words altogether. Rather, subconscious body motion and paralinguistic acoustic qualities unveiled deeper, sometimes hidden feelings, prompting reflection that happens after emotional expression rather than during it. We discuss both the capabilities and pitfalls of embodied journaling, ultimately challenging the idea that reflection culminates in linguistic reasoning.

**AI Summary:** This research explores the concept of embodied journaling in virtual reality, where participants use their body movements and spoken words as a medium for expression and reflection. The study found that participants often expressed unfiltered emotions through body movements and paralinguistic cues, leading to deeper reflection after emotional expression. This challenges the traditional idea that reflection is solely based on linguistic reasoning, highlighting the potential of embodied journaling as a unique and impactful form of self-expression.

---

## Tackling the Scaffolding Paradox: A Person-Centered Adaptive Robotic Interview Coach
**URL:** https://arxiv.org/abs/2601.15600

**Abstract:** Job interview anxiety is a prevalent challenge among university students and can undermine both performance and confidence in high-stakes evaluative situations. Social robots have shown promise in reducing anxiety through emotional support, yet how such systems should balance psychological safety with effective instructional guidance remains an open question. In this work, we present a three-phase iterative design study of a robotic interview coach grounded in Person-Centered Therapy (PCT) and instructional scaffolding theory. Across three weekly sessions (N=8), we systematically explored how different interaction strategies shape users' emotional experience, cognitive load, and perceived utility. Phase I demonstrated that a PCT-based robot substantially increased perceived psychological safety but introduced a Safety-Guidance Gap, in which users felt supported yet insufficiently coached. Phase II revealed a Scaffolding Paradox: immediate feedback improved clarity but disrupted conversational flow and increased cognitive load, whereas delayed feedback preserved realism but lacked actionable specificity. To resolve this tension, Phase III introduced an Agency-Driven Interaction Mode that allowed users to opt in to feedback dynamically. Qualitative findings indicated that user control acted as an anxiety buffer, restoring trust, reducing overload, and reframing the interaction as collaborative rather than evaluative. Quantitative measures further showed significant reductions in interview-related social and communication anxiety, while maintaining high perceived warmth and therapeutic alliance. We synthesize these findings into an Adaptive Scaffolding Ecosystem framework, highlighting user agency as a key mechanism for balancing emotional support and instructional guidance in social robot coaching systems.

**AI Summary:** This research explores the use of a robotic interview coach to help university students with job interview anxiety. The study found that a person-centered therapy-based robot increased perceived psychological safety but lacked sufficient coaching, leading to a Scaffolding Paradox. By introducing an Agency-Driven Interaction Mode, users were able to opt in to feedback dynamically, reducing anxiety and improving performance in interviews. This research highlights the importance of balancing emotional support and instructional guidance in social robot coaching systems.

---

## PromptHelper: A Prompt Recommender System for Encouraging Creativity in AI Chatbot Interactions
**URL:** https://arxiv.org/abs/2601.15575

**Abstract:** Prompting is central to interaction with AI systems, yet many users struggle to explore alternative directions, articulate creative intent, or understand how variations in prompts shape model outputs. We introduce prompt recommender systems (PRS) as an interaction approach that supports exploration, suggesting contextually relevant follow-up prompts. We present PromptHelper, a PRS prototype integrated into an AI chatbot that surfaces semantically diverse prompt suggestions while users work on real writing tasks. We evaluate PromptHelper in a 2x2 fully within-subjects study (N=32) across creative and academic writing tasks. Results show that PromptHelper significantly increases users' perceived exploration and expressiveness without increasing cognitive workload. Qualitative findings illustrate how prompt recommendations help users branch into new directions, overcome uncertainty about what to ask next, and better articulate their intent. We discuss implications for designing AI interfaces that scaffold exploratory interaction while preserving user agency, and release open-source resources to support research on prompt recommendation.

**AI Summary:** The research introduces PromptHelper, a prompt recommender system integrated into an AI chatbot to support exploration and creativity in user interactions. The study found that PromptHelper significantly increased users' perceived exploration and expressiveness without adding to cognitive workload, helping users branch into new directions, overcome uncertainty, and better articulate their intent. The findings suggest the importance of designing AI interfaces that facilitate exploratory interaction while maintaining user agency, and provide open-source resources for further research on prompt recommendation systems.

---

## Put Your Muscle Into It: Introducing XEM2, a Novel Approach for Monitoring Exertion in Stationary Physical Exercises Leveraging Muscle Work
**URL:** https://arxiv.org/abs/2601.15472

**Abstract:** We present a novel system for camera-based measurement and visualization of muscle work based on the Hill-Type-Muscle-Model: the exercise exertion muscle-work monitor (\textit{XEM}$^{2}$). Our aim is to complement and, thus, address issues of established measurement techniques that offer imprecise data for non-uniform movements (burned calories) or provide limited information on strain across different body parts (self-perception scales). We validate the reliability of XEM's measurements through a technical evaluation of ten participants and five exercises. Further, we assess the acceptance, usefulness, benefits, and opportunities of \textit{XEM}$^{2}$ in an empirical user study. Our results show that \textit{XEM}$^{2}$ provides reliable values of muscle work and supports participants in understanding their workout while also providing reliable information about perceived exertion per muscle group. With this paper, we introduce a novel system capable of measuring and visualizing exertion for single muscle groups, which has the potential to improve exercise monitoring to prevent unbalanced workouts.

**AI Summary:** The research introduces XEM2, a novel system for monitoring muscle work during stationary physical exercises using a camera-based approach. The system provides reliable measurements of muscle work and helps participants understand their workout, as well as providing information on perceived exertion per muscle group. The study highlights the potential of XEM2 to improve exercise monitoring and prevent unbalanced workouts by offering precise data on muscle work during different exercises.

---

## Shape of You: Implications of Social Context and Avatar Body Shape on Relatedness, Emotions, and Performance in a Virtual Reality Workout
**URL:** https://arxiv.org/abs/2601.15466

**Abstract:** It is obvious that emotions are causal variables of motivation, as they elicit states, forces and energies that trigger and guide labor behavior. Thus, a motivational tension that is not informed by needs alone, but also by emotions, intention, goals and means to achieve them is therefore generated within the mental, emotional and physical plane. Based on Montserrat's opinion (2004: 131), that "to motivate means, above all, to move and to transmit an emotion", we will undertake to identify the mutual influences between emotions and motivation. The main objectives of this article are to display a summary of the theories and definitions about emotions and to explore the links between emotions and motivation. Although interconnected, emotions and motivation can be contemplated from a double perspective: (1) emotions influence motivation and (2) motivation influences emotions. Moreover, we will consider motivation from three dimensions: (1) cognitive, (2) affective and (3) volitional. The ultimate purpose of this article is to issue a warning as to the importance of the emotional side of motivation. An important part in implementing such insight is to be played by managers (and by employees, also), who should develop the skills and know-how needed to keep a well-balanced emotional climate that effectively favors the maximization of individual and group motivation at the workplace.

**AI Summary:** This research explores the mutual influences between emotions and motivation in the context of virtual reality workouts. The study highlights the importance of emotions in driving motivation and performance, emphasizing the need for managers and employees to develop skills to create a well-balanced emotional climate to maximize motivation in the workplace. The findings suggest that social context and avatar body shape can impact relatedness, emotions, and performance in virtual reality workouts.

---

## Cloning the Self for Mental Well-Being: A Framework for Designing Safe and Therapeutic Self-Clone Chatbots
**URL:** https://arxiv.org/abs/2601.15465

**Abstract:** As digital tools increasingly mediate mental health care, self-clone chatbots can offer a uniquely novel approach to intra-personal exploration and self-derived support. Trained to replicate users' conversational patterns, self-clones allow users to talk to themselves through their digital replicas. Despite the promises, these systems may carry risks around identity confusion, negative reinforcement, and blurred user agency. Through interviews with 16 mental health professionals and 6 general users, we aim to uncover tensions and design opportunities in this emerging space to guide responsible self-clone design. Our analysis produces a design framework organized around three priorities: (1) defining goals and grounding the approach in existing therapeutic models, (2) design dimensions including the self-clone persona and user-clone relationship dynamics, and (3) considerations for minimizing potential emotional and ethical harms. This framework contributes an interdisciplinary foundation for designing self-clone chatbots as AI-mediated self-interaction tools that are emotionally and ethically attuned in mental health contexts.

**AI Summary:** The research explores the potential of self-clone chatbots as a novel approach to mental health care, allowing users to converse with digital replicas of themselves. The study highlights the risks of identity confusion and negative reinforcement in using these systems and proposes a design framework to guide responsible self-clone chatbot development. The framework emphasizes defining goals, designing the self-clone persona and user-clone relationship dynamics, and minimizing emotional and ethical harms, providing a foundation for creating emotionally and ethically attuned AI tools for mental health support.

---

## Reflexis: Supporting Reflexivity and Rigor in Collaborative Qualitative Analysis through Design for Deliberation
**URL:** https://arxiv.org/abs/2601.15445

**Abstract:** Reflexive Thematic Analysis (RTA) is a critical method for generating deep interpretive insights. Yet its core tenets, including researcher reflexivity, tangible analytical evolution, and productive disagreement, are often poorly supported by software tools that prioritize speed and consensus over interpretive depth. To address this gap, we introduce Reflexis, a collaborative workspace that centers these practices. It supports reflexivity by integrating in-situ reflection prompts, makes code evolution transparent and tangible, and scaffolds collaborative interpretation by turning differences into productive, positionality-aware dialogue. Results from our paired-analyst study (N=12) indicate that Reflexis encouraged participants toward more granular reflection and reframed disagreements as productive conversations. The evaluation also surfaced key design tensions, including a desire for higher-level, networked memos and more user control over the timing of proactive alerts. Reflexis contributes a design framework for tools that prioritize rigor and transparency to support deep, collaborative interpretation in an age of automation.

**AI Summary:** The research introduces Reflexis, a collaborative workspace designed to support Reflexive Thematic Analysis (RTA) by promoting researcher reflexivity, tangible analytical evolution, and productive disagreement. Results from a study with 12 participants showed that Reflexis encouraged more granular reflection and transformed disagreements into productive conversations. The tool contributes a design framework for supporting deep, collaborative interpretation in qualitative analysis, emphasizing rigor and transparency in an age of automation.

---

## Exploring Implicit Perspectives on Autism in Large Language Models Through Multi-Agent Simulations
**URL:** https://arxiv.org/abs/2601.15437

**Abstract:** Large Language Models (LLMs) like ChatGPT offer potential support for autistic people, but this potential requires understanding the implicit perspectives these models might carry, including their biases and assumptions about autism. Moving beyond single-agent prompting, we utilized LLM-based multi-agent systems to investigate complex social scenarios involving autistic and non-autistic agents. In our study, agents engaged in group-task conversations and answered structured interview questions, which we analyzed to examine ChatGPT's biases and how it conceptualizes autism. We found that ChatGPT assumes autistic people are socially dependent, which may affect how it interacts with autistic users or conveys information about autism. To address these challenges, we propose adopting the double empathy problem, which reframes communication breakdowns as a mutual challenge. We describe how future LLMs could address the biases we observed and improve interactions involving autistic people by incorporating the double empathy problem into their design.

**AI Summary:** This research explores the implicit perspectives on autism in large language models like ChatGPT through multi-agent simulations. The study found that ChatGPT assumes autistic individuals are socially dependent, which could impact interactions with autistic users. To improve interactions involving autistic individuals, the researchers suggest incorporating the double empathy problem into the design of future large language models.

---

## A Checklist for Trustworthy, Safe, and User-Friendly Mental Health Chatbots
**URL:** https://arxiv.org/abs/2601.15412

**Abstract:** Mental health concerns are rising globally, prompting increased reliance on technology to address the demand-supply gap in mental health services. In particular, mental health chatbots are emerging as a promising solution, but these remain largely untested, raising concerns about safety and potential harms. In this paper, we dive into the literature to identify critical gaps in the design and implementation of mental health chatbots. We contribute an operational checklist to help guide the development and design of more trustworthy, safe, and user-friendly chatbots. The checklist serves as both a developmental framework and an auditing tool to ensure ethical and effective chatbot design. We discuss how this checklist is a step towards supporting more responsible design practices and supporting new standards for sociotechnically sound digital mental health tools.

**AI Summary:** The paper discusses the increasing reliance on technology, specifically mental health chatbots, to address the growing demand for mental health services. The authors identify critical gaps in the design and implementation of these chatbots and propose an operational checklist to guide the development of more trustworthy, safe, and user-friendly chatbots. The checklist aims to ensure ethical and effective design practices, supporting new standards for digital mental health tools.

---

## VegaChat: A Robust Framework for LLM-Based Chart Generation and Assessment
**URL:** https://arxiv.org/abs/2601.15385

**Abstract:** Natural-language-to-visualization (NL2VIS) systems based on large language models (LLMs) have substantially improved the accessibility of data visualization. However, their further adoption is hindered by two coupled challenges: (i) the absence of standardized evaluation metrics makes it difficult to assess progress in the field and compare different approaches; and (ii) natural language descriptions are inherently underspecified, so multiple visualizations may be valid for the same query. To address these issues, we introduce VegaChat, a framework for generating, validating, and assessing declarative visualizations from natural language.
We propose two complementary metrics: Spec Score, a deterministic metric that measures specification-level similarity without invoking an LLM, and Vision Score, a library-agnostic, image-based metric that leverages a multimodal LLM to assess chart similarity and prompt compliance.
We evaluate VegaChat on the NLV Corpus and on the annotated subset of ChartLLM. VegaChat achieves near-zero rates of invalid or empty visualizations, while Spec Score and Vision Score exhibit strong correlation with human judgments (Pearson 0.65 and 0.71, respectively), indicating that the proposed metrics support consistent, cross-library comparison.
The code and evaluation artifacts are available at this https URL.

**AI Summary:** The research introduces VegaChat, a framework for generating and evaluating visualizations from natural language descriptions. It addresses challenges in assessing NL2VIS systems by introducing two new metrics, Spec Score and Vision Score, which show strong correlation with human judgments. The framework achieves high rates of valid visualizations and provides a standardized method for comparing different approaches in the field.

---

## When Generative AI Meets Extended Reality: Enabling Scalable and Natural Interactions
**URL:** https://arxiv.org/abs/2601.15308

**Abstract:** Extended Reality (XR), including virtual, augmented, and mixed reality, provides immersive and interactive experiences across diverse applications, from VR-based education to AR-based assistance and MR-based training. However, widespread XR adoption remains limited due to two key challenges: 1) the high cost and complexity of authoring 3D content, especially for large-scale environments or complex interactions; and 2) the steep learning curve associated with non-intuitive interaction methods like handheld controllers or scripted gestures. Generative AI (GenAI) presents a promising solution by enabling intuitive, language-driven interaction and automating content generation. Leveraging vision-language models and diffusion-based generation, GenAI can interpret ambiguous instructions, understand physical scenes, and generate or manipulate 3D content, significantly lowering barriers to XR adoption. This paper explores the integration of XR and GenAI through three concrete use cases, showing how they address key obstacles in scalability and natural interaction, and identifying technical challenges that must be resolved to enable broader adoption.

**AI Summary:** This research paper explores the integration of Generative AI (GenAI) with Extended Reality (XR) to address challenges in creating and interacting with 3D content in immersive environments. The study highlights how GenAI can enable intuitive, language-driven interactions and automate content generation, lowering barriers to XR adoption. Through three use cases, the paper demonstrates how the combination of XR and GenAI can enhance scalability and natural interaction, while also identifying technical challenges that need to be overcome for broader adoption of this technology.

---

## Elsewise: Authoring AI-Based Interactive Narrative with Possibility Space Visualization
**URL:** https://arxiv.org/abs/2601.15295

**Abstract:** Interactive narrative (IN) authors craft spaces of divergent narrative possibilities for players to explore, with the player's input determining which narrative possibilities they actually experience. Generative AI can enable new forms of IN by improvisationally expanding on pre-authored content in response to open-ended player input. However, this extrapolation risks widening the gap between author-envisioned and player-experienced stories, potentially limiting the strength of plot progression and the communication of the author's narrative intent. To bridge the gap, we introduce Elsewise: an authoring tool for AI-based INs that implements a novel Bundled Storyline concept to enhance author's perception and understanding of the narrative possibility space, allowing authors to explore similarities and differences between possible playthroughs of their IN in terms of open-ended, user-configurable narrative dimensions. A user study (n=12) shows that our approach improves author anticipation of player-experienced narrative, leading to more effective control and exploration of the narrative possibility spaces.

**AI Summary:** The research introduces Elsewise, an authoring tool for AI-based interactive narratives that helps authors better understand and control the narrative possibility space. By implementing a Bundled Storyline concept, authors can explore and anticipate the variations in player experiences, bridging the gap between author-envisioned and player-experienced stories. A user study demonstrated that this approach improves author anticipation of player-experienced narrative, enhancing the effectiveness of narrative control and exploration.

---

## KnowTeX: Visualizing Mathematical Dependencies
**URL:** https://arxiv.org/abs/2601.15294

**Abstract:** Mathematical knowledge exists in many forms, ranging from informal textbooks and lecture notes to large formal proof libraries, yet moving between these representations remains difficult. Informal texts hide dependencies, while formal systems expose every detail in ways that are not always human-readable. Dependency graphs offer a middle ground by making visible the structure of results, definitions, and proofs. We present KnowTeX, a standalone, user-friendly tool that extends the ideas of Lean's Blueprints, enabling the visualization of conceptual dependencies directly from LaTeX sources. Using a simple "uses" command, KnowTeX extracts relationships among statements and generates previewable graphs in DOT and TikZ formats. Applied to mathematical texts, such graphs clarify core results, support education and formalization, and provide a resource for aligning informal and formal mathematical representations. We argue that dependency graphs should become a standard feature of mathematical writing, benefiting both human readers and automated systems.

**AI Summary:** The research introduces KnowTeX, a tool that visualizes mathematical dependencies by generating graphs from LaTeX sources. These graphs help clarify core results, support education and formalization, and bridge the gap between informal and formal mathematical representations. The authors argue that dependency graphs should be a standard feature in mathematical writing to benefit both human readers and automated systems.

---

## Social Robotics for Disabled Students: An Empirical Investigation of Embodiment, Roles and Interaction
**URL:** https://arxiv.org/abs/2601.15293

**Abstract:** Institutional and social barriers in higher education often prevent students with disabilities from effectively accessing support, including lengthy procedures, insufficient information, and high social-emotional demands. This study empirically explores how disabled students perceive robot-based support, comparing two interaction roles, one information based (signposting) and one disclosure based (sounding board), and two embodiment types (physical robot/disembodied voice agent). Participants assessed these systems across five dimensions: perceived understanding, social energy demands, information access/clarity, task difficulty, and data privacy concerns. The main findings of the study reveal that the physical robot was perceived as more understanding than the voice-only agent, with embodiment significantly shaping perceptions of sociability, animacy, and privacy. We also analyse differences between disability types. These results provide critical insights into the potential of social robots to mitigate accessibility barriers in higher education, while highlighting ethical, social and technical challenges.

**AI Summary:** This study investigates how disabled students perceive robot-based support in higher education, comparing physical robots to disembodied voice agents in different interaction roles. The findings show that physical robots are perceived as more understanding than voice-only agents, with embodiment significantly influencing perceptions of sociability, animacy, and privacy. These results suggest that social robots have the potential to address accessibility barriers in higher education, but also raise important ethical, social, and technical considerations.

---

## A Mobile Application Front-End for Presenting Explainable AI Results in Diabetes Risk Estimation
**URL:** https://arxiv.org/abs/2601.15292

**Abstract:** Diabetes is a significant and continuously rising health challenge in Indonesia. Although many artificial intelligence (AI)-based health applications have been developed for early detection, most function as "black boxes," lacking transparency in their predictions. Explainable AI (XAI) methods offer a solution, yet their technical outputs are often incomprehensible to non-expert users. This research aims to develop a mobile application front-end that presents XAI-driven diabetes risk analysis in an intuitive, understandable format. Development followed the waterfall methodology, comprising requirements analysis, interface design, implementation, and evaluation. Based on user preference surveys, the application adopts two primary visualization types - bar charts and pie charts - to convey the contribution of each risk factor. These are complemented by personalized textual narratives generated via integration with GPT-4o. The application was developed natively for Android using Kotlin and Jetpack Compose. The resulting prototype interprets SHAP (SHapley Additive exPlanations), a key XAI approach, into accessible graphical visualizations and narratives. Evaluation through user comprehension testing (Likert scale and interviews) and technical functionality testing confirmed the research objectives were met. The combination of visualization and textual narrative effectively enhanced user understanding (average score 4.31/5) and empowered preventive action, supported by a 100% technical testing success rate.

**AI Summary:** This research developed a mobile application front-end using Explainable AI (XAI) methods to present diabetes risk analysis in a user-friendly format. The application utilized bar charts, pie charts, and personalized textual narratives to convey the contribution of each risk factor, enhancing user understanding and empowering preventive action. Evaluation results showed high user comprehension and technical functionality success, highlighting the significance of transparent AI applications in addressing health challenges like diabetes.

---

## Public transport challenges and technology-assisted accessibility for visually impaired elderly residents in urban environments
**URL:** https://arxiv.org/abs/2601.15291

**Abstract:** Independent navigation is a core aspect of maintaining social participation and individual health for vulnerable populations. While historic cities such as Edinburgh, as the capital of Scotland, often feature well-established public transport systems, urban accessibility challenges remain and are exacerbated by a complex landscape, especially for groups with multiple vulnerabilities such as the blind elderly. With limited research examining how real-time data feeds and developments in artificial intelligence can enhance navigation aids, we address this gap through a mixed-methods approach. Our work combines statistical and machine learning techniques, with a focus on spatial analysis to investigate network coverage, service patterns, and density through live Transport for Edinburgh data, with a qualitative thematic analysis of semi-structured interviews with the mentioned target group. The results demonstrate the highly centralised nature of the city's transport system, the significance of memory-based navigation, and the lack of travel information in usable formats. We also find that participants already use navigation technology to varying degrees and express a willingness to adopt artificial intelligence. Our analysis highlights the importance of dynamic tools in terms of sensory and cognitive needs to meaningfully improve independent travel.

**AI Summary:** This research focuses on the challenges faced by visually impaired elderly residents in accessing public transport in urban environments, specifically in Edinburgh. The study uses a mixed-methods approach to analyze the city's transport system and the use of navigation technology by the target group. The findings suggest that there is a need for more accessible and user-friendly travel information, and that artificial intelligence could play a significant role in improving independent travel for this vulnerable population.

---

## Agentic Persona Control and Task State Tracking for Realistic User Simulation in Interactive Scenarios
**URL:** https://arxiv.org/abs/2601.15290

**Abstract:** Testing conversational AI systems at scale across diverse domains necessitates realistic and diverse user interactions capturing a wide array of behavioral patterns. We present a novel multi-agent framework for realistic, explainable human user simulation in interactive scenarios, using persona control and task state tracking to mirror human cognitive processes during goal-oriented conversations. Our system employs three specialized AI agents: (1) a User Agent to orchestrate the overall interaction, (2) a State Tracking Agent to maintain structured task state, and (3) a Message Attributes Generation Agent that controls conversational attributes based on task progress and assigned persona. To validate our approach, we implement and evaluate the framework for guest ordering at a restaurant with scenarios rich in task complexity, behavioral diversity, and conversational ambiguity. Through systematic ablations, we evaluate the contributory efficacy of each agentic component to overall simulation quality in terms of persona adherence, task completion accuracy, explainability, and realism. Our experiments demonstrate that the complete multi-agent system achieves superior simulation quality compared to single-LLM baselines, with significant gains across all evaluation metrics. This framework establishes a powerful environment for orchestrating agents to simulate human users with cognitive plausibility, decomposing the simulation into specialized sub-agents that reflect distinct aspects of human thought processes applicable across interactive domains.

**AI Summary:** The research presents a novel multi-agent framework for realistic human user simulation in interactive scenarios, utilizing persona control and task state tracking to mimic human cognitive processes during goal-oriented conversations. The framework consists of three specialized AI agents that work together to improve simulation quality in terms of persona adherence, task completion accuracy, explainability, and realism. Through experiments, the researchers demonstrate that the multi-agent system outperforms single-LLM baselines, highlighting the significance of this approach for simulating human users with cognitive plausibility in various interactive domains.

---

## Timbre-Aware LLM-based Direct Speech-to-Speech Translation Extendable to Multiple Language Pairs
**URL:** https://arxiv.org/abs/2601.16023

**Abstract:** Direct Speech-to-Speech Translation (S2ST) has gained increasing attention for its ability to translate speech from one language to another, while reducing error propagation and latency inherent in traditional cascaded pipelines. However, existing direct S2ST systems continue to face notable challenges, including instability in semantic-acoustic alignment when parallel speech data is scarce, difficulty in preserving speaker identity, and limited multilingual scalability. In this work, we introduce DS2ST-LM, a scalable, single-stage direct S2ST framework leveraging a multilingual Large Language Model (LLM). The architecture integrates a Whisper speech encoder, a learnable projection module, a Qwen2-0.5B LLM, and a timbre-controlled vocoder. We construct GigaS2S-1000, a 1000-hour bilingual corpus by extending the GigaST dataset with high-fidelity synthetic target speech, and show that this synthetic data alleviates data scarcity to some extent. We investigate two semantic token generation strategies: speech-derived S3 tokens and text-derived tokens generated by a pre-trained LLM, and analyze their impact on training stability and semantic consistency. We further evaluate three projection architectures (Linear, Conv1D-Linear, and Q-Former) and observe that while higher-capacity projectors converge faster, the simple Linear projector achieves higher performance. Extensive experiments demonstrate that DS2ST-LM outperforms traditional cascaded and ST (Qwen-Audio) + TTS baselines across both lexical (BLEU, METEOR) and semantic (BLEURT, COMET) metrics, while extending to multiple language pairs, including French, Spanish, German, Hindi, Bengali, and Urdu. Furthermore, we incorporate timbre-aware speech synthesis to preserve speaker information, enabling DS2ST-LM to surpass prior direct S2ST systems in both speaker similarity and perceptual naturalness.

**AI Summary:** This research introduces a direct Speech-to-Speech Translation (S2ST) framework, DS2ST-LM, that leverages a multilingual Large Language Model (LLM) to address challenges in existing systems such as data scarcity and preserving speaker identity. The study shows that incorporating synthetic data and using a simple Linear projector can improve training stability and performance. The DS2ST-LM framework outperforms traditional cascaded systems and achieves better results in both lexical and semantic metrics across multiple language pairs, while also preserving speaker information for improved naturalness and speaker similarity.

---

## The Latency Wall: Benchmarking Off-the-Shelf Emotion Recognition for Real-Time Virtual Avatars
**URL:** https://arxiv.org/abs/2601.15914

**Abstract:** In the realm of Virtual Reality (VR) and Human-Computer Interaction (HCI), real-time emotion recognition shows promise for supporting individuals with Autism Spectrum Disorder (ASD) in improving social skills. This task requires a strict latency-accuracy trade-off, with motion-to-photon (MTP) latency kept below 140 ms to maintain contingency. However, most off-the-shelf Deep Learning models prioritize accuracy over the strict timing constraints of commodity hardware. As a first step toward accessible VR therapy, we benchmark State-of-the-Art (SOTA) models for Zero-Shot Facial Expression Recognition (FER) on virtual characters using the UIBVFED dataset. We evaluate Medium and Nano variants of YOLO (v8, v11, and v12) for face detection, alongside general-purpose Vision Transformers including CLIP, SigLIP, and this http URL results on CPU-only inference demonstrate that while face detection on stylized avatars is robust (100% accuracy), a "Latency Wall" exists in the classification stage. The YOLOv11n architecture offers the optimal balance for detection (~54 ms). However, general-purpose Transformers like CLIP and SigLIP fail to achieve viable accuracy (<23%) or speed (>150 ms) for real-time loops. This study highlights the necessity for lightweight, domain-specific architectures to enable accessible, real-time AI in therapeutic settings.

**AI Summary:** This research focuses on benchmarking off-the-shelf Deep Learning models for real-time emotion recognition in virtual avatars, with a specific application in supporting individuals with Autism Spectrum Disorder. The study finds that while face detection on stylized avatars is accurate, there is a "Latency Wall" in the classification stage, with existing models failing to meet the strict timing constraints required for real-time interaction. The research emphasizes the need for lightweight, domain-specific architectures to enable accessible and real-time AI in therapeutic settings.

---

## DeltaDorsal: Enhancing Hand Pose Estimation with Dorsal Features in Egocentric Views
**URL:** https://arxiv.org/abs/2601.15516

**Abstract:** The proliferation of XR devices has made egocentric hand pose estimation a vital task, yet this perspective is inherently challenged by frequent finger occlusions. To address this, we propose a novel approach that leverages the rich information in dorsal hand skin deformation, unlocked by recent advances in dense visual featurizers. We introduce a dual-stream delta encoder that learns pose by contrasting features from a dynamic hand with a baseline relaxed position. Our evaluation demonstrates that, using only cropped dorsal images, our method reduces the Mean Per Joint Angle Error (MPJAE) by 18% in self-occluded scenarios (fingers >=50% occluded) compared to state-of-the-art techniques that depend on the whole hand's geometry and large model backbones. Consequently, our method not only enhances the reliability of downstream tasks like index finger pinch and tap estimation in occluded scenarios but also unlocks new interaction paradigms, such as detecting isometric force for a surface "click" without visible movement while minimizing model size.

**AI Summary:** This research introduces a new approach, DeltaDorsal, for hand pose estimation in egocentric views using dorsal hand skin deformation information. The method, utilizing a dual-stream delta encoder, significantly reduces error in self-occluded scenarios compared to existing techniques, improving reliability for tasks like finger pinch and tap estimation. This not only enhances interaction capabilities but also minimizes model size, making it a valuable advancement in XR technology.

---

## Beyond Fixed Psychological Personas: State Beats Trait, but Language Models are State-Blind
**URL:** https://arxiv.org/abs/2601.15395

**Abstract:** User interactions with language models vary due to static properties of the user (trait) and the specific context of the interaction (state). However, existing persona datasets (like PersonaChat, PANDORA etc.) capture only trait, and ignore the impact of state. We introduce Chameleon, a dataset of 5,001 contextual psychological profiles from 1,667 Reddit users, each measured across multiple contexts. Using the Chameleon dataset, we present three key findings. First, inspired by Latent State-Trait theory, we decompose variance and find that 74\% is within-person(state) while only 26\% is between-person (trait). Second, we find that LLMs are state-blind: they focus on trait only, and produce similar responses regardless of state. Third, we find that reward models react to user state, but inconsistently: different models favor or penalize the same users in opposite directions. We release Chameleon to support research on affective computing, personalized dialogue, and RLHF alignment.

**AI Summary:** The research introduces the Chameleon dataset, which includes contextual psychological profiles from Reddit users to capture both trait and state aspects of user interactions with language models. The study reveals that the majority of variance in user interactions is within-person (state), rather than between-person (trait), and that existing language models are state-blind, focusing only on trait. Additionally, reward models react to user state inconsistently, highlighting the need for further research in affective computing, personalized dialogue, and reinforcement learning-human feedback alignment.

---

## Analysis of the Ventriloquism Aftereffect Using Network Theory Techniques
**URL:** https://arxiv.org/abs/2601.15321

**Abstract:** Ventriloquism After-Effect is the phenomenon where sustained exposure to the ventriloquist illusion causes a change in unisensory auditory localization towards the location where the visual stimulus was present. We investigate the recalibration in EEG networks that causes this change and the track the timeline of changes in the auditory processing pathway. Our results obtained using network analysis, non-stationary time series analysis and multivariate pattern classification show that recalibration takes place early in the auditory processing pathway and the after-effect decays with time after exposure to the illusion.

**AI Summary:** This research explores the Ventriloquism Aftereffect, which involves a shift in auditory localization towards a visual stimulus after prolonged exposure to the ventriloquist illusion. Through network analysis and time series analysis, the study reveals that recalibration occurs early in the auditory processing pathway and diminishes over time following exposure to the illusion. This research provides insights into how the brain adapts to multisensory information and could have implications for understanding perception and sensory integration in AI systems.

---

## Do people expect different behavior from large language models acting on their behalf? Evidence from norm elicitations in two canonical economic games
**URL:** https://arxiv.org/abs/2601.15312

**Abstract:** While delegating tasks to large language models (LLMs) can save people time, there is growing evidence that offloading tasks to such models produces social costs. We use behavior in two canonical economic games to study whether people have different expectations when decisions are made by LLMs acting on their behalf instead of themselves. More specifically, we study the social appropriateness of a spectrum of possible behaviors: when LLMs divide resources on our behalf (Dictator Game and Ultimatum Game) and when they monitor the fairness of splits of resources (Ultimatum Game). We use the Krupka-Weber norm elicitation task to detect shifts in social appropriateness ratings. Results of two pre-registered and incentivized experimental studies using representative samples from the UK and US (N = 2,658) show three key findings. First, people find that offers from machines - when no acceptance is necessary - are judged to be less appropriate than when they come from humans, although there is no shift in the modal response. Second - when acceptance is necessary - it is more appropriate for a person to reject offers from machines than from humans. Third, receiving a rejection of an offer from a machine is no less socially appropriate than receiving the same rejection from a human. Overall, these results suggest that people apply different norms for machines deciding on how to split resources but are not opposed to machines enforcing the norms. The findings are consistent with offers made by machines now being viewed as having both a cognitive and emotional component.

**AI Summary:** This research investigates how people perceive and react to decisions made by large language models (LLMs) in economic games. The study finds that people judge offers from machines to be less appropriate than offers from humans, especially when acceptance is necessary. However, people are not opposed to machines enforcing social norms. These findings suggest that people apply different norms for machines dividing resources but are open to machines enforcing these norms.

---

