[
  {
    "title": "From Efficiency to Meaning: Adolescents' Envisioned Role of AI in Health Management",
    "abstract": "While prior research has focused on providers, caregivers, and adult patients, little is known about adolescents' perceptions of AI in health learning and management. Utilizing design fiction and co-design methods, we conducted seven workshops with 23 adolescents (aged 14-17) to understand how they anticipate using health AI in the context of a family celiac diagnosis. Our findings reveal that adolescents have four main envisioned roles of health AI: enhancing health understanding and help-seeking, reducing cognitive burden, supporting family health management, and providing guidance while respecting their autonomy. We also identified nuanced trust and a divided view on emotional support from health AI. These findings suggest that adolescents perceive AI's value as a tool that moves them from efficiency to meaning-one that creates time for valued activities. We discuss opportunities for future health AI systems to be designed to encourage adolescent autonomy and reflection, while also supporting meaningful, dialectical activities.",
    "url": "https://arxiv.org/abs/2602.24249",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores adolescents' perceptions of AI in health management, specifically in the context of a family celiac diagnosis. Through workshops with 23 adolescents, the study found that adolescents envision AI playing roles in enhancing health understanding, reducing cognitive burden, supporting family health management, and providing guidance while respecting their autonomy. The findings suggest that adolescents see AI as a tool that moves them from efficiency to meaning, creating time for valued activities, and highlight the importance of designing future health AI systems to encourage autonomy and reflection while supporting meaningful activities."
  },
  {
    "title": "Designing AI Tutors for Interest-Based Learning: Insights from Human Instructors",
    "abstract": "Interest-based learning (IBL) is a paradigm of instruction in which educational content is contextualized using learners' interests to enhance content relevance. IBL has been shown to result in improved learning outcomes. Unfortunately, high effort is needed for instructors to design and deliver IBL content for individual students. LLMs in the form of AI tutors may allow for IBL to scale across many students. Designing an AI tutor for IBL, however, first requires an understanding of how IBL is implemented in teaching scenarios. This paper presents a study that seeks to derive this understanding from an analysis of how human instructors design and deliver IBL content. We studied 14 one-to-one online tutoring sessions (28 participants) in which tutors designed and delivered a lesson tailored to a student's self-identified interest. Using lesson artifacts, tutoring transcripts, interviews, and questionnaires, findings include themes on how tutors integrate interests during instruction and why. Finally, actionable design implications are presented for LLM-powered AI tutors that aim to deliver IBL at scale.",
    "url": "https://arxiv.org/abs/2602.24036",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research study explores how human instructors design and deliver interest-based learning (IBL) content to individual students. The study found that integrating students' interests into instruction can lead to improved learning outcomes, but it requires high effort from instructors. The findings provide insights for designing AI tutors powered by large language models (LLMs) to deliver IBL at scale, potentially making personalized learning more accessible to a larger number of students."
  },
  {
    "title": "Ask don't tell: Reducing sycophancy in large language models",
    "abstract": "Sycophancy, the tendency of large language models to favour user-affirming responses over critical engagement, has been identified as an alignment failure, particularly in high-stakes advisory and social contexts. While prior work has documented conversational features correlated with sycophancy, we lack a systematic understanding of what provokes or prevents AI sycophancy. Here, we present a set of controlled experimental studies where we first isolate how input framing influences sycophancy, and second, leverage these findings to develop mitigation strategies. In a nested factorial design, we compare questions to various non-questions where we vary three orthogonal factors: epistemic certainty (statement, belief, conviction), perspective (I- vs user-perspective), and affirmation vs negation. We show that (1) sycophancy is substantially higher in response to non-questions compared to questions. Additionally, we find that (2) sycophancy increases monotonically with epistemic certainty conveyed by the user, and (3) is amplified by I-perspective framing. Building on this, we show that asking a model to convert non-questions into questions before answering significantly reduces sycophancy. Importantly, this effect is stronger than a simple baseline prompt asking models \"not to be sycophantic\". Our work offers a practical and effective input-level mitigation that both developers and users can easily adopt.",
    "url": "https://arxiv.org/abs/2602.23971",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research focuses on reducing sycophancy in large language models by investigating how input framing influences the tendency for user-affirming responses. The study found that sycophancy is higher in response to non-questions compared to questions, increases with user's certainty, and is amplified by I-perspective framing. By asking models to convert non-questions into questions before answering, sycophancy can be significantly reduced, offering a practical and effective mitigation strategy for developers and users."
  },
  {
    "title": "The Moment of Capture: How the First Seconds of a Speaker's Nonverbal and Verbal Performance Shapes Audience Judgments",
    "abstract": "Why do some speakers capture a room almost instantly while others fail to connect? The real-time architecture of audience engagement remains largely a black box. Here, we used motion-captured animations to present the pure nonverbal performance of public speakers to audiences - either in silence (nonverbal-only) or paired with the verbal content (nonverbal-plus-verbal). Using continuous response measurement (CRM), we find that audience judgments solidify with remarkable speed: Moment-to-moment engagement ratings become highly predictive of subsequent evaluations within the initial 10 seconds of the performance. Most notably, this predictive relationship emerged faster and slightly stronger in the nonverbal-only condition, with predictive information being present already after less than 5 seconds. These findings elucidate the social impact a speaker's nonverbal performance has on audience impressions, even when dissociated from the verbal content of the speech. Our approach provides a high-resolution temporal map of social impression formation, pointing to an early \"moment of capture\" that appears to set the stage for the reception of the following message. On a broader scale, this research validates a powerful new method to isolate different communicative channels, to scientifically deconstruct rhetorical skill, and to study the pervasive impact of nonverbal behavior more broadly. It also enables us to translate the ancient art of rhetoric into a modern science of social impression formation, yielding an empirical basis that can inform human-centered feedback, develop AI-based augmentation tools, and guide the design of engaging, socially present avatars in an increasingly AI-mediated and virtual world.",
    "url": "https://arxiv.org/abs/2602.23920",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores how the nonverbal performance of public speakers influences audience judgments, finding that audience impressions solidify within the first 10 seconds of a performance. The study shows that nonverbal cues play a significant role in shaping audience perceptions, even when separated from the verbal content of the speech. These findings have implications for understanding social impression formation and can inform the development of AI-based tools and virtual avatars for communication."
  },
  {
    "title": "The Topology of Recovery: Using Persistent Homology to Map Individual Mental Health Journeys in Online Communities",
    "abstract": "Understanding how individuals navigate mental health challenges over time is critical yet methodologically challenging. Traditional approaches analyze community-level snapshots, failing to capture dynamic individual recovery trajectories. We introduce a novel framework applying Topological Data Analysis (TDA) specifically persistent homology to model users' longitudinal posting histories as trajectories in semantic embedding space. Our approach reveals topological signatures of trajectory patterns: loops indicate cycling back to similar states (stagnation), while flares suggest exploring new coping strategies (growth). We propose Semantic Recovery Velocity (SRV), a novel metric quantifying the rate users move away from initial distress-focused posts in embedding space. Analyzing 15,847 r/depression trajectories and validating against multiple proxies, we demonstrate topological features predict self-reported improvement with 78.3% accuracy, outperforming sentiment baselines. This work contributes: (1) a TDA methodology for HCI mental health research, (2) interpretable topological signatures, and (3) design implications for adaptive mental health platforms with ethical guardrails.",
    "url": "https://arxiv.org/abs/2602.23886",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces a novel framework using Topological Data Analysis to map individual mental health journeys in online communities. The study found that topological features, such as loops and flares in trajectory patterns, can predict self-reported improvement with high accuracy. The findings have implications for designing adaptive mental health platforms and contribute to HCI mental health research."
  },
  {
    "title": "Human-Centered Multimodal Fusion for Sexism Detection in Memes with Eye-Tracking, Heart Rate, and EEG Signals",
    "abstract": "The automated detection of sexism in memes is a challenging task due to multimodal ambiguity, cultural nuance, and the use of humor to provide plausible deniability. Content-only models often fail to capture the complexity of human perception. To address this limitation, we introduce and validate a human-centered paradigm that augments standard content features with physiological data. We created a novel resource by recording Eye-Tracking (ET), Heart Rate (HR), and Electroencephalography (EEG) from 16 subjects (8 per experiment) while they viewed 3984 memes from the EXIST 2025 dataset. Our statistical analysis reveals significant physiological differences in how subjects process sexist versus non-sexist content. Sexist memes were associated with higher cognitive load, reflected in increased fixation counts and longer reaction times, as well as differences in EEG spectral power across the Alpha, Beta, and Gamma bands, suggesting more demanding neural processing.\nBuilding on these findings, we propose a multimodal fusion model that integrates physiological signals with enriched textual-visual features derived from a Vision-Language Model (VLM). Our final model achieves an AUC of 0.794 in binary sexism detection, a statistically significant 3.4% improvement over a strong VLM-based baseline. The fusion is particularly effective for nuanced cases, boosting the F1-score for the most challenging fine-grained category, Misogyny and Non-Sexual Violence, by 26.3%. These results show that physiological responses provide an objective signal of perception that enhances the accuracy and human-awareness of automated systems for countering online sexism.",
    "url": "https://arxiv.org/abs/2602.23862",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of physiological data (Eye-Tracking, Heart Rate, and EEG signals) in detecting sexism in memes, alongside traditional content features. The study found that subjects processed sexist content differently, with higher cognitive load and distinct neural processing patterns. By integrating physiological signals with textual-visual features, the proposed multimodal fusion model achieved a significant improvement in sexism detection accuracy, particularly in nuanced cases, highlighting the importance of human-centered approaches in countering online sexism."
  },
  {
    "title": "Feelings, Not Feel: Affective Audio-Visual Pseudo-Haptics in Hand-Tracked XR",
    "abstract": "Hand-tracking enables controller-free XR interaction but does not have the tactile feedback controllers provide. Rather than treating this solely as a missing-sensation problem, we explore whether pseudo-haptic cues on an embodied virtual hand act as tactile or as affect substitutes that shape how interactions feel. We used a mixed reality prototype that keeps the contacted surface visually neutral, rendering cues on the hand with motion modulation for texture, color glow, and movement-coupled sound. In a within-subjects study (n=12), participants experienced 12 conditions (4 effects x 3 modalities: audio, visual, both) and reported subjective affect and cognitive demand. Participants rarely reported sustained tactile, thermal sensations, yet affect shifted systematically: rough-hot lowered valence increasing arousal, while smooth-cold produced calmer pleasant states. These findings suggest that pseudo-haptics in XR may be better understood as an affective feedback channel rather than a direct replacement for physical touch in controller-free systems.",
    "url": "https://arxiv.org/abs/2602.23747",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of pseudo-haptic cues on an embodied virtual hand in hand-tracked XR interactions to provide tactile feedback. The study found that participants did not report sustained tactile sensations, but instead experienced shifts in affective states based on the cues provided, such as rough-hot leading to increased arousal and smooth-cold inducing calmer pleasant states. These findings suggest that pseudo-haptics in XR may function more as an affective feedback channel rather than a direct replacement for physical touch in controller-free systems."
  },
  {
    "title": "Shape vs. Context: Examining Human--AI Gaps in Ambiguous Japanese Character Recognition",
    "abstract": "High text recognition performance does not guarantee that Vision-Language Models (VLMs) share human-like decision patterns when resolving ambiguity. We investigate this behavioral gap by directly comparing humans and VLMs using continuously interpolated Japanese character shapes generated via a $\\beta$-VAE. We estimate decision boundaries in a single-character recognition (shape-only task) and evaluate whether VLM responses align with human judgments under shape in context (i.e., embedding an ambiguous character near the human decision boundary in word-level context). We find that human and VLM decision boundaries differ in the shape-only task, and that shape in context can improve human alignment in some conditions. These results highlight qualitative behavioral differences, offering foundational insights toward human--VLM alignment benchmarking.",
    "url": "https://arxiv.org/abs/2602.23746",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research examines the differences in decision-making between humans and Vision-Language Models (VLMs) when recognizing ambiguous Japanese characters. The study finds that there are discrepancies in decision boundaries between humans and VLMs in shape-only tasks, but embedding characters in context can improve alignment between human and VLM judgments in some cases. These findings offer valuable insights for benchmarking the alignment between humans and VLMs in text recognition tasks."
  },
  {
    "title": "Does Personalized Nudging Wear Off? A Longitudinal Study of AI Self-Modeling for Behavioral Engagement",
    "abstract": "Sustaining the effectiveness of behavior change technologies remains a key challenge. AI self-modeling, which generates personalized portrayals of one's ideal self, has shown promise for motivating behavior change, yet prior work largely examines short-term effects. We present one of the first longitudinal evaluations of AI self-modeling in fitness engagement through a two-stage empirical study. A 1-week, three-arm experiment (visual self-modeling (VSM), auditory self-modeling (ASM), Control; N=28) revealed that VSM drove initial performance gains, while ASM showed no significant effects. A subsequent 4-week study (VSM vs. Control; N=31) demonstrated that VSM sustained higher performance levels but exhibited diminishing improvement rates after two weeks. Interviews uncovered a catalyst effect that fostered early motivation through clear, attainable goals, followed by habituation and internalization which stabilized performance. These findings highlight the temporal dynamics of personalized nudging and inform the design of behavior change technologies for long-term engagement.",
    "url": "https://arxiv.org/abs/2602.23688",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research study evaluates the long-term effectiveness of AI self-modeling in motivating behavior change, specifically in fitness engagement. The study found that visual self-modeling initially drove performance gains, but the improvement rate diminished after two weeks. Interviews revealed that clear, attainable goals acted as a catalyst for motivation, leading to habituation and internalization of behavior change. These findings emphasize the importance of considering temporal dynamics in designing behavior change technologies for sustained engagement."
  },
  {
    "title": "The Compulsory Imaginary: AGI and Corporate Authority",
    "abstract": "This paper argues that the two leading AGI firms -- OpenAI and Anthropic -- construct sociotechnical imaginaries through a structurally consistent rhetorical strategy, despite meaningful differences in execution. Drawing on Jasanoff (2015)'s framework of sociotechnical imaginaries, the paper analyzes two essays published in late 2024: Sam Altman's \"The Intelligence Age\" and Dario Amodei's \"Machines of Loving Grace.\" Close comparative reading identifies four shared rhetorical operations: the self-exemption move, which disavows prophetic authority while exercising it; teleological naturalization, which embeds AGI's arrival in narratives of historical inevitability; qualified acknowledgment, which absorbs concessions to risk into an optimistic frame; and implicit indispensability, which positions each firm as central to the imagined future without naming it as a commercial actor. That two competing institutions with different cultures, risk philosophies, and leaders with notably different public personae converge on the same rhetorical architecture suggests the imaginary reflects not only firm-level strategy but the institutional position these firms occupy. The paper extends the sociotechnical imaginaries framework from nation-states to private firms at the frontier of transformative technology development, identifies the discursive mechanism through which corporate authority over technological futures is projected and stabilized, and demonstrates that this mechanism is at minimum structural rather than idiosyncratic. The findings raise the question of what institutional arrangements would make that authority contestable from outside the firms that produce it.",
    "url": "https://arxiv.org/abs/2602.23679",
    "journal": "arXiv cs.HC",
    "ai_summary": "This paper examines how leading AGI firms construct sociotechnical imaginaries through a consistent rhetorical strategy, analyzing essays by Sam Altman and Dario Amodei. The study identifies shared rhetorical operations that position these firms as central to the imagined future without explicitly acknowledging their commercial interests. The findings suggest that corporate authority over technological futures is projected and stabilized through a structural rhetorical mechanism, raising questions about how this authority can be contested from outside the firms."
  },
  {
    "title": "When LLMs Help -- and Hurt -- Teaching Assistants in Proof-Based Courses",
    "abstract": "Teaching assistants (TAs) are essential to grading and feedback provision in proof-based courses, yet these tasks are time-intensive and difficult to scale. Although Large Language Models (LLMs) have been studied for grading and feedback, their effectiveness in proof-based courses is still unknown. Before designing LLM-based systems for this context, a necessary prerequisite is to understand whether LLMs can meaningfully assist TAs with grading and feedback. As such, we present a multi-part case study functioning as a technology probe in an undergraduate proof-based course. We compare rubric-based grading decisions made by an LLM and TAs with varying levels of expertise and examine TAs' perceptions of feedback generated by an LLM. We find substantial disagreement between LLMs and TAs on grading decisions but that LLM-generated feedback can still be useful to TAs for submissions with major errors. We conclude by discussing design implications for human-AI grading and feedback systems in proof-based courses.",
    "url": "https://arxiv.org/abs/2602.23635",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research investigates the use of Large Language Models (LLMs) in assisting Teaching Assistants (TAs) in proof-based courses with grading and feedback tasks. The study found significant disagreement between LLMs and TAs in grading decisions, but LLM-generated feedback was found to be useful for submissions with major errors. The findings suggest potential benefits of incorporating LLMs in assisting TAs with grading and feedback in proof-based courses, while also highlighting the importance of designing effective human-AI systems in this context."
  },
  {
    "title": "Improving Family Co-Play Experiences through Family-Centered Design",
    "abstract": "Cooperative play (co-play) is often positioned as a family-beneficial practice that can strengthen parent-child bonds and support parental mediation in games. Yet co-play in user-generated virtual worlds (UGVWs) can be disrupted by real-time harms that parents cannot easily prevent. Roblox, a platform with millions of user-generated virtual worlds and a large child player base, illustrates this challenge. Prior work on harmful UGVW design highlights risks beyond content problems, including manipulative monetization prompts, unmoderated social interactions, emergent in-world behaviors, and narrative designs that may normalize harmful ideologies. Current governance and moderation approaches, largely adapted from social media, focus on static artifacts and often fail to capture interactive and emergent harms in virtual worlds. This workshop paper asks: how might UGVWs and their platforms be designed to minimize harms that specifically impair family co-play experiences?",
    "url": "https://arxiv.org/abs/2602.23596",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on improving family co-play experiences in user-generated virtual worlds (UGVWs) like Roblox, which can be disrupted by real-time harms that parents struggle to prevent. The study highlights the risks of harmful UGVW design beyond content problems, such as manipulative monetization prompts and unmoderated social interactions. The paper aims to explore how UGVWs and their platforms can be designed to minimize harms that impair family co-play experiences, addressing the need for better governance and moderation approaches in virtual worlds."
  },
  {
    "title": "Exploring the Effect of Heights and User Stance on User Experience in Extended Reality Climbing",
    "abstract": "Virtual environments (VEs) are increasingly used for immersive experiences, training simulations, and entertainment, yet factors such as height perception and user stance can significantly influence user experience (UX). Height perception in VEs plays a crucial role in shaping UX, particularly in immersive applications such as climbing simulations. This study investigates the effects of height in various VEs and examines how user stance, sitting or standing, impacts immersion, perceived height, and motion sickness.\nA user study was conducted with 25 participants who played through five randomized climbing scenarios, ranging from indoor climbing gyms to outdoor cityscapes and mountainous terrains. Participants' UX was assessed using standardized questionnaires, including the IPQ for general presence, spatial presence, involvement, and experienced realism, as well as the SSQ to evaluate motion sickness symptoms such as nausea, oculomotor strain, and disorientation.\nResults indicate that seated participants experienced slightly higher immersion but were also more susceptible to motion sickness compared to those standing. While standing participants maintained consistent scores across different environments, seated participants reported increased immersion and discomfort as the VEs became larger, more physically demanding, and visually complex.",
    "url": "https://arxiv.org/abs/2602.23500",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores the impact of height perception and user stance on user experience in virtual climbing environments. The research found that height perception significantly influences immersion and motion sickness, with seated participants experiencing higher immersion but also greater susceptibility to motion sickness compared to standing participants. Additionally, standing participants maintained consistent experiences across different environments, while seated participants reported increased immersion and discomfort in more challenging and visually complex virtual environments."
  },
  {
    "title": "Too Immersive for the Field? Addressing Safety Risks in Extended Reality User Studies",
    "abstract": "Extended Reality (XR) technologies are increasingly tested outside the lab, in homes, schools, and public spaces. While this shift enables more realistic user insights, it also introduces safety challenges that are often overlooked. Physical risks, psychological distress, and accessibility issues can be increased in field studies and unsupervised testing, such as at home or crowdsourced trials. Without clear instructions, safety decisions are left to individual researchers, raising questions of responsibility and consistency. This position paper outlines key safety risks in XR user testing beyond the lab and calls for practical strategies that are needed to help researchers run XR studies in a safe and inclusive way across different environments.",
    "url": "https://arxiv.org/abs/2602.23497",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper discusses the safety risks associated with conducting Extended Reality (XR) user studies outside of controlled lab environments. The shift towards field studies in homes, schools, and public spaces poses challenges such as physical risks, psychological distress, and accessibility issues. The paper calls for practical strategies to ensure the safety and inclusivity of XR studies in various environments, highlighting the need for clear instructions and consistent safety protocols."
  },
  {
    "title": "Tidynote: Always-Clear Notebook Authoring",
    "abstract": "Recent work identified clarity as one of the top quality attributes that notebook users value, but notebooks lack support for maintaining clarity throughout the exploratory phases of the notebook authoring workflow. We propose always-clear notebook authoring that supports both clarity and exploration, and present a Jupyter implementation called Tidynote. The key to Tidynote is three-fold: (1) a scratchpad sidebar to facilitate exploration, (2) cells movable between the notebook and the scratchpad to maintain organization, and (3) linear execution with state forks to clarify program state. An exploratory study (N=13) of open-ended data analysis tasks shows that Tidynote features holistically promote clarity throughout a notebook's lifecycle, support realistic notebook tasks, and enable novel strategies for notebook clarity. These results suggest that Tidynote supports maintaining clarity throughout the entirety of notebook authoring.",
    "url": "https://arxiv.org/abs/2602.23490",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces Tidynote, a Jupyter implementation that aims to support clarity and exploration in notebook authoring. Tidynote includes features such as a scratchpad sidebar, movable cells, and linear execution with state forks to maintain organization and clarify program state. An exploratory study with 13 participants showed that Tidynote promotes clarity throughout the notebook's lifecycle, supports realistic tasks, and enables novel strategies for maintaining clarity in notebook authoring."
  },
  {
    "title": "Walking with Robots: Video Analysis of Human-Robot Interactions in Transit Spaces",
    "abstract": "The proliferation of robots in public spaces necessitates a deeper understanding of how these robots can interact with those they share the space with. In this paper, we present findings from video analysis of publicly deployed cleaning robots in a transit space, a major commercial airport, using their navigational 'troubles' as a tool to document what robots currently lack in interactional competence. We demonstrate that these robots, while technically proficient, can disrupt the social order of a space due to their inability to understand core aspects of human movement: mutual adjustment to others, the significance of understanding social groups, and the purpose of different locations. In discussion we argue for exploring a new design space of movement: socially-aware movement. By developing \"strong concepts\" that treat movement as an interactional and collaborative accomplishment, we can create systems that better integrate into the everyday rhythms of public life.",
    "url": "https://arxiv.org/abs/2602.23475",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper analyzes video footage of cleaning robots in a commercial airport to understand how they interact with humans in shared spaces. The study found that while the robots were technically proficient, they lacked the ability to understand key aspects of human movement and social interaction, leading to disruptions in the social order of the space. The researchers suggest exploring socially-aware movement design concepts to create robots that can better integrate into public spaces and collaborate with humans in everyday activities."
  },
  {
    "title": "Challenges in Automatic Speech Recognition for Adults with Cognitive Impairment",
    "abstract": "Millions of people live with cognitive impairment from Alzheimer's disease and related dementias (ADRD). Voice-enabled smart home systems offer promise for supporting daily living but rely on automatic speech recognition (ASR) to transcribe their speech to text. Prior work has shown reduced ASR performance for adults with cognitive impairment; however, the acoustic factors underlying these disparities remain poorly understood. This paper evaluates ASR performance for 83 older adults across cognitive groups (cognitively normal, mild cognitive impairment, dementia) reading commands to a voice assistant (Amazon Alexa). Results show that ASR errors are significantly higher for individuals with dementia, revealing a critical usability gap. To better understand these disparities, we conducted an acoustic analysis of speech features and found that a speaker's intensity, voice quality, and pause ratio predicted ASR accuracy. Based on these findings, we outline HCI design implications for AgeTech and voice interfaces, including speaker-personalized ASR, human-in-the-loop correction of ASR transcripts, and interaction-level personalization to support ability-based adaptation.",
    "url": "https://arxiv.org/abs/2602.23436",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper explores the challenges in automatic speech recognition (ASR) for adults with cognitive impairment, particularly those with dementia. The study found that ASR errors are significantly higher for individuals with dementia compared to cognitively normal individuals, highlighting a critical usability gap in voice-enabled smart home systems. The acoustic analysis of speech features revealed that a speaker's intensity, voice quality, and pause ratio can predict ASR accuracy, suggesting the need for speaker-personalized ASR and human-in-the-loop correction of ASR transcripts to improve usability for individuals with cognitive impairment."
  },
  {
    "title": "Now You See Me: Designing Responsible AI Dashboards for Early-Stage Health Innovation",
    "abstract": "Innovative HealthTech teams develop Artificial Intelligence (AI) systems in contexts where ethical expectations and organizational priorities must be balanced under severe resource constraints. While Responsible AI practices are expected to guide the design and evaluation of such systems, they frequently remain abstract or poorly aligned with the operational realities of early-stage innovation. At the ecosystem level, this misalignment disproportionately affects disadvantaged projects and founders, therefore limiting the diversity of problem-areas under consideration, solutions, stakeholder perspectives, and population datasets represented in AI-enabled healthcare systems.\nVisualization provides a practical mechanism for supporting decision-making across the AI lifecycle. When developed via a rigorous and collaborative design process, structured on domain knowledge and designed around real-world constraints, visual interfaces can operate as effective sociotechnical governance artifacts enabling responsible decision-making.\nGrounded in innovation-oriented Human-Centered Computing methodologies, we synthesize insights from a series of design studies conducted via a longitudinal visualization research program, a case study centered on governance dashboard design in a translational setting, and a survey of a cohort of early-stage HealthTech startups. Based on these findings, we articulate design process implications for governance-oriented visualization systems: co-creation with stakeholders, alignment with organizational maturity and context, and support for heterogeneous roles and tasks among others. This work contributes actionable guidance for designing Responsible AI governance dashboards that support decision-making and accountability in early-stage health innovation, and suggests that ecosystem-level coordination can enable more scalable and diverse AI innovation in healthcare.",
    "url": "https://arxiv.org/abs/2602.23378",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on designing responsible AI dashboards for early-stage health innovation, highlighting the importance of balancing ethical expectations and organizational priorities within resource constraints. The study emphasizes the significance of visualization in supporting decision-making throughout the AI lifecycle, especially when developed collaboratively and grounded in domain knowledge. The findings suggest that governance-oriented visualization systems can enhance responsible decision-making in AI-enabled healthcare systems, ultimately promoting more scalable and diverse innovation in the field."
  },
  {
    "title": "Complex Cognition: A New Theoretical Foundation for the Design and Evaluation of Visual Analytics Systems",
    "abstract": "Current research on visual analytics systems largely follows the research paradigm of interactive system design in the field of Human-Computer Interaction (HCI), and includes key methodologies including design requirement development based on user needs, interactive system design, and system evaluation. However, most studies under this paradigm have a contradiction: there is a significant mismatch between the research methods developed for simple cognitive behaviors (e.g., color perception, the perception of spatial relationship among interactive artifacts) and research goals targeting for complex analytical behaviors (e.g., reasoning, problem-solving, decision-making). This mismatch may hurt the theoretical contributions of research studies, in particularly the internal validity of a designed system and the external validity of design methods. To address this challenge, this paper argues for a need to go beyond traditional HCI theoretical foundations and proposes to adopt complex cognition theories to build new theoretical foundations. Specifically, this paper analyzes how current design and evaluation methods in research on visual analytics systems constrain the internal and external validity of research, discusses the connections between complex cognition theories and visual analytics tasks, and explores how problem-solving theories from complex cognition can guide research on visual analytics systems.",
    "url": "https://arxiv.org/abs/2602.23377",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper highlights the mismatch between research methods developed for simple cognitive behaviors and the goals targeting complex analytical behaviors in visual analytics systems. The paper argues for the adoption of complex cognition theories to build new theoretical foundations for designing and evaluating visual analytics systems. By analyzing the constraints of current design and evaluation methods and exploring the connections between complex cognition theories and visual analytics tasks, the paper suggests that problem-solving theories from complex cognition can guide future research in this field."
  },
  {
    "title": "Dynamic Personalization Through Continuous Feedback Loops in Interactive AI Systems",
    "abstract": "Interactive AI systems, such as recommendation engines and virtual assistants, commonly use static user profiles and predefined rules to personalize interactions. However, these methods often fail to capture the dynamic nature of user preferences and context. This study proposes a theoretical framework and practical implementation for integrating continuous feedback loops into personalization algorithms to enable real-time adaptation. By continuously collecting and analyzing user feedback, the AI system can dynamically adjust its recommendations, responses, and interactions to better align with the user's current context and preferences. We provide theoretical guarantees for the convergence and regret bounds of our adaptive personalization algorithm. Our experimental evaluation across three domains-recommendation systems, virtual assistants, and adaptive learning platforms-demonstrates that dynamic personalization improves user satisfaction by 15-23% compared to static methods while maintaining computational efficiency. We investigated the implementation challenges of continuous feedback mechanisms, evaluated their impact on user experience and satisfaction, and provided a comprehensive analysis of the trade-offs between personalization quality, computational overhead, and user fatigue.",
    "url": "https://arxiv.org/abs/2602.23376",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research proposes a method for integrating continuous feedback loops into interactive AI systems to enable real-time adaptation and dynamic personalization. By continuously collecting and analyzing user feedback, the AI system can adjust its recommendations and responses to better align with user preferences and context. Experimental evaluation across various domains shows that dynamic personalization improves user satisfaction by 15-23% compared to static methods while maintaining computational efficiency."
  },
  {
    "title": "Doc To The Future: Infomorphs for Interactive, Multimodal Document Transformation and Generation",
    "abstract": "Creating new documents by synthesizing information from existing sources is an important part of knowledge work in many domains. This process often involves gathering content from multiple documents, organizing it, and then transforming it into new forms such as reports, slides, or spreadsheets. While recent advances in Generative AI have shown potential in automating parts of this process, they often provide limited user control over the handling of multimodal inputs and outputs. In this work, we introduce the notion of \"infomorphs\" which are modular, user-steerable, AI-augmented transformations that support controlled synthesis, and restructuring of information across formats and modalities. We propose a design space that leverage infomorph-driven workflows to enable flexible, interactive, and multimodal document creation by combining Generative AI techniques with user intent and desired information context. As a concrete instantiation of this design space, we present DocuCraft, a canvas-based interface to visually compose infomorph workflows. DocuCraft allows users to chain together infomorphs that perform operations such as page extraction, content summarization, reformatting, and generation, leveraging Generative AI at each stage to support rich, cross-document and cross-modal transformations. We demonstrate the capabilities of DocuCraft through an example-driven usage scenario that spans across different facets of common knowledge work tasks illustrating its support for fluid, human-in-the-loop document synthesis and highlights opportunities for more transparent and modular interaction for Generative AI-assisted information work.",
    "url": "https://arxiv.org/abs/2602.23366",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces the concept of \"infomorphs\" as modular, user-controlled AI-augmented transformations for synthesizing and restructuring information across different formats and modalities. The proposed design space, implemented in the DocuCraft interface, allows users to visually compose workflows that leverage Generative AI techniques to support flexible, interactive, and multimodal document creation. The study demonstrates the potential of infomorph-driven workflows in enhancing user control and transparency in Generative AI-assisted information work tasks."
  },
  {
    "title": "Serendipity with Generative AI: Repurposing knowledge components during polycrisis with a Viable Systems Model approach",
    "abstract": "Organisations face polycrisis uncertainty yet overlook embedded knowledge. We show how generative AI can operate as a serendipity engine and knowledge transducer to discover, classify and mobilise reusable components (models, frameworks, patterns) from existing documents. Using 206 papers, our pipeline extracted 711 components (approx 3.4 per paper) and organised them into a repository aligned to Beer's Viable System Model (VSM). We contribute i) conceptually, a theory of planned serendipity in which GenAI lowers transduction costs between VSM subsystems, ii) empirically, a component repository and temporal/subject patterns, iii) managerially, a vignette and process blueprint for organisational adoption and iv) socially, pathways linking repurposing to environmental and social benefits. We propose testable links between repository creation, discovery-to-deployment time, and reuse rates, and discuss implications for shifting innovation portfolios from breakthrough bias toward systematic repurposing.",
    "url": "https://arxiv.org/abs/2602.23365",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores how generative AI can be used to discover and repurpose reusable components from existing documents to help organizations navigate polycrisis uncertainty. The study extracted 711 components from 206 papers and organized them into a repository based on Beer's Viable System Model. The findings suggest that this approach can lower transduction costs between VSM subsystems, improve discovery-to-deployment time, and increase reuse rates, offering a systematic method for innovation through repurposing knowledge components."
  },
  {
    "title": "Beyond the Click: A Framework for Inferring Cognitive Traces in Search",
    "abstract": "User simulators are essential for evaluating search systems, but they primarily copy user actions without understanding the underlying thought process. This gap exists since large-scale interaction logs record what users do, but not what they might be thinking or feeling, such as confusion or satisfaction. To solve this problem, we present a framework to infer cognitive traces from behavior logs. Our method uses a multi-agent system grounded in Information Foraging Theory (IFT) and human expert judgment. These traces improve model performance on tasks like forecasting session outcomes and user struggle recovery. We release a collection of annotations for several public datasets, including AOL and Stack Overflow, and an open-source tool that allows researchers to apply our method to their own data. This work provides the tools and data needed to build more human-like user simulators and to assess retrieval systems on user-oriented dimensions of performance.",
    "url": "https://arxiv.org/abs/2602.24265",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces a framework for inferring cognitive traces from behavior logs in search systems, bridging the gap between user actions and underlying thought processes. By using a multi-agent system grounded in Information Foraging Theory and human expert judgment, the method improves model performance in tasks like forecasting session outcomes and user struggle recovery. The release of annotations for public datasets and an open-source tool allows researchers to create more human-like user simulators and evaluate retrieval systems based on user-oriented dimensions of performance."
  },
  {
    "title": "UXSim: Towards a Hybrid User Search Simulation",
    "abstract": "Simulating nuanced user experiences within complex interactive search systems poses distinct challenge for traditional methodologies, which often rely on static user proxies or, more recently, on standalone large language model (LLM) agents that may lack deep, verifiable grounding. The true dynamism and personalization inherent in human-computer interaction demand a more integrated approach. This work introduces UXSim, a novel framework that integrates both approaches. It leverages grounded data from traditional simulators to inform and constrain the reasoning of an adaptive LLM agent. This synthesis enables more accurate and dynamic simulations of user behavior while also providing a pathway for the explainable validation of the underlying cognitive processes.",
    "url": "https://arxiv.org/abs/2602.24241",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces UXSim, a new framework that combines traditional user search simulation methods with large language model (LLM) agents to create more accurate and dynamic simulations of user behavior in interactive search systems. By integrating grounded data from traditional simulators with the reasoning of an adaptive LLM agent, UXSim offers a pathway for validating the cognitive processes underlying user interactions, addressing the challenges of simulating nuanced user experiences in complex systems."
  },
  {
    "title": "Colour Contrast on the Web: A WCAG 2.1 Level AA Compliance Audit of Common Crawl's Top 500 Domains",
    "abstract": "We present a large-scale automated audit of WCAG 2.1/2.2 Level AA colour contrast compliance across the 500 most frequently crawled registered domains in Common Crawl's CC-MAIN-2026-08 February 2026 crawl archive. Rather than conducting a live crawl, all page content was sourced from Common Crawl's open WARC archives, ensuring reproducibility and eliminating any load on target web servers. Our static CSS analysis of 240 homepages identified 4,327 unique foreground/background colour pairings, of which 1,771 (40.9%) failed to meet the 4.5:1 contrast ratio threshold for normal text. The median per-site pass rate was 62.7%, with 20.4% of sites achieving full compliance across all detected colour pairings. These findings suggest that colour contrast remains a widespread accessibility barrier on the most prominent websites, with significant variation across domain categories.",
    "url": "https://arxiv.org/abs/2602.24067",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research conducted a large-scale audit of color contrast compliance on the top 500 domains in Common Crawl's archive. The study found that a significant percentage of foreground/background color pairings did not meet the 4.5:1 contrast ratio threshold for normal text, indicating a widespread accessibility barrier on popular websites. The findings highlight the need for improved color contrast practices to ensure web accessibility for all users."
  },
  {
    "title": "From Continuous sEMG Signals to Discrete Muscle State Tokens: A Robust and Interpretable Representation Framework",
    "abstract": "Surface electromyography (sEMG) signals exhibit substantial inter-subject variability and are highly susceptible to noise, posing challenges for robust and interpretable decoding. To address these limitations, we propose a discrete representation of sEMG signals based on a physiology-informed tokenization framework. The method employs a sliding window aligned with the minimal muscle contraction cycle to isolate individual muscle activation events. From each window, ten time-frequency features, including root mean square (RMS) and median frequency (MDF), are extracted, and K-means clustering is applied to group segments into representative muscle-state tokens. We also introduce a large-scale benchmark dataset, ActionEMG-43, comprising 43 diverse actions and sEMG recordings from 16 major muscle groups across the body. Based on this dataset, we conduct extensive evaluations to assess the inter-subject consistency, representation capacity, and interpretability of the proposed sEMG tokens. Our results show that the token representation exhibits high inter-subject consistency (Cohen's Kappa = 0.82+-0.09), indicating that the learned tokens capture consistent and subject-independent muscle activation patterns. In action recognition tasks, models using sEMG tokens achieve Top-1 accuracies of 75.5% with ViT and 67.9% with SVM, outperforming raw-signal baselines (72.8% and 64.4%, respectively), despite a 96% reduction in input dimensionality. In movement quality assessment, the tokens intuitively reveal patterns of muscle underactivation and compensatory activation, offering interpretable insights into neuromuscular control. Together, these findings highlight the effectiveness of tokenized sEMG representations as a compact, generalizable, and physiologically meaningful feature space for applications in rehabilitation, human-machine interaction, and motor function analysis.",
    "url": "https://arxiv.org/abs/2602.23738",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research proposes a new method for representing sEMG signals using a discrete tokenization framework, which isolates individual muscle activation events and groups them into representative muscle-state tokens. The study introduces a benchmark dataset, ActionEMG-43, and shows that the token representation exhibits high inter-subject consistency and outperforms raw-signal baselines in action recognition tasks and movement quality assessment. These findings demonstrate the effectiveness of tokenized sEMG representations as a compact, generalizable, and physiologically meaningful feature space for various applications in rehabilitation, human-machine interaction, and motor function analysis."
  },
  {
    "title": "Assessment of Display Performance and Comparative Evaluation of Web Map Libraries for Extensive 3D Geospatial Data",
    "abstract": "Large-scale 3D geospatial data visualization has become increasingly critical for the development of the digital society infrastructure in Japan. This study conducted a comprehensive performance evaluation of two major WebGL-based web mapping libraries, CesiumJS and MapLibre GL JS, using large-scale 3D point-cloud data from the VIRTUAL SHIZUOKA and PLATEAU building models. The research employs standardized 3D Tiles 1.1, and Mapbox Vector Tiles (MVT) formats, comparing performance across different data scales (2nd and 3rd grid levels) using Core Web Vitals metrics, including First Contentful Paint (FCP), Largest Contentful Paint (LCP), Speed Index, Total Blocking Time (TBT), and Cumulative Layout Shift (CLS).\nThe results demonstrate that MVT-based building visualization with MapLibre GL JS achieves optimal performance (FCP 0.8s, TBT 0ms), whereas MapLibre GL JS combined with this http URL shows superior performance for large-scale point cloud processing (TBT: 3ms, CesiumJS: 21,357ms). This study provides data-driven selection guidelines for appropriate technology choices according to use cases, establishing reproducible performance evaluation frameworks for 3D web mapping technologies during the WebGPU and OGC 3D Tiles 1.1 standardization era.",
    "url": "https://arxiv.org/abs/2602.23660",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research evaluates the performance of two major web mapping libraries, CesiumJS and MapLibre GL JS, using large-scale 3D geospatial data from the VIRTUAL SHIZUOKA and PLATEAU building models in Japan. The study found that MapLibre GL JS with MVT-based visualization outperformed CesiumJS for building visualization, and combining MapLibre GL JS with an http URL showed superior performance for large-scale point cloud processing. The findings offer guidelines for selecting the appropriate technology for different use cases and establish reproducible performance evaluation frameworks for 3D web mapping technologies."
  },
  {
    "title": "Critical Infrastructure in the Multi-Cloud Strategy: Use of Cloud Computing in SMEs",
    "abstract": "Cloud computing enables cost-effective on-demand network access to a shared pool of configurable computing resources. The purpose of this paper is to examine and identifying the use of Cloud computing in the critical infrastructure domain among small and medium sized enterprises (SMEs). The data for this study were gathered from a survey of different academic, industry, governmental and online literature related to the use of Cloud computing in SMEs. The result revealed that there are risks involved in the use of Cloud computing, SMEs are deploying Cloud computing using different deployment models and reaching a high level of deployment within the critical infrastructure. The research findings are useful for SMEs that are planning or are in the use of Cloud computing, as well as for SMEs policymakers and business support community that engaged with Cloud computing initiatives.",
    "url": "https://arxiv.org/abs/2602.23658",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper explores the use of cloud computing in critical infrastructure among small and medium-sized enterprises (SMEs). The study found that while there are risks involved, SMEs are increasingly adopting cloud computing for their critical infrastructure needs using various deployment models. The findings are valuable for SMEs considering cloud computing, as well as policymakers and business support communities involved in cloud computing initiatives."
  },
  {
    "title": "Understanding Usage and Engagement in AI-Powered Scientific Research Tools: The Asta Interaction Dataset",
    "abstract": "AI-powered scientific research tools are rapidly being integrated into research workflows, yet the field lacks a clear lens into how researchers use these systems in real-world settings. We present and analyze the Asta Interaction Dataset, a large-scale resource comprising over 200,000 user queries and interaction logs from two deployed tools (a literature discovery interface and a scientific question-answering interface) within an LLM-powered retrieval-augmented generation platform. Using this dataset, we characterize query patterns, engagement behaviors, and how usage evolves with experience. We find that users submit longer and more complex queries than in traditional search, and treat the system as a collaborative research partner, delegating tasks such as drafting content and identifying research gaps. Users treat generated responses as persistent artifacts, revisiting and navigating among outputs and cited evidence in non-linear ways. With experience, users issue more targeted queries and engage more deeply with supporting citations, although keyword-style queries persist even among experienced users. We release the anonymized dataset and analysis with a new query intent taxonomy to inform future designs of real-world AI research assistants and to support realistic evaluation.",
    "url": "https://arxiv.org/abs/2602.23335",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research presents the Asta Interaction Dataset, which contains user queries and interaction logs from AI-powered scientific research tools. The findings show that users treat the tools as collaborative research partners, delegating tasks and revisiting generated responses. With experience, users issue more targeted queries and engage more deeply with supporting citations, providing insights for the design of future AI research assistants."
  },
  {
    "title": "Evaluating Zero-Shot and One-Shot Adaptation of Small Language Models in Leader-Follower Interaction",
    "abstract": "Leader-follower interaction is an important paradigm in human-robot interaction (HRI). Yet, assigning roles in real time remains challenging for resource-constrained mobile and assistive robots. While large language models (LLMs) have shown promise for natural communication, their size and latency limit on-device deployment. Small language models (SLMs) offer a potential alternative, but their effectiveness for role classification in HRI has not been systematically evaluated. In this paper, we present a benchmark of SLMs for leader-follower communication, introducing a novel dataset derived from a published database and augmented with synthetic samples to capture interaction-specific dynamics. We investigate two adaptation strategies: prompt engineering and fine-tuning, studied under zero-shot and one-shot interaction modes, compared with an untrained baseline. Experiments with Qwen2.5-0.5B reveal that zero-shot fine-tuning achieves robust classification performance (86.66% accuracy) while maintaining low latency (22.2 ms per sample), significantly outperforming baseline and prompt-engineered approaches. However, results also indicate a performance degradation in one-shot modes, where increased context length challenges the model's architectural capacity. These findings demonstrate that fine-tuned SLMs provide an effective solution for direct role assignment, while highlighting critical trade-offs between dialogue complexity and classification reliability on the edge.",
    "url": "https://arxiv.org/abs/2602.23312",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research evaluates the effectiveness of small language models (SLMs) for role classification in leader-follower interaction scenarios with mobile and assistive robots. The study introduces a benchmark dataset and compares two adaptation strategies (prompt engineering and fine-tuning) under zero-shot and one-shot interaction modes. Results show that zero-shot fine-tuning of SLMs achieves high classification performance and low latency, making them a promising solution for direct role assignment in human-robot interactions, but performance may degrade in more complex dialogue scenarios."
  },
  {
    "title": "BRIDGE: Borderless Reconfiguration for Inclusive and Diverse Gameplay Experience via Embodiment Transformation",
    "abstract": "Training resources for parasports are limited, reducing opportunities for athletes and coaches to engage with sport-specific movements and tactical coordination. To address this gap, we developed BRIDGE, a system that integrates a reconstruction pipeline, which detects and tracks players from broadcast video to generate 3D play sequences, with an embodiment-aware visualization framework that decomposes head, trunk, and wheelchair base orientations to represent attention, intent, and mobility. We evaluated BRIDGE in two controlled studies with 20 participants (10 national wheelchair basketball team players and 10 amateur players). The results showed that BRIDGE significantly enhanced the perceived naturalness of player postures and made tactical intentions easier to understand. In addition, it supported functional classification by realistically conveying players' capabilities, which in turn improved participants' sense of self-efficacy. This work advances inclusive sports learning and accessible coaching practices, contributing to more equitable access to tactical resources in parasports.",
    "url": "https://arxiv.org/abs/2602.23288",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces BRIDGE, a system that uses a reconstruction pipeline to generate 3D play sequences from broadcast video and an embodiment-aware visualization framework to represent player movements in wheelchair basketball. The study involving 20 participants showed that BRIDGE improved the naturalness of player postures, made tactical intentions easier to understand, and supported functional classification, ultimately enhancing participants' sense of self-efficacy. This research contributes to inclusive sports learning and accessible coaching practices in parasports, providing more equitable access to tactical resources."
  },
  {
    "title": "VRSL:Exploring the Comprehensibility of 360-Degree Camera Feeds for Sign Language Communication in Virtual Reality",
    "abstract": "This study explores integrating sign language into virtual reality (VR) by examining the comprehensibility and user experience of viewing American Sign Language (ASL) videos captured with body-mounted 360-degree cameras. Ten participants identified ASL signs from videos recorded at three body-mounted positions: head, shoulder, and chest. Results showed the shoulder-mounted camera achieved the highest accuracy (85%), though differences between positions were not statistically significant. Participants noted that peripheral distortion in 360-degree videos impacted clarity, highlighting areas for improvement. Despite challenges, the overall comprehension success rate of 83.3% demonstrates the potential of video-based ASL communication in VR. Feedback emphasized the need to refine camera angles, reduce distortion, and explore alternative mounting positions. Participants expressed a preference for signing over text-based communication in VR, highlighting the importance of developing this approach to enhance accessibility and collaboration for Deaf and Hard of Hearing (DHH) users in virtual environments.",
    "url": "https://arxiv.org/abs/2602.23265",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study examines the use of 360-degree camera feeds to incorporate American Sign Language (ASL) into virtual reality (VR) for Deaf and Hard of Hearing (DHH) users. Results show that shoulder-mounted cameras had the highest accuracy in identifying ASL signs, with an overall comprehension success rate of 83.3%. Participants expressed a preference for signing over text-based communication in VR, emphasizing the potential of video-based ASL communication to enhance accessibility and collaboration in virtual environments."
  },
  {
    "title": "FuturePrism: Supporting Adolescence in Collaborative Storytelling to Cope with Future Uncertainty",
    "abstract": "FuturePrism is a GenAI-empowered collaborative storytelling system designed to scaffold adolescents to navigate future life challenges. Adolescents often suffer from anxiety related to future uncertainty for lacking the executive function to develop concrete pathways. Operationalizing Snyder's Hope Theory, the system utilizes a triadic role-play mechanics to externalize cognitive processes through four narrative chapters: The Goal, The Opportunity, The Challenge, and The Agency. An evaluation workshop with 20 adolescents demonstrated that FuturePrism significantly enhances momentary hope levels, particularly in the Agency dimension. Participants reported high levels of narrative immersion and positive feedback towards system usability. Participants also confirmed that the AI-scaffolded collaborative storytelling empowered them to develop positive attitudes towards future challenges.",
    "url": "https://arxiv.org/abs/2602.23108",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces FuturePrism, a collaborative storytelling system powered by GenAI to help adolescents navigate future uncertainties and develop concrete pathways. By incorporating Snyder's Hope Theory and utilizing triadic role-play mechanics, the system was found to significantly enhance momentary hope levels, particularly in the Agency dimension. Evaluation with adolescents showed high levels of narrative immersion, positive feedback on usability, and empowerment in developing positive attitudes towards future challenges through AI-scaffolded storytelling."
  },
  {
    "title": "TaleBot: A Tangible AI Companion to Support Children in Co-creative Storytelling for Resilience Cultivation",
    "abstract": "Resilience is a key factor affecting children's mental wellbeing and future development. Yet, limited HCI research has explored how to help children build resilience through adversarial experiences. Informed by a formative study with elementary school teachers and professional psychologists, we design TaleBot, an AI-empowered system that supports children to co-create stories about overcoming everyday adversities tailored to their personal situations. We evaluated the system with 12 elementary children in school counseling rooms under teacher guidance and conducted reflective interviews with parents upon the Child-AI co-created stories. The findings show that TaleBot encourages children in self-expression of feelings and thoughts, creating opportunities for teachers to provide personalized support and for parents to better understand the profound impact of family communication on children's mental wellbeing. We conclude with design implications for using generative AI to support children's mental health education and interventions across school and family contexts.",
    "url": "https://arxiv.org/abs/2602.23095",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research explores the use of an AI system called TaleBot to help children build resilience through co-creative storytelling about overcoming adversities. Through evaluations with elementary school children and reflective interviews with parents, the study found that TaleBot encourages self-expression, provides personalized support from teachers, and helps parents understand the impact of family communication on children's mental wellbeing. The findings suggest the potential for using generative AI to support children's mental health education and interventions in school and family settings."
  },
  {
    "title": "Beyond Faders: Understanding 6DoF Gesture Ecologies in Music Mixing",
    "abstract": "Extended reality (XR) enables new music-mixing workflows by moving beyond 2D faders toward embodied, spatial interaction. However, it remains unclear which six-degree-of-freedom (6DoF) gestures align with real-world mixing practices and whether such interactions support manageable cognitive load and positive user experience. We conducted a design workshop with experienced mixers to elicit gesture concepts for core audio tasks gain, compression, equalization, and automation, and implemented these in an XR prototype. A user study (n=12) evaluated the ecological validity of the gestures using cognitive load measures, user-experience ratings, and interviews. Participants generally found 6DoF gestures intuitive and well-mapped to mixing tasks, reporting strong immersion and a sense of connection with the audio environment. Cognitive load differences across gestures were minimal, though participants expressed preferences shaped by workflow familiarity and perceived control. We discuss implications for designing XR mixing tools that balance expressiveness, precision, and ecological validity.",
    "url": "https://arxiv.org/abs/2602.23090",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of six-degree-of-freedom (6DoF) gestures in music mixing in extended reality (XR) environments. The study found that experienced mixers found the 6DoF gestures intuitive and well-mapped to mixing tasks, leading to strong immersion and a sense of connection with the audio environment. The findings suggest that designing XR mixing tools with a balance of expressiveness, precision, and ecological validity can enhance user experience in music mixing workflows."
  },
  {
    "title": "Understanding Older Adults' Experiences of Support, Concerns, and Risks from Kinship-Role AI-Generated Influencers",
    "abstract": "AI-generated influencers are rapidly gaining popularity on Chinese short-video platforms, often adopting kinship-based roles such as AI grandchildren to attract older adults. Although this trend has raised public concern, little is known about the design strategies behind these influencers, how older adults experience them, and the benefits and risks involved. In this study, we combined social media analysis with interviews to unpack the above questions. Our findings show that influencers use both visual and conversational cues to enact kinship roles, prompting audiences to engage in kinship-based role-play. Interviews further show that these cues arouse emotional resonance, help fulfill older adults' informational and emotional needs, while also raising concerns about emotional displacement and unequal emotional investment. We highlight the complex relationship between virtual avatars and real family ties, shaped by broader sociocultural norms, and discuss how AI might strengthen social support for older adults while mitigating risks within cultural contexts.",
    "url": "https://arxiv.org/abs/2602.22993",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research examines the use of AI-generated influencers adopting kinship roles to attract older adults on Chinese short-video platforms. The study found that these influencers use visual and conversational cues to prompt audiences to engage in kinship-based role-play, fulfilling older adults' informational and emotional needs but also raising concerns about emotional displacement and unequal emotional investment. The findings highlight the complex relationship between virtual avatars and real family ties, suggesting that AI could strengthen social support for older adults while mitigating risks within cultural contexts."
  },
  {
    "title": "TableTale: Reviving the Narrative Interplay Between Data Tables and Text in Scientific Papers",
    "abstract": "Data tables play a central role in scientific papers. However, their meaning is often co-constructed with surrounding text through narrative interplay, making comprehension cognitively demanding for readers. In this work, we explore how interfaces can better support this reading process. We conducted a formative study that revealed key characteristics of text-table narrative interplay, including linking mechanisms, multi-granularity alignments, and mention typologies, as well as a layered framework of readers' intents. Informed by these insights, we present TableTale, an augmented reading interface that enriches text with data tables at multiple granularities, including paragraphs, sentences, and mentions. TableTale automatically constructs a document-level linking schema within the paper and progressively renders cascade visual cues on text and tables that unfold as readers move through the text. A within-subject study with 24 participants showed that TableTale reduced cognitive workload and improved reading efficiency, demonstrating its potential to enhance paper reading and inform future reading interface design.",
    "url": "https://arxiv.org/abs/2602.22908",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research explores how interfaces can better support the narrative interplay between data tables and text in scientific papers, which can be cognitively demanding for readers. The study identified key characteristics of this interplay and developed TableTale, an augmented reading interface that enriches text with data tables at multiple granularities. A study with 24 participants showed that TableTale reduced cognitive workload and improved reading efficiency, suggesting its potential to enhance paper reading and inform future interface design."
  },
  {
    "title": "InfoAlign: A Human-AI Co-Creation System for Storytelling with Infographics",
    "abstract": "Storytelling infographics are a powerful medium for communicating data-driven stories through visual presentation. However, existing authoring tools lack support for maintaining story consistency and aligning with users' story goals throughout the design process. To address this gap, we conducted formative interviews and a quantitative analysis to identify design needs and common story-informed layout patterns in infographics. Based on these insights, we propose a narrative-centric workflow for infographic creation consisting of three phases: story construction, visual encoding, and spatial composition. Building on this workflow, we developed InfoAlign, a human-AI co-creation system that transforms long or unstructured text into stories, recommends semantically aligned visual designs, and generates layout blueprints. Users can intervene and refine the design at any stage, ensuring their intent is preserved and the infographic creation process remains transparent. Evaluations show that InfoAlign preserves story coherence across authoring stages and effectively supports human-AI co-creation for storytelling infographic design.",
    "url": "https://arxiv.org/abs/2602.22901",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research focuses on addressing the lack of support for maintaining story consistency and aligning with users' story goals in the design process of storytelling infographics. Through formative interviews and quantitative analysis, the researchers identified design needs and common layout patterns in infographics, leading to the development of a narrative-centric workflow for infographic creation. The proposed system, InfoAlign, allows for human-AI co-creation by transforming text into stories, recommending visual designs, and generating layout blueprints, ultimately preserving story coherence and supporting transparent collaboration between humans and AI in infographic design."
  },
  {
    "title": "They Think AI Can Do More Than It Actually Can: Practices, Challenges, & Opportunities of AI-Supported Reporting In Local Journalism",
    "abstract": "Declining newspaper revenues prompt local newsrooms to adopt automation to maintain efficiency and keep the community informed. However, current research provides a limited understanding of how local journalists work with digital data and which newsroom processes would benefit most from AI-supported (data) reporting. To bridge this gap, we conducted 21 semi-structured interviews with local journalists in Germany. Our study investigates how local journalists use data and AI (RQ1); the challenges they encounter when interacting with data and AI (RQ2); and the self-perceived opportunities of AI-supported reporting systems through the lens of discursive design (RQ3). Our findings reveal that local journalists do not fully leverage AI's potential to support data-related work. Despite local journalists' limited awareness of AI's capabilities, they are willing to use it to process data and discover stories. Finally, we provide recommendations for improving AI-supported reporting in the context of local news, grounded in the journalists' socio-technical perspective and their imagined AI future capabilities.",
    "url": "https://arxiv.org/abs/2602.22887",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research explores how local journalists in Germany use data and AI in their reporting, revealing that they do not fully utilize AI's potential despite being willing to use it for data processing. The study highlights the challenges journalists face when interacting with data and AI, as well as the opportunities for AI-supported reporting systems in local newsrooms. Recommendations are provided to enhance AI-supported reporting based on journalists' perspectives and potential future capabilities of AI."
  },
  {
    "title": "Input-Envelope-Output: Auditable Generative Music Rewards in Sensory-Sensitive Contexts",
    "abstract": "Generative feedback in sensory-sensitive contexts poses a core design challenge: large individual differences in sensory tolerance make it difficult to sustain engagement without compromising safety. This tension is exemplified in autism spectrum disorder (ASD), where auditory sensitivities are common yet highly heterogeneous. Existing interactive music systems typically encode safety implicitly within direct input-output (I-O) mappings, which can preserve novelty but make system behavior hard to predict or audit. We instead propose a constraint-first Input-Envelope-Output (I-E-O) framework that makes safety explicit and verifiable while preserving action-output causality. I-E-O introduces a low-risk envelope layer between user input and audio output to specify safe bounds, enforce them deterministically, and log interventions for audit. From this architecture, we derive four verifiable design principles and instantiate them in MusiBubbles, a web-based prototype. Contributions include the I-E-O architecture, MusiBubbles as an exemplar implementation, and a reproducibility package to support adoption in ASD and other sensory-sensitive domains.",
    "url": "https://arxiv.org/abs/2602.22813",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research focuses on creating a framework for generative music systems in sensory-sensitive contexts, specifically in autism spectrum disorder where auditory sensitivities vary widely. The Input-Envelope-Output (I-E-O) framework proposed in the study introduces a layer to ensure safety and verifiability while maintaining causality between user input and audio output. The research provides a new approach to designing interactive music systems that can be audited and replicated, with potential applications in ASD and other sensory-sensitive domains."
  },
  {
    "title": "TherapyProbe: Generating Design Knowledge for Relational Safety in Mental Health Chatbots Through Adversarial Simulation",
    "abstract": "As mental health chatbots proliferate to address the global treatment gap, a critical question emerges: How do we design for relational safety the quality of interaction patterns that unfold across conversations rather than the correctness of individual responses? Current safety evaluations assess single-turn crisis responses, missing the therapeutic dynamics that determine whether chatbots help or harm over time. We introduce TherapyProbe, a design probe methodology that generates actionable design knowledge by systematically exploring chatbot conversation trajectories through adversarial multi-agent simulation. Using open-source models, TherapyProbe surfaces relational safety failures interaction patterns like \"validation spirals\" where chatbots progressively reinforce hopelessness, or \"empathy fatigue\" where responses become mechanical over turns. Our contribution is translating these failures into a Safety Pattern Library of 23 failure archetypes with corresponding design recommendations. We contribute: (1) a replicable methodology requiring no API costs, (2) a clinically-grounded failure taxonomy, and (3) design implications for developers, clinicians, and policymakers.",
    "url": "https://arxiv.org/abs/2602.22775",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces TherapyProbe, a methodology that explores chatbot conversation trajectories to identify patterns that may lead to relational safety failures in mental health chatbots. By using adversarial multi-agent simulation, the study identifies failure archetypes such as \"validation spirals\" and \"empathy fatigue\" and provides design recommendations to address these issues. This research is significant as it goes beyond evaluating single-turn responses and focuses on the quality of interactions over time, providing actionable design knowledge for developers, clinicians, and policymakers to improve the safety of mental health chatbots."
  },
  {
    "title": "An AI-Based Structured Semantic Control Model for Stable and Coherent Dynamic Interactive Content Generation",
    "abstract": "This study addresses the challenge that generative models struggle to balance flexibility, stability, and controllability in complex interactive scenarios. It proposes a controllable generation framework for dynamic interactive content construction. The framework builds a structured semantic state space that encodes user input, environmental conditions, and historical context into actionable latent representations and generates directional control vectors to guide the content generation process. It introduces multilevel constraints, including semantic consistency constraints, structural stability constraints, and semantic drift penalties, which help the model maintain clear semantic paths and coherent logic in dynamic environments. These constraints prevent content deviation, unstable tone, or structural breaks. Based on these components, the study designs a systematic controllable generation pipeline in which semantic modeling, control signals, and generation strategies work together within one framework. Sensitivity analyses on control vector dimension, hidden layer size, noise intensity, and training sample scale are conducted on a public dialogue dataset to validate the framework. The results show that the approach improves semantic structure, contextual consistency, and controllable expression, providing a structured and effective solution for interactive content generation.",
    "url": "https://arxiv.org/abs/2602.22762",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces a controllable generation framework for dynamic interactive content generation that addresses the challenges of balancing flexibility, stability, and controllability. By incorporating multilevel constraints and a structured semantic state space, the model can maintain semantic paths and coherent logic in dynamic environments, preventing content deviation and structural breaks. The study demonstrates improved semantic structure, contextual consistency, and controllable expression, offering a structured and effective solution for interactive content generation."
  },
  {
    "title": "Simulation-based Optimization for Augmented Reading",
    "abstract": "Augmented reading systems aim to adapt text presentation to improve comprehension and task performance, yet existing approaches rely heavily on heuristics, opaque data-driven models, or repeated human involvement in the design loop. We propose framing augmented reading as a simulation-based optimization problem grounded in resource-rational models of human reading. These models instantiate a simulated reader that allocates limited cognitive resources, such as attention, memory, and time under task demands, enabling systematic evaluation of text user interfaces. We introduce two complementary optimization pipelines: an offline approach that explores design alternatives using simulated readers, and an online approach that personalizes reading interfaces in real time using ongoing interaction data. Together, this perspective enables adaptive, explainable, and scalable augmented reading design without relying solely on human testing.",
    "url": "https://arxiv.org/abs/2602.22735",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research proposes a simulation-based optimization approach for augmented reading systems, which aims to improve comprehension and task performance by adapting text presentation. By using resource-rational models of human reading, the study introduces two optimization pipelines - one offline for exploring design alternatives and one online for real-time personalization. This approach allows for adaptive, explainable, and scalable design of augmented reading interfaces without the need for repeated human involvement in the design process."
  },
  {
    "title": "CoLyricist: Enhancing Lyric Writing with AI through Workflow-Aligned Support",
    "abstract": "We propose CoLyricist, an AI-assisted lyric writing tool designed to support the typical workflows of experienced lyricists and enhance their creative efficiency. While lyricists have unique processes, many follow common stages. Tools that fail to accommodate these stages challenge integration into creative practices. Existing research and tools lack sufficient understanding of these songwriting stages and their associated challenges, resulting in ineffective designs. Through a formative study involving semi-structured interviews with 10 experienced lyricists, we identified four key stages: Theme Setting, Ideation, Drafting Lyrics, and Melody Fitting. CoLyricist addresses these needs by incorporating tailored AI-driven support for each stage, optimizing the lyric writing process to be more seamless and efficient. To examine whether this workflow-aligned design also benefits those without prior experience, we conducted a user study with 16 participants, including both experienced and novice lyricists. Results showed that CoLyricist enhances the songwriting experience across skill levels. Novice users especially appreciated the Melody-Fitting feature, while experienced users valued the Ideation support.",
    "url": "https://arxiv.org/abs/2602.22606",
    "journal": "arXiv cs.HC",
    "ai_summary": "The study introduces CoLyricist, an AI tool designed to assist lyricists in their creative process by aligning with their typical workflow stages. Through interviews with experienced lyricists, four key stages were identified: Theme Setting, Ideation, Drafting Lyrics, and Melody Fitting. The study found that CoLyricist improved the songwriting experience for both experienced and novice users, with novice users benefiting from the Melody-Fitting feature and experienced users valuing the Ideation support."
  },
  {
    "title": "DuoMorph: Synergistic Integration of FDM Printing and Pneumatic Actuation for Shape-Changing Interfaces",
    "abstract": "We introduce DuoMorph, a design and fabrication method that synergistically integrates Fused Deposition Modeling (FDM) printing and pneumatic actuation to create novel shape-changing interfaces. In DuoMorph, the printed structures and heat-sealed pneumatic elements are mutually designed to actuate and constrain each other, enabling functions that are difficult for either component to achieve in isolation. Moreover, the entire hybrid structure can be fabricated through a single, seamless process using only a standard FDM printer, including both heat-sealing and 3D and 4D printing. In this paper, we define a design space including four primitive categories that capture the fundamental ways in which printed and pneumatic components can interact. To support this process, we present a fabrication method and an accompanying design tool. Finally, we demonstrate the potential of DuoMorph through a series of example applications and performance demonstrations.",
    "url": "https://arxiv.org/abs/2602.22604",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces DuoMorph, a method that combines FDM printing and pneumatic actuation to create shape-changing interfaces. This integration allows for novel functions that neither component could achieve alone, all fabricated using a standard FDM printer. The study defines a design space and presents a fabrication method and design tool, showcasing the potential of DuoMorph through various applications and demonstrations."
  },
  {
    "title": "Addressing Climate Action Misperceptions with Generative AI",
    "abstract": "Mitigating climate change requires behaviour change. However, even climate-concerned individuals often hold misperceptions about which actions most reduce carbon emissions. We recruited 1201 climate-concerned individuals to examine whether discussing climate actions with a large language model (LLM) equipped with climate knowledge and prompted to provide personalised responses would foster more accurate perceptions of the impacts of climate actions and increase willingness to adopt feasible, high-impact behaviours. We compared this to having participants run a web search, have a conversation with an unspecialised LLM, and no intervention. The personalised climate LLM was the only condition that led to increased knowledge about the impacts of climate actions and greater intentions to adopt impactful behaviours. While the personalised climate LLM did not outperform a web search in improving understanding of climate action impacts, the ability of LLMs to deliver personalised, actionable guidance may make them more effective at motivating impactful pro-climate behaviour change.",
    "url": "https://arxiv.org/abs/2602.22564",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores how using a large language model (LLM) equipped with climate knowledge to provide personalized responses can help correct misperceptions about climate actions and increase willingness to adopt impactful behaviors. The study found that interacting with a personalized climate LLM was the most effective in improving knowledge about climate actions and increasing intentions to adopt impactful behaviors compared to other interventions. The findings suggest that LLMs can play a significant role in motivating behavior change towards addressing climate change."
  },
  {
    "title": "Relational Appliances: A Robot in the Refrigerator for Home-Based Health Promotion",
    "abstract": "Kitchen appliances are frequently used domestic artifacts situated at the point of everyday dietary decision making, making them a promising but underexplored site for health promotion. We explore the concept of relational appliances: everyday household devices designed as embodied social actors that engage users through ongoing, personalized interaction. We focus on the refrigerator, whose unique affordances, including a fixed, sensor-rich environment, private interaction space, and close coupling to food items, support contextualized, conversational engagement during snack choices. We present an initial exploration of this concept through a pilot study deploying an anthropomorphic robotic head inside a household refrigerator. In a home-lab apartment, participants repeatedly retrieved snacks during simulated TV \"commercial breaks\" while interacting with a human-sized robotic head. Participants were randomized to either a health-promotion condition, in which the robot made healthy snack recommendations, or a social-chat control condition. Outcomes included compliance with recommendations, nutritional quality of selected snacks, and psychosocial measures related to acceptance of the robot. Results suggest that participants found the robot persuasive, socially engaging, and increasingly natural over time, often describing it as helpful, aware, and companionable. Most participants reported greater awareness of their snack decisions and expressed interest in having such a robot in their own home. We discuss implications for designing relational appliances that leverage anthropomorphism, trust, and long-term human-technology relationships for home-based health promotion.",
    "url": "https://arxiv.org/abs/2602.22542",
    "journal": "arXiv cs.HC",
    "ai_summary": "The study explores the concept of relational appliances, specifically focusing on using a robotic head inside a refrigerator for health promotion. Participants interacted with the robot while making snack choices, with some receiving healthy snack recommendations and others engaging in social chat. Results showed that participants found the robot persuasive and engaging, leading to increased awareness of snack decisions and interest in having such a robot in their own home, highlighting the potential for using anthropomorphism and trust in designing household devices for health promotion."
  },
  {
    "title": "Skewed Dual Normal Distribution Model: Predicting 1D Touch Pointing Success Rate for Targets Near Screen Edges",
    "abstract": "Typical success-rate prediction models for tapping exclude targets near screen edges; however, design constraints often force such placements. Additionally, in scrollable UIs any element can move close to an edge. In this work, we model how target--edge distance affects 1D touch pointing accuracy. We propose the Skewed Dual Normal Distribution Model, which assumes the tap coordinate distribution is skewed by a nearby edge. The results of two smartphone experiments showed that, as targets approached the edge, the distribution's peak shifted toward the edge and its tail extended away. In contrast to prior reports, the success rate improved when the target touched the edge, suggesting a strategy of ``tapping the target together with the edge.'' By accounting for skew, our model predicts success rates across a wide range of conditions, including edge-adjacent targets, thus extending coverage to the whole screen and informing UI design support tools.",
    "url": "https://arxiv.org/abs/2602.22454",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces the Skewed Dual Normal Distribution Model to predict 1D touch pointing success rates for targets near screen edges. The model takes into account how the distance between the target and edge affects accuracy, showing that success rates actually improve when the target touches the edge. By considering skew in the distribution, the model can accurately predict success rates for a variety of conditions, including edge-adjacent targets, informing UI design support tools and extending coverage to the entire screen."
  },
  {
    "title": "The Way We Notice, That's What Really Matters: Instantiating UI Components with Distinguishing Variations",
    "abstract": "Front-end developers author UI components to be broadly reusable by parameterizing visual and behavioral properties. While flexible, this makes instantiation harder, as developers must reason about numerous property values and interactions. In practice, they must explore the component's large design space and provide realistic and natural values to properties. To address this, we introduce distinguishing variations: variations that are both mimetic and distinct. We frame distinguishing variation generation as design-space sampling, combining symbolic inference to identify visually important properties with an LLM-driven mimetic sampler to produce realistic instantiations from its world knowledge. We instantiate distinguishing variations in Celestial, a tool that helps developers explore and visualize distinguishing variations. In a study with front-end developers (n=12), participants found these variations useful for comparing and mapping component design spaces, reported that mimetic instantiations were domain-relevant, and validated that Celestial transformed component instantiation from a manual process into a structured, exploratory activity.",
    "url": "https://arxiv.org/abs/2602.22436",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research focuses on addressing the challenge of instantiating UI components with numerous parameterized properties by introducing distinguishing variations that are both mimetic and distinct. By combining symbolic inference and an LLM-driven mimetic sampler, developers can generate realistic instantiations from a component's design space. The tool Celestial helps developers explore and visualize these variations, transforming component instantiation from a manual process to a structured and exploratory activity, as validated by a study with front-end developers."
  },
  {
    "title": "Seeing Graphs Like Humans: Benchmarking Computational Measures and MLLMs for Similarity Assessment",
    "abstract": "Comparing graphs to identify similarities is a fundamental task in visual analytics of graph data. To support this, visual analytics systems frequently employ quantitative computational measures to provide automated guidance. However, it remains unclear how well these measures align with subjective human visual perception, thereby offering recommendations that conflict with analysts' intuitive judgments, potentially leading to confusion rather than reducing cognitive load. Multimodal Large Language Models (MLLMs), capable of visually interpreting graphs and explaining their reasoning in natural language, have emerged as a potential alternative to address this challenge. This paper bridges the gap between human and machine assessment of graph similarity through three interconnected experiments using a dataset of 1,881 node-link diagrams. Experiment 1 collects relative similarity judgments and rationales from 32 human participants, revealing consensus on graph similarity while prioritizing global shapes and edge densities over exact topological details. Experiment 2 benchmarks 16 computational measures against these human judgments, identifying Portrait divergence as the best-performing metric, though with only moderate alignment. Experiment 3 evaluates the potential of three state-of-the-art MLLMs (GPT-5, Gemini 2.5 Pro, Claude Sonnet 4.5) as perceptual proxies. The results demonstrate that MLLMs, particularly GPT-5, significantly outperform traditional measures in aligning with human graph similarity perception and provide interpretable rationales for their decisions, whereas Claude Sonnet 4.5 shows the best computational efficiency. Our findings suggest that MLLMs hold significant promise not only as effective, explainable proxies for human perception but also as intelligent guides that can uncover subtle nuances that might be overlooked by human analysts in visual analytics systems.",
    "url": "https://arxiv.org/abs/2602.22416",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the alignment between human perception and computational measures in assessing graph similarity. The study finds that traditional computational measures do not always align with human judgments, leading to potential confusion. Multimodal Large Language Models (MLLMs), particularly GPT-5, show promise in providing more accurate and interpretable assessments of graph similarity, offering potential as intelligent guides in visual analytics systems."
  }
]