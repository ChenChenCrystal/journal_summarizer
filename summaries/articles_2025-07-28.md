# arXiv cs.AI Summary â€“ 2025-07-28

## IoT and Older Adults: Towards Multimodal EMG and AI-Based Interaction with Smart Home
**URL:** https://arxiv.org/abs/2507.19479

**Abstract:** We report preliminary insights from an exploratory study on non-standard non-invasive interfaces for Smart Home Technologies (SHT). This study is part of a broader research project on effective Smart Home ecosystem Sagacity that will target older adults, impaired persons, and other groups disadvantaged in the main technology discourse. Therefore, this research is in line with a long-term research framework of the HASE research group (Human Aspects in Science and Engineering) by the Living Lab Kobo. In our study, based on the prototype of the comprehensive SHT management system Sagacity, we investigated the potential of bioelectric signals, in particular EMG and EOG as a complementary interface for SHT. Based on our previous participatory research and studies on multimodal interfaces, including VUI and BCI, we prepared an in-depth interactive hands-on experience workshops with direct involvement of various groups of potential end users, including older adults and impaired persons (total 18 subjects) to explore and investigate the potential of solutions based on this type of non-standard interfaces. The preliminary insights from the study unveil the potential of EMG/EOG interfaces in multimodal SHT management, alongside limitations and challenges stemming from the current state of technology and recommendations for designing multimodal interaction paradigms pinpointing areas of interest to pursue in further studies.

**AI Summary:** This research explores the use of bioelectric signals, specifically EMG and EOG, as interfaces for Smart Home Technologies targeted towards older adults and impaired individuals. The study involved interactive workshops with potential end users to assess the potential of these non-standard interfaces. The findings suggest that EMG/EOG interfaces have potential in multimodal Smart Home management, but also highlight limitations and challenges that need to be addressed in further studies.

---

## Towards Effective Immersive Technologies in Medicine: Potential and Future Applications based on VR, AR, XR and AI solutions
**URL:** https://arxiv.org/abs/2507.19466

**Abstract:** Mixed Reality (MR) technologies such as Virtual and Augmented Reality (VR, AR) are well established in medical practice, enhancing diagnostics, treatment, and education. However, there are still some limitations and challenges that may be overcome thanks to the latest generations of equipment, software, and frameworks based on eXtended Reality (XR) by enabling immersive systems that support safer, more controlled environments for training and patient care. Our review highlights recent VR and AR applications in key areas of medicine. In medical education, these technologies provide realistic clinical simulations, improving skills and knowledge retention. In surgery, immersive tools enhance procedural precision with detailed anatomical visualizations. VR-based rehabilitation has shown effectiveness in restoring motor functions and balance, particularly for neurological patients. In mental health, VR has been successful in treating conditions like PTSD and phobias. Although VR and AR solutions are well established, there are still some important limitations, including high costs and limited tactile feedback, which may be overcome with implementing new technologies that may improve the effectiveness of immersive medical applications such as XR, psychophysiological feedback or integration of artificial intelligence (AI) for real-time data analysis and personalized healthcare and training.

**AI Summary:** The research abstract discusses the potential and future applications of immersive technologies in medicine, such as Virtual and Augmented Reality (VR, AR) and eXtended Reality (XR), with the integration of AI solutions. The review highlights the benefits of these technologies in medical education, surgery, rehabilitation, and mental health treatment, showcasing their ability to improve skills, precision, and effectiveness in patient care. Despite the existing limitations, such as high costs and limited tactile feedback, the integration of AI and new technologies may enhance the effectiveness of immersive medical applications in the future.

---

## Archiverse: an Approach for Immersive Cultural Heritage
**URL:** https://arxiv.org/abs/2507.19376

**Abstract:** Digital technologies and tools have transformed the way we can study cultural heritage and the way we can recreate it digitally. Techniques such as laser scanning, photogrammetry, and a variety of Mixed Reality solutions have enabled researchers to examine cultural objects and artifacts more precisely and from new perspectives. In this part of the panel, we explore how Virtual Reality (VR) and eXtended Reality (XR) can serve as tools to recreate and visualize the remains of historical cultural heritage and experience it in simulations of its original complexity, which means immersive and interactive. Visualization of material culture exemplified by archaeological sites and architecture can be particularly useful when only ruins or archaeological remains survive. However, these advancements also bring significant challenges, especially in the area of transdisciplinary cooperation between specialists from many, often distant, fields, and the dissemination of virtual immersive environments among both professionals and the general public.

**AI Summary:** The research explores the use of Virtual Reality and eXtended Reality technologies to recreate and visualize historical cultural heritage in immersive and interactive simulations. These tools allow for a more precise examination of artifacts and archaeological sites, especially when only ruins or remains are present. However, the research also highlights the challenges of transdisciplinary cooperation and dissemination of these immersive environments to professionals and the general public.

---

## Where are the Frontlines? A Visualization Approach for Map Control in Team-Based Games
**URL:** https://arxiv.org/abs/2507.19193

**Abstract:** A central area of interest in many competitive online games is spatial behavior which due to its complexity can be difficult to visualize. Such behaviors of interest include not only overall movement patterns but also being able to understand which player or team is exerting control over an area to inform decision-making. Map control can, however, be challenging to quantify. In this paper, we propose a method for calculating frontlines and first efforts towards a visualization of them. The visualization can show map control and frontlines at a specific time point or changes of these over time. For this purpose, it utilizes support vector machines to derive frontlines from unit positions. We illustrate our algorithm and visualization with examples based on the team-based online game World of Tanks.

**AI Summary:** This research paper introduces a method for calculating frontlines in team-based online games to visualize map control and player movement patterns. The proposed visualization approach utilizes support vector machines to determine frontlines based on unit positions, allowing for a better understanding of which player or team is exerting control over specific areas. This research is significant as it provides a tool for players and developers to analyze and improve their strategies in competitive online games by visualizing map control and frontlines.

---

## A Therapeutic Role-Playing VR Game for Children with Intellectual Disabilities
**URL:** https://arxiv.org/abs/2507.19114

**Abstract:** Virtual Reality (VR) offers promising avenues for innovative therapeutic interventions in populations with intellectual disabilities (ID). This paper presents the design, development, and evaluation of Space Exodus, a novel VR-based role-playing game specifically tailored for children with ID. By integrating immersive gameplay with therapeutic task design, Space Exodus aims to enhance concentration, cognitive processing, and fine motor skills through structured hand-eye coordination exercises. A six-week pre-test/post-test study was conducted with 16 children in Ecuador, using standardized assessments, the Toulouse-Pieron Cancellation Test, and the Moss Attention Rating Scale complemented by detailed observational metrics. Quantitative results indicate statistically significant improvements in concentration scores, with test scores increasing from 65.2 to 80.3 and 55.4 to 68.7, respectively (p < 0.01). Qualitative observations revealed reduced task attempts, enhanced user confidence, and increased active participation. The inclusion of a VR assistant provided consistent guidance that further boosted engagement. These findings demonstrate the potential of immersive, game-based learning environments as practical therapeutic tools, laying a robust foundation for developing inclusive and adaptive rehabilitation strategies for children with ID.

**AI Summary:** This research paper discusses the development and evaluation of a VR-based role-playing game called Space Exodus for children with intellectual disabilities. The game aims to improve concentration, cognitive processing, and fine motor skills through structured hand-eye coordination exercises. A study conducted with 16 children in Ecuador showed statistically significant improvements in concentration scores, highlighting the potential of immersive game-based learning environments as effective therapeutic tools for children with ID.

---

## A systematic literature review to unveil users objective reaction to virtual experiences: Complemented with a conceptual model (QoUX in VE)
**URL:** https://arxiv.org/abs/2507.19104

**Abstract:** In pursuit of documenting users Neurophysiological responses during experiencing virtual environments (VE), this systematic review presents a novel conceptual model of UX in VE. Searching across seven databases yielded to 1743 articles. Rigorous screenings, included only 66 articles. Notably, UX in VE lacks a consensus definition. Obviously, this UX has many unique sub-dimensions that are not mentioned in other products. The presented conceptual model contains 26 subdimensions which mostly not supported in previous subjective tools and questionnaires. While EEG and ECG were common, brain ultrasound, employed in one study, highlights the need for using neurophysiological assessments to comprehensively grasp immersive UX intricacies.

**AI Summary:** This systematic literature review explores users' neurophysiological responses during virtual experiences and introduces a novel conceptual model of user experience in virtual environments (VE). The review found that there is a lack of consensus on the definition of UX in VE and identified 26 unique subdimensions not mentioned in other products. The use of neurophysiological assessments, such as EEG and ECG, was common, but the inclusion of brain ultrasound in one study highlights the need for a comprehensive understanding of immersive UX intricacies.

---

## Environmental (in)considerations in the Design of Smartphone Settings
**URL:** https://arxiv.org/abs/2507.19094

**Abstract:** Designing for sufficiency is one of many approaches that could foster more moderate and sustainable digital practices. Based on the Sustainable Information and Communication Technologies (ICT) and Human-Computer Interaction (HCI) literature, we identify five environmental settings categories. However, our analysis of three mobile OS and nine representative applications shows an overall lack of environmental concerns in settings design, leading us to identify six pervasive anti-patterns. Environmental settings, where they exist, are set on the most intensive option by default. They are not presented as such, are not easily accessible, and offer little explanation of their impact. Instead, they encourage more intensive use. Based on these findings, we create a design workbook that explores design principles for environmental settings: presenting the environmental potential of settings; shifting to environmentally neutral states; previewing effects to encourage moderate use; rethinking defaults; facilitating settings access and; exploring more frugal settings. Building upon this workbook, we discuss how settings can tie individual behaviors to systemic factors.

**AI Summary:** This research explores the lack of environmental considerations in smartphone settings design, identifying six pervasive anti-patterns. The study found that environmental settings are often set on the most intensive option by default, leading to more intensive use. The researchers propose design principles for environmental settings to encourage more moderate and sustainable digital practices.

---

## Exploring post-neoliberal futures for managing commercial heating and cooling through speculative praxis
**URL:** https://arxiv.org/abs/2507.19072

**Abstract:** What could designing for carbon reduction of heating and cooling in commercial settings look like in the near future? How can we challenge dominant mindsets and paradigms of efficiency and behaviour change? How can we help build worlds through our practice that can become future realities? This paper introduces the fictional consultancy this http URL to explore opportunities for making space in research projects that can encourage more systems-oriented interventions. We present a design fiction that asks `what if energy management and reduction practice embraced systems thinking?'. Our design fiction explores how future energy consultancies could utilise systems thinking, and (more than) human centred design to re-imagine energy management practice and change systems in ways that are currently unfathomable. We finish by discussing how LIMITS research can utilise design fiction and speculative praxis to help build new material realities where more holistic perspectives, the leveraging of systems change, and the imagining of post-neoliberal futures is the norm.

**AI Summary:** This research paper explores the potential future of managing commercial heating and cooling by challenging current efficiency and behavior change paradigms. The authors introduce a fictional consultancy to encourage more systems-oriented interventions and propose a design fiction that envisions energy management practices embracing systems thinking. The study highlights the importance of utilizing design fiction and speculative praxis to build new material realities that prioritize holistic perspectives, systems change, and post-neoliberal futures.

---

## RhythmTA: A Visual-Aided Interactive System for ESL Rhythm Training via Dubbing Practice
**URL:** https://arxiv.org/abs/2507.19026

**Abstract:** English speech rhythm, the temporal patterns of stressed syllables, is essential for English as a second language (ESL) learners to produce natural-sounding and comprehensible speech. Rhythm training is generally based on imitation of native speech. However, it relies heavily on external instructor feedback, preventing ESL learners from independent practice. To address this gap, we present RhythmTA, an interactive system for ESL learners to practice speech rhythm independently via dubbing, an imitation-based approach. The system automatically extracts rhythm from any English speech and introduces novel visual designs to support three stages of dubbing practice: (1) Synchronized listening with visual aids to enhance perception, (2) Guided repeating by visual cues for self-adjustment, and (3) Comparative reflection from a parallel view for self-monitoring. Our design is informed by a formative study with nine spoken English instructors, which identified current practices and challenges. A user study with twelve ESL learners demonstrates that RhythmTA effectively enhances learners' rhythm perception and shows significant potential for improving rhythm production.

**AI Summary:** The research introduces RhythmTA, an interactive system designed to help ESL learners improve their English speech rhythm through dubbing practice. The system uses visual aids to support three stages of dubbing practice, allowing learners to independently practice and improve their rhythm perception and production. The study shows that RhythmTA has the potential to be a valuable tool for ESL learners looking to enhance their spoken English skills.

---

## Rethinking Dataset Discovery with DataScout
**URL:** https://arxiv.org/abs/2507.18971

**Abstract:** Dataset Search -- the process of finding appropriate datasets for a given task -- remains a critical yet under-explored challenge in data science workflows. Assessing dataset suitability for a task (e.g., training a classification model) is a multi-pronged affair that involves understanding: data characteristics (e.g. granularity, attributes, size), semantics (e.g., data semantics, creation goals), and relevance to the task at hand. Present-day dataset search interfaces are restrictive -- users struggle to convey implicit preferences and lack visibility into the search space and result inclusion criteria -- making query iteration challenging. To bridge these gaps, we introduce DataScout to proactively steer users through the process of dataset discovery via -- (i) AI-assisted query reformulations informed by the underlying search space, (ii) semantic search and filtering based on dataset content, including attributes (columns) and granularity (rows), and (iii) dataset relevance indicators, generated dynamically based on the user-specified task. A within-subjects study with 12 participants comparing DataScout to keyword and semantic dataset search reveals that users uniquely employ DataScout's features not only for structured explorations, but also to glean feedback on their search queries and build conceptual models of the search space.

**AI Summary:** The research introduces DataScout, a tool designed to assist users in discovering datasets for specific tasks by providing AI-assisted query reformulations, semantic search and filtering, and dynamic dataset relevance indicators. A study comparing DataScout to traditional keyword and semantic dataset search methods found that users utilized DataScout's features to not only explore datasets, but also to receive feedback on their search queries and develop conceptual models of the search space. This research highlights the importance of improving dataset discovery processes in data science workflows through more user-friendly and efficient interfaces.

---

## TreeReader: A Hierarchical Academic Paper Reader Powered by Language Models
**URL:** https://arxiv.org/abs/2507.18945

**Abstract:** Efficiently navigating and understanding academic papers is crucial for scientific progress. Traditional linear formats like PDF and HTML can cause cognitive overload and obscure a paper's hierarchical structure, making it difficult to locate key information. While LLM-based chatbots offer summarization, they often lack nuanced understanding of specific sections, may produce unreliable information, and typically discard the document's navigational structure. Drawing insights from a formative study on academic reading practices, we introduce TreeReader, a novel language model-augmented paper reader. TreeReader decomposes papers into an interactive tree structure where each section is initially represented by an LLM-generated concise summary, with underlying details accessible on demand. This design allows users to quickly grasp core ideas, selectively explore sections of interest, and verify summaries against the source text. A user study was conducted to evaluate TreeReader's impact on reading efficiency and comprehension. TreeReader provides a more focused and efficient way to navigate and understand complex academic literature by bridging hierarchical summarization with interactive exploration.

**AI Summary:** The abstract discusses the challenges of navigating and understanding academic papers and introduces TreeReader, a new language model-augmented paper reader that breaks down papers into an interactive tree structure with concise summaries for each section. This design allows users to quickly grasp core ideas, selectively explore sections of interest, and verify summaries against the source text, ultimately improving reading efficiency and comprehension of complex academic literature. The research highlights the significance of bridging hierarchical summarization with interactive exploration to enhance the overall academic paper reading experience.

---

## Limits at a Distance: Design Directions to Address Psychological Distance in Policy Decisions Affecting Planetary Boundaries
**URL:** https://arxiv.org/abs/2507.18913

**Abstract:** Policy decisions relevant to the environment rely on tools like dashboards, risk models, and prediction models to provide information and data visualizations that enable decision-makers to make trade-offs. The conventional paradigm of data visualization practices for policy and decision-making is to convey data in a supposedly neutral, objective manner for rational decision-makers. Feminist critique advocates for nuanced and reflexive approaches that take into account situated decision-makers and their affective relationships to data. This paper sheds light on a key cognitive aspect that impacts how decision-makers interpret data. Because all outcomes from policies relevant to climate change occur at a distance, decision-makers experience so-called `psychological distance' to environmental decisions in terms of space, time, social identity, and hypotheticality. This profoundly impacts how they perceive and evaluate outcomes. Since policy decisions to achieve a safe planetary space are urgently needed for immediate transition and change, we need a design practice that takes into account how psychological distance affects cognition and decision-making. Our paper explores the role of alternative design approaches in developing visualizations used for climate policymaking. We conduct a literature review and synthesis which bridges psychological distance with speculative design and data visceralization by illustrating the value of affective design methods via examples from previous research. Through this work, we propose a novel premise for the communication and visualization of environmental data. Our paper lays out how future research on the impacts of alternative design approaches on psychological distance can make data used for policy decisions more tangible and visceral.

**AI Summary:** This research paper explores how policy decisions related to climate change are influenced by psychological distance, which refers to the perceived distance in space, time, social identity, and hypotheticality. The conventional data visualization practices for policy-making may not adequately account for decision-makers' affective relationships to data. The paper suggests that alternative design approaches, such as affective design methods, can make environmental data more tangible and visceral, ultimately leading to more informed and impactful policy decisions for achieving a safe planetary space.

---

## Rethinking Accessible Prototyping Methods for Blind and Visually Impaired Passengers in Highly Automated Vehicles
**URL:** https://arxiv.org/abs/2507.18880

**Abstract:** Highly Automated Vehicles (HAVs) can improve mobility for blind and visually impaired people (BVIPs). However, designing non-visual interfaces that enable them to maintain situation awareness inside the vehicle is a challenge. This paper presents two of our participatory design workshops that explored what information BVIPs need in HAVs and what an interface that meets these needs might look like. Based on the participants' insights, we created final systems to improve their situation awareness. The two workshops used different approaches: in the first, participants built their own low-fidelity prototypes; in the second, they evaluated and discussed the initial prototypes we provided. We will outline how each workshop was set up and share lessons learned about prototyping methods for BVIPs and how they could be improved.

**AI Summary:** This research explores accessible prototyping methods for blind and visually impaired passengers in highly automated vehicles (HAVs) to improve their situation awareness inside the vehicle. The study involved participatory design workshops where participants identified the information they needed in HAVs and collaborated to create final systems to meet these needs. The findings suggest that involving BVIPs in the design process and utilizing different prototyping approaches can lead to more effective solutions for enhancing their mobility and safety in HAVs.

---

## Improving the State of the Art for Training Human-AI Teams: Technical Report #5 -- Individual Differences and Team Qualities to Measure in a Human-AI Teaming Testbed
**URL:** https://arxiv.org/abs/2507.18878

**Abstract:** Sonalysts, Inc. (Sonalysts) is working on an initiative to expand our expertise in teaming to include Human-Artificial Intelligence (AI) teams. The first step of this process is to develop a Synthetic Task Environment (STE) to support our original research. Prior knowledge elicitation efforts within the Human-AI teaming research stakeholder community revealed a desire to support data collection using pre- and post-performance surveys. In this technical report, we review a number of constructs that capture meaningful individual differences and teaming qualities. Additionally, we explore methods of measuring those constructs within the STE.

**AI Summary:** Sonalysts, Inc. is developing a Synthetic Task Environment (STE) to support research on Human-Artificial Intelligence (AI) teams. The research focuses on identifying and measuring individual differences and team qualities in order to improve the training of Human-AI teams. The study aims to enhance the understanding of how these factors impact team performance within the STE.

---

## A Survey on Methodological Approaches to Collaborative Embodiment in Virtual Reality
**URL:** https://arxiv.org/abs/2507.18877

**Abstract:** The application and implementation of collaborative embodiment in virtual reality (VR) are a critical aspect of the computer science landscape, aiming to enhance multi-user interaction and teamwork in immersive environments. A notable and enduring area of collaborative embodiment research focuses on approaches that enable multiple users to share control, interact, and investigate scenarios involving supernumerary arms in virtual spaces. In this survey, we will present an extensive overview of the methodologies employed in the past decade to enable collaboration in VR environments, particularly through embodiment. Using the PRISMA guidelines, we plan to analyze the study details from over 137 relevant research papers. Through this analysis, a critical assessment of the effectiveness of these methodologies will be conducted, highlighting current challenges and limitations in implementing collaborative embodiment in VR. Lastly, we discuss potential future research directions and opportunities for enhancing collaboration embodiment in virtual environments.

**AI Summary:** This survey explores the methodologies used in collaborative embodiment research in virtual reality to enhance multi-user interaction and teamwork. The focus is on enabling multiple users to share control and interact in virtual spaces, particularly with scenarios involving supernumerary arms. The analysis of over 137 research papers reveals current challenges and limitations in implementing collaborative embodiment in VR, as well as potential future research directions to enhance collaboration in virtual environments.

---

## Uncertainty on Display: The Effects of Communicating Confidence Cues in Autonomous Vehicle-Pedestrian Interactions
**URL:** https://arxiv.org/abs/2507.18836

**Abstract:** Uncertainty is an inherent aspect of autonomous vehicle (AV) decision-making, yet it is rarely communicated to pedestrians, which hinders transparency. This study investigates how AV uncertainty can be conveyed through two approaches: explicit communication (confidence percentage displays) and implicit communication (vehicle motion cues), across different confidence levels (high and low). Through a within-subject VR experiment (N=26), we evaluated these approaches in a crossing scenario, assessing interface qualities (visibility and intuitiveness), how well the information conveyed the vehicle's level of confidence, and their impact on participants' perceived safety, trust, and user experience. Our results show that explicit communication is more effective and preferred for conveying uncertainty, enhancing safety, trust, and user experience. Conversely, implicit communication introduces ambiguity, especially when AV confidence is low. This research provides empirical insights into how uncertainty communication shapes pedestrian interpretation of AV behaviour and offer design guidance for external interfaces that integrate uncertainty as a communicative element.

**AI Summary:** This study explores how uncertainty in autonomous vehicle decision-making can be effectively communicated to pedestrians through explicit (confidence percentage displays) and implicit (vehicle motion cues) methods. The research found that explicit communication of uncertainty is more effective and preferred by participants, enhancing safety, trust, and user experience. In contrast, implicit communication can introduce ambiguity, particularly when confidence levels are low, highlighting the importance of transparent communication in autonomous vehicle-pedestrian interactions.

---

## Ethical Considerations for Observational Research in Social VR
**URL:** https://arxiv.org/abs/2507.18828

**Abstract:** Social VR introduces new ethical challenges for observational research. The current paper presents a narrative literature review of ethical considerations in observational methods, with a focus on work in HCI. We examine how unobtrusive or selectively disclosed observation is implemented in public face-to-face and social VR settings. Our review extends ethical discussions from traditional public research into the context of social VR, highlighting tensions between observer visibility, data traceability, and participant autonomy. Drawing on insights distilled from prior literature, we propose five constructive guidelines for ethical observational research in public social VR environments. Our work offers key implications for future research, addressing anticipated improvements in platform design, the management of researcher presence, and the development of community-informed consent mechanisms.

**AI Summary:** The paper discusses the ethical considerations of observational research in social VR, highlighting the challenges and tensions between observer visibility, data traceability, and participant autonomy. The review proposes five guidelines for ethical observational research in public social VR environments, offering implications for platform design, researcher presence management, and community-informed consent mechanisms. This research is significant as it addresses the need for ethical guidelines in a rapidly evolving field of study, ensuring the protection of participants in social VR research.

---

## DxHF: Providing High-Quality Human Feedback for LLM Alignment via Interactive Decomposition
**URL:** https://arxiv.org/abs/2507.18802

**Abstract:** Human preferences are widely used to align large language models (LLMs) through methods such as reinforcement learning from human feedback (RLHF). However, the current user interfaces require annotators to compare text paragraphs, which is cognitively challenging when the texts are long or unfamiliar. This paper contributes by studying the decomposition principle as an approach to improving the quality of human feedback for LLM alignment. This approach breaks down the text into individual claims instead of directly comparing two long-form text responses. Based on the principle, we build a novel user interface DxHF. It enhances the comparison process by showing decomposed claims, visually encoding the relevance of claims to the conversation and linking similar claims. This allows users to skim through key information and identify differences for better and quicker judgment. Our technical evaluation shows evidence that decomposition generally improves feedback accuracy regarding the ground truth, particularly for users with uncertainty. A crowdsourcing study with 160 participants indicates that using DxHF improves feedback accuracy by an average of 5%, although it increases the average feedback time by 18 seconds. Notably, accuracy is significantly higher in situations where users have less certainty. The finding of the study highlights the potential of HCI as an effective method for improving human-AI alignment.

**AI Summary:** This research explores the use of decomposition as a method to improve the quality of human feedback for aligning large language models (LLMs). By breaking down text into individual claims and presenting them in a visually enhanced user interface called DxHF, users can more easily compare information and make judgments. The study shows that using DxHF results in a 5% improvement in feedback accuracy, particularly for users with less certainty, highlighting the potential of human-computer interaction (HCI) in enhancing human-AI alignment.

---

## Comparing Human and AI Performance in Visual Storytelling through Creation of Comic Strips: A Case Study
**URL:** https://arxiv.org/abs/2507.18641

**Abstract:** This article presents a case study comparing the capabilities of humans and artificial intelligence (AI) for visual storytelling. We developed detailed instructions to recreate a three-panel Nancy cartoon strip by Ernie Bushmiller and provided them to both humans and AI systems. The human participants were 20-something students with basic artistic training but no experience or knowledge of this comic strip. The AI systems used were popular commercial models trained to draw and paint like artists, though their training sets may not necessarily include Bushmiller's work. Results showed that AI systems excel at mimicking professional art but struggle to create coherent visual stories. In contrast, humans proved highly adept at transforming instructions into meaningful visual narratives.

**AI Summary:** This study compared the abilities of humans and AI systems in visual storytelling by having them recreate a three-panel comic strip. While AI systems were able to mimic professional art styles, they struggled to create coherent narratives. In contrast, human participants, despite having no prior knowledge of the comic strip, were able to effectively transform instructions into meaningful visual stories.

---

## How good are humans at detecting AI-generated images? Learnings from an experiment
**URL:** https://arxiv.org/abs/2507.18640

**Abstract:** As AI-powered image generation improves, a key question is how well human beings can differentiate between "real" and AI-generated or modified images. Using data collected from the online game "Real or Not Quiz.", this study investigates how effectively people can distinguish AI-generated images from real ones. Participants viewed a randomized set of real and AI-generated images, aiming to identify their authenticity. Analysis of approximately 287,000 image evaluations by over 12,500 global participants revealed an overall success rate of only 62\%, indicating a modest ability, slightly above chance. Participants were most accurate with human portraits but struggled significantly with natural and urban landscapes. These results highlight the inherent challenge humans face in distinguishing AI-generated visual content, particularly images without obvious artifacts or stylistic cues. This study stresses the need for transparency tools, such as watermarks and robust AI detection tools to mitigate the risks of misinformation arising from AI-generated content

**AI Summary:** This study investigated how well humans can differentiate between real and AI-generated images using data from an online game. The results showed that participants had a modest success rate of 62%, with higher accuracy in identifying human portraits compared to natural and urban landscapes. The study emphasizes the need for transparency tools and robust AI detection tools to address the challenges posed by AI-generated visual content and mitigate the risks of misinformation.

---

## People Are Highly Cooperative with Large Language Models, Especially When Communication Is Possible or Following Human Interaction
**URL:** https://arxiv.org/abs/2507.18639

**Abstract:** Machines driven by large language models (LLMs) have the potential to augment humans across various tasks, a development with profound implications for business settings where effective communication, collaboration, and stakeholder trust are paramount. To explore how interacting with an LLM instead of a human might shift cooperative behavior in such settings, we used the Prisoner's Dilemma game -- a surrogate of several real-world managerial and economic scenarios. In Experiment 1 (N=100), participants engaged in a thirty-round repeated game against a human, a classic bot, and an LLM (GPT, in real-time). In Experiment 2 (N=192), participants played a one-shot game against a human or an LLM, with half of them allowed to communicate with their opponent, enabling LLMs to leverage a key advantage over older-generation machines. Cooperation rates with LLMs -- while lower by approximately 10-15 percentage points compared to interactions with human opponents -- were nonetheless high. This finding was particularly notable in Experiment 2, where the psychological cost of selfish behavior was reduced. Although allowing communication about cooperation did not close the human-machine behavioral gap, it increased the likelihood of cooperation with both humans and LLMs equally (by 88%), which is particularly surprising for LLMs given their non-human nature and the assumption that people might be less receptive to cooperating with machines compared to human counterparts. Additionally, cooperation with LLMs was higher following prior interaction with humans, suggesting a spillover effect in cooperative behavior. Our findings validate the (careful) use of LLMs by businesses in settings that have a cooperative component.

**AI Summary:** Research shows that people are highly cooperative with large language models (LLMs) in various tasks, especially when communication is possible or following human interaction. Despite a slight decrease in cooperation rates compared to interactions with humans, participants still displayed high levels of cooperation with LLMs. The findings suggest that LLMs can be effectively used in business settings that require cooperation, communication, and trust among stakeholders.

---

## Prompt Engineering and the Effectiveness of Large Language Models in Enhancing Human Productivity
**URL:** https://arxiv.org/abs/2507.18638

**Abstract:** The widespread adoption of large language models (LLMs) such as ChatGPT, Gemini, and DeepSeek has significantly changed how people approach tasks in education, professional work, and creative domains. This paper investigates how the structure and clarity of user prompts impact the effectiveness and productivity of LLM outputs. Using data from 243 survey respondents across various academic and occupational backgrounds, we analyze AI usage habits, prompting strategies, and user satisfaction. The results show that users who employ clear, structured, and context-aware prompts report higher task efficiency and better outcomes. These findings emphasize the essential role of prompt engineering in maximizing the value of generative AI and provide practical implications for its everyday use.

**AI Summary:** This research paper explores how the effectiveness and productivity of large language models (LLMs) such as ChatGPT and Gemini are influenced by the clarity and structure of user prompts. Through analyzing data from 243 survey respondents, the study found that users who use clear, structured, and context-aware prompts experience higher task efficiency and better outcomes when utilizing LLMs. These findings highlight the importance of prompt engineering in maximizing the value of generative AI and offer practical implications for its everyday use in education, professional work, and creative fields.

---

## More Expert-like Eye Gaze Movement Patterns are Related to Better X-ray Reading
**URL:** https://arxiv.org/abs/2507.18637

**Abstract:** Understanding how novices acquire and hone visual search skills is crucial for developing and optimizing training methods across domains. Network analysis methods can be used to analyze graph representations of visual expertise. This study investigates the relationship between eye-gaze movements and learning outcomes among undergraduate dentistry students who were diagnosing dental radiographs over multiple semesters. We use network analysis techniques to model eye-gaze scanpaths as directed graphs and examine changes in network metrics over time. Using time series clustering on each metric, we identify distinct patterns of visual search strategies and explore their association with students' diagnostic performance. Our findings suggest that the network metric of transition entropy is negatively correlated with performance scores, while the number of nodes and edges as well as average PageRank are positively correlated with performance scores. Changes in network metrics for individual students over time suggest a developmental shift from intermediate to expert-level processing. These insights contribute to understanding expertise acquisition in visual tasks and can inform the design of AI-assisted learning interventions.

**AI Summary:** This study explores the relationship between eye-gaze movements and diagnostic performance in undergraduate dentistry students reading dental radiographs. Using network analysis techniques, the researchers found that more expert-like eye gaze patterns, characterized by higher numbers of nodes and edges as well as average PageRank, were associated with better performance. The study highlights the importance of understanding visual expertise acquisition and suggests that AI-assisted learning interventions could benefit from these insights.

---

## Conversations Gone Awry, But Then? Evaluating Conversational Forecasting Models
**URL:** https://arxiv.org/abs/2507.19470

**Abstract:** We often rely on our intuition to anticipate the direction of a conversation. Endowing automated systems with similar foresight can enable them to assist human-human interactions. Recent work on developing models with this predictive capacity has focused on the Conversations Gone Awry (CGA) task: forecasting whether an ongoing conversation will derail. In this work, we revisit this task and introduce the first uniform evaluation framework, creating a benchmark that enables direct and reliable comparisons between different architectures. This allows us to present an up-to-date overview of the current progress in CGA models, in light of recent advancements in language modeling. Our framework also introduces a novel metric that captures a model's ability to revise its forecast as the conversation progresses.

**AI Summary:** This research focuses on developing models that can predict whether a conversation will go off track, known as the Conversations Gone Awry (CGA) task. By creating a uniform evaluation framework, the study allows for direct comparisons between different models and provides an updated overview of the progress in CGA models. The introduction of a novel metric that measures a model's ability to adjust its forecast as the conversation evolves is a significant contribution to the field of conversational forecasting.

---

## Human-AI Synergy in Adaptive Active Learning for Continuous Lithium Carbonate Crystallization Optimization
**URL:** https://arxiv.org/abs/2507.19316

**Abstract:** As demand for high-purity lithium surges with the growth of the electric vehicle (EV) industry, cost-effective extraction from lower-grade North American sources like the Smackover Formation is critical. These resources, unlike high-purity South American brines, require innovative purification techniques to be economically viable. Continuous crystallization is a promising method for producing battery-grade lithium carbonate, but its optimization is challenged by a complex parameter space and limited data. This study introduces a Human-in-the-Loop (HITL) assisted active learning framework to optimize the continuous crystallization of lithium carbonate. By integrating human expertise with data-driven insights, our approach accelerates the optimization of lithium extraction from challenging sources. Our results demonstrate the framework's ability to rapidly adapt to new data, significantly improving the process's tolerance to critical impurities like magnesium from the industry standard of a few hundred ppm to as high as 6000 ppm. This breakthrough makes the exploitation of low-grade, impurity-rich lithium resources feasible, potentially reducing the need for extensive pre-refinement processes. By leveraging artificial intelligence, we have refined operational parameters and demonstrated that lower-grade materials can be used without sacrificing product quality. This advancement is a significant step towards economically harnessing North America's vast lithium reserves, such as those in the Smackover Formation, and enhancing the sustainability of the global lithium supply chain.

**AI Summary:** This study focuses on optimizing the continuous crystallization of lithium carbonate from lower-grade North American sources using a Human-in-the-Loop assisted active learning framework. By integrating human expertise with data-driven insights, the framework accelerates the optimization process and improves tolerance to critical impurities like magnesium. The results show that this approach allows for the exploitation of low-grade, impurity-rich lithium resources, potentially reducing the need for extensive pre-refinement processes and enhancing the sustainability of the global lithium supply chain.

---

## Towards Multimodal Social Conversations with Robots: Using Vision-Language Models
**URL:** https://arxiv.org/abs/2507.19196

**Abstract:** Large language models have given social robots the ability to autonomously engage in open-domain conversations. However, they are still missing a fundamental social skill: making use of the multiple modalities that carry social interactions. While previous work has focused on task-oriented interactions that require referencing the environment or specific phenomena in social interactions such as dialogue breakdowns, we outline the overall needs of a multimodal system for social conversations with robots. We then argue that vision-language models are able to process this wide range of visual information in a sufficiently general manner for autonomous social robots. We describe how to adapt them to this setting, which technical challenges remain, and briefly discuss evaluation practices.

**AI Summary:** The abstract discusses the importance of incorporating multiple modalities, such as vision and language, in social interactions with robots. While previous research has focused on task-oriented interactions, this study highlights the need for a more comprehensive approach to enable autonomous social conversations. The authors propose using vision-language models to process visual information in a general manner, outlining technical challenges and potential evaluation practices in adapting these models for social interactions with robots.

---

## An Empirical Investigation of Gender Stereotype Representation in Large Language Models: The Italian Case
**URL:** https://arxiv.org/abs/2507.19156

**Abstract:** The increasing use of Large Language Models (LLMs) in a large variety of domains has sparked worries about how easily they can perpetuate stereotypes and contribute to the generation of biased content. With a focus on gender and professional bias, this work examines in which manner LLMs shape responses to ungendered prompts, contributing to biased outputs. This analysis uses a structured experimental method, giving different prompts involving three different professional job combinations, which are also characterized by a hierarchical relationship. This study uses Italian, a language with extensive grammatical gender differences, to highlight potential limitations in current LLMs' ability to generate objective text in non-English languages. Two popular LLM-based chatbots are examined, namely OpenAI ChatGPT (gpt-4o-mini) and Google Gemini (gemini-1.5-flash). Through APIs, we collected a range of 3600 responses. The results highlight how content generated by LLMs can perpetuate stereotypes. For example, Gemini associated 100% (ChatGPT 97%) of 'she' pronouns to the 'assistant' rather than the 'manager'. The presence of bias in AI-generated text can have significant implications in many fields, such as in the workplaces or in job selections, raising ethical concerns about its use. Understanding these risks is pivotal to developing mitigation strategies and assuring that AI-based systems do not increase social inequalities, but rather contribute to more equitable outcomes. Future research directions include expanding the study to additional chatbots or languages, refining prompt engineering methods or further exploiting a larger experimental base.

**AI Summary:** This research investigates how Large Language Models (LLMs) can perpetuate gender stereotypes and biases in their generated content, focusing on professional job combinations in the Italian language. The study found that LLMs like OpenAI ChatGPT and Google Gemini tend to associate 'she' pronouns with lower-level job roles, highlighting the potential limitations of current LLMs in generating unbiased text in non-English languages. The presence of bias in AI-generated text has significant implications for various fields, emphasizing the importance of understanding and addressing these issues to ensure more equitable outcomes in AI-based systems.

---

## OS-MAP: How Far Can Computer-Using Agents Go in Breadth and Depth?
**URL:** https://arxiv.org/abs/2507.19132

**Abstract:** Computer-using agents have shown strong potential to boost human productivity and enable new application forms across platforms. While recent advances have led to usable applications, existing benchmarks fail to account for the internal task heterogeneity and the corresponding agent capabilities, as well as their alignment with actual user demands-hindering both targeted capability development and the reliable transition of research progress into practical deployment. To bridge the gap, we present OS-MAP, a benchmark for daily computer-using automation that organizes its 416 realistic tasks across 15 applications along two key dimensions: a five-level taxonomy of automation and a generalization scope derived from a real-world user demand hierarchy. To enable fine-grained analysis of required capabilities and alignment with real-world scenarios, OS-MAP evaluates agents along two dimensions: automation level across a five-level taxonomy, and generalization scope across a demand hierarchy. This design captures varying levels of required agent autonomy and generalization, forming a performance-generalization evaluation matrix for structured and comprehensive assessment. Experiments show that even State-of-the-Art agents with VLM backbones struggle with higher-level tasks involving perception, reasoning, and coordination-highlighting the need for a deeper understanding of current strengths and limitations to drive the future progress in computer-using agents research and deployment. All code, environments, baselines, and data are publicly available at this https URL.

**AI Summary:** The research introduces OS-MAP, a benchmark for computer-using automation that evaluates agents based on a taxonomy of automation levels and real-world user demands. The study reveals that even State-of-the-Art agents struggle with higher-level tasks, emphasizing the need for a better understanding of current capabilities and limitations to advance research and deployment of computer-using agents. The benchmark is publicly available, providing a structured and comprehensive assessment tool for future developments in this field.

---

## Large language models provide unsafe answers to patient-posed medical questions
**URL:** https://arxiv.org/abs/2507.18905

**Abstract:** Millions of patients are already using large language model (LLM) chatbots for medical advice on a regular basis, raising patient safety concerns. This physician-led red-teaming study compares the safety of four publicly available chatbots--Claude by Anthropic, Gemini by Google, GPT-4o by OpenAI, and Llama3-70B by Meta--on a new dataset, HealthAdvice, using an evaluation framework that enables quantitative and qualitative analysis. In total, 888 chatbot responses are evaluated for 222 patient-posed advice-seeking medical questions on primary care topics spanning internal medicine, women's health, and pediatrics. We find statistically significant differences between chatbots. The rate of problematic responses varies from 21.6 percent (Claude) to 43.2 percent (Llama), with unsafe responses varying from 5 percent (Claude) to 13 percent (GPT-4o, Llama). Qualitative results reveal chatbot responses with the potential to lead to serious patient harm. This study suggests that millions of patients could be receiving unsafe medical advice from publicly available chatbots, and further work is needed to improve the clinical safety of these powerful tools.

**AI Summary:** This study compares the safety of four popular chatbots providing medical advice and finds significant differences in the rate of problematic and unsafe responses. The research highlights the potential for serious patient harm from inaccurate advice given by these chatbots, suggesting a need for further improvement in the clinical safety of large language models used in healthcare settings.

---

## MetaMorph -- A Metamodelling Approach For Robot Morphology
**URL:** https://arxiv.org/abs/2507.18820

**Abstract:** Robot appearance crucially shapes Human-Robot Interaction (HRI) but is typically described via broad categories like anthropomorphic, zoomorphic, or technical. More precise approaches focus almost exclusively on anthropomorphic features, which fail to classify robots across all types, limiting the ability to draw meaningful connections between robot design and its effect on interaction. In response, we present MetaMorph, a comprehensive framework for classifying robot morphology. Using a metamodeling approach, MetaMorph was synthesized from 222 robots in the IEEE Robots Guide, offering a structured method for comparing visual features. This model allows researchers to assess the visual distances between robot models and explore optimal design traits tailored to different tasks and contexts.

**AI Summary:** The research introduces MetaMorph, a new framework for classifying robot morphology that goes beyond traditional categories like anthropomorphic and zoomorphic. By synthesizing data from 222 robots, MetaMorph provides a structured method for comparing visual features and assessing the visual distances between robot models. This framework allows researchers to explore optimal design traits for different tasks and contexts, ultimately improving our understanding of how robot appearance influences human-robot interaction.

---

## Evaluation of a Provenance Management Tool for Immersive Virtual Fieldwork
**URL:** https://arxiv.org/abs/2507.18622

**Abstract:** Ensuring reproducibility of research is an integral part of good scientific practice. One way to support this is through provenance: information about research workflows from data gathering to researchers' sensemaking processes leading to published results. This is highly important in disciplines such as geosciences, where researchers use software for interactive and immersive visualizations of geospatial data, doing virtual measurements in simulated fieldwork on 3D models. We evaluated a provenance management tool, which allows recording of interactions with a virtual fieldwork tool and annotating different states of the visualization. The user study investigated how researchers used this Digital Lab Book (DLB) and whether perceived ease of use and perceived usefulness differed between groups in immersive or non-immersive settings. Participants perceived the DLB as both useful and easy to use. While there were indications of differences in perceived ease of use (higher for immersive setting), usage patterns showed no significant group differences.

**AI Summary:** This research evaluated a provenance management tool for immersive virtual fieldwork, aiming to support reproducibility in research workflows. The study found that participants perceived the Digital Lab Book (DLB) as useful and easy to use, with indications of higher ease of use in immersive settings. While there were no significant group differences in usage patterns, the DLB was seen as a valuable tool for recording interactions and annotating visualizations in geosciences research.

---

## MeloKids: Multisensory VR System to Enhance Speech and Motor Coordination in Children with Hearing Loss
**URL:** https://arxiv.org/abs/2507.18619

**Abstract:** Children with hearing impairments face ongoing challenges in language and motor development. This study explores how multi-sensory feedback technology based on virtual reality (VR), integrating auditory, visual, and tactile stimuli, can enhance rehabilitation outcomes. Using functional near-infrared spectroscopy (fNIRS) technology, we assessed cortical activation patterns in children during pitch-matching tasks across different interaction modes. Our findings aim to provide evidence for designing personalized, interactive rehabilitation systems that enhance cognitive engagement and motor control in children with hearing impairments.

**AI Summary:** This study investigates the use of a multisensory VR system to improve speech and motor coordination in children with hearing loss. By integrating auditory, visual, and tactile stimuli, the technology aims to enhance rehabilitation outcomes for these children. The use of fNIRS technology to assess cortical activation patterns during pitch-matching tasks provides valuable insights for designing personalized interactive rehabilitation systems that can improve cognitive engagement and motor control in children with hearing impairments.

---

## PosterMate: Audience-driven Collaborative Persona Agents for Poster Design
**URL:** https://arxiv.org/abs/2507.18572

**Abstract:** Poster designing can benefit from synchronous feedback from target audiences. However, gathering audiences with diverse perspectives and reconciling them on design edits can be challenging. Recent generative AI models present opportunities to simulate human-like interactions, but it is unclear how they may be used for feedback processes in design. We introduce PosterMate, a poster design assistant that facilitates collaboration by creating audience-driven persona agents constructed from marketing documents. PosterMate gathers feedback from each persona agent regarding poster components, and stimulates discussion with the help of a moderator to reach a conclusion. These agreed-upon edits can then be directly integrated into the poster design. Through our user study (N=12), we identified the potential of PosterMate to capture overlooked viewpoints, while serving as an effective prototyping tool. Additionally, our controlled online evaluation (N=100) revealed that the feedback from an individual persona agent is appropriate given its persona identity, and the discussion effectively synthesizes the different persona agents' perspectives.

**AI Summary:** The research introduces PosterMate, a poster design assistant that uses generative AI models to create audience-driven persona agents for feedback on poster designs. The study found that PosterMate was effective in capturing diverse perspectives and facilitating collaboration among different persona agents, leading to improved poster designs. The controlled online evaluation also showed that feedback from individual persona agents was appropriate and discussions effectively synthesized different perspectives.

---

## ForcePinch: Force-Responsive Spatial Interaction for Tracking Speed Control in XR
**URL:** https://arxiv.org/abs/2507.18510

**Abstract:** Spatial interaction in 3D environments requires balancing efficiency and precision, which requires dynamic tracking speed adjustments. However, existing techniques often couple tracking speed adjustments directly with hand movements, reducing interaction flexibility. Inspired by the natural friction control inherent in the physical world, we introduce ForcePinch, a novel force-responsive spatial interaction method that enables users to intuitively modulate pointer tracking speed and smoothly transition between rapid and precise movements by varying their pinching force. To implement this concept, we developed a hardware prototype integrating a pressure sensor with a customizable mapping function that translates pinching force into tracking speed adjustments. We conducted a user study with 20 participants performing well-established 1D, 2D, and 3D object manipulation tasks, comparing ForcePinch against the distance-responsive technique Go-Go and speed-responsive technique PRISM. Results highlight distinctive characteristics of the force-responsive approach across different interaction contexts. Drawing on these findings, we highlight the contextual meaning and versatility of force-responsive interactions through four illustrative examples, aiming to inform and inspire future spatial interaction design.

**AI Summary:** The research introduces ForcePinch, a force-responsive spatial interaction method that allows users to adjust pointer tracking speed by varying their pinching force, enabling smooth transitions between rapid and precise movements in 3D environments. The study compared ForcePinch with distance-responsive and speed-responsive techniques, showing distinctive characteristics of the force-responsive approach in various interaction contexts. The findings suggest the potential for force-responsive interactions to enhance spatial interaction design in XR applications.

---

## High-Dimensional Data Classification in Concentric Coordinates
**URL:** https://arxiv.org/abs/2507.18450

**Abstract:** The visualization of multi-dimensional data with interpretable methods remains limited by capabilities for both high-dimensional lossless visualizations that do not suffer from occlusion and that are computationally capable by parameterized visualization. This paper proposes a low to high dimensional data supporting framework using lossless Concentric Coordinates that are a more compact generalization of Parallel Coordinates along with former Circular Coordinates. These are forms of the General Line Coordinate visualizations that can directly support machine learning algorithm visualization and facilitate human interaction.

**AI Summary:** This paper introduces a new framework called Concentric Coordinates for visualizing high-dimensional data in a lossless and computationally efficient manner. This framework is a more compact and generalizable version of Parallel Coordinates and Circular Coordinates, allowing for better interpretation of machine learning algorithms and enhancing human interaction with the data. The use of Concentric Coordinates addresses the limitations of current methods for visualizing multi-dimensional data and offers a promising approach for improving data classification tasks.

---

## Towards Understanding Decision Problems As a Goal of Visualization Design
**URL:** https://arxiv.org/abs/2507.18428

**Abstract:** Decision-making is a central yet under-defined goal in visualization research. While existing task models address decision processes, they often neglect the conditions framing a decision. To better support decision-making tasks, we propose a characterization scheme that describes decision problems through key properties of the data, users, and task context. This scheme helps visualization researchers specify decision-support claims more precisely and informs the design of appropriate visual encodings and interactions. We demonstrate the utility of our approach by applying it to characterize decision tasks targeted by existing design studies, highlighting opportunities for future research in decision-centric visualization.

**AI Summary:** This research focuses on understanding decision-making as a goal in visualization design by proposing a scheme that characterizes decision problems based on data, users, and task context. By specifying decision-support claims more precisely, researchers can design visual encodings and interactions that better support decision-making tasks. The study demonstrates the usefulness of this approach by applying it to existing design studies and identifying opportunities for future research in decision-centric visualization.

---

## Multisensory Integration and Sensory Substitution Across Vision, Audition, and Haptics: Answering the What, Which, and When in Study Protocols
**URL:** https://arxiv.org/abs/2507.18401

**Abstract:** We experience the world through multiple senses that work together to create a cohesive perception, whether in daily life or immersive technologies. Understanding this multisensory integration (MSI) requires examining the interactions between sensory modalities, each with unique temporal dynamics and characteristics. While most research focuses on unimodal or bimodal cues, the integration of three or more modalities remains underexplored. MSI studies must account for factors like cross-modal correspondence, congruence, cognitive load, and stimulus timing, which become increasingly complex as modalities multiply. This article examines these key factors and how they can be applied to 8 design effective MSI study protocols.

**AI Summary:** This research explores the integration of multiple sensory modalities in creating a cohesive perception, emphasizing the importance of understanding the interactions between vision, audition, and haptics. The study highlights the need to consider factors such as cross-modal correspondence, congruence, cognitive load, and stimulus timing in designing effective multisensory integration protocols. By addressing these key factors, researchers can gain insights into how different sensory modalities work together and enhance immersive technologies.

---

## PALM: PAnoramic Learning Map Integrating Learning Analytics and Curriculum Map for Scalable Insights Across Courses
**URL:** https://arxiv.org/abs/2507.18393

**Abstract:** This study proposes and evaluates the PAnoramic Learning Map (PALM), a learning analytics (LA) dashboard designed to address the scalability challenges of LA by integrating curriculum-level information. Traditional LA research has predominantly focused on individual courses or learners and often lacks a framework that considers the relationships between courses and the long-term trajectory of learning. To bridge this gap, PALM was developed to integrate multilayered educational data into a curriculum map, enabling learners to intuitively understand their learning records and academic progression. We conducted a system evaluation to assess PALM's effectiveness in two key areas: (1) its impact on students' awareness of their learning behaviors, and (2) its comparative performance against existing systems. The results indicate that PALM enhances learners' awareness of study planning and reflection, particularly by improving perceived behavioral control through the visual presentation of individual learning histories and statistical trends, which clarify the links between learning actions and outcomes. Although PALM requires ongoing refinement as a system, it received significantly higher evaluations than existing systems in terms of visual appeal and usability. By serving as an information resource with previously inaccessible insights, PALM enhances self-regulated learning and engagement, representing a significant step beyond conventional LA toward a comprehensive and scalable approach.

**AI Summary:** The study introduces the PALM learning analytics dashboard, which integrates curriculum-level information to provide scalable insights across courses. PALM enhances students' awareness of their learning behaviors and study planning, outperforming existing systems in visual appeal and usability. By offering previously inaccessible insights, PALM represents a significant advancement in promoting self-regulated learning and engagement.

---

## Talking to...uh...um...Machines: The Impact of Disfluent Speech Agents on Partner Models and Perspective Taking
**URL:** https://arxiv.org/abs/2507.18315

**Abstract:** Speech disfluencies play a role in perspective-taking and audience design in human-human communication (HHC), but little is known about their impact in human-machine dialogue (HMD). In an online Namer-Matcher task, sixty-one participants interacted with a speech agent using either fluent or disfluent speech. Participants completed a partner-modelling questionnaire (PMQ) both before and after the task. Post-interaction evaluations indicated that participants perceived the disfluent agent as more competent, despite no significant differences in pre-task ratings. However, no notable differences were observed in assessments of conversational flexibility or human-likeness. Our findings also reveal evidence of egocentric and allocentric language production when participants interact with speech agents. Interaction with disfluent speech agents appears to increase egocentric communication in comparison to fluent agents. Although the wide credibility intervals mean this effect is not clear-cut. We discuss potential interpretations of this finding, focusing on how disfluencies may impact partner models and language production in HMD.

**AI Summary:** This study explores the impact of speech disfluencies in human-machine dialogue, finding that participants perceived disfluent speech agents as more competent despite no significant differences in pre-task ratings. The study also reveals evidence of egocentric language production when interacting with speech agents, with disfluent agents increasing egocentric communication compared to fluent agents. These findings suggest that disfluencies may influence partner models and language production in human-machine dialogue.

---

## Multimodal Behavioral Patterns Analysis with Eye-Tracking and LLM-Based Reasoning
**URL:** https://arxiv.org/abs/2507.18252

**Abstract:** Eye-tracking data reveals valuable insights into users' cognitive states but is difficult to analyze due to its structured, non-linguistic nature. While large language models (LLMs) excel at reasoning over text, they struggle with temporal and numerical data. This paper presents a multimodal human-AI collaborative framework designed to enhance cognitive pattern extraction from eye-tracking signals. The framework includes: (1) a multi-stage pipeline using horizontal and vertical segmentation alongside LLM reasoning to uncover latent gaze patterns; (2) an Expert-Model Co-Scoring Module that integrates expert judgment with LLM output to generate trust scores for behavioral interpretations; and (3) a hybrid anomaly detection module combining LSTM-based temporal modeling with LLM-driven semantic analysis. Our results across several LLMs and prompt strategies show improvements in consistency, interpretability, and performance, with up to 50% accuracy in difficulty prediction tasks. This approach offers a scalable, interpretable solution for cognitive modeling and has broad potential in adaptive learning, human-computer interaction, and educational analytics.

**AI Summary:** This research paper introduces a multimodal framework that combines eye-tracking data analysis with large language models (LLMs) to extract cognitive patterns. The framework includes a multi-stage pipeline, an Expert-Model Co-Scoring Module, and a hybrid anomaly detection module, resulting in improved consistency, interpretability, and performance in difficulty prediction tasks. This approach has potential applications in adaptive learning, human-computer interaction, and educational analytics.

---

## Recommender systems, representativeness, and online music: A psychosocial analysis of Italian listeners
**URL:** https://arxiv.org/abs/2507.18169

**Abstract:** Recommender systems shape music listening worldwide due to their widespread adoption in online platforms. Growing concerns about representational harms that these systems may cause are nowadays part of the scientific and public debate, wherein music listener perspectives are oftentimes reported and discussed from a cognitive-behaviorism perspective, but rarely contextualised under a psychosocial and cultural lens. We proceed in this direction, by interviewing a group of Italian music listeners and analysing their narratives through Emotional Textual Analysis. Thanks to this, we identify shared cultural repertoires that reveal people's complex relationship with listening practices: even when familiar with online platforms, listeners may still lack a critical understanding of recommender systems. Moreover, representational issues, particularly gender disparities, seem not yet fully grasped in the context of online music listening. This study underscores the need for interdisciplinary research to address representational harms, and the role of algorithmic awareness and digital literacy in developing trustworthy recommender systems.

**AI Summary:** This study explores the impact of recommender systems on music listening habits of Italian listeners, highlighting concerns about representational harms and gender disparities. Through Emotional Textual Analysis of interviews, the study reveals a lack of critical understanding of recommender systems among listeners and emphasizes the importance of interdisciplinary research to address these issues. The findings underscore the need for algorithmic awareness and digital literacy in developing trustworthy recommender systems in the context of online music consumption.

---

## ProactiveVA: Proactive Visual Analytics with LLM-Based UI Agent
**URL:** https://arxiv.org/abs/2507.18165

**Abstract:** Visual analytics (VA) is typically applied to complex data, thus requiring complex tools. While visual analytics empowers analysts in data analysis, analysts may get lost in the complexity occasionally. This highlights the need for intelligent assistance mechanisms. However, even the latest LLM-assisted VA systems only provide help when explicitly requested by the user, making them insufficiently intelligent to offer suggestions when analysts need them the most. We propose a ProactiveVA framework in which LLM-powered UI agent monitors user interactions and delivers context-aware assistance proactively. To design effective proactive assistance, we first conducted a formative study analyzing help-seeking behaviors in user interaction logs, identifying when users need proactive help, what assistance they require, and how the agent should intervene. Based on this analysis, we distilled key design requirements in terms of intent recognition, solution generation, interpretability and controllability. Guided by these requirements, we develop a three-stage UI agent pipeline including perception, reasoning, and acting. The agent autonomously perceives users' needs from VA interaction logs, providing tailored suggestions and intuitive guidance through interactive exploration of the system. We implemented the framework in two representative types of VA systems, demonstrating its generalizability, and evaluated the effectiveness through an algorithm evaluation, case and expert study and a user study. We also discuss current design trade-offs of proactive VA and areas for further exploration.

**AI Summary:** The research proposes a ProactiveVA framework with a UI agent powered by LLM to provide context-aware assistance proactively in visual analytics. The framework monitors user interactions to identify when users need help and delivers tailored suggestions and guidance. The study highlights the effectiveness of the framework in improving user experience and discusses design trade-offs and areas for further exploration in proactive visual analytics with intelligent assistance mechanisms.

---

## Understood: Real-Time Communication Support for Adults with ADHD Using Mixed Reality
**URL:** https://arxiv.org/abs/2507.18151

**Abstract:** Adults with Attention Deficit Hyperactivity Disorder (ADHD) often experience communication challenges, primarily due to executive dysfunction and emotional dysregulation, even after years of social integration. While existing interventions predominantly target children through structured or intrusive methods, adults lack tools that translate clinical strategies into daily communication support. To address this gap, we present Understood, a Mixed Reality (MR) system implemented on Microsoft HoloLens 2, designed to assist adults with ADHD in real-world communication. Through formative semi-structured interviews and a design workshop, we identified critical communication barriers and derived design goals for the system. Understood combines three key features: (1) real-time conversation summarization to reduce cognitive load, (2) context-aware subsequent word suggestions during moments of disfluency, and (3) topic shifting detection and reminding to mitigate off-topic transitions. A within-subjects user study and expert interviews demonstrate that Understood effectively supports communication with high usability, offering a complement to therapist-mediated interventions.

**AI Summary:** The research focuses on developing a Mixed Reality system called Understood to assist adults with ADHD in real-world communication. The system includes features such as conversation summarization, word suggestions during moments of disfluency, and topic shifting detection to improve communication. The study found that Understood effectively supports communication with high usability, providing a valuable tool for adults with ADHD to navigate social interactions.

---

## Effects of variation in system responsiveness on user performance in virtual environments
**URL:** https://arxiv.org/abs/2507.18085

**Abstract:** System responsiveness (SR) is defined as the elapsed time until a system responds to user control. SR fluctuates over time, so it must be described statistically with mean (MSR) and standard deviation (SDSR). In this paper, we examine SR in virtual environments (VEs), outlining its components and methods of experimental measurement and manipulation. Three studies of MSR and SDSR effects on performance of grasp and placement tasks are then presented. The studies used within-subjects designs with 11, 12, and 10 participants, respectively. Results showed that SDSR affected performance only if it was above 82 ms. Placement required more frequent visual feedback and was more sensitive to SR. We infer that VE designers need not tightly control SDSR and may wish to vary SR control based on required visual feedback frequency. These results may be used to improve the human-computer interface in a wide range of interactive graphical applications, including scientific visualization, training, mental health, and entertainment.

**AI Summary:** This research examines the effects of system responsiveness (SR) on user performance in virtual environments (VEs) by analyzing mean (MSR) and standard deviation (SDSR) of SR. The studies found that SDSR only affected performance if it was above 82 ms, with placement tasks being more sensitive to SR. The results suggest that VE designers do not need to tightly control SDSR and can vary SR control based on visual feedback frequency, which can improve human-computer interfaces in various interactive graphical applications.

---

## "I Would Not Be This Version of Myself Today": Elaborating on the Effects of Eudaimonic Gaming Experiences
**URL:** https://arxiv.org/abs/2507.18084

**Abstract:** While much of the research in digital games has emphasized hedonic experiences, such as flow, enjoyment, and positive affect, recent years have seen increased interest in eudaimonic gaming experiences, typically mixed-affect and associated with personal meaningfulness and growth. The formation of such experiences in games is theorized to have four constituent elements: motivation, game use, experience, and effects. However, while the first three elements have been relatively well explored in the literature, the effects - and how they may influence positive individual outcomes - have been underexplored thus far. To this end, in this work, we investigate the perceived outcomes of eudaimonic gaming and how different components of the experience influence these effects. We conducted a survey (n = 166) in which respondents recounted meaningful gaming experiences and how they affected their present lives. We used a mixed-methods approach to classify effects and identify significant subcomponents of their formation. We contribute an empirical understanding of how meaningful gaming experiences can lead to positive reflective, learning, social, health, and career effects, extending current theoretical models of eudaimonic gaming experiences and offering implications for how researchers and practitioners might use these findings to promote positive outcomes for players.

**AI Summary:** This research focuses on eudaimonic gaming experiences, which are associated with personal growth and meaningfulness. The study explores the effects of these experiences on individuals, including positive outcomes in reflective, learning, social, health, and career aspects. The findings contribute to understanding how meaningful gaming experiences can lead to beneficial effects and offer implications for promoting positive outcomes for players.

---

## Evaluating judgment of spatial correlation in visual displays of scalar field distributions
**URL:** https://arxiv.org/abs/2507.17997

**Abstract:** In this work we study the identification of spatial correlation in distributions of 2D scalar fields, presented across different forms of visual displays. We study simple visual displays that directly show color-mapped scalar fields, namely those drawn from a distribution, and whether humans can identify strongly correlated spatial regions in these displays. In this setting, the recognition of correlation requires making judgments on a set of fields, rather than just one field. Thus, in our experimental design we compare two basic visualization designs: animation-based displays against juxtaposed views of scalar fields, along different choices of color scales. Moreover, we investigate the impacts of the distribution itself, controlling for the level of spatial correlation and discriminability in spatial scales. Our study's results illustrate the impacts of these distribution characteristics, while also highlighting how different visual displays impact the types of judgments made in assessing spatial correlation. Supplemental material is available at this https URL

**AI Summary:** This research investigates how humans identify spatial correlation in distributions of 2D scalar fields presented in visual displays. The study compares animation-based displays with juxtaposed views of scalar fields using different color scales. The results demonstrate the impact of distribution characteristics and visual displays on judgments of spatial correlation, providing insights into how different visualization designs affect perception of spatial relationships in scalar field distributions.

---

## Decoding Instructional Dialogue: Human-AI Collaborative Analysis of Teacher Use of AI Tool at Scale
**URL:** https://arxiv.org/abs/2507.17985

**Abstract:** The integration of large language models (LLMs) into educational tools has the potential to substantially impact how teachers plan instruction, support diverse learners, and engage in professional reflection. Yet little is known about how educators actually use these tools in practice and how their interactions with AI can be meaningfully studied at scale. This paper presents a human-AI collaborative methodology for large-scale qualitative analysis of over 140,000 educator-AI messages drawn from a generative AI platform used by K-12 teachers. Through a four-phase coding pipeline, we combined inductive theme discovery, codebook development, structured annotation, and model benchmarking to examine patterns of educator engagement and evaluate the performance of LLMs in qualitative coding tasks. We developed a hierarchical codebook aligned with established teacher evaluation frameworks, capturing educators' instructional goals, contextual needs, and pedagogical strategies. Our findings demonstrate that LLMs, particularly Claude 3.5 Haiku, can reliably support theme identification, extend human recognition in complex scenarios, and outperform open-weight models in both accuracy and structural reliability. The analysis also reveals substantive patterns in how educators inquire AI to enhance instructional practices (79.7 percent of total conversations), create or adapt content (76.1 percent), support assessment and feedback loop (46.9 percent), attend to student needs for tailored instruction (43.3 percent), and assist other professional responsibilities (34.2 percent), highlighting emerging AI-related competencies that have direct implications for teacher preparation and professional development. This study offers a scalable, transparent model for AI-augmented qualitative research and provides foundational insights into the evolving role of generative AI in educational practice.

**AI Summary:** This research paper presents a methodology for analyzing over 140,000 educator-AI messages to understand how teachers use AI tools in practice. The study shows that large language models (LLMs) can effectively support educators in various instructional tasks, such as identifying themes, creating content, and providing tailored instruction. The findings suggest that AI tools like Claude 3.5 Haiku have the potential to enhance teacher preparation and professional development by improving instructional practices and supporting diverse learners.

---

## Automated Brake Onset Detection in Naturalistic Driving Data
**URL:** https://arxiv.org/abs/2507.17943

**Abstract:** Response timing measures play a crucial role in the assessment of automated driving systems (ADS) in collision avoidance scenarios, including but not limited to establishing human benchmarks and comparing ADS to human driver response performance. For example, measuring the response time (of a human driver or ADS) to a conflict requires the determination of a stimulus onset and a response onset. In existing studies, response onset relies on manual annotation or vehicle control signals such as accelerator and brake pedal movements. These methods are not applicable when analyzing large scale data where vehicle control signals are not available. This holds in particular for the rapidly expanding sets of ADS log data where the behavior of surrounding road users is observed via onboard sensors. To advance evaluation techniques for ADS and enable measuring response timing when vehicle control signals are not available, we developed a simple and efficient algorithm, based on a piecewise linear acceleration model, to automatically estimate brake onset that can be applied to any type of driving data that includes vehicle longitudinal time series data. We also proposed a manual annotation method to identify brake onset and used it as ground truth for validation. R2 was used as a confidence metric to measure the accuracy of the algorithm, and its classification performance was analyzed using naturalistic collision avoidance data of both ADS and humans, where our method was validated against human manual annotation. Although our algorithm is subject to certain limitations, it is efficient, generalizable, applicable to any road user and scenario types, and is highly configurable.

**AI Summary:** The study focuses on developing an algorithm to automatically detect brake onset in naturalistic driving data, particularly in the context of assessing automated driving systems (ADS) in collision avoidance scenarios. The algorithm, based on a piecewise linear acceleration model, was found to be efficient and accurate when compared to manual annotation methods. This research is significant as it provides a method for evaluating ADS response timing in situations where vehicle control signals are not available, contributing to the advancement of ADS evaluation techniques.

---

## Same Data, Different Audiences: Using Personas to Scope a Supercomputing Job Queue Visualization
**URL:** https://arxiv.org/abs/2507.17898

**Abstract:** Domain-specific visualizations sometimes focus on narrow, albeit important, tasks for one group of users. This focus limits the utility of a visualization to other groups working with the same data. While tasks elicited from other groups can present a design pitfall if not disambiguated, they also present a design opportunity -- development of visualizations that support multiple groups. This development choice presents a trade off of broadening the scope but limiting support for the more narrow tasks of any one group, which in some cases can enhance the overall utility of the visualization. We investigate this scenario through a design study where we develop \textit{Guidepost}, a notebook-embedded visualization of supercomputer queue data that helps scientists assess supercomputer queue wait times, machine learning researchers understand prediction accuracy, and system maintainers analyze usage trends. We adapt the use of personas for visualization design from existing literature in the HCI and software engineering domains and apply them in categorizing tasks based on their uniqueness across the stakeholder personas. Under this model, tasks shared between all groups should be supported by interactive visualizations and tasks unique to each group can be deferred to scripting with notebook-embedded visualization design. We evaluate our visualization with nine expert analysts organized into two groups: a "research analyst" group that uses supercomputer queue data in their research (representing the Machine Learning researchers and Jobs Data Analyst personas) and a "supercomputer user" group that uses this data conditionally (representing the HPC User persona). We find that our visualization serves our three stakeholder groups by enabling users to successfully execute shared tasks with point-and-click interaction while facilitating case-specific programmatic analysis workflows.

**AI Summary:** The research explores the use of personas to design a visualization tool, called Guidepost, for supercomputer queue data. The tool caters to different user groups, such as scientists, machine learning researchers, and system maintainers, by supporting shared tasks with interactive visualizations and unique tasks with scripting capabilities. The evaluation with expert analysts demonstrates that the visualization successfully serves the needs of multiple stakeholder groups by allowing for both point-and-click interaction and case-specific programmatic analysis workflows.

---

## Human-AI Co-Creation: A Framework for Collaborative Design in Intelligent Systems
**URL:** https://arxiv.org/abs/2507.17774

**Abstract:** As artificial intelligence (AI) continues to evolve from a back-end computational tool into an interactive, generative collaborator, its integration into early-stage design processes demands a rethinking of traditional workflows in human-centered design. This paper explores the emergent paradigm of human-AI co-creation, where AI is not merely used for automation or efficiency gains, but actively participates in ideation, visual conceptualization, and decision-making. Specifically, we investigate the use of large language models (LLMs) like GPT-4 and multimodal diffusion models such as Stable Diffusion as creative agents that engage designers in iterative cycles of proposal, critique, and revision.

**AI Summary:** This research paper discusses the concept of human-AI co-creation in the design process, where artificial intelligence is not just a tool for efficiency but actively collaborates with humans in ideation and decision-making. The study focuses on the use of large language models like GPT-4 and multimodal diffusion models to engage designers in iterative cycles of proposal, critique, and revision, highlighting the potential for AI to enhance creativity and innovation in design processes.

---

