# arXiv cs.AI Summary â€“ 2025-10-20

## Sound Clouds: Exploring ambient intelligence in public spaces to elicit deep human experience of awe, wonder, and beauty
**URL:** https://arxiv.org/abs/2510.15865

**Abstract:** While the ambient intelligence (AmI) systems we encounter in our daily lives, including security monitoring and energy-saving systems, typically serve pragmatic purposes, we wonder how we can design and implement ambient artificial intelligence experiences in public spaces that elicit deep human feelings of awe, wonder, and beauty. As a manifestation, we introduce Sound Clouds, an immersive art installation that generates live music based on participants' interaction with several human-height spheres. Our installation serves as a provocation into future ambient intelligence that provokes, not limits, the future possibilities of AmI.

**AI Summary:** This research explores the potential for ambient artificial intelligence experiences in public spaces to evoke feelings of awe, wonder, and beauty. The researchers introduce Sound Clouds, an immersive art installation that generates live music based on participant interaction with spheres. This study challenges the traditional pragmatic purposes of ambient intelligence systems and suggests new possibilities for creating meaningful and engaging experiences in public spaces.

---

## The Spark Effect: On Engineering Creative Diversity in Multi-Agent AI Systems
**URL:** https://arxiv.org/abs/2510.15568

**Abstract:** Creative services teams increasingly rely on large language models (LLMs) to accelerate ideation, yet production systems often converge on homogeneous outputs that fail to meet brand or artistic expectations. Art of X developed persona-conditioned LLM agents -- internally branded as "Sparks" and instantiated through a library of role-inspired system prompts -- to intentionally diversify agent behaviour within a multi-agent workflow. This white paper documents the problem framing, experimental design, and quantitative evidence behind the Spark agent programme. Using an LLM-as-a-judge protocol calibrated against human gold standards, we observe a mean diversity gain of +4.1 points (on a 1-10 scale) when persona-conditioned Spark agents replace a uniform system prompt, narrowing the gap to human experts to 1.0 point. We also surface evaluator bias and procedural considerations for future deployments.

**AI Summary:** The research explores the use of persona-conditioned LLM agents, called "Sparks," to increase creative diversity in multi-agent AI systems used for ideation in creative services teams. By implementing Sparks with role-inspired system prompts, the study found a significant increase in diversity of outputs compared to uniform prompts, narrowing the gap to human experts. The findings suggest that intentional diversification of agent behavior can improve the quality of outputs in AI systems and provide insights for future deployments.

---

## A Feasibility Study on Usability and Trust among Population Groups of a Medical Avatar Supported by Large Language Models with Retrieval Augmented Generation
**URL:** https://arxiv.org/abs/2510.15531

**Abstract:** Healthcare professionals have limited time to support patients and their relatives, but their information needs are high. Therefore, the Radboud University together with the Canisius Wilhelmina Hospital hospital developed a speaking virtual hu-man avatar which, contrary to many avatars, uses a Large Language Model (LLM) enhanced with Retrieval Augmented Generation (RAG). The RAG tech-nique enables medical information supplied by the hospital to be utilized during interactions, rather than generic LLM information. Two videos were produced, one presenting a patient-avatar interaction regarding a total hip surgery, and an-other one presenting an interaction between a relative of a patient and the avatar concerning postoperative delirium. A survey was conducted among adults over 40 from the Netherlands, the UK and the USA to study the effects of gender, country and education level on usability and trust, which are important factors for avatar acceptance. Participants watched videos, imagining themselves as the pa-tient (video 1) or relative (video 2), and rated the constructs on a 7-point Likert scale (0-6). 165 persons (MeanAge=51.6, SDAge=8.9, Male=80, Female=85) completed the survey. In the patient role, participants scored the usability as M=4.61 (SD=0.97) and trust as M=3.92 (SD=1.10), all above the mean scale value. In the role as relative to the patient, participants scored usability as M=4.64 (SD=1.08) and trust as M=4.31 (SD=1.06). No effects were found of gender, country and education level.

**AI Summary:** This study examines the usability and trust in a medical avatar supported by Large Language Models with Retrieval Augmented Generation. The avatar was well-received by participants, scoring high in usability and trust regardless of gender, country, or education level. This research highlights the potential of using advanced AI technology to improve patient interactions and information delivery in healthcare settings.

---

## LLM-based In-situ Thought Exchanges for Critical Paper Reading
**URL:** https://arxiv.org/abs/2510.15234

**Abstract:** Critical reading is a primary way through which researchers develop their critical thinking skills. While exchanging thoughts and opinions with peers can strengthen critical reading, junior researchers often lack access to peers who can offer diverse perspectives. To address this gap, we designed an in-situ thought exchange interface informed by peer feedback from a formative study (N=8) to support junior researchers' critical paper reading. We evaluated the effects of thought exchanges under three conditions (no-agent, single-agent, and multi-agent) with 46 junior researchers over two weeks. Our results showed that incorporating agent-mediated thought exchanges during paper reading significantly improved participants' critical thinking scores compared to the no-agent condition. In the single-agent condition, participants more frequently made reflective annotations on the paper content. In the multi-agent condition, participants engaged more actively with agents' responses. Our qualitative analysis further revealed that participants compared and analyzed multiple perspectives in the multi-agent condition. This work contributes to understanding in-situ AI-based support for critical paper reading through thought exchanges and offers design implications for future research.

**AI Summary:** This research explores the use of AI-based in-situ thought exchanges to support critical paper reading for junior researchers. The study found that incorporating agent-mediated thought exchanges during paper reading improved participants' critical thinking scores, with different effects observed in single-agent and multi-agent conditions. The results suggest that AI-based support can enhance critical reading skills by providing diverse perspectives and encouraging active engagement with the material.

---

## Quantifying the Engagement Effectiveness of Cyber Cognitive Attacks: A Behavioral Metric for Disinformation Campaigns
**URL:** https://arxiv.org/abs/2510.15805

**Abstract:** As disinformation-driven cognitive attacks become increasingly sophisticated, the ability to quantify their impact is essential for advancing cybersecurity defense strategies. This paper presents a novel framework for measuring the engagement effectiveness of cognitive attacks by introducing a weighted interaction metric that accounts for both the type and volume of user engagement relative to the number of attacker-generated transmissions. Applying this model to real-world disinformation campaigns across social media platforms, we demonstrate how the metric captures not just reach but the behavioral depth of user engagement. Our findings provide new insights into the behavioral dynamics of cognitive warfare and offer actionable tools for researchers and practitioners seeking to assess and counter the spread of malicious influence online.

**AI Summary:** This research paper introduces a new framework for measuring the effectiveness of cognitive attacks in disinformation campaigns by analyzing user engagement. The weighted interaction metric developed in this study considers both the type and volume of user engagement in relation to the number of attacker-generated transmissions. By applying this model to real-world disinformation campaigns on social media, the researchers were able to gain insights into the behavioral dynamics of cognitive warfare and provide useful tools for cybersecurity researchers and practitioners to combat malicious influence online.

---

## Towards Proactive Defense Against Cyber Cognitive Attacks
**URL:** https://arxiv.org/abs/2510.15801

**Abstract:** Cyber cognitive attacks leverage disruptive innovations (DIs) to exploit psychological biases and manipulate decision-making processes. Emerging technologies, such as AI-driven disinformation and synthetic media, have accelerated the scale and sophistication of these threats. Prior studies primarily categorize current cognitive attack tactics, lacking predictive mechanisms to anticipate future DIs and their malicious use in cognitive attacks. This paper addresses these gaps by introducing a novel predictive methodology for forecasting the emergence of DIs and their malicious uses in cognitive attacks. We identify trends in adversarial tactics and propose proactive defense strategies.

**AI Summary:** This research focuses on proactive defense against cyber cognitive attacks, which use disruptive innovations to manipulate decision-making processes. The study introduces a predictive methodology to anticipate future disruptive innovations and their malicious use in cognitive attacks, aiming to address the gaps in current categorization of attack tactics. The findings suggest the importance of identifying trends in adversarial tactics and implementing proactive defense strategies to combat evolving cyber threats.

---

## Preliminary Quantitative Study on Explainability and Trust in AI Systems
**URL:** https://arxiv.org/abs/2510.15769

**Abstract:** Large-scale AI models such as GPT-4 have accelerated the deployment of artificial intelligence across critical domains including law, healthcare, and finance, raising urgent questions about trust and transparency. This study investigates the relationship between explainability and user trust in AI systems through a quantitative experimental design. Using an interactive, web-based loan approval simulation, we compare how different types of explanations, ranging from basic feature importance to interactive counterfactuals influence perceived trust. Results suggest that interactivity enhances both user engagement and confidence, and that the clarity and relevance of explanations are key determinants of trust. These findings contribute empirical evidence to the growing field of human-centered explainable AI, highlighting measurable effects of explainability design on user perception

**AI Summary:** This study examines the impact of explainability on user trust in AI systems, using a loan approval simulation. The results show that interactive explanations increase user engagement and confidence, with clear and relevant explanations being crucial for building trust. These findings provide valuable insights for the design of human-centered explainable AI systems in critical domains.

---

## Extending Load Forecasting from Zonal Aggregates to Individual Nodes for Transmission System Operators
**URL:** https://arxiv.org/abs/2510.14983

**Abstract:** The reliability of local power grid infrastructure is challenged by sustainable energy developments increasing electric load uncertainty. Transmission System Operators (TSOs) need load forecasts of higher spatial resolution, extending current forecasting operations from zonal aggregates to individual nodes. However, nodal loads are less accurate to forecast and require a large number of individual forecasts, which are hard to manage for the human experts assessing risks in the control room's daily operations (operator). In collaboration with a TSO, we design a multi-level system that meets the needs of operators for hourly day-ahead load forecasting. Utilizing a uniquely extensive dataset of zonal and nodal net loads, we experimentally evaluate our system components. First, we develop an interpretable and scalable forecasting model that allows for TSOs to gradually extend zonal operations to include nodal forecasts. Second, we evaluate solutions to address the heterogeneity and volatility of nodal load, subject to a trade-off. Third, our system is manageable with a fully parallelized single-model forecasting workflow. Our results show accuracy and interpretability improvements for zonal forecasts, and substantial improvements for nodal forecasts. In practice, our multi-level forecasting system allows operators to adjust forecasts with unprecedented confidence and accuracy, and to diagnose otherwise opaque errors precisely.

**AI Summary:** This research focuses on extending load forecasting from zonal aggregates to individual nodes for Transmission System Operators (TSOs) in response to increasing electric load uncertainty. The study presents a multi-level forecasting system that improves the accuracy and interpretability of both zonal and nodal load forecasts, allowing operators to adjust forecasts with confidence and diagnose errors more precisely. The results show significant improvements in nodal load forecasting, addressing the challenges of managing a large number of individual forecasts and providing TSOs with valuable insights for daily operations.

---

## Design of Paper Robot Building Kits
**URL:** https://arxiv.org/abs/2510.14914

**Abstract:** Building robots is an engaging activity that provides opportunities for hands-on learning. However, traditional robot-building kits are usually costly with limited functionality due to material and technology constraints. To improve the accessibility and flexibility of such kits, we take paper as the building material and extensively explore the versatility of paper-based interactions. Based on an analysis of current robot-building kits and paper-based interaction research, we propose a design space for devising paper robots. We also analyzed our building kit designs using this design space, where these kits demonstrate the potential of paper as a cost-effective material for robot building. As a starting point, our design space and building kit examples provide a guideline that inspires and informs future research and development of novel paper robot-building kits.

**AI Summary:** This research explores the use of paper as a cost-effective and versatile material for building robots, aiming to improve accessibility and flexibility in robot-building kits. By analyzing current kits and paper-based interaction research, the study proposes a design space for creating paper robots and presents examples of paper robot-building kits. The findings suggest that paper can be a viable material for building robots, offering a starting point for future research and development in this area.

---

## Dude, Where's My (Autonomous) Car? Defining an Accessible Description Logic for Blind and Low Vision Travelers Using Autonomous Vehicles
**URL:** https://arxiv.org/abs/2510.14911

**Abstract:** Purpose: Autonomous vehicles (AVs) are becoming a promising transportation solution for blind and low-vision (BLV) travelers, offering the potential for greater independent mobility. This paper explores the information needs of BLV users across multiple steps of the transportation journey, including finding and navigating to, entering, and exiting vehicles independently.
Methods: A survey with 202 BLV respondents and interviews with 12 BLV individuals revealed the perspectives of BLV end-users and informed the sequencing of natural language information required for successful travel. Whereas the survey identified key information needs across the three trip segments, the interviews helped prioritize how that information should be presented in a sequence of accessible descriptions to travelers.
Results: Taken together, the survey and interviews reveal that BLV users prioritize knowing the vehicle's make and model and how to find the correct vehicle during the navigation phase. They also emphasize the importance of confirmations about the vehicle's destination and onboard safety features upon entering the vehicle. While exiting, BLV users value information about hazards and obstacles, as well as knowing which side of the vehicle to exit. Furthermore, results highlight that BLV travelers desire using their own smartphone devices when receiving information from AVs and prefer audio-based interaction.
Conclusion: The findings from this research contribute a structured framework for delivering trip-related information to BLV users, useful for designers incorporating natural language descriptions tailored to each travel segment. This work offers important contributions for sequencing transportation-related descriptions throughout the AV journey, ultimately enhancing the mobility and independence of BLV individuals.

**AI Summary:** This research explores the information needs of blind and low-vision travelers using autonomous vehicles, highlighting the importance of providing accessible descriptions tailored to each step of the transportation journey. The study found that BLV users prioritize knowing the vehicle's make and model, finding the correct vehicle, receiving confirmations about the destination and safety features upon entering, and being informed about hazards and obstacles when exiting. The findings offer a structured framework for designers to deliver trip-related information to BLV users, ultimately enhancing their mobility and independence when using autonomous vehicles.

---

## If You Hold Me Without Hurting Me: Pathways to Designing Game Audio for Healthy Escapism and Player Well-being
**URL:** https://arxiv.org/abs/2510.14691

**Abstract:** Escapism in games can support recovery or lead to harmful avoidance. Self-regulation, understood as combining autonomy with positive outcomes, is key to this distinction. We argue that audio, often overlooked, plays a central role in regulation. It can modulate arousal, mark transitions, and provide closure, yet its contribution to well-being remains underexplored. This paper identifies methodological and accessibility gaps that limit recognition of audio's potential and outlines ways to address them. We aim to encourage researchers and developers to integrate audio more deliberately into the design and study of healthier escapist play.

**AI Summary:** This research explores the role of audio in promoting healthy escapism in video games, highlighting its potential to support recovery and well-being. The study emphasizes the importance of self-regulation in distinguishing between beneficial escapism and harmful avoidance. The paper identifies gaps in understanding the impact of audio on player well-being and suggests ways for researchers and developers to integrate audio more intentionally in designing and studying healthier escapist gameplay.

---

## An Active Inference Model of Mouse Point-and-Click Behaviour
**URL:** https://arxiv.org/abs/2510.14611

**Abstract:** We explore the use of Active Inference (AIF) as a computational user model for spatial pointing, a key problem in Human-Computer Interaction (HCI). We present an AIF agent with continuous state, action, and observation spaces, performing one-dimensional mouse pointing and clicking. We use a simple underlying dynamic system to model the mouse cursor dynamics with realistic perceptual delay. In contrast to previous optimal feedback control-based models, the agent's actions are selected by minimizing Expected Free Energy, solely based on preference distributions over percepts, such as observing clicking a button correctly. Our results show that the agent creates plausible pointing movements and clicks when the cursor is over the target, with similar end-point variance to human users. In contrast to other models of pointing, we incorporate fully probabilistic, predictive delay compensation into the agent. The agent shows distinct behaviour for differing target difficulties without the need to retune system parameters, as done in other approaches. We discuss the simulation results and emphasize the challenges in identifying the correct configuration of an AIF agent interacting with continuous systems.

**AI Summary:** This research explores the use of Active Inference (AIF) as a computational user model for spatial pointing in Human-Computer Interaction. The AIF agent successfully performs mouse pointing and clicking tasks with realistic perceptual delay, minimizing Expected Free Energy to select actions based on preference distributions over percepts. The results show that the agent's behavior closely resembles human users in pointing movements and clicks, and can adapt to different target difficulties without the need for parameter retuning.

---

## Exploring the Effects of Different Asymmetric Game Designs on User Experience in Collaborative Virtual Reality
**URL:** https://arxiv.org/abs/2510.14607

**Abstract:** The risk of isolation in virtual reality (VR) stems from the immersive nature of the technology. VR can transport users to entirely virtual environments, often disconnecting them from the physical world and real-life interactions. Asymmetric multiplayer options have been explored to address this issue and encourage social interaction by requiring players to communicate and collaborate to achieve common objectives. Nevertheless, research on implementing these designs and their effects is limited, mainly due to the novelty of multiplayer VR gaming. This article investigates how different game design approaches affect the player experience during an asymmetric multiplayer VR game. Four versions of a VR experience were created and tested in a study involving 74 participants. Each version differs in terms of the sharing of virtual environments (shared vs separated) and the players' dependency on the experience (mutual vs unidirectional). The results showed that variations in game design influenced aspects of the player experience, such as system usability, pragmatic UX quality, immersion control, and intrinsic motivation. Notably, the player roles and the co-presence in the virtual environment did not simultaneously impact these aspects, suggesting that the degree to which players depend on each other changes the player experience.

**AI Summary:** This research explores the impact of different asymmetric game designs on user experience in collaborative virtual reality (VR). The study found that variations in game design, such as shared vs separated virtual environments and mutual vs unidirectional player dependency, influenced aspects of player experience like system usability, pragmatic UX quality, immersion control, and intrinsic motivation. The results suggest that the degree to which players depend on each other in asymmetric multiplayer VR games can significantly affect the overall player experience.

---

## Sales Skills Training in Virtual Reality: An evaluation utilizing CAVE and Virtual Avatars
**URL:** https://arxiv.org/abs/2510.14603

**Abstract:** This study investigates the potential of virtual reality (VR) for enhancing sales skills training using a Cave Automatic Virtual Environment (CAVE). VR technology enables users to practice interpersonal and negotiation skills in controlled, immersive environments that mimic real-world scenarios. In this study, participants engaged in sales simulations set in a virtual dealership, interacting with avatars in different work settings and with various communication styles. The research employed a within-subjects experimental design involving 20 university students. Each participant experienced four distinct sales scenarios randomized for environmental and customer conditions. Training effectiveness was assessed using validated metrics alongside custom experience questions. Findings revealed consistent user experience and presence across all scenarios, with no significant differences detected based on communication styles or environmental conditions. The study highlights the advantages of semi-immersive VR systems for collaborative learning, peer feedback, and realistic training environments. However, further research is recommended to refine VR designs, improve engagement, and maximize skills transfer to real-world applications.

**AI Summary:** This study explores the use of virtual reality (VR) technology for enhancing sales skills training through immersive simulations in a Cave Automatic Virtual Environment (CAVE). Participants engaged in sales scenarios in a virtual dealership, interacting with avatars in different work settings and communication styles. The research found consistent user experience and presence across scenarios, indicating the potential of semi-immersive VR systems for realistic training environments and collaborative learning. Further research is needed to refine VR designs and improve skills transfer to real-world applications.

---

## Two Explorative Studies on Tangible Augmented Reality for Neurodevelopmental Disorders
**URL:** https://arxiv.org/abs/2510.14598

**Abstract:** Tangible Augmented Reality (TAR) is an interaction paradigm that integrates physical and digital worlds to create immersive, interactive experiences. This paper explores two TAR applications, Holomarket and Along the Oceanic Flow (ATOF), and presents insights from two exploratory studies evaluating their usability and likeability among individuals with neurodevelopmental disorders (NDD). Holomarket is designed to simulate a supermarket shopping experience, helping users develop essential life skills such as item selection, basic arithmetic, and money handling. Participants interacted with augmented food items and a smart cash register, navigating a virtual supermarket environment. While participants enjoyed the realistic setting and tangible interactions, some usability challenges, such as difficulty manipulating virtual objects and discomfort with prolonged headset use, were noted. ATOF transforms the user environment into an oceanic world, where participants use a dolphin-shaped smart object to complete tasks like collecting items and solving puzzles. This application aims to improve motor coordination and cognitive skills. Participants appreciated the immersive experience, the customizable tasks, and the tangible dolphin interface. However, some faced difficulties interacting with specific virtual elements. Overall, both applications demonstrated potential as therapeutic tools for NDD, offering engaging and immersive experiences. Despite some usability challenges and hardware limitations, the positive feedback suggests that TAR could play a crucial role in future therapeutic interventions. Further research is needed to refine these applications and enhance user interaction and comfort.

**AI Summary:** This research explores the use of Tangible Augmented Reality (TAR) applications, Holomarket and Along the Oceanic Flow (ATOF), for individuals with neurodevelopmental disorders (NDD). Holomarket helps users develop life skills through a simulated shopping experience, while ATOF aims to improve motor coordination and cognitive skills in an oceanic world setting. Both applications showed potential as therapeutic tools, with participants enjoying the immersive experiences and tangible interactions, despite some usability challenges and hardware limitations. Further research is needed to refine these applications and enhance user comfort and interaction.

---

## Just-In-Time Objectives: A General Approach for Specialized AI Interactions
**URL:** https://arxiv.org/abs/2510.14591

**Abstract:** Large language models promise a broad set of functions, but when not given a specific objective, they default to milquetoast results such as drafting emails littered with cliches. We demonstrate that inferring the user's in-the-moment objective, then rapidly optimizing for that singular objective, enables LLMs to produce tools, interfaces, and responses that are more responsive and desired. We contribute an architecture for automatically inducing just-in-time objectives by passively observing user behavior, then steering downstream AI systems through generation and evaluation against this objective. Inducing just-in-time objectives (e.g., "Clarify the abstract's research contribution") enables automatic generation of tools, e.g., those that critique a draft based on relevant HCI methodologies, anticipate related researchers' reactions, or surface ambiguous terminology. In a series of experiments (N=14, N=205) on participants' own tasks, JIT objectives enable LLM outputs that achieve 66-86% win rates over typical LLMs, and in-person use sessions (N=17) confirm that JIT objectives produce specialized tools unique to each participant.

**AI Summary:** The research explores the concept of just-in-time objectives for large language models, showing that inferring and optimizing for the user's specific objective in the moment leads to more responsive and desired outcomes. By automatically inducing these objectives based on user behavior, the AI systems can generate tools and responses tailored to the user's needs, resulting in higher success rates and specialized tools unique to each participant. This approach has the potential to significantly improve the functionality and effectiveness of AI interactions in various tasks.

---

## State Your Intention to Steer Your Attention: An AI Assistant for Intentional Digital Living
**URL:** https://arxiv.org/abs/2510.14513

**Abstract:** When working on digital devices, people often face distractions that can lead to a decline in productivity and efficiency, as well as negative psychological and emotional impacts. To address this challenge, we introduce a novel Artificial Intelligence (AI) assistant that elicits a user's intention, assesses whether ongoing activities are in line with that intention, and provides gentle nudges when deviations occur. The system leverages a large language model to analyze screenshots, application titles, and URLs, issuing notifications when behavior diverges from the stated goal. Its detection accuracy is refined through initial clarification dialogues and continuous user feedback. In a three-week, within-subjects field deployment with 22 participants, we compared our assistant to both a rule-based intent reminder system and a passive baseline that only logged activity. Results indicate that our AI assistant effectively supports users in maintaining focus and aligning their digital behavior with their intentions. Our source code is publicly available at this https URL

**AI Summary:** The research introduces an AI assistant designed to help users stay focused and aligned with their intentions while using digital devices. By analyzing screenshots, application titles, and URLs, the system provides gentle nudges when behavior deviates from the stated goal, leading to improved productivity and well-being. In a field deployment with 22 participants, the AI assistant outperformed a rule-based system and passive baseline, demonstrating its effectiveness in supporting intentional digital living.

---

## ReUseIt: Synthesizing Reusable AI Agent Workflows for Web Automation
**URL:** https://arxiv.org/abs/2510.14308

**Abstract:** AI-powered web agents have the potential to automate repetitive tasks, such as form filling, information retrieval, and scheduling, but they struggle to reliably execute these tasks without human intervention, requiring users to provide detailed guidance during every run. We address this limitation by automatically synthesizing reusable workflows from an agent's successful and failed attempts. These workflows incorporate execution guards that help agents detect and fix errors while keeping users informed of progress and issues. Our approach enables agents to successfully complete repetitive tasks of the same type with minimal intervention, increasing the success rates from 24.2% to 70.1% across fifteen tasks. To evaluate this approach, we invited nine users and found that our agent helped them complete web tasks with a higher success rate and less guidance compared to two baseline methods, as well as allowed users to easily monitor agent behavior and understand failures.

**AI Summary:** The research focuses on improving the reliability of AI-powered web agents in automating repetitive tasks by synthesizing reusable workflows from successful and failed attempts. The approach increases success rates from 24.2% to 70.1% across fifteen tasks and helps users complete web tasks with higher success rates and less guidance compared to baseline methods. The synthesized workflows incorporate execution guards to detect and fix errors, allowing users to easily monitor agent behavior and understand failures.

---

## GenLARP: Enabling Immersive Live Action Role-Play through LLM-Generated Worlds and Characters
**URL:** https://arxiv.org/abs/2510.14277

**Abstract:** We introduce GenLARP, a virtual reality (VR) system that transforms personalized stories into immersive live action role-playing (LARP) experiences. GenLARP enables users to act as both creators and players, allowing them to design characters based on their descriptions and live in the story world. Generative AI and agents powered by Large Language Models (LLMs) enrich these experiences.

**AI Summary:** GenLARP is a VR system that allows users to create and participate in immersive LARP experiences by transforming personalized stories into interactive worlds and characters. The system enables users to design characters based on their descriptions and live in the story world, enhancing the overall experience with generative AI and agents powered by Large Language Models (LLMs). This research demonstrates the potential of AI technology to revolutionize storytelling and gaming experiences in virtual reality.

---

## TapNav: Adaptive Spatiotactile Screen Readers for Tactually Guided Touchscreen Interactions for Blind and Low Vision People
**URL:** https://arxiv.org/abs/2510.14267

**Abstract:** Screen readers are audio-based software that Blind and Low Vision (BLV) people use to interact with computing devices, such as tablets and smartphones. Although this technology has significantly improved the accessibility of touchscreen devices, the sequential nature of audio limits the bandwidth of information users can receive and process. We introduce TapNav, an adaptive spatiotactile screen reader prototype developed to interact with touchscreen interfaces spatially. TapNav's screen reader provides adaptive auditory feedback that, in combination with a tactile overlay, conveys spatial information and location of interface elements on-screen. We evaluated TapNav with 12 BLV users who interacted with TapNav to explore a data visualization and interact with a bank transactions application. Our qualitative findings show that touch points and spatially constrained navigation helped users anticipate outcomes for faster exploration, and offload cognitive load to touch. We provide design guidelines for creating tactile overlays for adaptive spatiotactile screen readers and discuss their generalizability beyond our exploratory data analysis and everyday application navigation scenarios.

**AI Summary:** The research introduces TapNav, an adaptive spatiotactile screen reader prototype designed to enhance the interaction of Blind and Low Vision (BLV) users with touchscreen devices. The study found that the combination of auditory feedback and tactile overlays provided spatial information and improved user experience, enabling faster exploration and reducing cognitive load. The findings suggest that this approach could enhance accessibility for BLV individuals when navigating complex interfaces and interacting with various applications on touchscreen devices.

---

## VisAider: AI-Assisted Context-Aware Visualization Support for Data Presentations
**URL:** https://arxiv.org/abs/2510.14247

**Abstract:** Effective real-time data presentation is essential in small-group interactive contexts, where discussions evolve dynamically and presenters must adapt visualizations to shifting audience interests. However, most existing interactive visualization systems rely on fixed mappings between user actions and visualization commands, limiting their ability to support richer operations such as changing visualization types, adjusting data transformations, or incorporating additional datasets on the fly during live presentations. This work-in-progress paper presents VisAider, an AI-assisted interactive data presentation prototype that continuously analyzes the live presentation context, including the available dataset, active visualization, ongoing conversation, and audience profile, to generate ranked suggestions for relevant visualization aids. Grounded in a formative study with experienced data analysts, we identified key challenges in adapting visual content in real time and distilled design considerations to guide system development. A prototype implementation demonstrates the feasibility of this approach in simulated scenarios, and preliminary testing highlights challenges in inferring appropriate data transformations, resolving ambiguous visualization tasks, and achieving low-latency responsiveness. Ongoing work focuses on addressing these limitations, integrating the system into presentation environments, and preparing a summative user study to evaluate usability and communicative impact.

**AI Summary:** The research paper introduces VisAider, an AI-assisted interactive data presentation system designed to support real-time adjustments to visualizations during live presentations. The system analyzes the presentation context, including audience interests and ongoing conversation, to generate suggestions for relevant visualization aids. The prototype implementation demonstrates the feasibility of this approach, but challenges remain in inferring data transformations, resolving ambiguous tasks, and ensuring low-latency responsiveness. Ongoing work aims to address these limitations, integrate the system into presentation environments, and conduct a user study to evaluate usability and impact.

---

## Understanding Data Usage when Making High-Stakes Frontline Decisions in Homelessness Services
**URL:** https://arxiv.org/abs/2510.14141

**Abstract:** Frontline staff of emergency shelters face challenges such as vicarious trauma, compassion fatigue, and burnout. The technology they use is often not designed for their unique needs, and can feel burdensome on top of their already cognitively and emotionally taxing work. While existing literature focuses on data-driven technologies that automate or streamline frontline decision-making about vulnerable individuals, we discuss scenarios in which staff may resist such automation. We then suggest how data-driven technologies can better align with their human-centred decision-making processes. This paper presents findings from a qualitative fieldwork study conducted from 2022 to 2024 at a large emergency shelter in Canada. The goal of this fieldwork was to co-design, develop, and deploy an interactive data-navigation interface that supports frontline staff when making collaborative, high-stakes decisions about individuals experiencing homelessness. By reflecting on this fieldwork, we contribute insight into the role that administrative shelter data play during decision-making, and unpack staff members' apparent reluctance to outsource decisions about vulnerable individuals to data systems. Our findings suggest a data-outsourcing continuum, which we discuss in terms of how designers may create technologies to support compassionate, data-driven decision-making in nonprofit domains.

**AI Summary:** This research explores the challenges faced by frontline staff in homelessness services when using technology for decision-making, highlighting the importance of aligning data-driven technologies with human-centered decision-making processes. The study conducted at a Canadian emergency shelter from 2022 to 2024 reveals staff reluctance to fully automate decision-making processes and suggests a data-outsourcing continuum for designers to create technologies that support compassionate, data-driven decision-making in nonprofit domains. The findings emphasize the significance of understanding and improving data usage in high-stakes frontline decisions to better support individuals experiencing homelessness.

---

## Reversing the Lens: Using Explainable AI to Understand Human Expertise
**URL:** https://arxiv.org/abs/2510.13814

**Abstract:** Both humans and machine learning models learn from experience, particularly in safety- and reliability-critical domains. While psychology seeks to understand human cognition, the field of Explainable AI (XAI) develops methods to interpret machine learning models. This study bridges these domains by applying computational tools from XAI to analyze human learning. We modeled human behavior during a complex real-world task -- tuning a particle accelerator -- by constructing graphs of operator subtasks. Applying techniques such as community detection and hierarchical clustering to archival operator data, we reveal how operators decompose the problem into simpler components and how these problem-solving structures evolve with expertise. Our findings illuminate how humans develop efficient strategies in the absence of globally optimal solutions, and demonstrate the utility of XAI-based methods for quantitatively studying human cognition.

**AI Summary:** This study explores the use of Explainable AI (XAI) methods to analyze human expertise in complex tasks, specifically in the context of tuning a particle accelerator. By applying computational tools to operator data, the researchers reveal how operators break down the task into simpler components and how these problem-solving structures evolve with expertise. The findings highlight how humans develop efficient strategies in challenging situations and demonstrate the value of XAI in quantitatively studying human cognition.

---

## Puzzlegram: a Serious Game Designed for the Elderly in Group Settings
**URL:** https://arxiv.org/abs/2510.13813

**Abstract:** An original serious game prototype named 'Puzzlegram' is created for the elderly demographic in group settings as the target players. Puzzlegram is precisely designed to accentuate memory, auditory interaction as well as haptic response to visual signals with the use of music. Music is introduced as a key component for establishing the game design that provides a source of meaningful contextualization (familiar music from the past) for setting the game mechanics, which facilitated the construction of the serious game design process. The discussion topics raised include the need to design serious games for fostering meaningful interactions, as well as developing a thorough framework for constructing purposeful design for serious games. A potential integral of artificial intelligence to Puzzlegram may involve assigning a novel dimension to its existing problem solving task by adapting to varying states of cognitive function for monitoring purposes based on an individual's interaction with the game.

**AI Summary:** The research introduces a serious game prototype called 'Puzzlegram' designed for elderly individuals in group settings to enhance memory, auditory interaction, and haptic response through the use of music. The incorporation of music in the game design provides a meaningful context for players, emphasizing the importance of designing serious games for fostering meaningful interactions. The potential integration of artificial intelligence in Puzzlegram could involve adapting the game's problem-solving tasks based on an individual's cognitive function, highlighting the significance of monitoring player interactions for personalized gameplay.

---

## MindBenchAI: An Actionable Platform to Evaluate the Profile and Performance of Large Language Models in a Mental Healthcare Context
**URL:** https://arxiv.org/abs/2510.13812

**Abstract:** Individuals are increasingly utilizing large language model (LLM)based tools for mental health guidance and crisis support in place of human experts. While AI technology has great potential to improve health outcomes, insufficient empirical evidence exists to suggest that AI technology can be deployed as a clinical replacement; thus, there is an urgent need to assess and regulate such tools. Regulatory efforts have been made and multiple evaluation frameworks have been proposed, however,field-wide assessment metrics have yet to be formally integrated. In this paper, we introduce a comprehensive online platform that aggregates evaluation approaches and serves as a dynamic online resource to simplify LLM and LLM-based tool assessment: MindBenchAI. At its core, MindBenchAI is designed to provide easily accessible/interpretable information for diverse stakeholders (patients, clinicians, developers, regulators, etc.). To create MindBenchAI, we built off our work developing this http URL to support informed decision-making around smartphone app use for mental health, and expanded the technical this http URL framework to encompass novel large language model (LLM) functionalities through benchmarking approaches. The MindBenchAI platform is designed as a partnership with the National Alliance on Mental Illness (NAMI) to provide assessment tools that systematically evaluate LLMs and LLM-based tools with objective and transparent criteria from a healthcare standpoint, assessing both profile (i.e. technical features, privacy protections, and conversational style) and performance characteristics (i.e. clinical reasoning skills).

**AI Summary:** The research introduces MindBenchAI, an online platform designed to evaluate large language models (LLMs) used in mental healthcare. The platform aims to provide easily accessible information for stakeholders such as patients, clinicians, developers, and regulators. By assessing both profile and performance characteristics of LLMs, MindBenchAI can help ensure the safe and effective deployment of AI technology in mental health settings.

---

## Generative AI in Heritage Practice: Improving the Accessibility of Heritage Guidance
**URL:** https://arxiv.org/abs/2510.13811

**Abstract:** This paper discusses the potential for integrating Generative Artificial Intelligence (GenAI) into professional heritage practice with the aim of enhancing the accessibility of public-facing guidance documents. We developed HAZEL, a GenAI chatbot fine-tuned to assist with revising written guidance relating to heritage conservation and interpretation. Using quantitative assessments, we compare HAZEL's performance to that of ChatGPT (GPT-4) in a series of tasks related to the guidance writing process. The results of this comparison indicate a slightly better performance of HAZEL over ChatGPT, suggesting that the GenAI chatbot is more effective once the underlying large language model (LLM) has been fine-tuned. However, we also note significant limitations, particularly in areas requiring cultural sensitivity and more advanced technical expertise. These findings suggest that, while GenAI cannot replace human heritage professionals in technical authoring tasks, its potential to automate and expedite certain aspects of guidance writing could offer valuable benefits to heritage organisations, especially in resource-constrained contexts.

**AI Summary:** This research explores the use of Generative Artificial Intelligence (GenAI) in improving the accessibility of heritage guidance documents. The study developed a GenAI chatbot named HAZEL, which showed slightly better performance compared to ChatGPT in tasks related to guidance writing after being fine-tuned. While GenAI may not fully replace human heritage professionals, it has the potential to automate and expedite certain aspects of guidance writing, offering valuable benefits to heritage organizations, particularly in resource-constrained contexts.

---

## Choreographing Trash Cans: On Speculative Futures of Weak Robots in Public Spaces
**URL:** https://arxiv.org/abs/2510.13810

**Abstract:** Delivering groceries or cleaning airports, mobile robots exist in public spaces. While these examples showcase robots that execute tasks, this paper explores mobile robots that encourage posthuman collaboration rather than managing environments independently. With feigned fragility, cuteness and incomplete functionalities, the so-called "weak robots" invite passersby to engage not only on a utilitarian level, but also through imaginative and emotional responses. After examining the workings of "weak robots" by queering notions of function and ability, we introduce two speculative design fiction vignettes that describe choreographies of such robots in future urban spaces -- one exploring a utopian weak robot and the other a dystopian weak robot. We introduce these speculations in order to discuss how different values may drive design decisions, and how such decisions may shape and drive different socio-technical futures in which robots and humans share public spaces that incentivise collaboration.

**AI Summary:** This research paper explores the concept of "weak robots" in public spaces, which are designed to encourage collaboration and engagement with passersby through feigned fragility, cuteness, and incomplete functionalities. By queering traditional notions of function and ability, the paper presents two speculative design fiction vignettes depicting both utopian and dystopian scenarios of weak robots in future urban spaces. The study highlights the importance of considering different values in design decisions for robots in public spaces, as they can shape and drive socio-technical futures that promote collaboration between robots and humans.

---

## Detecting Early and Implicit Suicidal Ideation via Longitudinal and Information Environment Signals on Social Media
**URL:** https://arxiv.org/abs/2510.14889

**Abstract:** On social media, many individuals experiencing suicidal ideation (SI) do not disclose their distress explicitly. Instead, signs may surface indirectly through everyday posts or peer interactions. Detecting such implicit signals early is critical but remains challenging. We frame early and implicit SI as a forward-looking prediction task and develop a computational framework that models a user's information environment, consisting of both their longitudinal posting histories as well as the discourse of their socially proximal peers. We adopted a composite network centrality measure to identify top neighbors of a user, and temporally aligned the user's and neighbors' interactions -- integrating the multi-layered signals in a fine-tuned DeBERTa-v3 model. In a Reddit study of 1,000 (500 Case and 500 Control) users, our approach improves early and implicit SI detection by 15% over individual-only baselines. These findings highlight that peer interactions offer valuable predictive signals and carry broader implications for designing early detection systems that capture indirect as well as masked expressions of risk in online environments.

**AI Summary:** This research focuses on detecting early and implicit suicidal ideation on social media by analyzing users' posting histories and interactions with peers. By integrating these signals into a computational framework and using a DeBERTa-v3 model, the study found that including peer interactions improved detection of suicidal ideation by 15% compared to individual-only baselines. This highlights the importance of considering indirect and masked expressions of risk in online environments for designing effective early detection systems.

---

## Beyond Hallucinations: The Illusion of Understanding in Large Language Models
**URL:** https://arxiv.org/abs/2510.14665

**Abstract:** Large language models (LLMs) are becoming deeply embedded in human communication and decision-making, yet they inherit the ambiguity, bias, and lack of direct access to truth inherent in language itself. While their outputs are fluent, emotionally resonant, and coherent, they are generated through statistical prediction rather than grounded reasoning. This creates the risk of hallucination, responses that sound convincing but lack factual validity. Building on Geoffrey Hinton's observation that AI mirrors human intuition rather than reasoning, this paper argues that LLMs operationalize System 1 cognition at scale: fast, associative, and persuasive, but without reflection or falsification. To address this, we introduce the Rose-Frame, a three-dimensional framework for diagnosing cognitive and epistemic drift in human-AI interaction. The three axes are: (i) Map vs. Territory, which distinguishes representations of reality (epistemology) from reality itself (ontology); (ii) Intuition vs. Reason, drawing on dual-process theory to separate fast, emotional judgments from slow, reflective thinking; and (iii) Conflict vs. Confirmation, which examines whether ideas are critically tested through disagreement or simply reinforced through mutual validation. Each dimension captures a distinct failure mode, and their combination amplifies misalignment. Rose-Frame does not attempt to fix LLMs with more data or rules. Instead, it offers a reflective tool that makes both the model's limitations and the user's assumptions visible, enabling more transparent and critically aware AI deployment. It reframes alignment as cognitive governance: intuition, whether human or artificial, must remain governed by human reason. Only by embedding reflective, falsifiable oversight can we align machine fluency with human understanding.

**AI Summary:** This research paper discusses the limitations of large language models (LLMs) in terms of generating outputs that may lack factual validity, leading to the risk of hallucination. The authors introduce the Rose-Frame, a framework for diagnosing cognitive and epistemic drift in human-AI interaction, focusing on distinguishing reality from representations of reality, separating intuition from reasoning, and examining critical testing of ideas. The framework aims to enable more transparent and critically aware AI deployment by highlighting the limitations of LLMs and the assumptions of users, emphasizing the importance of embedding reflective oversight to align machine fluency with human understanding.

---

## From Binary to Bilingual: How the National Weather Service is Using Artificial Intelligence to Develop a Comprehensive Translation Program
**URL:** https://arxiv.org/abs/2510.14369

**Abstract:** To advance a Weather-Ready Nation, the National Weather Service (NWS) is developing a systematic translation program to better serve the 68.8 million people in the U.S. who do not speak English at home. This article outlines the foundation of an automated translation tool for NWS products, powered by artificial intelligence. The NWS has partnered with LILT, whose patented training process enables large language models (LLMs) to adapt neural machine translation (NMT) tools for weather terminology and messaging. Designed for scalability across Weather Forecast Offices (WFOs) and National Centers, the system is currently being developed in Spanish, Simplified Chinese, Vietnamese, and other widely spoken non-English languages. Rooted in best practices for multilingual risk communication, the system provides accurate, timely, and culturally relevant translations, significantly reducing manual translation time and easing operational workloads across the NWS. To guide the distribution of these products, GIS mapping was used to identify language needs across different NWS regions, helping prioritize resources for the communities that need them most. We also integrated ethical AI practices throughout the program's design, ensuring that transparency, fairness, and human oversight guide how automated translations are created, evaluated, and shared with the public. This work has culminated into a website featuring experimental multilingual NWS products, including translated warnings, 7-day forecasts, and educational campaigns, bringing the country one step closer to a national warning system that reaches all Americans.

**AI Summary:** The National Weather Service is using artificial intelligence to develop a comprehensive translation program to better serve non-English speakers in the U.S. This program, powered by large language models and neural machine translation tools, aims to provide accurate and culturally relevant translations, reducing manual translation time and easing operational workloads. By integrating ethical AI practices and using GIS mapping to identify language needs, the NWS is working towards creating a national warning system that reaches all Americans through multilingual products.

---

## Ensembling Large Language Models to Characterize Affective Dynamics in Student-AI Tutor Dialogues
**URL:** https://arxiv.org/abs/2510.13862

**Abstract:** While recent studies have examined the leaning impact of large language model (LLM) in educational contexts, the affective dynamics of LLM-mediated tutoring remain insufficiently understood. This work introduces the first ensemble-LLM framework for large-scale affect sensing in tutoring dialogues, advancing the conversation on responsible pathways for integrating generative AI into education by attending to learners' evolving affective states. To achieve this, we analyzed two semesters' worth of 16,986 conversational turns exchanged between PyTutor, an LLM-powered AI tutor, and 261 undergraduate learners across three U.S. institutions. To investigate learners' emotional experiences, we generate zero-shot affect annotations from three frontier LLMs (Gemini, GPT-4o, Claude), including scalar ratings of valence, arousal, and learning-helpfulness, along with free-text emotion labels. These estimates are fused through rank-weighted intra-model pooling and plurality consensus across models to produce robust emotion profiles. Our analysis shows that during interaction with the AI tutor, students typically report mildly positive affect and moderate arousal. Yet learning is not uniformly smooth: confusion and curiosity are frequent companions to problem solving, and frustration, while less common, still surfaces in ways that can derail progress. Emotional states are short-lived--positive moments last slightly longer than neutral or negative ones, but they are fragile and easily disrupted. Encouragingly, negative emotions often resolve quickly, sometimes rebounding directly into positive states. Neutral moments frequently act as turning points, more often steering students upward than downward, suggesting opportunities for tutors to intervene at precisely these junctures.

**AI Summary:** This research focuses on understanding the affective dynamics in student-AI tutor dialogues using large language models (LLMs). By analyzing conversations between an LLM-powered AI tutor and undergraduate learners, the study found that students typically experience mildly positive affect and moderate arousal during interactions. However, emotional states are short-lived and can easily be disrupted, with confusion and curiosity frequently accompanying problem-solving. The findings highlight the importance of considering learners' evolving affective states in integrating generative AI into education.

---

## BenchPress: A Human-in-the-Loop Annotation System for Rapid Text-to-SQL Benchmark Curation
**URL:** https://arxiv.org/abs/2510.13853

**Abstract:** Large language models (LLMs) have been successfully applied to many tasks, including text-to-SQL generation. However, much of this work has focused on publicly available datasets, such as Fiben, Spider, and Bird. Our earlier work showed that LLMs are much less effective in querying large private enterprise data warehouses and released Beaver, the first private enterprise text-to-SQL benchmark. To create Beaver, we leveraged SQL logs, which are often readily available. However, manually annotating these logs to identify which natural language questions they answer is a daunting task. Asking database administrators, who are highly trained experts, to take on additional work to construct and validate corresponding natural language utterances is not only challenging but also quite costly. To address this challenge, we introduce BenchPress, a human-in-the-loop system designed to accelerate the creation of domain-specific text-to-SQL benchmarks. Given a SQL query, BenchPress uses retrieval-augmented generation (RAG) and LLMs to propose multiple natural language descriptions. Human experts then select, rank, or edit these drafts to ensure accuracy and domain alignment. We evaluated BenchPress on annotated enterprise SQL logs, demonstrating that LLM-assisted annotation drastically reduces the time and effort required to create high-quality benchmarks. Our results show that combining human verification with LLM-generated suggestions enhances annotation accuracy, benchmark reliability, and model evaluation robustness. By streamlining the creation of custom benchmarks, BenchPress offers researchers and practitioners a mechanism for assessing text-to-SQL models on a given domain-specific workload. BenchPress is freely available via our public GitHub repository at this https URL and is also accessible on our website at this http URL.

**AI Summary:** The research introduces BenchPress, a human-in-the-loop annotation system that utilizes large language models (LLMs) to accelerate the creation of domain-specific text-to-SQL benchmarks. By combining LLM-generated suggestions with human verification, BenchPress significantly reduces the time and effort required to create high-quality benchmarks from enterprise SQL logs. This approach enhances annotation accuracy, benchmark reliability, and model evaluation robustness, providing researchers and practitioners with a valuable tool for assessing text-to-SQL models on specific domains.

---

## ConsistencyAI: A Benchmark to Assess LLMs' Factual Consistency When Responding to Different Demographic Groups
**URL:** https://arxiv.org/abs/2510.13852

**Abstract:** Is an LLM telling you different facts than it's telling me? This paper introduces ConsistencyAI, an independent benchmark for measuring the factual consistency of large language models (LLMs) for different personas. ConsistencyAI tests whether, when users of different demographics ask identical questions, the model responds with factually inconsistent answers. Designed without involvement from LLM providers, this benchmark offers impartial evaluation and accountability. In our experiment, we queried 19 LLMs with prompts that requested 5 facts for each of 15 topics. We repeated this query 100 times for each LLM, each time adding prompt context from a different persona selected from a subset of personas modeling the general population. We processed the responses into sentence embeddings, computed cross-persona cosine similarity, and computed the weighted average of cross-persona cosine similarity to calculate factual consistency scores. In 100-persona experiments, scores ranged from 0.9065 to 0.7896, and the mean was 0.8656, which we adopt as a benchmark threshold. xAI's Grok-3 is most consistent, while several lightweight models rank lowest. Consistency varies by topic: the job market is least consistent, G7 world leaders most consistent, and issues like vaccines or the Israeli-Palestinian conflict diverge by provider. These results show that both the provider and the topic shape the factual consistency. We release our code and interactive demo to support reproducible evaluation and encourage persona-invariant prompting strategies.

**AI Summary:** This research introduces ConsistencyAI, a benchmark to measure the factual consistency of large language models (LLMs) across different demographic groups. The experiment involved querying 19 LLMs with prompts from various personas and calculating factual consistency scores based on the responses. The results show variations in consistency based on the provider and topic, with implications for improving the reliability of LLM responses across diverse user groups.

---

## GQVis: A Dataset of Genomics Data Questions and Visualizations for Generative AI
**URL:** https://arxiv.org/abs/2510.13816

**Abstract:** Data visualization is a fundamental tool in genomics research, enabling the exploration, interpretation, and communication of complex genomic features. While machine learning models show promise for transforming data into insightful visualizations, current models lack the training foundation for domain-specific tasks. In an effort to provide a foundational resource for genomics-focused model training, we present a framework for generating a dataset that pairs abstract, low-level questions about genomics data with corresponding visualizations. Building on prior work with statistical plots, our approach adapts to the complexity of genomics data and the specialized representations used to depict them. We further incorporate multiple linked queries and visualizations, along with justifications for design choices, figure captions, and image alt-texts for each item in the dataset. We use genomics data retrieved from three distinct genomics data repositories (4DN, ENCODE, Chromoscope) to produce GQVis: a dataset consisting of 1.14 million single-query data points, 628k query pairs, and 589k query chains. The GQVis dataset and generation code are available at this https URL and this https URL.

**AI Summary:** The research introduces GQVis, a dataset that pairs genomics data questions with visualizations to provide a foundation for training generative AI models in the genomics domain. The dataset includes over 1 million data points, query pairs, and query chains, incorporating multiple linked queries and visualizations with justifications and captions. This resource aims to improve the ability of machine learning models to generate insightful visualizations for complex genomics data, ultimately enhancing research, interpretation, and communication in the field.

---

## Speculating a Tactile Grammar: Toward Task-Aligned Chart Design for Non-Visual Perception
**URL:** https://arxiv.org/abs/2510.13731

**Abstract:** Tactile graphics are often adapted from visual chart designs, yet many of these encodings do not translate effectively to non-visual exploration. Blind and low-vision (BLV) people employ a variety of physical strategies such as measuring lengths with fingers or scanning for texture differences to interpret tactile charts. These observations suggest an opportunity to move beyond direct visual translation and toward a tactile-first design approach. We outline a speculative tactile design framework that explores how data analysis tasks may align with tactile strategies and encoding choices. While this framework is not yet validated, it offers a lens for generating tactile-first chart designs and sets the stage for future empirical exploration. We present speculative mockups to illustrate how the Tactile Perceptual Grammar might guide the design of an accessible COVID-19 dashboard. This scenario illustrates how the grammar can guide encoding choices that better support comparison, trend detection, and proportion estimation in tactile formats. We conclude with design implications and a discussion of future validation through co-design and task-based evaluation.

**AI Summary:** The research explores the development of a tactile-first design approach for creating accessible charts for blind and low-vision individuals. By analyzing how tactile strategies and encoding choices align with data analysis tasks, the study proposes a Tactile Perceptual Grammar to guide the design of tactile graphics. The research suggests that moving beyond direct visual translation can lead to more effective chart designs that support comparison, trend detection, and proportion estimation for non-visual exploration.

---

## Smart UX-design for Rescue Operations Wearable - A Knowledge Graph Informed Visualization Approach for Information Retrieval in Emergency Situations
**URL:** https://arxiv.org/abs/2510.13539

**Abstract:** This paper presents a knowledge graph-informed smart UX-design approach for supporting information retrieval for a wearable, providing treatment recommendations during emergency situations to health professionals. This paper describes requirements that are unique to knowledge graph-based solutions, as well as the direct requirements of health professionals. The resulting implementation is provided for the project, which main goal is to improve first-aid rescue operations by supporting artificial intelligence in situation detection and knowledge graph representation via a contextual-based recommendation for treatment assistance.

**AI Summary:** This research paper introduces a smart UX-design approach for wearables in rescue operations, utilizing knowledge graphs to provide treatment recommendations to health professionals during emergencies. The study outlines the specific requirements for knowledge graph-based solutions and highlights the importance of supporting AI in situation detection and contextual-based treatment assistance to enhance first-aid rescue operations.

---

## Adapting to the User: A Systematic Review of Personalized Interaction in VR
**URL:** https://arxiv.org/abs/2510.13123

**Abstract:** As virtual reality (VR) systems become increasingly more advanced, they are likewise expected to respond intelligently and adapt to individual user states, abilities, and preferences. Recent work has explored how VR can be adapted and tailored to individual users. However, existing reviews tend to address either user-state sensing or adaptive interaction design in isolation, limiting our understanding of their combined implementation in VR. Therefore, in this paper, we examine the growing research on personalized interaction in VR, with a particular focus on utilizing participants' immersion information and adaptation mechanisms to modify virtual environments and enhance engagement, performance, or a specific goal. We synthesize findings from studies that employ adaptive techniques across diverse application domains and summarize a five-stage conceptual framework that unifies adaptive mechanisms across domains. Our analysis reveals emerging trends, including the integration of multimodal sensors, an increasing reliance on user state inference, and the challenge of balancing responsiveness with transparency. We conclude by proposing future directions for developing more user-centered VR systems.

**AI Summary:** This systematic review explores how virtual reality systems can be adapted to individual users by utilizing their immersion information and adaptation mechanisms to enhance engagement, performance, or specific goals. The analysis reveals trends such as the integration of multimodal sensors, reliance on user state inference, and the challenge of balancing responsiveness with transparency. The paper proposes a five-stage conceptual framework to unify adaptive mechanisms across diverse application domains and suggests future directions for developing more user-centered VR systems.

---

## Unmasking Hiring Bias: Platform Data Analysis and Controlled Experiments on Bias in Online Freelance Marketplaces via RAG-LLM Generated Contents
**URL:** https://arxiv.org/abs/2510.13091

**Abstract:** Online freelance marketplaces, a rapidly growing part of the global labor market, are creating a fair environment where professional skills are the main factor for hiring. While these platforms can reduce bias from traditional hiring, the personal information in user profiles raises concerns about ongoing discrimination. Past studies on this topic have mostly used existing data, which makes it hard to control for other factors and clearly see the effect of things like gender or race. To solve these problems, this paper presents a new method that uses Retrieval-Augmented Generation (RAG) with a Large Language Model (LLM) to create realistic, artificial freelancer profiles for controlled experiments. This approach effectively separates individual factors, enabling a clearer statistical analysis of how different variables influence the freelancer project process. In addition to analyzing extracted data with traditional statistical methods for post-project stage analysis, our research utilizes a dataset with highly controlled variables, generated by an RAG-LLM, to conduct a simulated hiring experiment for pre-project stage analysis. The results of our experiments show that, regarding gender, while no significant preference emerged in initial hiring decisions, female freelancers are substantially more likely to receive imperfect ratings post-project stage. Regarding regional bias, a strong and consistent preference favoring US-based freelancers shows that people are more likely to be selected in the simulated experiments, perceived as more leader-like, and receive higher ratings on the live platform.

**AI Summary:** This research explores bias in online freelance marketplaces and presents a new method using RAG-LLM to create artificial freelancer profiles for controlled experiments. The results show that while initial hiring decisions do not show significant gender bias, female freelancers are more likely to receive imperfect ratings post-project. Additionally, US-based freelancers are favored in the hiring process, perceived as more leader-like, and receive higher ratings on the platform. This study highlights the importance of addressing bias in online hiring platforms and the need for more controlled experiments to understand the impact of different variables on the hiring process.

---

## Deliberate Lab: A Platform for Real-Time Human-AI Social Experiments
**URL:** https://arxiv.org/abs/2510.13011

**Abstract:** Social and behavioral scientists increasingly aim to study how humans interact, collaborate, and make decisions alongside artificial intelligence. However, the experimental infrastructure for such work remains underdeveloped: (1) few platforms support real-time, multi-party studies at scale; (2) most deployments require bespoke engineering, limiting replicability and accessibility, and (3) existing tools do not treat AI agents as first-class participants. We present Deliberate Lab, an open-source platform for large-scale, real-time behavioral experiments that supports both human participants and large language model (LLM)-based agents. We report on a 12-month public deployment of the platform (N=88 experimenters, N=9195 experiment participants), analyzing usage patterns and workflows. Case studies and usage scenarios are aggregated from platform users, complemented by in-depth interviews with select experimenters. By lowering technical barriers and standardizing support for hybrid human-AI experimentation, Deliberate Lab expands the methodological repertoire for studying collective decision-making and human-centered AI.

**AI Summary:** The research introduces Deliberate Lab, an open-source platform for conducting large-scale, real-time behavioral experiments involving both human participants and artificial intelligence (AI) agents. The platform addresses the limitations of existing experimental infrastructure by supporting multi-party studies, enhancing replicability and accessibility, and treating AI agents as equal participants. Through a 12-month public deployment involving 88 experimenters and 9195 participants, the study demonstrates the potential of Deliberate Lab to facilitate research on collective decision-making and human-AI interaction, expanding the methodological toolkit for social and behavioral scientists.

---

## Developing and Validating the Arabic Version of the Attitudes Toward Large Language Models Scale
**URL:** https://arxiv.org/abs/2510.13009

**Abstract:** As the use of large language models (LLMs) becomes increasingly global, understanding public attitudes toward these systems requires tools that are adapted to local contexts and languages. In the Arab world, LLM adoption has grown rapidly with both globally dominant platforms and regional ones like Fanar and Jais offering Arabic-specific solutions. This highlights the need for culturally and linguistically relevant scales to accurately measure attitudes toward LLMs in the region. Tools assessing attitudes toward artificial intelligence (AI) can provide a base for measuring attitudes specific to LLMs. The 5-item Attitudes Toward Artificial Intelligence (ATAI) scale, which measures two dimensions, the AI Fear and the AI Acceptance, has been recently adopted and adapted to develop new instruments in English using a sample from the UK: the Attitudes Toward General LLMs (AT-GLLM) and Attitudes Toward Primary LLM (AT-PLLM) scales. In this paper, we translate the two scales, AT-GLLM and AT-PLLM, and validate them using a sample of 249 Arabic-speaking adults. The results show that the scale, translated into Arabic, is a reliable and valid tool that can be used for the Arab population and language. Psychometric analyses confirmed a two-factor structure, strong measurement invariance across genders, and good internal reliability. The scales also demonstrated strong convergent and discriminant validity. Our scales will support research in a non-Western context, a much-needed effort to help draw a global picture of LLM perceptions, and will also facilitate localized research and policy-making in the Arab region.

**AI Summary:** This research developed and validated the Arabic version of the Attitudes Toward General LLMs (AT-GLLM) and Attitudes Toward Primary LLM (AT-PLLM) scales to measure attitudes toward large language models (LLMs) in the Arab world. The results showed that the translated scales are reliable and valid tools for assessing attitudes toward LLMs among Arabic-speaking adults, with strong measurement invariance, internal reliability, and convergent and discriminant validity. This research will support localized research and policy-making in the Arab region and contribute to a better understanding of global perceptions of LLMs.

---

## Deep Learning-Based Visual Fatigue Detection Using Eye Gaze Patterns in VR
**URL:** https://arxiv.org/abs/2510.12994

**Abstract:** Prolonged exposure to virtual reality (VR) systems leads to visual fatigue, impairs user comfort, performance, and safety, particularly in high-stakes or long-duration applications. Existing fatigue detection approaches rely on subjective questionnaires or intrusive physiological signals, such as EEG, heart rate, or eye-blink count, which limit their scalability and real-time applicability. This paper introduces a deep learning-based study for detecting visual fatigue using continuous eye-gaze trajectories recorded in VR. We use the GazeBaseVR dataset comprising binocular eye-tracking data from 407 participants across five immersive tasks, extract cyclopean eye-gaze angles, and evaluate six deep classifiers. Our results demonstrate that EKYT achieves up to 94% accuracy, particularly in tasks demanding high visual attention, such as video viewing and text reading. We further analyze gaze variance and subjective fatigue measures, indicating significant behavioral differences between fatigued and non-fatigued conditions. These findings establish eye-gaze dynamics as a reliable and nonintrusive modality for continuous fatigue detection in immersive VR, offering practical implications for adaptive human-computer interactions.

**AI Summary:** This research paper introduces a deep learning-based approach for detecting visual fatigue in virtual reality (VR) users using eye-gaze patterns. The study shows that the EKYT classifier achieves up to 94% accuracy in detecting fatigue, especially during tasks requiring high visual attention. The findings suggest that eye-gaze dynamics can be a reliable and nonintrusive method for continuous fatigue detection in VR, with practical implications for improving user comfort and performance in immersive applications.

---

## Behavioral Biometrics for Automatic Detection of User Familiarity in VR
**URL:** https://arxiv.org/abs/2510.12988

**Abstract:** As virtual reality (VR) devices become increasingly integrated into everyday settings, a growing number of users without prior experience will engage with VR systems. Automatically detecting a user's familiarity with VR as an interaction medium enables real-time, adaptive training and interface adjustments, minimizing user frustration and improving task performance. In this study, we explore the automatic detection of VR familiarity by analyzing hand movement patterns during a passcode-based door-opening task, which is a well-known interaction in collaborative virtual environments such as meeting rooms, offices, and healthcare spaces. While novice users may lack prior VR experience, they are likely to be familiar with analogous real-world tasks involving keypad entry. We conducted a pilot study with 26 participants, evenly split between experienced and inexperienced VR users, who performed tasks using both controller-based and hand-tracking interactions. Our approach uses state-of-the-art deep classifiers for automatic VR familiarity detection, achieving the highest accuracies of 92.05% and 83.42% for hand-tracking and controller-based interactions, respectively. In the cross-device evaluation, where classifiers trained on controller data were tested using hand-tracking data, the model achieved an accuracy of 78.89%. The integration of both modalities in the mixed-device evaluation obtained an accuracy of 94.19%. Our results underline the promise of using hand movement biometrics for the real-time detection of user familiarity in critical VR applications, paving the way for personalized and adaptive VR experiences.

**AI Summary:** This research explores the use of behavioral biometrics, specifically hand movement patterns, to automatically detect user familiarity with virtual reality (VR) systems. By analyzing hand movements during a passcode-based task, the study found that deep classifiers could accurately detect VR familiarity, with high accuracies achieved for both hand-tracking and controller-based interactions. The results suggest that this approach could enable real-time, adaptive training and interface adjustments in VR applications, improving user experience and task performance.

---

## TaskAudit: Detecting Functiona11ity Errors in Mobile Apps via Agentic Task Execution
**URL:** https://arxiv.org/abs/2510.12972

**Abstract:** Accessibility checkers are tools in support of accessible app development and their use is encouraged by accessibility best practices. However, most current checkers evaluate static or mechanically-generated contexts, failing to capture common accessibility errors impacting mobile app functionality. We present TaskAudit, an accessibility evaluation system that focuses on detecting functiona11ity errors through simulated interactions. TaskAudit comprises three components: a Task Generator that constructs interactive tasks from app screens, a Task Executor that uses agents with a screen reader proxy to perform these tasks, and an Accessibility Analyzer that detects and reports accessibility errors by examining interaction traces. Evaluation on real-world apps shows that our strategy detects 48 functiona11ity errors from 54 app screens, compared to between 4 and 20 with existing checkers. Our analysis demonstrates common error patterns that TaskAudit can detect in addition to prior work, including label-functionality mismatch, cluttered navigation, and inappropriate feedback.

**AI Summary:** The research introduces TaskAudit, a system designed to detect functionality errors in mobile apps through simulated interactions. By using interactive tasks, screen reader proxies, and an Accessibility Analyzer, TaskAudit was able to identify 48 functionality errors in real-world apps, compared to existing checkers which only found between 4 and 20 errors. The study highlights the importance of focusing on functionality errors in mobile app accessibility evaluation and demonstrates the effectiveness of TaskAudit in detecting common error patterns.

---

## Changing Oneself by Teaching Others? Exploring the ProtÃ©gÃ© Effect in Digital Stress Self-Regulation
**URL:** https://arxiv.org/abs/2510.12944

**Abstract:** The protÃ©gÃ©e effect suggests that individuals learn more effectively when they teach a subject. While this has shown potential for acquiring knowledge and skills, can it also support acquiring a new behaviour? This study evaluated a protÃ©gÃ©-based intervention designed to manage digital stress. Over three weeks, 137 participants with moderate to high digital stress were assigned to four groups. Two were protÃ©gÃ©e-based: a passive group, given material to teach, and an active group, received headlines and had to search for and prepare teaching content. Both groups completed three sessions, each focused on one digital stress component: availability demand stress, approval anxiety, and fear of missing out. A digital literacy group received similar content and quizzes, and a control group. Outcomes measured included digital stress, problematic social media use, word-of-mouth about its management, and issue involvement. Findings highlight the challenge of translating cognitive engagement into behavioural change, especially amid persistent digital habits and socially reinforced stressors. Results offer insights into the limitations of interventions based on the protÃ©gÃ©e effect when applied to behaviour change, particularly in the context of reflective digital wellbeing strategies. Future research could explore interactive formats, such as peer engagement or self-regulatory elements, to enhance motivation and impact.

**AI Summary:** This study investigated whether the protÃ©gÃ©e effect, where individuals learn by teaching others, could be used to help individuals manage digital stress. Participants were assigned to different groups, including a protÃ©gÃ©e-based intervention group, a digital literacy group, and a control group. The findings suggest that while cognitive engagement through teaching can be effective in acquiring knowledge and skills, it may not always translate into behavioral change, especially in the context of digital stress management. Future research could explore interactive formats to enhance motivation and impact in digital wellbeing strategies.

---

## DIGITWISE: Digital Twin-based Modeling of Adaptive Video Streaming Engagement
**URL:** https://arxiv.org/abs/2510.13267

**Abstract:** As the popularity of video streaming entertainment continues to grow, understanding how users engage with the content and react to its changes becomes a critical success factor for every stakeholder. User engagement, i.e., the percentage of video the user watches before quitting, is central to customer loyalty, content personalization, ad relevance, and A/B testing. This paper presents DIGITWISE, a digital twin-based approach for modeling adaptive video streaming engagement. Traditional adaptive bitrate (ABR) algorithms assume that all users react similarly to video streaming artifacts and network issues, neglecting individual user sensitivities. DIGITWISE leverages the concept of a digital twin, a digital replica of a physical entity, to model user engagement based on past viewing sessions. The digital twin receives input about streaming events and utilizes supervised machine learning to predict user engagement for a given session. The system model consists of a data processing pipeline, machine learning models acting as digital twins, and a unified model to predict engagement. DIGITWISE employs the XGBoost model in both digital twins and unified models. The proposed architecture demonstrates the importance of personal user sensitivities, reducing user engagement prediction error by up to 5.8% compared to non-user-aware models. Furthermore, DIGITWISE can optimize content provisioning and delivery by identifying the features that maximize engagement, providing an average engagement increase of up to 8.6%.

**AI Summary:** The paper introduces DIGITWISE, a digital twin-based approach for modeling adaptive video streaming engagement. Traditional adaptive bitrate algorithms do not account for individual user sensitivities, but DIGITWISE leverages digital twins to predict user engagement based on past viewing sessions. The system reduces prediction error by up to 5.8% and can optimize content delivery, leading to an average engagement increase of up to 8.6%.

---

## NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models
**URL:** https://arxiv.org/abs/2510.13068

**Abstract:** Electroencephalography (EEG) captures neural activity across multiple temporal and spectral scales, yielding signals that are rich but complex for representation learning. Recently, EEG foundation models trained to predict masked signal-tokens have shown promise for learning generalizable representations. However, their performance is hindered by their signal tokenization modules. Existing neural tokenizers fail to preserve high-frequency dynamics, limiting their ability to reconstruct EEG signals with high fidelity. We introduce NeuroRVQ, a scalable Large Brainwave Model (LBM) centered on a codebook-based tokenizer. Our tokenizer integrates: (i) multi-scale feature extraction modules that capture the full frequency neural spectrum; (ii) hierarchical residual vector quantization (RVQ) codebooks for high-resolution encoding; and, (iii) an EEG signal phase- and amplitude-aware loss function for efficient training. This design enables efficient EEG compression while supporting accurate reconstruction across all frequency bands, leading to robust generative masked modeling. Our empirical results demonstrate that NeuroRVQ achieves lower reconstruction error and outperforms existing LBMs on a variety of downstream tasks. More broadly, NeuroRVQ tokenizer establishes a strong prior for codebook-based general-purpose brainwave models, enabling advances in neural decoding, generative modeling and multimodal biosignal integration.

**AI Summary:** The NeuroRVQ model is introduced as a scalable Large Brainwave Model (LBM) that utilizes a codebook-based tokenizer to capture the full frequency neural spectrum and enable accurate reconstruction of EEG signals with high fidelity. This design improves EEG compression efficiency and outperforms existing LBMs on various downstream tasks, showcasing its potential for advances in neural decoding, generative modeling, and multimodal biosignal integration.

---

## Data-Model Co-Evolution: Growing Test Sets to Refine LLM Behavior
**URL:** https://arxiv.org/abs/2510.12728

**Abstract:** A long-standing challenge in machine learning has been the rigid separation between data work and model refinement, enforced by slow fine-tuning cycles. The rise of Large Language Models (LLMs) overcomes this historical barrier, allowing applications developers to instantly govern model behavior by editing prompt instructions. This shift enables a new paradigm: data-model co-evolution, where a living test set and a model's instructions evolve in tandem. We operationalize this paradigm in an interactive system designed to address the critical challenge of encoding subtle, domain-specific policies into prompt instructions. The system's structured workflow guides people to discover edge cases, articulate rationales for desired behavior, and iteratively evaluate instruction revisions against a growing test set. A user study shows our workflow helps participants refine instructions systematically and specify ambiguous policies more concretely. This work points toward more robust and responsible LLM applications through human-in-the-loop development aligned with local preferences and policies.

**AI Summary:** This research introduces a new paradigm of data-model co-evolution in machine learning, enabled by Large Language Models (LLMs), where developers can instantly refine model behavior by editing prompt instructions. The interactive system designed in this study guides users to discover edge cases, articulate rationales for desired behavior, and iteratively evaluate instruction revisions against a growing test set. A user study demonstrates that this workflow helps participants systematically refine instructions and specify ambiguous policies more concretely, leading to more robust and responsible LLM applications aligned with local preferences and policies.

---

## Who is a Better Matchmaker? Human vs. Algorithmic Judge Assignment in a High-Stakes Startup Competition
**URL:** https://arxiv.org/abs/2510.12692

**Abstract:** There is growing interest in applying artificial intelligence (AI) to automate and support complex decision-making tasks. However, it remains unclear how algorithms compare to human judgment in contexts requiring semantic understanding and domain expertise. We examine this in the context of the judge assignment problem, matching submissions to suitably qualified judges. Specifically, we tackled this problem at the Harvard President's Innovation Challenge, the university's premier venture competition awarding over \$500,000 to student and alumni startups. This represents a real-world environment where high-quality judge assignment is essential. We developed an AI-based judge-assignment algorithm, Hybrid Lexical-Semantic Similarity Ensemble (HLSE), and deployed it at the competition. We then evaluated its performance against human expert assignments using blinded match-quality scores from judges on $309$ judge-venture pairs. Using a Mann-Whitney U statistic based test, we found no statistically significant difference in assignment quality between the two approaches ($AUC=0.48, p=0.40$); on average, algorithmic matches are rated $3.90$ and manual matches $3.94$ on a 5-point scale, where 5 indicates an excellent match. Furthermore, manual assignments that previously required a full week could be automated in several hours by the algorithm during deployment. These results demonstrate that HLSE achieves human-expert-level matching quality while offering greater scalability and efficiency, underscoring the potential of AI-driven solutions to support and enhance human decision-making for judge assignment in high-stakes settings.

**AI Summary:** This research compares the performance of an AI-based judge-assignment algorithm, HLSE, to human expert assignments in a high-stakes startup competition at Harvard. The study found no statistically significant difference in assignment quality between the two approaches, with the algorithm achieving human-expert-level matching quality. Additionally, the algorithm was able to automate assignments that previously took a week for humans to complete in just a few hours, demonstrating the potential of AI-driven solutions to enhance decision-making in high-stakes settings.

---

## Gauging the Competition: Understanding Social Comparison and Anxiety through Eye-tracking in Virtual Reality Group Interview
**URL:** https://arxiv.org/abs/2510.12590

**Abstract:** Virtual Reality (VR) is a promising tool for interview training, yet the psychological dynamics of group interviews, such as social comparison, remain underexplored. We investigate this phenomenon by developing an immersive VR group interview system and conducting an eye-tracking study with 73 participants. We manipulated peer performance using ambiguous behavioral cues (e.g., hand-raising) and objective information (public test scores) to measure their effect on participants' attention and self-concept. Our results demonstrate a "Big-Fish-Little-Pond Effect" in VR: an increase in high-achieving peer behaviors heightened participants' processing of social comparison information and significantly lowered their self-assessments. The introduction of objective scores further intensified these comparative behaviors. We also found that lower perceived realism of the VR environment correlated with higher anxiety. These findings offer key insights and design considerations for creating more effective and psychologically-aware virtual training environments that account for complex social dynamics.

**AI Summary:** This study used virtual reality to explore the impact of social comparison on participants in group interviews. The results showed that high-achieving peer behaviors increased participants' focus on social comparison information and lowered their self-assessments, with objective scores intensifying these effects. The study also found that lower perceived realism in the VR environment was associated with higher anxiety, highlighting the importance of creating psychologically-aware virtual training environments.

---

## Hey Dashboard!: Supporting Voice, Text, and Pointing Modalities in Dashboard Onboarding
**URL:** https://arxiv.org/abs/2510.12386

**Abstract:** Visualization dashboards are regularly used for data exploration and analysis, but their complex interactions and interlinked views often require time-consuming onboarding sessions from dashboard authors. Preparing these onboarding materials is labor-intensive and requires manual updates when dashboards change. Recent advances in multimodal interaction powered by large language models (LLMs) provide ways to support self-guided onboarding. We present DIANA (Dashboard Interactive Assistant for Navigation and Analysis), a multimodal dashboard assistant that helps users for navigation and guided analysis through chat, audio, and mouse-based interactions. Users can choose any interaction modality or a combination of them to onboard themselves on the dashboard. Each modality highlights relevant dashboard features to support user orientation. Unlike typical LLM systems that rely solely on text-based chat, DIANA combines multiple modalities to provide explanations directly in the dashboard interface. We conducted a qualitative user study to understand the use of different modalities for different types of onboarding tasks and their complexities.

**AI Summary:** The research explores the use of multimodal interaction, including chat, audio, and mouse-based interactions, to support self-guided onboarding in visualization dashboards. The DIANA system allows users to choose their preferred modality or a combination of them to navigate and analyze dashboard features, improving user orientation. Unlike traditional text-based chat systems, DIANA provides explanations directly within the dashboard interface, making onboarding more efficient and user-friendly.

---

