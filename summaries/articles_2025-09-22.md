# arXiv cs.AI Summary â€“ 2025-09-22

## Designing Culturally Aligned AI Systems For Social Good in Non-Western Contexts
**URL:** https://arxiv.org/abs/2509.16158

**Abstract:** AI technologies are increasingly deployed in high-stakes domains such as education, healthcare, law, and agriculture to address complex challenges in non-Western contexts. This paper examines eight real-world deployments spanning seven countries and 18 languages, combining 17 interviews with AI developers and domain experts with secondary research. Our findings identify six cross-cutting factors - Language, Domain, Demography, Institution, Task, and Safety - that structured how systems were designed and deployed. These factors were shaped by sociocultural (diversity, practices), institutional (resources, policies), and technological (capabilities, limits) influences. We find that building AI systems required extensive collaboration between AI developers and domain experts. Notably, human resources proved more critical to achieving safe and effective systems in high-stakes domains than technological expertise alone. We present an analytical framework that synthesizes these dynamics and conclude with recommendations for designing AI for social good systems that are culturally grounded, equitable, and responsive to the needs of non-Western contexts.

**AI Summary:** This research paper examines the deployment of AI technologies in non-Western contexts across various domains and languages. The study identifies six key factors that influence the design and deployment of AI systems, highlighting the importance of collaboration between AI developers and domain experts. The findings emphasize the significance of human resources in creating safe and effective AI systems in high-stakes domains, and recommend a culturally grounded approach to designing AI for social good in non-Western contexts.

---

## AnchoredAI: Contextual Anchoring of AI Comments Improves Writer Agency and Ownership
**URL:** https://arxiv.org/abs/2509.16128

**Abstract:** Generative AI is increasingly integrated into writing support, yet current chat-based interfaces often obscure referential context and risk amplifying automation bias and overreliance. We introduce AnchoredAI, a novel system that anchors AI feedback directly to relevant text spans. AnchoredAI implements two key mechanisms: (1) an Anchoring Context Window (ACW) that maintains unique, context-rich references, and (2) an update-aware context retrieval method that preserves the intent of prior comments after document edits. In a controlled user study, we compared AnchoredAI to a chat-based LLM interface. Results show that AnchoredAI led to more targeted revisions while fostering a stronger agency metrics (e.g., control and ownership) among writers. These findings highlight how interface design shapes AI-assisted writing, suggesting that anchoring can mitigate overreliance and enable more precise, user-driven revision practices.

**AI Summary:** The research introduces AnchoredAI, a system that anchors AI feedback directly to relevant text spans to improve writer agency and ownership in writing support. The study compared AnchoredAI to a chat-based LLM interface and found that AnchoredAI led to more targeted revisions and fostered stronger agency metrics among writers. The findings suggest that interface design, such as anchoring AI feedback, can mitigate overreliance on AI and enable more precise, user-driven revision practices.

---

## A Systematic Survey of Empirical User Studies of Unintentional Information Disclosure in Everyday Digital Interaction
**URL:** https://arxiv.org/abs/2509.16003

**Abstract:** The exchange of personal information in digital environments poses significant risks, including identity theft, privacy breaches, and data misuse. Addressing these challenges requires a deep understanding of user behavior and mental models in diverse contexts. This paper presents a systematic literature review of empirical user studies on unintentional information disclosure in usable security, covering 101 papers published across six leading conferences from 2018 to 2023. The studies are categorized based on methodologies-quantitative and qualitative-and analyzed for their applications in various scenarios. Major subtopics, including data privacy, security in browsers, and privacy tools, are examined to highlight research trends and focal areas. This review provides details on topics and application areas that have received the most research attention. Moreover, by comparing descriptive and experimental approaches, findings aim to guide researchers of strategies to mitigate risks associated with online everyday interaction.

**AI Summary:** This paper presents a systematic review of empirical user studies on unintentional information disclosure in digital environments, focusing on user behavior and mental models in diverse contexts. The review covers 101 papers published across leading conferences from 2018 to 2023, categorizing studies based on methodologies and analyzing their applications in various scenarios. The review highlights research trends in data privacy, security in browsers, and privacy tools, providing insights for researchers on strategies to mitigate risks associated with online interaction.

---

## Explainable AI for Maritime Autonomous Surface Ships (MASS): Adaptive Interfaces and Trustworthy Human-AI Collaboration
**URL:** https://arxiv.org/abs/2509.15959

**Abstract:** Autonomous navigation in maritime domains is accelerating alongside advances in artificial intelligence, sensing, and connectivity. Opaque decision-making and poorly calibrated human-automation interaction remain key barriers to safe adoption. This article synthesizes 100 studies on automation transparency for Maritime Autonomous Surface Ships (MASS) spanning situation awareness (SA), human factors, interface design, and regulation. We (i) map the Guidance-Navigation-Control stack to shore-based operational modes -- remote supervision (RSM) and remote control (RCM) -- and identify where human unsafe control actions (Human-UCAs) concentrate in handover and emergency loops; (ii) summarize evidence that transparency features (decision rationales, alternatives, confidence/uncertainty, and rule-compliance indicators) improve understanding and support trust calibration, though reliability and predictability often dominate trust; (iii) distill design strategies for transparency at three layers: sensor/SA acquisition and fusion, HMI/eHMI presentation (textual/graphical overlays, color coding, conversational and immersive UIs), and engineer-facing processes (resilient interaction design, validation, and standardization). We integrate methods for Human-UCA identification (STPA-Cog + IDAC), quantitative trust/SA assessment, and operator workload monitoring, and outline regulatory and rule-based implications including COLREGs formalization and route exchange. We conclude with an adaptive transparency framework that couples operator state estimation with explainable decision support to reduce cognitive overload and improve takeover timeliness. The review highlights actionable figure-of-merit displays (e.g., CPA/TCPA risk bars, robustness heatmaps), transparent model outputs (rule traceability, confidence), and training pipelines (HIL/MIL, simulation) as near-term levers for safer MASS operations.

**AI Summary:** This research article explores the importance of transparency in decision-making for Maritime Autonomous Surface Ships (MASS) to ensure safe adoption. The study synthesizes 100 research studies on automation transparency, highlighting the need for explainable AI features such as decision rationales, confidence indicators, and rule-compliance indicators to improve understanding and trust calibration. The article proposes a framework for adaptive transparency that combines operator state estimation with explainable decision support to reduce cognitive overload and improve takeover timeliness, emphasizing the use of actionable displays, transparent model outputs, and training pipelines for safer MASS operations.

---

## Understanding the Role of Large Language Models in Competitive Programming
**URL:** https://arxiv.org/abs/2509.15867

**Abstract:** This paper investigates how large language models (LLMs) are reshaping competitive programming. The field functions as an intellectual contest within computer science education and is marked by rapid iteration, real-time feedback, transparent solutions, and strict integrity norms. Prior work has evaluated LLMs performance on contest problems, but little is known about how human stakeholders -- contestants, problem setters, coaches, and platform stewards -- are adapting their workflows and contest norms under LLMs-induced shifts. At the same time, rising AI-assisted misuse and inconsistent governance expose urgent gaps in sustaining fairness and credibility. Drawing on 37 interviews spanning all four roles and a global survey of 207 contestants, we contribute: (i) an empirical account of evolving workflows, (ii) an analysis of contested fairness norms, and (iii) a chess-inspired governance approach with actionable measures -- real-time LLMs checks in online contests, peer co-monitoring and reporting, and cross-validation against offline performance -- to curb LLMs-assisted misuse while preserving fairness, transparency, and credibility.

**AI Summary:** This research paper explores the impact of large language models (LLMs) on competitive programming, a field within computer science education characterized by rapid iteration and strict integrity norms. The study investigates how human stakeholders in competitive programming are adapting their workflows and contest norms in response to LLMs. The findings highlight the need for measures to address AI-assisted misuse and ensure fairness, transparency, and credibility in competitive programming contests.

---

## Relational Dissonance in Human-AI Interactions: The Case of Knowledge Work
**URL:** https://arxiv.org/abs/2509.15836

**Abstract:** When AI systems allow human-like communication, they elicit increasingly complex relational responses. Knowledge workers face a particular challenge: They approach these systems as tools while interacting with them in ways that resemble human social interaction. To understand the relational contexts that arise when humans engage with anthropomorphic conversational agents, we need to expand existing human-computer interaction frameworks. Through three workshops with qualitative researchers, we found that the fundamental ontological and relational ambiguities inherent in anthropomorphic conversational agents make it difficult for individuals to maintain consistent relational stances toward them. Our findings indicate that people's articulated positioning toward such agents often differs from the relational dynamics that occur during interactions. We propose the concept of relational dissonance to help researchers, designers, and policymakers recognize the resulting tensions in the development, deployment, and governance of anthropomorphic conversational agents and address the need for relational transparency.

**AI Summary:** This research explores the complexities of human-AI interactions in knowledge work, particularly when AI systems exhibit human-like communication. The study found that individuals often struggle to maintain consistent relational stances towards anthropomorphic conversational agents, leading to relational dissonance. The concept of relational dissonance is proposed to address the tensions that arise in the development, deployment, and governance of such AI systems, highlighting the need for relational transparency in human-computer interaction frameworks.

---

## Campus AI vs. Commercial AI: How Customizations Shape Trust and Usage of LLM as-a-Service Chatbots
**URL:** https://arxiv.org/abs/2509.15826

**Abstract:** As the use of LLM chatbots by students and researchers becomes more prevalent, universities are pressed to develop AI strategies. One strategy that many universities pursue is to customize pre-trained LLM as-a-service (LLMaaS). While most studies on LLMaaS chatbots prioritize technical adaptations, we focus on psychological effects of user-salient customizations, such as interface changes. We assume that such customizations influence users' perception of the system and are therefore important in guiding safe and appropriate use. In a field study, we examine how students and employees (N = 526) at a German university perceive and use their institution's customized LLMaaS chatbot compared to ChatGPT. Participants using both systems (n = 116) reported greater trust, higher perceived privacy and less experienced hallucinations with their university's customized LLMaaS chatbot in contrast to ChatGPT. We discuss theoretical implications for research on calibrated trust, and offer guidance on the design and deployment of LLMaaS chatbots.

**AI Summary:** The research study examines the impact of customizations on the trust and usage of LLM chatbots in a university setting compared to commercial chatbots like ChatGPT. The findings suggest that user-salient customizations, such as interface changes, can significantly influence users' perception of the system, leading to greater trust, higher perceived privacy, and fewer experienced hallucinations. This highlights the importance of considering psychological effects in the design and deployment of LLMaaS chatbots to guide safe and appropriate use.

---

## Affective Air Quality Dataset: Personal Chemical Emissions from Emotional Videos
**URL:** https://arxiv.org/abs/2509.15774

**Abstract:** Inspired by the role of chemosignals in conveying emotional states, this paper introduces the Affective Air Quality (AAQ) dataset, a novel dataset collected to explore the potential of volatile odor compound and gas sensor data for non-contact emotion detection. This dataset bridges the gap between the realms of breath \& body odor emission (personal chemical emissions) analysis and established practices in affective computing. Comprising 4-channel gas sensor data from 23 participants at two distances from the body (wearable and desktop), alongside emotional ratings elicited by targeted movie clips, the dataset encapsulates initial groundwork to analyze the correlation between personal chemical emissions and varied emotional responses. The AAQ dataset also provides insights drawn from exit interviews, thereby painting a holistic picture of perceptions regarding air quality monitoring and its implications for privacy. By offering this dataset alongside preliminary attempts at emotion recognition models based on it to the broader research community, we seek to advance the development of odor-based affect recognition models that prioritize user privacy and comfort.

**AI Summary:** This research introduces the Affective Air Quality (AAQ) dataset, which explores the potential of volatile odor compound and gas sensor data for non-contact emotion detection. The dataset includes gas sensor data from participants at different distances from the body, along with emotional ratings from movie clips, to analyze the correlation between personal chemical emissions and emotional responses. The study aims to advance the development of odor-based affect recognition models that prioritize user privacy and comfort.

---

## Leveraging Familiarity with Television to Enrich Older Adults' Engagement and Wellbeing: A Feasibility Study Using Video Probes
**URL:** https://arxiv.org/abs/2509.15618

**Abstract:** The shift away from multigenerational families to nuclear families in India has created a growing need to support older adults living independently. While technology can help address this gap, older adults' limited exposure to newer technology restricts the adoption of such solutions. However, they remain comfortable with long-standing technologies like television (TV). This study explores their daily technology usage and challenges, aiming to determine whether TV can be leveraged to improve their quality of life. We examined how TV systems could be enhanced to assist older adults with tasks such as staying connected, receiving health alerts, and ensuring security. Using a participatory design approach, we developed video probes using the prototype of the TV-based application and interviewed 27 older adults to assess its acceptance and usability. Our findings demonstrate older adults' strong interest in a TV-based solution and a preference for familiar technology to support security, independence, and wellbeing.

**AI Summary:** This study investigates the feasibility of using television technology to improve the quality of life for older adults in India who are more familiar with traditional technologies like TV. The research shows that older adults have a strong interest in using TV-based solutions for tasks such as staying connected, receiving health alerts, and ensuring security, highlighting the potential of leveraging familiar technology to enhance their engagement and wellbeing. The findings suggest that incorporating familiar technology like TV into solutions for older adults can help bridge the gap created by the shift towards nuclear families and limited exposure to newer technologies.

---

## Process-Driven Visual Analysis of Cybersecurity Capture the Flag Exercises
**URL:** https://arxiv.org/abs/2509.15589

**Abstract:** Hands-on training sessions become a standard way to develop and increase knowledge in cybersecurity. As practical cybersecurity exercises are strongly process-oriented with knowledge-intensive processes, process mining techniques and models can help enhance learning analytics tools. The design of our open-source analytical dashboard is backed by guidelines for visualizing multivariate networks complemented with temporal views and clustering. The design aligns with the requirements for post-training analysis of a special subset of cybersecurity exercises -- supervised Capture the Flag games. Usability is demonstrated in a case study using trainees' engagement measurement to reveal potential flaws in training design or organization.

**AI Summary:** This research focuses on using process mining techniques and models to enhance learning analytics tools for cybersecurity training exercises, specifically supervised Capture the Flag games. The development of an open-source analytical dashboard with visualizations of multivariate networks, temporal views, and clustering helps to identify potential flaws in training design or organization by measuring trainees' engagement. This approach aims to improve the effectiveness of hands-on cybersecurity training sessions by providing insights into knowledge-intensive processes.

---

## Designing with Culture: How Social Norms Shape Trust and Preference in Health Chatbots
**URL:** https://arxiv.org/abs/2509.15575

**Abstract:** AI-driven chatbots are increasingly used to support community health workers (CHWs) in developing regions, yet little is known about how cultural framings in chatbot design shape trust in collectivist contexts where decisions are rarely made in isolation. This paper examines how CHWs in rural India responded to chatbots that delivered identical health content but varied in one specific cultural lever -- social norms. Through a mixed-methods study with 61 ASHAs who compared four normative framings -- neutral, descriptive, narrative identity, and injunctive authority -- we (1) analyze how framings influence preferences and trust, and (2) compare effects across low- and high-ambiguity scenarios. Results show that narrative framings were most preferred but encouraged uncritical overreliance, while authority framings were least preferred yet supported calibrated trust. We conclude with design recommendations for dynamic framing strategies that adapt to context and argue for calibrated trust -- following correct advice and resisting incorrect advice -- as a critical evaluation metric for safe, culturally-grounded AI.

**AI Summary:** This research explores how cultural framings in chatbot design impact trust and preference among community health workers in rural India. The study found that narrative framings were most preferred but led to uncritical reliance, while authority framings were least preferred but supported calibrated trust. The findings suggest the importance of dynamic framing strategies that adapt to context and emphasize calibrated trust as a key evaluation metric for culturally-grounded AI in healthcare settings.

---

## In-Ear Electrode EEG for Practical SSVEP BCI
**URL:** https://arxiv.org/abs/2509.15449

**Abstract:** Steady State Visual Evoked Potential (SSVEP) methods for brain computer interfaces (BCI) are popular due to higher information transfer rate and easier setup with minimal training, compared to alternative methods. With precisely generated visual stimulus frequency, it is possible to translate brain signals into external actions or signals. Traditionally, SSVEP data is collected from the occipital region using electrodes with or without gel, normally mounted on a head cap. In this experimental study, we develop an in ear electrode to collect SSVEP data for four different flicker frequencies and compare against occipital scalp electrode data. Data from five participants demonstrates the feasibility of in-ear electrode based SSVEP, significantly enhancing the practicability of wearable BCI applications.

**AI Summary:** This research study explores the use of in-ear electrodes for collecting SSVEP data in brain computer interfaces, comparing it to traditional occipital scalp electrodes. The results show that in-ear electrodes are feasible and effective for capturing SSVEP data for different flicker frequencies, making wearable BCI applications more practical and user-friendly. This study highlights the potential for in-ear electrodes to improve the ease of setup and information transfer rate in SSVEP-based BCIs.

---

## Where Do I 'Add the Egg'?: Exploring Agency and Ownership in AI Creative Co-Writing Systems
**URL:** https://arxiv.org/abs/2509.15440

**Abstract:** AI co-writing systems challenge long held ideals about agency and ownership in the creative process, thereby hindering widespread adoption. In order to address this, we investigate conceptions of agency and ownership in AI creative co-writing. Drawing on insights from a review of commercial systems, we developed three co-writing systems with identical functionality but distinct interface metaphors: agentic, tool-like, and magical. Through interviews with professional and non-professional writers (n = 18), we explored how these metaphors influenced participants' sense of control and authorship. Our analysis resulted in a taxonomy of agency and ownership subtypes and underscore how tool-like metaphors shift writers' expected points of control while agentic metaphors foreground conceptual contributions. We argue that interface metaphors not only guide expectations of control but also frame conceptions of authorship. We conclude with recommendations for the design of AI co-writing systems, emphasizing how metaphor shapes user experience and creative practice.

**AI Summary:** This research explores the impact of different interface metaphors on the sense of agency and ownership in AI creative co-writing systems. By developing three systems with different metaphors and conducting interviews with writers, the study found that metaphors influence users' sense of control and authorship. The findings suggest that interface design plays a crucial role in shaping user experience and creative practice in AI co-writing systems.

---

## Beyond Community Notes: A Framework for Understanding and Building Crowdsourced Context Systems
**URL:** https://arxiv.org/abs/2509.15434

**Abstract:** Social media platforms are increasingly developing features that display crowdsourced context alongside posts, modeled after X's Community Notes. These systems, which we term Crowdsourced Context Systems (CCS), have the potential to reshape our information ecosystem as major platforms embrace them as alternatives to top-down fact-checking. To deeply understand the features and implications of such systems, we perform a systematic literature review of existing CCS research and analyze several real-world CSS implementations. Based on our analysis, we develop a framework with three distinct components. First, we present a theoretical model to help conceptualize and define CCS. Second, we identify a design space encompassing six key aspects of CCS: participation, inputs, curation, presentation, platform treatment, and transparency. Third, we identify key normative implications of different CCS design and implementation choices. Our framework integrates these theoretical, design, and ethical perspectives to establish a foundation for future human-centered research on Crowdsourced Context Systems.

**AI Summary:** The research explores Crowdsourced Context Systems (CCS) on social media platforms, which display user-generated context alongside posts. The study includes a literature review and analysis of real-world implementations to develop a framework with three components: a theoretical model, a design space covering six key aspects, and normative implications of design choices. This framework provides a foundation for future research on CCS, which have the potential to reshape the information ecosystem as an alternative to top-down fact-checking.

---

## Re-imagining Behavioral Sleep Medicine: Designing Conversational Sleep Diary and Visualization Tool
**URL:** https://arxiv.org/abs/2509.15378

**Abstract:** The sleep diary is a widely used clinical tool for understanding sleep disorders; however, low patient compliance and limited capture of contextual information constrain its effectiveness and leave specialists with an incomplete picture of patients' sleep-related behaviors. In this work, we re-imagine Behavioral Sleep Medicine (BSM) by designing a voice-based conversational sleep diary and specialist-facing visualization tool. Through this design process, we probed specialists' vision of how conversational agents (CAs) could extend beyond diary intake to enhance behavioral sleep medicine. Our multi-stage approach included: (1) interviews with specialists to identify shortcomings in current use of text-based diaries, (2) iterative co-design of a conversational diary and visualization tool, and (3) focus groups to explore the broader potential of CAs in BSM. This work contributes design insights into how CAs can support behavioral interventions, highlights opportunities and challenges for integration into practice, and expands the design space of CAs for behavioral health.

**AI Summary:** This research explores the limitations of traditional text-based sleep diaries in Behavioral Sleep Medicine (BSM) and proposes a voice-based conversational sleep diary and visualization tool to improve patient compliance and capture more contextual information. The study involved interviews with specialists to identify shortcomings, co-design of the new tools, and focus groups to explore the broader potential of conversational agents in BSM. The findings suggest that conversational agents can enhance behavioral interventions in sleep medicine and offer new opportunities for integrating AI technology into clinical practice.

---

## Experience Level Influences User's Criteria for Avatar Animation Realism
**URL:** https://arxiv.org/abs/2509.15372

**Abstract:** The sense of realism in avatar animation is a widely pursued goal in social VR applications. A common approach to enhancing realism is improving the match between avatar motion and real-world human movement. However, experience with existing VR platforms may reshape users' expectations, suggesting that matching reality is not the only path to enhancing the sense of realism. This study examines how different levels of experience with a social VR platform influence users' criteria for evaluating the realism of avatar animation. Participants were shown a set of animations varying in the degree they reflected real-world motion and motion seen on the social VR platform VRChat. Results showed that users with no VRChat experience found animations recorded on VRChat unnatural and unrealistic, but experienced users in fact rated these animations as more likely to come from a real person than the motion-capture animations. Additionally, highly experienced users recognized the intent to imitate VRChat's style and noted the differences from genuine in-platform animations. All these results suggest users' expectations of and criteria for realistic animation were shaped by their experience level. The findings support the idea that realism in avatar animation does not solely depend on mimicking real-world movement. Experience with VR platforms can shape how users expect, perceive, and evaluate animation realism. This insight can inform the design of more immersive VR environments and virtual humans in the future.

**AI Summary:** This study explores how experience level with a social VR platform influences users' perceptions of avatar animation realism. Results show that users with no experience found animations from the platform unnatural, while experienced users rated them as more realistic than motion-capture animations. The findings suggest that users' expectations and criteria for realistic animation are shaped by their experience, highlighting the importance of considering user experience in designing immersive VR environments.

---

## Collective Voice: Recovered-Peer Support Mediated by An LLM-Based Chatbot for Eating Disorder Recovery
**URL:** https://arxiv.org/abs/2509.15289

**Abstract:** Peer recovery narratives provide unique benefits beyond professional or lay mentoring by fostering hope and sustained recovery in eating disorder (ED) contexts. Yet, such support is limited by the scarcity of peer-involved programs and potential drawbacks on recovered peers, including relapse risk. To address this, we designed RecoveryTeller, a chatbot adopting a recovered-peer persona that portrays itself as someone recovered from an ED. We examined whether such a persona can reproduce the support affordances of peer recovery narratives. We compared RecoveryTeller with a lay-mentor persona chatbot offering similar guidance but without a recovery background. We conducted a 20-day cross-over deployment study with 26 ED participants, each using both chatbots for 10 days. RecoveryTeller elicited stronger emotional resonance than a lay-mentor chatbot, yet tensions between emotional and epistemic trust led participants to view the two personas as complementary rather than substitutes. We provide design implications for mental health chatbot persona design.

**AI Summary:** The research explores the use of a chatbot, named RecoveryTeller, adopting a recovered-peer persona to provide support for individuals with eating disorders. The study found that the chatbot elicited stronger emotional resonance compared to a lay-mentor chatbot, indicating the potential benefits of using a recovered-peer persona for support. However, participants viewed the two personas as complementary rather than substitutes, suggesting that a combination of emotional and epistemic trust is important in mental health chatbot design.

---

## Subject Matter Expertise vs Professional Management in Collective Sequential Decision Making
**URL:** https://arxiv.org/abs/2509.15263

**Abstract:** Your company's CEO is retiring. You search for a successor. You can promote an employee from the company familiar with the company's operations, or recruit an external professional manager. Who should you prefer? It has not been clear how to address this question, the "subject matter expertise vs. professional manager debate", quantitatively and objectively. We note that a company's success depends on long sequences of interdependent decisions, with often-opposing recommendations of diverse board members. To model this task in a controlled environment, we utilize chess - a complex, sequential game with interdependent decisions which allows for quantitative analysis of performance and expertise (since the states, actions and game outcomes are well-defined). The availability of chess engines differing in style and expertise, allows scalable experimentation. We considered a team of (computer) chess players. At each turn, team members recommend a move and a manager chooses a recommendation. We compared the performance of two manager types. For manager as "subject matter expert", we used another (computer) chess player that assesses the recommendations of the team members based on its own chess expertise. We examined the performance of such managers at different strength levels. To model a "professional manager", we used Reinforcement Learning (RL) to train a network that identifies the board positions in which different team members have relative advantage, without any pretraining in chess. We further examined this network to see if any chess knowledge is acquired implicitly. We found that subject matter expertise beyond a minimal threshold does not significantly contribute to team synergy. Moreover, performance of a RL-trained "professional" manager significantly exceeds that of even the best "expert" managers, while acquiring only limited understanding of chess.

**AI Summary:** This research compares the performance of subject matter expert managers and professional managers in collective decision-making using a chess model. The study found that professional managers trained through reinforcement learning outperformed expert managers, even without prior chess knowledge. This suggests that in complex decision-making scenarios, professional management may be more effective than relying solely on subject matter expertise.

---

## A Matter of Height: The Impact of a Robotic Object on Human Compliance
**URL:** https://arxiv.org/abs/2509.16032

**Abstract:** Robots come in various forms and have different characteristics that may shape the interaction with them. In human-human interactions, height is a characteristic that shapes human dynamics, with taller people typically perceived as more persuasive. In this work, we aspired to evaluate if the same impact replicates in a human-robot interaction and specifically with a highly non-humanoid robotic object. The robot was designed with modules that could be easily added or removed, allowing us to change its height without altering other design features. To test the impact of the robot's height, we evaluated participants' compliance with its request to volunteer to perform a tedious task. In the experiment, participants performed a cognitive task on a computer, which was framed as the main experiment. When done, they were informed that the experiment was completed. While waiting to receive their credits, the robotic object, designed as a mobile robotic service table, entered the room, carrying a tablet that invited participants to complete a 300-question questionnaire voluntarily. We compared participants' compliance in two conditions: A Short robot composed of two modules and 95cm in height and a Tall robot consisting of three modules and 132cm in height. Our findings revealed higher compliance with the Short robot's request, demonstrating an opposite pattern to human dynamics. We conclude that while height has a substantial social impact on human-robot interactions, it follows a unique pattern of influence. Our findings suggest that designers cannot simply adopt and implement elements from human social dynamics to robots without testing them first.

**AI Summary:** This research explores the impact of a robot's height on human compliance in a human-robot interaction. Contrary to human dynamics where taller individuals are perceived as more persuasive, the study found that participants were more compliant with a shorter robot's request compared to a taller one. The findings highlight the importance of considering unique social dynamics in human-robot interactions and suggest that designers should test and adapt elements from human interactions carefully when designing robots.

---

## Defining and Monitoring Complex Robot Activities via LLMs and Symbolic Reasoning
**URL:** https://arxiv.org/abs/2509.16006

**Abstract:** Recent years have witnessed a growing interest in automating labor-intensive and complex activities, i.e., those consisting of multiple atomic tasks, by deploying robots in dynamic and unpredictable environments such as industrial and agricultural settings. A key characteristic of these contexts is that activities are not predefined: while they involve a limited set of possible tasks, their combinations may vary depending on the situation. Moreover, despite recent advances in robotics, the ability for humans to monitor the progress of high-level activities - in terms of past, present, and future actions - remains fundamental to ensure the correct execution of safety-critical processes. In this paper, we introduce a general architecture that integrates Large Language Models (LLMs) with automated planning, enabling humans to specify high-level activities (also referred to as processes) using natural language, and to monitor their execution by querying a robot. We also present an implementation of this architecture using state-of-the-art components and quantitatively evaluate the approach in a real-world precision agriculture scenario.

**AI Summary:** This research paper focuses on automating complex activities using robots in dynamic environments. The study introduces an architecture that combines Large Language Models (LLMs) with automated planning to allow humans to define high-level activities using natural language and monitor their execution. The implementation of this architecture in a precision agriculture scenario shows promising results in terms of enabling humans to oversee and ensure the correct execution of safety-critical processes.

---

## EmoHeal: An End-to-End System for Personalized Therapeutic Music Retrieval from Fine-grained Emotions
**URL:** https://arxiv.org/abs/2509.15986

**Abstract:** Existing digital mental wellness tools often overlook the nuanced emotional states underlying everyday challenges. For example, pre-sleep anxiety affects more than 1.5 billion people worldwide, yet current approaches remain largely static and "one-size-fits-all", failing to adapt to individual needs. In this work, we present EmoHeal, an end-to-end system that delivers personalized, three-stage supportive narratives. EmoHeal detects 27 fine-grained emotions from user text with a fine-tuned XLM-RoBERTa model, mapping them to musical parameters via a knowledge graph grounded in music therapy principles (GEMS, iso-principle). EmoHeal retrieves audiovisual content using the CLAMP3 model to guide users from their current state toward a calmer one ("match-guide-target"). A within-subjects study (N=40) demonstrated significant supportive effects, with participants reporting substantial mood improvement (M=4.12, p<0.001) and high perceived emotion recognition accuracy (M=4.05, p<0.001). A strong correlation between perceived accuracy and therapeutic outcome (r=0.72, p<0.001) validates our fine-grained approach. These findings establish the viability of theory-driven, emotion-aware digital wellness tools and provides a scalable AI blueprint for operationalizing music therapy principles.

**AI Summary:** The research introduces EmoHeal, an AI system that detects fine-grained emotions and provides personalized therapeutic music retrieval to address individual emotional needs. The system was found to significantly improve mood and accurately recognize emotions, validating the effectiveness of the fine-grained approach. This study demonstrates the potential of theory-driven, emotion-aware digital wellness tools based on music therapy principles, offering a scalable AI blueprint for implementing personalized mental health interventions.

---

## VoXtream: Full-Stream Text-to-Speech with Extremely Low Latency
**URL:** https://arxiv.org/abs/2509.15969

**Abstract:** We present VoXtream, a fully autoregressive, zero-shot streaming text-to-speech (TTS) system for real-time use that begins speaking from the first word. VoXtream directly maps incoming phonemes to audio tokens using a monotonic alignment scheme and a dynamic look-ahead that does not delay onset. Built around an incremental phoneme transformer, a temporal transformer predicting semantic and duration tokens, and a depth transformer producing acoustic tokens, VoXtream achieves, to our knowledge, the lowest initial delay among publicly available streaming TTS: 102 ms on GPU. Despite being trained on a mid-scale 9k-hour corpus, it matches or surpasses larger baselines on several metrics, while delivering competitive quality in both output- and full-streaming settings. Demo and code are available at this https URL.

**AI Summary:** The research presents VoXtream, a real-time streaming text-to-speech system with extremely low latency of 102 ms on GPU. It uses a unique approach of directly mapping incoming phonemes to audio tokens without delaying onset, achieving competitive quality in both output and full-streaming settings. Despite being trained on a smaller corpus, VoXtream matches or surpasses larger baselines on various metrics, making it a significant advancement in the field of streaming TTS.

---

## EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol
**URL:** https://arxiv.org/abs/2509.15957

**Abstract:** Background: Large language models (LLMs) show promise in medicine, but their deployment in hospitals is limited by restricted access to electronic health record (EHR) systems. The Model Context Protocol (MCP) enables integration between LLMs and external tools.
Objective: To evaluate whether an LLM connected to an EHR database via MCP can autonomously retrieve clinically relevant information in a real hospital setting.
Methods: We developed EHR-MCP, a framework of custom MCP tools integrated with the hospital EHR database, and used GPT-4.1 through a LangGraph ReAct agent to interact with it. Six tasks were tested, derived from use cases of the infection control team (ICT). Eight patients discussed at ICT conferences were retrospectively analyzed. Agreement with physician-generated gold standards was measured.
Results: The LLM consistently selected and executed the correct MCP tools. Except for two tasks, all tasks achieved near-perfect accuracy. Performance was lower in the complex task requiring time-dependent calculations. Most errors arose from incorrect arguments or misinterpretation of tool results. Responses from EHR-MCP were reliable, though long and repetitive data risked exceeding the context window.
Conclusions: LLMs can retrieve clinical data from an EHR via MCP tools in a real hospital setting, achieving near-perfect performance in simple tasks while highlighting challenges in complex ones. EHR-MCP provides an infrastructure for secure, consistent data access and may serve as a foundation for hospital AI agents. Future work should extend beyond retrieval to reasoning, generation, and clinical impact assessment, paving the way for effective integration of generative AI into clinical practice.

**AI Summary:** This research explores the use of Large Language Models (LLMs) connected to Electronic Health Record (EHR) databases via the Model Context Protocol (MCP) to autonomously retrieve clinically relevant information in a real hospital setting. The study found that the LLM consistently selected and executed the correct MCP tools, achieving near-perfect accuracy in simple tasks but facing challenges in more complex tasks. The results suggest that EHR-MCP could provide a foundation for AI agents in hospitals, with potential for further development in reasoning, generation, and clinical impact assessment.

---

## From Development to Deployment of AI-assisted Telehealth and Screening for Vision- and Hearing-threatening diseases in resource-constrained settings: Field Observations, Challenges and Way Forward
**URL:** https://arxiv.org/abs/2509.15558

**Abstract:** Vision- and hearing-threatening diseases cause preventable disability, especially in resource-constrained settings(RCS) with few specialists and limited screening setup. Large scale AI-assisted screening and telehealth has potential to expand early detection, but practical deployment is challenging in paper-based workflows and limited documented field experience exist to build upon. We provide insights on challenges and ways forward in development to adoption of scalable AI-assisted Telehealth and screening in such settings. Specifically, we find that iterative, interdisciplinary collaboration through early prototyping, shadow deployment and continuous feedback is important to build shared understanding as well as reduce usability hurdles when transitioning from paper-based to AI-ready workflows. We find public datasets and AI models highly useful despite poor performance due to domain shift. In addition, we find the need for automated AI-based image quality check to capture gradable images for robust screening in high-volume camps.
Our field learning stress the importance of treating AI development and workflow digitization as an end-to-end, iterative co-design process. By documenting these practical challenges and lessons learned, we aim to address the gap in contextual, actionable field knowledge for building real-world AI-assisted telehealth and mass-screening programs in RCS.

**AI Summary:** The research focuses on the development and deployment of AI-assisted telehealth and screening for vision- and hearing-threatening diseases in resource-constrained settings. The study highlights the challenges faced in transitioning from paper-based workflows to AI-ready systems, emphasizing the importance of interdisciplinary collaboration, feedback, and image quality checks for successful implementation. The findings underscore the need for iterative co-design processes and the use of public datasets and AI models in building scalable telehealth and mass-screening programs in resource-constrained settings.

---

## Measurement and Potential Field-Based Patient Modeling for Model-Mediated Tele-ultrasound
**URL:** https://arxiv.org/abs/2509.15325

**Abstract:** Teleoperated ultrasound can improve diagnostic medical imaging access for remote communities. Having accurate force feedback is important for enabling sonographers to apply the appropriate probe contact force to optimize ultrasound image quality. However, large time delays in communication make direct force feedback impractical. Prior work investigated using point cloud-based model-mediated teleoperation and internal potential field models to estimate contact forces and torques. We expand on this by introducing a method to update the internal potential field model of the patient with measured positions and forces for more transparent model-mediated tele-ultrasound. We first generate a point cloud model of the patient's surface and transmit this to the sonographer in a compact data structure. This is converted to a static voxelized volume where each voxel contains a potential field value. These values determine the forces and torques, which are rendered based on overlap between the voxelized volume and a point shell model of the ultrasound transducer. We solve for the potential field using a convex quadratic that combines the spatial Laplace operator with measured forces. This was evaluated on volunteer patients ($n=3$) by computing the accuracy of rendered forces. Results showed the addition of measured forces to the model reduced the force magnitude error by an average of 7.23 N and force vector angle error by an average of 9.37$^{\circ}$ compared to using only Laplace's equation.

**AI Summary:** This research focuses on improving model-mediated tele-ultrasound by updating the internal potential field model of the patient with measured positions and forces. By incorporating measured forces into the model, the accuracy of rendered forces was significantly improved, reducing force magnitude error by an average of 7.23 N and force vector angle error by an average of 9.37$^{\circ}$. This method has the potential to enhance diagnostic medical imaging access for remote communities by providing more accurate force feedback to sonographers during teleoperated ultrasound procedures.

---

## An Evaluation-Centric Paradigm for Scientific Visualization Agents
**URL:** https://arxiv.org/abs/2509.15160

**Abstract:** Recent advances in multi-modal large language models (MLLMs) have enabled increasingly sophisticated autonomous visualization agents capable of translating user intentions into data visualizations. However, measuring progress and comparing different agents remains challenging, particularly in scientific visualization (SciVis), due to the absence of comprehensive, large-scale benchmarks for evaluating real-world capabilities. This position paper examines the various types of evaluation required for SciVis agents, outlines the associated challenges, provides a simple proof-of-concept evaluation example, and discusses how evaluation benchmarks can facilitate agent self-improvement. We advocate for a broader collaboration to develop a SciVis agentic evaluation benchmark that would not only assess existing capabilities but also drive innovation and stimulate future development in the field.

**AI Summary:** The abstract discusses the challenges in evaluating scientific visualization agents and proposes the need for comprehensive benchmarks to measure their real-world capabilities. The paper highlights the importance of collaboration in developing evaluation benchmarks to drive innovation and stimulate future development in the field of scientific visualization agents. The key findings suggest a focus on creating a benchmark that can assess existing capabilities and facilitate agent self-improvement.

---

## Learning in Context: Personalizing Educational Content with Large Language Models to Enhance Student Learning
**URL:** https://arxiv.org/abs/2509.15068

**Abstract:** Standardized, one-size-fits-all educational content often fails to connect with students' individual backgrounds and interests, leading to disengagement and a perceived lack of relevance. To address this challenge, we introduce PAGE, a novel framework that leverages large language models (LLMs) to automatically personalize educational materials by adapting them to each student's unique context, such as their major and personal interests. To validate our approach, we deployed PAGE in a semester-long intelligent tutoring system and conducted a user study to evaluate its impact in an authentic educational setting. Our findings show that students who received personalized content demonstrated significantly improved learning outcomes and reported higher levels of engagement, perceived relevance, and trust compared to those who used standardized materials. This work demonstrates the practical value of LLM-powered personalization and offers key design implications for creating more effective, engaging, and trustworthy educational experiences.

**AI Summary:** The research introduces a framework called PAGE that uses large language models to personalize educational content based on students' individual backgrounds and interests. The study found that students who received personalized content showed improved learning outcomes, higher engagement levels, perceived relevance, and trust compared to those using standardized materials. This work highlights the importance of personalized educational content in enhancing student learning experiences and offers insights for creating more effective and engaging educational materials.

---

## QuizRank: Picking Images by Quizzing VLMs
**URL:** https://arxiv.org/abs/2509.15059

**Abstract:** Images play a vital role in improving the readability and comprehension of Wikipedia articles by serving as `illustrative aids.' However, not all images are equally effective and not all Wikipedia editors are trained in their selection. We propose QuizRank, a novel method of image selection that leverages large language models (LLMs) and vision language models (VLMs) to rank images as learning interventions. Our approach transforms textual descriptions of the article's subject into multiple-choice questions about important visual characteristics of the concept. We utilize these questions to quiz the VLM: the better an image can help answer questions, the higher it is ranked. To further improve discrimination between visually similar items, we introduce a Contrastive QuizRank that leverages differences in the features of target (e.g., a Western Bluebird) and distractor concepts (e.g., Mountain Bluebird) to generate questions. We demonstrate the potential of VLMs as effective visual evaluators by showing a high congruence with human quiz-takers and an effective discriminative ranking of images.

**AI Summary:** The research introduces QuizRank, a method of image selection for Wikipedia articles that leverages large language models (LLMs) and vision language models (VLMs to rank images based on their ability to answer multiple-choice questions about important visual characteristics of the subject. The study demonstrates the effectiveness of VLMs in evaluating images by showing high congruence with human quiz-takers and providing a discriminative ranking of images, which can help improve the readability and comprehension of Wikipedia articles.

---

## Confirmation Bias as a Cognitive Resource in LLM-Supported Deliberation
**URL:** https://arxiv.org/abs/2509.14824

**Abstract:** Large language models (LLMs) are increasingly used in group decision-making, but their influence risks fostering conformity and reducing epistemic vigilance. Drawing on the Argumentative Theory of Reasoning, we argue that confirmation bias, often seen as detrimental, can be harnessed as a resource when paired with critical evaluation. We propose a three-step process in which individuals first generate ideas independently, then use LLMs to refine and articulate them, and finally engage with LLMs as epistemic provocateurs to anticipate group critique. This framing positions LLMs as tools for scaffolding disagreement, helping individuals prepare for more productive group discussions.

**AI Summary:** This research explores the role of large language models (LLMs) in group decision-making, highlighting the potential for confirmation bias to be a cognitive resource when paired with critical evaluation. The proposed three-step process involves individuals generating ideas independently, using LLMs to refine them, and then engaging with LLMs as epistemic provocateurs to anticipate group critique, ultimately facilitating more productive group discussions. This study suggests that LLMs can serve as tools for scaffolding disagreement and enhancing epistemic vigilance in group deliberation.

---

## UMind: A Unified Multitask Network for Zero-Shot M/EEG Visual Decoding
**URL:** https://arxiv.org/abs/2509.14772

**Abstract:** Decoding visual information from time-resolved brain recordings, such as EEG and MEG, plays a pivotal role in real-time brain-computer interfaces. However, existing approaches primarily focus on direct brain-image feature alignment and are limited to single-task frameworks or task-specific models. In this paper, we propose a Unified MultItask Network for zero-shot M/EEG visual Decoding (referred to UMind), including visual stimulus retrieval, classification, and reconstruction, where multiple tasks mutually enhance each other. Our method learns robust neural-visual and semantic representations through multimodal alignment with both image and text modalities. The integration of both coarse and fine-grained texts enhances the extraction of these neural representations, enabling more detailed semantic and visual decoding. These representations then serve as dual conditional inputs to a pre-trained diffusion model, guiding visual reconstruction from both visual and semantic perspectives. Extensive evaluations on MEG and EEG datasets demonstrate the effectiveness, robustness, and biological plausibility of our approach in capturing spatiotemporal neural dynamics. Our approach sets a multitask pipeline for brain visual decoding, highlighting the synergy of semantic information in visual feature extraction.

**AI Summary:** The research introduces UMind, a Unified Multitask Network for zero-shot M/EEG visual decoding, which improves upon existing approaches by incorporating multiple tasks such as visual stimulus retrieval, classification, and reconstruction. By integrating neural-visual and semantic representations through multimodal alignment with image and text modalities, UMind enhances the extraction of detailed semantic and visual information from brain recordings. The results of the study demonstrate the effectiveness, robustness, and biological plausibility of UMind in capturing spatiotemporal neural dynamics, setting a new standard for brain visual decoding by highlighting the importance of semantic information in visual feature extraction.

---

## Chameleon: A Surface-Anchored Smartphone AR Prototype with Visually Blended Mobile Display
**URL:** https://arxiv.org/abs/2509.14643

**Abstract:** Augmented reality (AR) is often realized through head-mounted displays, offering immersive but egocentric experiences. While smartphone-based AR is more accessible, it remains limited to handheld, single-user interaction. We introduce Chameleon, a prototype AR system that transforms smartphones into surface-anchored displays for co-located use. When placed flat, the phone creates a transparency illusion and anchors digital content visible to multiple users. Chameleon supports natural repositioning on the surface without external hardware by combining two techniques: (1) Background Acquisition uses opportunistic sensing and language model-assisted pattern generation to blend with surrounding surfaces, and (2) Real-Time Position Tracking augments inertial sensing to maintain spatial stability. This work shows how lightweight sensing can support casual, collaborative AR experiences using existing devices.

**AI Summary:** The research introduces Chameleon, an AR system that turns smartphones into surface-anchored displays for shared use, allowing multiple users to view digital content when the phone is placed flat. The system utilizes background acquisition and real-time position tracking techniques to create a transparency illusion and maintain spatial stability without additional hardware. This work demonstrates how lightweight sensing can enable casual and collaborative AR experiences using smartphones.

---

## Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech
**URL:** https://arxiv.org/abs/2509.14627

**Abstract:** Human conversation involves language, speech, and visual cues, with each medium providing complementary information. For instance, speech conveys a vibe or tone not fully captured by text alone. While multimodal LLMs focus on generating text responses from diverse inputs, less attention has been paid to generating natural and engaging speech. We propose a human-like agent that generates speech responses based on conversation mood and responsive style information. To achieve this, we build a novel MultiSensory Conversation dataset focused on speech to enable agents to generate natural speech. We then propose a multimodal LLM-based model for generating text responses and voice descriptions, which are used to generate speech covering paralinguistic information. Experimental results demonstrate the effectiveness of utilizing both visual and audio modalities in conversation to generate engaging speech. The source code is available in this https URL

**AI Summary:** This research focuses on creating a human-like conversational agent that generates engaging speech responses by incorporating visual and audio cues. The study introduces a new dataset, MultiSensory Conversation, to enable the generation of natural speech. Results show the effectiveness of using both visual and audio modalities in conversation for producing engaging speech responses.

---

## Can I Trust This Chatbot? Assessing User Privacy in AI-Healthcare Chatbot Applications
**URL:** https://arxiv.org/abs/2509.14581

**Abstract:** As Conversational Artificial Intelligence (AI) becomes more integrated into everyday life, AI-powered chatbot mobile applications are increasingly adopted across industries, particularly in the healthcare domain. These chatbots offer accessible and 24/7 support, yet their collection and processing of sensitive health data present critical privacy concerns. While prior research has examined chatbot security, privacy issues specific to AI healthcare chatbots have received limited attention. Our study evaluates the privacy practices of 12 widely downloaded AI healthcare chatbot apps available on the App Store and Google Play in the United States. We conducted a three-step assessment analyzing: (1) privacy settings during sign-up, (2) in-app privacy controls, and (3) the content of privacy policies. The analysis identified significant gaps in user data protection. Our findings reveal that half of the examined apps did not present a privacy policy during sign up, and only two provided an option to disable data sharing at that stage. The majority of apps' privacy policies failed to address data protection measures. Moreover, users had minimal control over their personal data. The study provides key insights for information science researchers, developers, and policymakers to improve privacy protections in AI healthcare chatbot apps.

**AI Summary:** This study evaluates the privacy practices of 12 AI healthcare chatbot apps and finds significant gaps in user data protection, with half of the apps not presenting a privacy policy during sign up and minimal control over personal data for users. The findings highlight the need for improved privacy protections in AI healthcare chatbot apps and provide valuable insights for information science researchers, developers, and policymakers in addressing privacy concerns in this rapidly growing industry.

---

## TypedSchematics: A Block-based PCB Design Tool with Real-time Detection of Common Connection Errors
**URL:** https://arxiv.org/abs/2509.14576

**Abstract:** Within PCB design, the reuse of circuit design blocks is a major preventing factor inhibiting beginners from reusing designs made by experts, a common practice in software but non-existent in circuit design at large. Despite efforts to improve reusability (e.g. block-based PCB design) by platforms such as SparkFun ALC and Altium Upverter, they lack merging techniques that safely guide users in connecting different circuit blocks without requiring assistance from third-party engineers. In this paper, we propose TypedSchematics, a block-based standalone PCB design tool that supports beginners create their own PCBs by providing a language syntax for typing circuit blocks with circuit data that addresses multiple challenges, from real-time detection of connection errors to automated composition and user-scalable libraries of circuit blocks. Through a user study, we demonstrate TypedSchematics improvements in design support for merging circuit blocks compared to Fusion 360. Three PCBs designed with TypedSchematics further showcase our tool capabilities, one designed by high school students demonstrates the potential of TypedSchematics to significantly lower the PCB design skill-floor.

**AI Summary:** The research introduces TypedSchematics, a block-based PCB design tool that addresses the lack of merging techniques in existing platforms, allowing beginners to create their own PCBs with ease. The tool provides real-time detection of connection errors, automated composition, and user-scalable libraries of circuit blocks, improving design support for merging circuit blocks compared to Fusion 360. The study demonstrates the potential of TypedSchematics to lower the skill-floor for PCB design, as evidenced by PCBs designed by high school students using the tool.

---

## VisMoDAl: Visual Analytics for Evaluating and Improving Corruption Robustness of Vision-Language Models
**URL:** https://arxiv.org/abs/2509.14571

**Abstract:** Vision-language (VL) models have shown transformative potential across various critical domains due to their capability to comprehend multi-modal information. However, their performance frequently degrades under distribution shifts, making it crucial to assess and improve robustness against real-world data corruption encountered in practical applications. While advancements in VL benchmark datasets and data augmentation (DA) have contributed to robustness evaluation and improvement, there remain challenges due to a lack of in-depth comprehension of model behavior as well as the need for expertise and iterative efforts to explore data patterns. Given the achievement of visualization in explaining complex models and exploring large-scale data, understanding the impact of various data corruption on VL models aligns naturally with a visual analytics approach. To address these challenges, we introduce VisMoDAl, a visual analytics framework designed to evaluate VL model robustness against various corruption types and identify underperformed samples to guide the development of effective DA strategies. Grounded in the literature review and expert discussions, VisMoDAl supports multi-level analysis, ranging from examining performance under specific corruptions to task-driven inspection of model behavior and corresponding data slice. Unlike conventional works, VisMoDAl enables users to reason about the effects of corruption on VL models, facilitating both model behavior understanding and DA strategy formulation. The utility of our system is demonstrated through case studies and quantitative evaluations focused on corruption robustness in the image captioning task.

**AI Summary:** The research introduces VisMoDAl, a visual analytics framework designed to evaluate and improve the corruption robustness of vision-language models. The framework allows for multi-level analysis, enabling users to assess model performance under various corruption types and identify underperformed samples to guide the development of data augmentation strategies. VisMoDAl facilitates a better understanding of how corruption affects VL models, ultimately aiding in the improvement of model behavior and the formulation of effective data augmentation strategies.

---

## ClearFairy: Capturing Creative Workflows through Decision Structuring, In-Situ Questioning, and Rationale Inference
**URL:** https://arxiv.org/abs/2509.14537

**Abstract:** Capturing professionals' decision-making in creative workflows is essential for reflection, collaboration, and knowledge sharing, yet existing methods often leave rationales incomplete and implicit decisions hidden. To address this, we present CLEAR framework that structures reasoning into cognitive decision steps-linked units of actions, artifacts, and self-explanations that make decisions traceable. Building on this framework, we introduce ClearFairy, a think-aloud AI assistant for UI design that detects weak explanations, asks lightweight clarifying questions, and infers missing rationales to ease the knowledge-sharing burden. In a study with twelve creative professionals, 85% of ClearFairy's inferred rationales were accepted, increasing strong explanations from 14% to over 83% of decision steps without adding cognitive demand. The captured steps also enhanced generative AI agents in Figma, yielding next-action predictions better aligned with professionals and producing more coherent design outcomes. For future research on human knowledge-grounded creative AI agents, we release a dataset of captured 417 decision steps.

**AI Summary:** The research introduces the CLEAR framework and ClearFairy, an AI assistant for UI design, that helps capture professionals' decision-making in creative workflows by structuring reasoning into cognitive decision steps. ClearFairy detects weak explanations, asks clarifying questions, and infers missing rationales to improve knowledge sharing. In a study with creative professionals, ClearFairy's inferred rationales were accepted by 85% of participants, leading to an increase in strong explanations and more coherent design outcomes. This research contributes to the development of human knowledge-grounded creative AI agents and provides a dataset of captured decision steps for future research.

---

## Why Johnny Can't Use Agents: Industry Aspirations vs. User Realities with AI Agent Software
**URL:** https://arxiv.org/abs/2509.14528

**Abstract:** There is growing imprecision about what "AI agents" are, what they can do, and how effectively they can be used by their intended users. We pose two key research questions: (i) How does the tech industry conceive of and market "AI agents"? (ii) What challenges do end-users face when attempting to use commercial AI agents for their advertised uses? We first performed a systematic review of marketed use cases for 102 commercial AI agents, finding that they fall into three umbrella categories: orchestration, creation, and insight. Next, we conducted a usability assessment where N = 31 participants attempted representative tasks for each of these categories on two popular commercial AI agent tools: Operator and Manus. We found that users were generally impressed with these agents but faced several critical usability challenges ranging from agent capabilities that were misaligned with user mental models to agents lacking the meta-cognitive abilities necessary for effective collaboration.

**AI Summary:** The research examines the disconnect between how the tech industry markets AI agents and the actual user experience. They found that commercial AI agents are categorized into orchestration, creation, and insight, but users faced usability challenges due to misalignment with user mental models and lack of necessary meta-cognitive abilities for collaboration. This highlights the importance of understanding user realities and improving AI agent software to meet user needs effectively.

---

## Understanding Physical Therapy Challenges for Older Adults through Mixed Reality
**URL:** https://arxiv.org/abs/2509.14514

**Abstract:** Physical therapy (PT) is crucial in helping older adults manage chronic conditions and weakening muscles, but older adults face increasing challenges that can impact their PT experience, including increased fatigue, memory loss, and mobility and travel constraints. While current technology attempts to facilitate remote care, they have limitations and are used in-practice infrequently. Mixed reality (MR) technology shows promise for addressing these challenges by creating immersive, context-aware environments remotely that previously could only be achieved in clinical settings. To bridge the gap between MR's potential and its practical application in geriatric PT, we conducted in-depth interviews with three PT clinicians and six older adult patients to understand challenges with PT care and adherence that MR may address. Our findings inform design considerations for supporting older adults' needs through MR and outline technical requirements for practical implementation.

**AI Summary:** This research explores the challenges older adults face with physical therapy, such as fatigue, memory loss, and mobility constraints, and the limitations of current technology in addressing these issues. The study suggests that mixed reality technology could provide a solution by creating immersive, context-aware environments for remote PT care. Interviews with PT clinicians and older adult patients inform design considerations and technical requirements for implementing MR in geriatric PT, potentially improving care and adherence for older adults.

---

## On Optimality and Human Prediction of Event Duration in Real-Time, Real-World Contexts
**URL:** https://arxiv.org/abs/2509.14482

**Abstract:** The focus of the current work concerned the psychological processes that underlie prediction of an events duration. The objective was to push forward existing psychological theory on event duration prediction, something made possible by the unique features of our data context. The provisional findings suggested that the prior, existing theoretical mechanism of event duration prediction is incomplete because: i. it does not support adaptive responses when event duration judgments are dependent, ii. it does not afford the integration of new, on the fly, information. Our findings suggest specific directions for future research.

**AI Summary:** This research explores the psychological processes involved in predicting the duration of events in real-time, real-world contexts. The findings suggest that existing theoretical mechanisms for event duration prediction may be incomplete as they do not support adaptive responses to dependent event duration judgments or the integration of new information. This study provides insights that could lead to further research and advancements in understanding human prediction of event duration.

---

## Sensing the Shape of Data: Non-Visual Exploration of Statistical Concepts in Histograms with Blind and Low-Vision Learners
**URL:** https://arxiv.org/abs/2509.14452

**Abstract:** Statistical concepts often rely heavily on visual cues for comprehension, presenting challenges for individuals who face difficulties using visual information, such as the blind and low-vision (BLV) community. While prior work has explored making data visualizations accessible, limited research examines how BLV individuals conceptualize and learn the underlying statistical concepts these visualizations represent. To better understand BLV individuals' learning strategies for potentially unfamiliar statistical concepts, we conducted a within-subjects experiment with 7 BLV individuals, controlling for vision condition using blindfolds. Each participant leveraged three different non-visual representations (Swell Touch tactile graph (STGs), shaped data patterns on a refreshable display (BDPs), sonification) to understand three different statistical concepts in histograms (skewness, modality, kurtosis). We collected quantitative metrics (accuracy, completion time, self-reported confidence levels) and qualitative insights (gesture analysis) to identify participants' unique meaning-making strategies. Results revealed that the braille condition led to the most accurate results, with sonification tasks being completed the fastest. Participants demonstrated various adaptive techniques when exploring each histogram, often developing alternative mental models that helped them non-visually encode statistical visualization concepts. Our findings reveal important implications for statistics educators and assistive technology designers, suggesting that effective learning tools must go beyond simple translation of visual information to support the unique cognitive strategies employed by BLV learners.

**AI Summary:** This research explores how blind and low-vision individuals can learn statistical concepts through non-visual representations such as tactile graphs, shaped data patterns, and sonification. The study found that participants were able to accurately understand statistical concepts using braille and complete tasks quickly with sonification. The findings suggest that effective learning tools for blind and low-vision learners should support their unique cognitive strategies and go beyond simply translating visual information.

---

## Value Alignment of Social Media Ranking Algorithms
**URL:** https://arxiv.org/abs/2509.14434

**Abstract:** While social media feed rankings are primarily driven by engagement signals rather than any explicit value system, the resulting algorithmic feeds are not value-neutral: engagement may prioritize specific individualistic values. This paper presents an approach for social media feed value alignment. We adopt Schwartz's theory of Basic Human Values -- a broad set of human values that articulates complementary and opposing values forming the building blocks of many cultures -- and we implement an algorithmic approach that models and then ranks feeds by expressions of Schwartz's values in social media posts. Our approach enables controls where users can express weights on their desired values, combining these weights and post value expressions into a ranking that respects users' articulated trade-offs. Through controlled experiments (N=141 and N=250), we demonstrate that users can use these controls to architect feeds reflecting their desired values. Across users, value-ranked feeds align with personal values, diverging substantially from existing engagement-driven feeds.

**AI Summary:** This research paper addresses the issue of social media feed rankings being influenced by engagement signals and individualistic values, rather than a neutral value system. The study introduces an algorithmic approach based on Schwartz's theory of Basic Human Values to align social media feeds with users' desired values. Through experiments, the researchers show that users can use this approach to create feeds that reflect their personal values, diverging significantly from the current engagement-driven feeds.

---

## Nudging the Somas: Exploring How Live-Configurable Mixed Reality Objects Shape Open-Ended Intercorporeal Movements
**URL:** https://arxiv.org/abs/2509.14432

**Abstract:** Mixed Reality (MR) experiences increasingly explore how virtual elements can shape physical behaviour, yet how MR objects guide group movement remains underexplored. We address this gap by examining how virtual objects can nudge collective, co-located movement without relying on explicit instructions or choreography. We developed GravField, a co-located MR performance system where an "object jockey" live-configures virtual objects, springs, ropes, magnets, with real-time, parameterised "digital physics" (e.g., weight, elasticity, force) to influence the movement of headset-wearing participants. These properties were made perceptible through augmented visual and audio feedback, creating dynamic cognitive-somatic cues. Our analysis of the performances, based on video, interviews, soma trajectories, and field notes, indicates that these live nudges support emergent intercorporeal coordination and that ambiguity and real-time configuration sustain open-ended, exploratory engagement. Ultimately, our work offers empirical insights and design principles for MR systems that can guide group movement through embodied, felt dynamics.

**AI Summary:** This research explores how virtual objects in Mixed Reality (MR) experiences can influence group movement without explicit instructions. The study developed a system called GravField where virtual objects are live-configured to influence participants' movements through dynamic cognitive-somatic cues. The findings suggest that these live nudges support emergent coordination and open-ended engagement, offering insights for designing MR systems that guide group movement through embodied dynamics.

---

## Investigating the Ways in Which Mobile Phone Images with Open-Source Data Can Be Used to Create an Augmented Virtual Environment (AVE)
**URL:** https://arxiv.org/abs/2509.14374

**Abstract:** This paper presents the development of an interactive system for constructing Augmented Virtual Environments (AVEs) by fusing mobile phone images with open-source geospatial data. By integrating 2D image data with 3D models derived from sources such as OpenStreetMap (OSM) and Digital Terrain Models (DTM), the proposed system generates immersive environments that enhance situational context. The system leverages Python for data processing and Unity for 3D visualization, interconnected via UDP-based two-way communication. Preliminary user evaluation demonstrates that the resulting AVEs accurately represent real-world scenes and improve users' contextual understanding. Key challenges addressed include projector calibration, precise model construction from heterogeneous data, and object detection for dynamic scene representation.

**AI Summary:** This research paper introduces a system that combines mobile phone images with open-source geospatial data to create immersive Augmented Virtual Environments (AVEs). By integrating 2D image data with 3D models from sources like OpenStreetMap and Digital Terrain Models, the system enhances situational context and improves users' contextual understanding. The system, utilizing Python for data processing and Unity for 3D visualization, addresses challenges such as projector calibration, precise model construction, and object detection for dynamic scene representation.

---

## From Sea to System: Exploring User-Centered Explainable AI for Maritime Decision Support
**URL:** https://arxiv.org/abs/2509.15084

**Abstract:** As autonomous technologies increasingly shape maritime operations, understanding why an AI system makes a decision becomes as crucial as what it decides. In complex and dynamic maritime environments, trust in AI depends not only on performance but also on transparency and interpretability. This paper highlights the importance of Explainable AI (XAI) as a foundation for effective human-machine teaming in the maritime domain, where informed oversight and shared understanding are essential. To support the user-centered integration of XAI, we propose a domain-specific survey designed to capture maritime professionals' perceptions of trust, usability, and explainability. Our aim is to foster awareness and guide the development of user-centric XAI systems tailored to the needs of seafarers and maritime teams.

**AI Summary:** This research focuses on the importance of Explainable AI (XAI) in maritime decision support, emphasizing the need for transparency and interpretability in AI systems operating in dynamic maritime environments. The study proposes a domain-specific survey to gather maritime professionals' perceptions of trust, usability, and explainability to guide the development of user-centric XAI systems tailored to the needs of seafarers and maritime teams. The findings suggest that understanding why an AI system makes a decision is crucial for building trust and effective human-machine teaming in maritime operations.

---

## Calibrated Generative AI as Meta-Reviewer: A Systemic Functional Linguistics Discourse Analysis of Reviews of Peer Reviews
**URL:** https://arxiv.org/abs/2509.15035

**Abstract:** This study investigates the use of generative AI to support formative assessment through machine generated reviews of peer reviews in graduate online courses in a public university in the United States. Drawing on Systemic Functional Linguistics and Appraisal Theory, we analyzed 120 metareviews to explore how generative AI feedback constructs meaning across ideational, interpersonal, and textual dimensions. The findings suggest that generative AI can approximate key rhetorical and relational features of effective human feedback, offering directive clarity while also maintaining a supportive stance. The reviews analyzed demonstrated a balance of praise and constructive critique, alignment with rubric expectations, and structured staging that foregrounded student agency. By modeling these qualities, AI metafeedback has the potential to scaffold feedback literacy and enhance leaner engagement with peer review.

**AI Summary:** This research explores the use of generative AI to provide feedback on peer reviews in graduate online courses. The study found that AI-generated feedback can effectively mimic the key elements of human feedback, such as providing clear guidance and maintaining a supportive tone. The results suggest that AI metafeedback has the potential to improve student engagement with peer review and enhance feedback literacy.

---

## Affordance-Based Disambiguation of Surgical Instructions for Collaborative Robot-Assisted Surgery
**URL:** https://arxiv.org/abs/2509.14967

**Abstract:** Effective human-robot collaboration in surgery is affected by the inherent ambiguity of verbal communication. This paper presents a framework for a robotic surgical assistant that interprets and disambiguates verbal instructions from a surgeon by grounding them in the visual context of the operating field. The system employs a two-level affordance-based reasoning process that first analyzes the surgical scene using a multimodal vision-language model and then reasons about the instruction using a knowledge base of tool capabilities. To ensure patient safety, a dual-set conformal prediction method is used to provide a statistically rigorous confidence measure for robot decisions, allowing it to identify and flag ambiguous commands. We evaluated our framework on a curated dataset of ambiguous surgical requests from cholecystectomy videos, demonstrating a general disambiguation rate of 60% and presenting a method for safer human-robot interaction in the operating room.

**AI Summary:** This research paper introduces a framework for a robotic surgical assistant that can interpret and clarify ambiguous verbal instructions from a surgeon by using visual cues from the operating field. The system employs a two-level affordance-based reasoning process and a dual-set conformal prediction method to ensure patient safety by providing a statistically rigorous confidence measure for robot decisions. The framework was tested on a dataset of ambiguous surgical requests, showing a disambiguation rate of 60% and offering a safer method for human-robot collaboration in surgery.

---

## Human Interaction for Collaborative Semantic SLAM using Extended Reality
**URL:** https://arxiv.org/abs/2509.14949

**Abstract:** Semantic SLAM (Simultaneous Localization and Mapping) systems enrich robot maps with structural and semantic information, enabling robots to operate more effectively in complex environments. However, these systems struggle in real-world scenarios with occlusions, incomplete data, or ambiguous geometries, as they cannot fully leverage the higher-level spatial and semantic knowledge humans naturally apply. We introduce HICS-SLAM, a Human-in-the-Loop semantic SLAM framework that uses a shared extended reality environment for real-time collaboration. The system allows human operators to directly interact with and visualize the robot's 3D scene graph, and add high-level semantic concepts (e.g., rooms or structural entities) into the mapping process. We propose a graph-based semantic fusion methodology that integrates these human interventions with robot perception, enabling scalable collaboration for enhanced situational awareness. Experimental evaluations on real-world construction site datasets demonstrate improvements in room detection accuracy, map precision, and semantic completeness compared to automated baselines, demonstrating both the effectiveness of the approach and its potential for future extensions.

**AI Summary:** The research introduces HICS-SLAM, a Human-in-the-Loop semantic SLAM framework that allows human operators to collaborate with robots in real-time using extended reality. By enabling humans to interact and add high-level semantic concepts to the mapping process, the system improves room detection accuracy, map precision, and semantic completeness in real-world scenarios. The approach demonstrates the effectiveness of human-robot collaboration in enhancing situational awareness and shows potential for future extensions in complex environments.

---

## Investigating the Effect of LED Signals and Emotional Displays in Human-Robot Shared Workspaces
**URL:** https://arxiv.org/abs/2509.14748

**Abstract:** Effective communication is essential for safety and efficiency in human-robot collaboration, particularly in shared workspaces. This paper investigates the impact of nonverbal communication on human-robot interaction (HRI) by integrating reactive light signals and emotional displays into a robotic system. We equipped a Franka Emika Panda robot with an LED strip on its end effector and an animated facial display on a tablet to convey movement intent through colour-coded signals and facial expressions. We conducted a human-robot collaboration experiment with 18 participants, evaluating three conditions: LED signals alone, LED signals with reactive emotional displays, and LED signals with pre-emptive emotional displays. We collected data through questionnaires and position tracking to assess anticipation of potential collisions, perceived clarity of communication, and task performance. The results indicate that while emotional displays increased the perceived interactivity of the robot, they did not significantly improve collision anticipation, communication clarity, or task efficiency compared to LED signals alone. These findings suggest that while emotional cues can enhance user engagement, their impact on task performance in shared workspaces is limited.

**AI Summary:** This research study explores the impact of nonverbal communication in human-robot collaboration by incorporating LED signals and emotional displays into a robotic system. The study found that while emotional displays increased the perceived interactivity of the robot, they did not significantly improve collision anticipation, communication clarity, or task efficiency compared to LED signals alone. This suggests that while emotional cues can enhance user engagement, their influence on task performance in shared workspaces may be limited.

---

## SimCoachCorpus: A naturalistic dataset with language and trajectories for embodied teaching
**URL:** https://arxiv.org/abs/2509.14548

**Abstract:** Curated datasets are essential for training and evaluating AI approaches, but are often lacking in domains where language and physical action are deeply intertwined. In particular, few datasets capture how people acquire embodied skills through verbal instruction over time. To address this gap, we introduce SimCoachCorpus: a unique dataset of race car simulator driving that allows for the investigation of rich interactive phenomena during guided and unguided motor skill acquisition. In this dataset, 29 humans were asked to drive in a simulator around a race track for approximately ninety minutes. Fifteen participants were given personalized one-on-one instruction from a professional performance driving coach, and 14 participants drove without coaching. \name\ includes embodied features such as vehicle state and inputs, map (track boundaries and raceline), and cone landmarks. These are synchronized with concurrent verbal coaching from a professional coach and additional feedback at the end of each lap. We further provide annotations of coaching categories for each concurrent feedback utterance, ratings on students' compliance with coaching advice, and self-reported cognitive load and emotional state of participants (gathered from surveys during the study). The dataset includes over 20,000 concurrent feedback utterances, over 400 terminal feedback utterances, and over 40 hours of vehicle driving data. Our naturalistic dataset can be used for investigating motor learning dynamics, exploring linguistic phenomena, and training computational models of teaching. We demonstrate applications of this dataset for in-context learning, imitation learning, and topic modeling. The dataset introduced in this work will be released publicly upon publication of the peer-reviewed version of this paper. Researchers interested in early access may register at this https URL.

**AI Summary:** The SimCoachCorpus dataset is a unique collection of race car simulator driving data that includes verbal coaching from a professional driving coach, as well as vehicle state and inputs, map information, and cone landmarks. This dataset allows for the study of how people acquire motor skills through verbal instruction over time. The dataset, which includes over 20,000 feedback utterances and 40 hours of driving data, can be used for investigating motor learning dynamics, linguistic phenomena, and training computational models of teaching.

---

## Keywords are not always the key: A metadata field analysis for natural language search on open data portals
**URL:** https://arxiv.org/abs/2509.14457

**Abstract:** Open data portals are essential for providing public access to open datasets. However, their search interfaces typically rely on keyword-based mechanisms and a narrow set of metadata fields. This design makes it difficult for users to find datasets using natural language queries. The problem is worsened by metadata that is often incomplete or inconsistent, especially when users lack familiarity with domain-specific terminology. In this paper, we examine how individual metadata fields affect the success of conversational dataset retrieval and whether LLMs can help bridge the gap between natural queries and structured metadata. We conduct a controlled ablation study using simulated natural language queries over real-world datasets to evaluate retrieval performance under various metadata configurations. We also compare existing content of the metadata field 'description' with LLM-generated content, exploring how different prompting strategies influence quality and impact on search outcomes. Our findings suggest that dataset descriptions play a central role in aligning with user intent, and that LLM-generated descriptions can support effective retrieval. These results highlight both the limitations of current metadata practices and the potential of generative models to improve dataset discoverability in open data portals.

**AI Summary:** This research examines the challenges of using keyword-based search mechanisms on open data portals and the impact of incomplete or inconsistent metadata on dataset discoverability. The study finds that dataset descriptions are crucial for aligning with user intent, and that using LLMs to generate descriptions can improve retrieval performance. These findings underscore the importance of improving metadata practices and leveraging generative models to enhance dataset discoverability in open data portals.

---

