# arXiv cs.AI Summary â€“ 2025-10-13

## VisPile: A Visual Analytics System for Analyzing Multiple Text Documents With Large Language Models and Knowledge Graphs
**URL:** https://arxiv.org/abs/2510.09605

**Abstract:** Intelligence analysts perform sensemaking over collections of documents using various visual and analytic techniques to gain insights from large amounts of text. As data scales grow, our work explores how to leverage two AI technologies, large language models (LLMs) and knowledge graphs (KGs), in a visual text analysis tool, enhancing sensemaking and helping analysts keep pace. Collaborating with intelligence community experts, we developed a visual analytics system called VisPile. VisPile integrates an LLM and a KG into various UI functions that assist analysts in grouping documents into piles, performing sensemaking tasks like summarization and relationship mapping on piles, and validating LLM- and KG-generated evidence. Our paper describes the tool, as well as feedback received from six professional intelligence analysts that used VisPile to analyze a text document corpus.

**AI Summary:** The research explores the use of large language models (LLMs) and knowledge graphs (KGs) in a visual text analysis tool called VisPile to assist intelligence analysts in sensemaking over collections of documents. The tool integrates LLM and KG into various UI functions to help analysts group documents, perform tasks like summarization and relationship mapping, and validate evidence. Feedback from professional intelligence analysts who used VisPile to analyze a text document corpus is discussed in the paper, highlighting the significance of the tool in enhancing sensemaking processes for analysts.

---

## Differential Analysis of Pseudo Haptic Feedback: Novel Comparative Study of Visual and Auditory Cue Integration for Psychophysical Evaluation
**URL:** https://arxiv.org/abs/2510.09570

**Abstract:** Pseudo-haptics exploit carefully crafted visual or auditory cues to trick the brain into "feeling" forces that are never physically applied, offering a low-cost alternative to traditional haptic hardware. Here, we present a comparative psychophysical study that quantifies how visual and auditory stimuli combine to evoke pseudo-haptic pressure sensations on a commodity tablet. Using a Unity-based Rollball game, participants (n = 4) guided a virtual ball across three textured terrains while their finger forces were captured in real time with a Robotous RFT40 force-torque sensor. Each terrain was paired with a distinct rolling-sound profile spanning 440 Hz - 4.7 kHz, 440 Hz - 13.1 kHz, or 440 Hz - 8.9 kHz; crevice collisions triggered additional "knocking" bursts to heighten realism. Average tactile forces increased systematically with cue intensity: 0.40 N, 0.79 N and 0.88 N for visual-only trials and 0.41 N, 0.81 N and 0.90 N for audio-only trials on Terrains 1-3, respectively. Higher audio frequencies and denser visual textures both elicited stronger muscle activation, and their combination further reduced the force needed to perceive surface changes, confirming multisensory integration. These results demonstrate that consumer-grade isometric devices can reliably induce and measure graded pseudo-haptic feedback without specialized actuators, opening a path toward affordable rehabilitation tools, training simulators and assistive interfaces.

**AI Summary:** This study explores how visual and auditory cues can be used to create pseudo-haptic feedback on a tablet, allowing users to "feel" forces without physical contact. The research found that higher audio frequencies and denser visual textures resulted in stronger muscle activation and reduced the force needed to perceive surface changes, confirming the effectiveness of multisensory integration. These findings suggest that consumer-grade devices can be used to create affordable rehabilitation tools, training simulators, and assistive interfaces without the need for specialized actuators.

---

## scellop: A Scalable Redesign of Cell Population Plots for Single-Cell Data
**URL:** https://arxiv.org/abs/2510.09554

**Abstract:** Summary: Cell population plots are visualizations showing cell population distributions in biological samples with single-cell data, traditionally shown with stacked bar charts. Here, we address issues with this approach, particularly its limited scalability with increasing number of cell types and samples, and present scellop, a novel interactive cell population viewer combining visual encodings optimized for common user tasks in studying populations of cells across samples or conditions.
Availability and Implementation: Scellop is available under the MIT licence at this https URL, and is available on PyPI (this https URL) and NPM (this https URL). A demo is available at this https URL.

**AI Summary:** The research introduces scellop, a new interactive cell population viewer designed to address scalability issues with traditional stacked bar chart visualizations of single-cell data. The tool offers optimized visual encodings for studying populations of cells across samples or conditions, providing a more efficient and user-friendly way to analyze complex biological data. Scellop is available for use under the MIT license and offers a demo for users to explore its capabilities.

---

## Convivial Conversational Agents -- shifting toward relationships
**URL:** https://arxiv.org/abs/2510.09516

**Abstract:** Conversational AI (CAI) systems offer opportunities to scale service provision to unprecedented levels and governments and corporations are already beginning to deploy them across services. The economic argument is similar across domains: use CAI to automate the time-consuming conversations required for customer, client or patient support. Herein we draw on our work in dementia care to explore some of the challenges and opportunities for CAI, and how a new way of conceptualising these systems could help ensure essential aspects for human thriving are not lost in the process of automation.

**AI Summary:** This research discusses the potential of conversational AI systems to automate customer support services, with governments and corporations starting to implement them. The study focuses on the challenges and opportunities of using CAI in dementia care, emphasizing the importance of maintaining essential aspects of human interaction in the process of automation. The findings highlight the need for a new approach to conceptualizing CAI systems to ensure they support human relationships and well-being.

---

## LibraryLens: An Interactive Tool for Exploring and Arranging Digital Bookshelves
**URL:** https://arxiv.org/abs/2510.09502

**Abstract:** Existing digital book management platforms often fail to capture the rich spatial and visual cues inherent to physical bookshelves, hindering users' ability to fully engage with their collections. We present LibraryLens, a novel visualization tool that addresses these shortcomings by enabling users to create, explore, and interact with immersive, two-dimensional representations of their personal libraries. The tool also caters to the growing trend of social sharing within online book communities, allowing users to create visually appealing representations of their libraries that can be easily shared on social platforms. Despite limitations inherent to the metadata being rendered, formative evaluations suggest that LibraryLens has the potential to lower the barrier to entry for users seeking to optimize their book organization without the constraints of physical space or manual labor, ultimately fostering deeper engagement with their personal libraries.

**AI Summary:** LibraryLens is a new visualization tool that helps users create, explore, and interact with digital representations of their personal libraries, addressing the limitations of existing book management platforms. The tool allows for easy social sharing of visually appealing library layouts and has the potential to make book organization more accessible and engaging for users, ultimately leading to deeper engagement with their collections.

---

## Barriers that Programming Instructors Face While Performing Emergency Pedagogical Design to Shape Student-AI Interactions with Generative AI Tools
**URL:** https://arxiv.org/abs/2510.09492

**Abstract:** Generative AI (GenAI) tools are increasingly pervasive, pushing instructors to redesign how students use GenAI tools in coursework. We conceptualize this work as emergency pedagogical design: reactive, indirect efforts by instructors to shape student-AI interactions without control over commercial interfaces. To understand practices of lead users conducting emergency pedagogical design, we conducted interviews (n=13) and a survey (n=169) of computing instructors. These instructors repeatedly encountered five barriers: fragmented buy-in for revising courses; policy crosswinds from non-prescriptive institutional guidance; implementation challenges as instructors attempt interventions; assessment misfit as student-AI interactions are only partially visible to instructors; and lack of resources, including time, staffing, and paid tool access. We use these findings to present emergency pedagogical design as a distinct design setting for HCI and outline recommendations for HCI researchers, academic institutions, and organizations to effectively support instructors in adapting courses to GenAI.

**AI Summary:** This research explores the challenges faced by programming instructors in redesigning coursework to incorporate Generative AI tools, which are becoming more common in education. The study identifies five key barriers instructors face, including fragmented buy-in, policy constraints, implementation challenges, assessment difficulties, and lack of resources. The findings highlight the need for support and resources for instructors to effectively adapt their courses to incorporate GenAI tools.

---

## Investigating the Impact of Rational Dilated Wavelet Transform on Motor Imagery EEG Decoding with Deep Learning Models
**URL:** https://arxiv.org/abs/2510.09242

**Abstract:** The present study investigates the impact of the Rational Discrete Wavelet Transform (RDWT), used as a plug-in preprocessing step for motor imagery electroencephalographic (EEG) decoding prior to applying deep learning classifiers. A systematic paired evaluation (with/without RDWT) is conducted on four state-of-the-art deep learning architectures: EEGNet, ShallowConvNet, MBEEG\_SENet, and EEGTCNet. This evaluation was carried out across three benchmark datasets: High Gamma, BCI-IV-2a, and BCI-IV-2b. The performance of the RDWT is reported with subject-wise averages using accuracy and Cohen's kappa, complemented by subject-level analyses to identify when RDWT is beneficial. On BCI-IV-2a, RDWT yields clear average gains for EEGTCNet (+4.44 percentage points, pp; kappa +0.059) and MBEEG\_SENet (+2.23 pp; +0.030), with smaller improvements for EEGNet (+2.08 pp; +0.027) and ShallowConvNet (+0.58 pp; +0.008). On BCI-IV-2b, the enhancements observed are modest yet consistent for EEGNet (+0.21 pp; +0.044) and EEGTCNet (+0.28 pp; +0.077). On HGD, average effects are modest to positive, with the most significant gain observed for MBEEG\_SENet (+1.65 pp; +0.022), followed by EEGNet (+0.76 pp; +0.010) and EEGTCNet (+0.54 pp; +0.008). Inspection of the subject material reveals significant enhancements in challenging recordings (e.g., non-stationary sessions), indicating that RDWT can mitigate localized noise and enhance rhythm-specific information. In conclusion, RDWT is shown to be a low-overhead, architecture-aware preprocessing technique that can yield tangible gains in accuracy and agreement for deep model families and challenging subjects.

**AI Summary:** This study explores the impact of using the Rational Discrete Wavelet Transform (RDWT) as a preprocessing step for motor imagery EEG decoding with deep learning models. The results show that RDWT can lead to improvements in accuracy and agreement for deep learning architectures across different benchmark datasets. The findings suggest that RDWT is a beneficial and low-overhead technique that can enhance the performance of deep learning models, particularly in challenging scenarios such as non-stationary sessions.

---

## Promptimizer: User-Led Prompt Optimization for Personal Content Classification
**URL:** https://arxiv.org/abs/2510.09009

**Abstract:** While LLMs now enable users to create content classifiers easily through natural language, automatic prompt optimization techniques are often necessary to create performant classifiers. However, such techniques can fail to consider how social media users want to evolve their filters over the course of usage, including desiring to steer them in different ways during initialization and iteration. We introduce a user-centered prompt optimization technique, Promptimizer, that maintains high performance and ease-of-use but additionally (1) allows for user input into the optimization process and (2) produces final prompts that are interpretable. A lab experiment (n=16) found that users significantly preferred Promptimizer's human-in-the-loop optimization over a fully automatic approach. We further implement Promptimizer into Puffin, a tool to support YouTube content creators in creating and maintaining personal classifiers to manage their comments. Over a 3-week deployment with 10 creators, participants successfully created diverse filters to better understand their audiences and protect their communities.

**AI Summary:** The research introduces Promptimizer, a user-centered prompt optimization technique that allows users to provide input into the optimization process and produces interpretable final prompts for content classification. A lab experiment showed that users significantly preferred Promptimizer over fully automatic approaches. The implementation of Promptimizer in Puffin, a tool for YouTube content creators, allowed participants to successfully create diverse filters to understand their audiences and protect their communities.

---

## Creation, Critique, and Consumption: Exploring Generative AI Descriptions for Supporting Blind and Low Vision Professionals with Visual Tasks
**URL:** https://arxiv.org/abs/2510.08991

**Abstract:** Many blind and low vision (BLV) people are excluded from professional roles that may involve visual tasks due to access barriers and persisting stigmas. Advancing generative AI systems can support BLV people through providing contextual and personalized visual descriptions for creation, critique, and consumption. In this workshop paper, we provide design suggestions for how visual descriptions can be better contextualized for multiple professional tasks. We conclude by discussing how these designs can improve autonomy, inclusion, and skill development over time.

**AI Summary:** This research explores how generative AI systems can provide contextual and personalized visual descriptions to support blind and low vision professionals in performing visual tasks. The study suggests design improvements to better contextualize visual descriptions for various professional tasks, ultimately aiming to enhance autonomy, inclusion, and skill development for BLV individuals. The findings highlight the potential of AI technology to break down access barriers and stigmas, enabling BLV professionals to participate more fully in visual tasks.

---

## Co-Authoring the Self: A Human-AI Interface for Interest Reflection in Recommenders
**URL:** https://arxiv.org/abs/2510.08930

**Abstract:** Natural language-based user profiles in recommender systems have been explored for their interpretability and potential to help users scrutinize and refine their interests, thereby improving recommendation quality. Building on this foundation, we introduce a human-AI collaborative profile for a movie recommender system that presents editable personalized interest summaries of a user's movie history. Unlike static profiles, this design invites users to directly inspect, modify, and reflect on the system's inferences. In an eight-week online field deployment with 1775 active movie recommender users, we find persistent gaps between user-perceived and system-inferred interests, show how the profile encourages engagement and reflection, and identify design directions for leveraging imperfect AI-powered user profiles to stimulate more user intervention and build more transparent and trustworthy recommender experiences.

**AI Summary:** This research explores the use of a human-AI collaborative profile in a movie recommender system to present editable personalized interest summaries to users. The study found persistent gaps between user-perceived and system-inferred interests, highlighting the importance of user intervention in refining recommendations. The design encourages user engagement and reflection, offering insights into how imperfect AI-powered profiles can be leveraged to create more transparent and trustworthy recommender experiences.

---

## "I know it's not right, but that's what it said to do": Investigating Trust in AI Chatbots for Cybersecurity Policy
**URL:** https://arxiv.org/abs/2510.08917

**Abstract:** AI chatbots are an emerging security attack vector, vulnerable to threats such as prompt injection, and rogue chatbot creation. When deployed in domains such as corporate security policy, they could be weaponized to deliver guidance that intentionally undermines system defenses. We investigate whether users can be tricked by a compromised AI chatbot in this scenario. A controlled study (N=15) asked participants to use a chatbot to complete security-related tasks. Without their knowledge, the chatbot was manipulated to give incorrect advice for some tasks. The results show how trust in AI chatbots is related to task familiarity, and confidence in their ownn judgment. Additionally, we discuss possible reasons why people do or do not trust AI chatbots in different scenarios.

**AI Summary:** This research investigates the potential for compromised AI chatbots to deceive users in cybersecurity policy tasks. The study found that users' trust in AI chatbots is influenced by their familiarity with the task and their confidence in their own judgment. The findings highlight the importance of understanding and addressing vulnerabilities in AI chatbots to prevent them from being used maliciously in cybersecurity settings.

---

## Beyond Words: Infusing Conversational Agents with Human-like Typing Behaviors
**URL:** https://arxiv.org/abs/2510.08912

**Abstract:** Recently, large language models have facilitated the emergence of highly intelligent conversational AI capable of engaging in human-like dialogues. However, a notable distinction lies in the fact that these AI models predominantly generate responses rapidly, often producing extensive content without emulating the thoughtful process characteristic of human cognition and typing. This paper presents a design aimed at simulating human-like typing behaviors, including patterns such as hesitation and self-editing, as well as a preliminary user experiment to understand whether and to what extent the agent with human-like typing behaviors could potentially affect conversational engagement and its trustworthiness. We've constructed an interactive platform featuring user-adjustable parameters, allowing users to personalize the AI's communication style and thus cultivate a more enriching and immersive conversational experience. Our user experiment, involving interactions with three types of agents - a baseline agent, one simulating hesitation, and another integrating both hesitation and self-editing behaviors - reveals a preference for the agent that incorporates both behaviors, suggesting an improvement in perceived naturalness and trustworthiness. Through the insights from our design process and both quantitative and qualitative feedback from user experiments, this paper contributes to the multimodal interaction design and user experience for conversational AI, advocating for a more human-like, engaging, and trustworthy communication paradigm.

**AI Summary:** This research explores infusing conversational agents with human-like typing behaviors to enhance the naturalness and trustworthiness of AI interactions. By simulating hesitation and self-editing in AI responses, the study found that users preferred agents with these behaviors, indicating improved perceived naturalness and trustworthiness. This design approach contributes to the development of more engaging and immersive conversational experiences with AI, highlighting the importance of human-like communication paradigms in AI design.

---

## Green Grid: Smart Tech Meets E-Waste
**URL:** https://arxiv.org/abs/2510.08888

**Abstract:** Electronic waste (e-waste) is a rapidly growing global problem caused by shorter device lifecycles and rising consumption. India ranks third globally in e-waste generation, producing over 1.7 million tonnes in 2023-24, of which less than half is formally processed. To address this, we propose Green Grid, an integrated AI-powered e-waste management platform combining IoT-enabled smart collection, AI-based device classification, blockchain-based traceability, and gamified citizen engagement. The system features smart recycling bins with sensors for real-time monitoring, deep learning models for device identification and sorting, a blockchain ledger for tamper-proof tracking, and a reward-based mobile or web app to encourage user participation. Additionally, Green Grid offers analytics dashboards and an eco-marketplace to support policymakers and recyclers. By bridging technology, sustainability, and community participation, the platform enhances transparency, increases formal recycling rates, and advances India's transition toward a circular economy.

**AI Summary:** The research introduces Green Grid, an AI-powered e-waste management platform designed to address the growing global issue of electronic waste. The platform combines IoT-enabled smart collection, AI-based device classification, blockchain-based traceability, and gamified citizen engagement to increase formal recycling rates and promote sustainability. By integrating technology, transparency, and community participation, Green Grid aims to advance India's transition toward a circular economy and reduce the environmental impact of e-waste.

---

## MLLM as a UI Judge: Benchmarking Multimodal LLMs for Predicting Human Perception of User Interfaces
**URL:** https://arxiv.org/abs/2510.08783

**Abstract:** In an ideal design pipeline, user interface (UI) design is intertwined with user research to validate decisions, yet studies are often resource-constrained during early exploration. Recent advances in multimodal large language models (MLLMs) offer a promising opportunity to act as early evaluators, helping designers narrow options before formal testing. Unlike prior work that emphasizes user behavior in narrow domains such as e-commerce with metrics like clicks or conversions, we focus on subjective user evaluations across varied interfaces. We investigate whether MLLMs can mimic human preferences when evaluating individual UIs and comparing them. Using data from a crowdsourcing platform, we benchmark GPT-4o, Claude, and Llama across 30 interfaces and examine alignment with human judgments on multiple UI factors. Our results show that MLLMs approximate human preferences on some dimensions but diverge on others, underscoring both their potential and limitations in supplementing early UX research.

**AI Summary:** This research explores the use of multimodal large language models (MLLMs) as early evaluators of user interfaces (UI) to help designers make decisions before formal testing. The study focuses on subjective user evaluations across various interfaces and compares MLLMs' ability to mimic human preferences. Results show that while MLLMs can approximate human preferences on some dimensions, they diverge on others, highlighting their potential and limitations in supplementing early UX research.

---

## Understanding and Predicting Temporal Visual Attention Influenced by Dynamic Highlights in Monitoring Task
**URL:** https://arxiv.org/abs/2510.08777

**Abstract:** Monitoring interfaces are crucial for dynamic, highstakes tasks where effective user attention is essential. Visual highlights can guide attention effectively but may also introduce unintended disruptions. To investigate this, we examined how visual highlights affect users' gaze behavior in a drone monitoring task, focusing on when, how long, and how much attention they draw. We found that highlighted areas exhibit distinct temporal characteristics compared to non-highlighted ones, quantified using normalized saliency (NS) metrics. Highlights elicited immediate responses, with NS peaking quickly, but this shift came at the cost of reduced search efforts elsewhere, potentially impacting situational awareness. To predict these dynamic changes and support interface design, we developed the Highlight-Informed Saliency Model (HISM), which provides granular predictions of NS over time. These predictions enable evaluations of highlight effectiveness and inform the optimal timing and deployment of highlights in future monitoring interface designs, particularly for time-sensitive tasks.

**AI Summary:** This research examines how visual highlights impact users' gaze behavior in a drone monitoring task, finding that highlighted areas attract immediate attention but may reduce search efforts elsewhere. The study introduces the Highlight-Informed Saliency Model (HISM) to predict changes in attention over time, aiding in the design of more effective monitoring interfaces for time-sensitive tasks. These findings are important for improving situational awareness and optimizing the deployment of visual highlights in dynamic, high-stakes tasks.

---

## Identifying & Interactively Refining Ambiguous User Goals for Data Visualization Code Generation
**URL:** https://arxiv.org/abs/2510.09390

**Abstract:** Establishing shared goals is a fundamental step in human-AI communication. However, ambiguities can lead to outputs that seem correct but fail to reflect the speaker's intent. In this paper, we explore this issue with a focus on the data visualization domain, where ambiguities in natural language impact the generation of code that visualizes data. The availability of multiple views on the contextual (e.g., the intended plot and the code rendering the plot) allows for a unique and comprehensive analysis of diverse ambiguity types. We develop a taxonomy of types of ambiguity that arise in this task and propose metrics to quantify them. Using Matplotlib problems from the DS-1000 dataset, we demonstrate that our ambiguity metrics better correlate with human annotations than uncertainty baselines. Our work also explores how multi-turn dialogue can reduce ambiguity, therefore, improve code accuracy by better matching user goals. We evaluate three pragmatic models to inform our dialogue strategies: Gricean Cooperativity, Discourse Representation Theory, and Questions under Discussion. A simulated user study reveals how pragmatic dialogues reduce ambiguity and enhance code accuracy, highlighting the value of multi-turn exchanges in code generation.

**AI Summary:** This research focuses on identifying and refining ambiguous user goals for data visualization code generation, which is crucial for effective human-AI communication. The study develops a taxonomy of ambiguity types and proposes metrics to quantify them, showing that these metrics outperform uncertainty baselines in correlating with human annotations. The research also explores how multi-turn dialogue can reduce ambiguity and improve code accuracy by better aligning with user goals, highlighting the importance of pragmatic dialogues in code generation tasks.

---

## Towards Safer and Understandable Driver Intention Prediction
**URL:** https://arxiv.org/abs/2510.09200

**Abstract:** Autonomous driving (AD) systems are becoming increasingly capable of handling complex tasks, mainly due to recent advances in deep learning and AI. As interactions between autonomous systems and humans increase, the interpretability of decision-making processes in driving systems becomes increasingly crucial for ensuring safe driving operations. Successful human-machine interaction requires understanding the underlying representations of the environment and the driving task, which remains a significant challenge in deep learning-based systems. To address this, we introduce the task of interpretability in maneuver prediction before they occur for driver safety, i.e., driver intent prediction (DIP), which plays a critical role in AD systems. To foster research in interpretable DIP, we curate the eXplainable Driving Action Anticipation Dataset (DAAD-X), a new multimodal, ego-centric video dataset to provide hierarchical, high-level textual explanations as causal reasoning for the driver's decisions. These explanations are derived from both the driver's eye-gaze and the ego-vehicle's perspective. Next, we propose Video Concept Bottleneck Model (VCBM), a framework that generates spatio-temporally coherent explanations inherently, without relying on post-hoc techniques. Finally, through extensive evaluations of the proposed VCBM on the DAAD-X dataset, we demonstrate that transformer-based models exhibit greater interpretability than conventional CNN-based models. Additionally, we introduce a multilabel t-SNE visualization technique to illustrate the disentanglement and causal correlation among multiple explanations. Our data, code and models are available at: this https URL

**AI Summary:** This research focuses on the importance of interpretability in autonomous driving systems to ensure safe operations. The study introduces the concept of driver intent prediction (DIP) and presents a new dataset, DAAD-X, for interpretable maneuver prediction. The proposed Video Concept Bottleneck Model (VCBM) demonstrates that transformer-based models offer greater interpretability than traditional CNN-based models, and a multilabel t-SNE visualization technique is introduced to illustrate causal correlations among multiple explanations.

---

## Student Development Agent: Risk-free Simulation for Evaluating AIED Innovations
**URL:** https://arxiv.org/abs/2510.09183

**Abstract:** In the age of AI-powered educational (AIED) innovation, evaluating the developmental consequences of novel designs before they are exposed to students has become both essential and challenging. Since such interventions may carry irreversible effects, it is critical to anticipate not only potential benefits but also possible harms. This study proposes a student development agent framework based on large language models (LLMs), designed to simulate how students with diverse characteristics may evolve under different educational settings without administering them to real students. By validating the approach through a case study on a multi-agent learning environment (MAIC), we demonstrate that the agent's predictions align with real student outcomes in non-cognitive developments. The results suggest that LLM-based simulations hold promise for evaluating AIED innovations efficiently and ethically. Future directions include enhancing profile structures, incorporating fine-tuned or small task-specific models, validating effects of empirical findings, interpreting simulated data and optimizing evaluation methods.

**AI Summary:** This research proposes a framework using large language models to simulate how students may develop under different educational settings without actually exposing them to interventions. The study shows that the agent's predictions align with real student outcomes in non-cognitive developments, suggesting the potential of LLM-based simulations for evaluating AIED innovations effectively and ethically. Future directions include improving profile structures, incorporating task-specific models, validating empirical findings, interpreting simulated data, and optimizing evaluation methods.

---

## Training Models to Detect Successive Robot Errors from Human Reactions
**URL:** https://arxiv.org/abs/2510.09080

**Abstract:** As robots become more integrated into society, detecting robot errors is essential for effective human-robot interaction (HRI). When a robot fails repeatedly, how can it know when to change its behavior? Humans naturally respond to robot errors through verbal and nonverbal cues that intensify over successive failures-from confusion and subtle speech changes to visible frustration and impatience. While prior work shows that human reactions can indicate robot failures, few studies examine how these evolving responses reveal successive failures. This research uses machine learning to recognize stages of robot failure from human reactions. In a study with 26 participants interacting with a robot that made repeated conversational errors, behavioral features were extracted from video data to train models for individual users. The best model achieved 93.5% accuracy for detecting errors and 84.1% for classifying successive failures. Modeling the progression of human reactions enhances error detection and understanding of repeated interaction breakdowns in HRI.

**AI Summary:** This research focuses on using machine learning to detect stages of robot failure from human reactions in order to improve human-robot interaction. The study found that human responses to robot errors intensify over successive failures, from confusion to frustration, and that these evolving reactions can be used to accurately detect and classify robot errors. By training models on individual user data, the research achieved high accuracy in detecting errors and understanding the progression of human reactions during repeated interactions with robots.

---

## Emotion-Disentangled Embedding Alignment for Noise-Robust and Cross-Corpus Speech Emotion Recognition
**URL:** https://arxiv.org/abs/2510.09072

**Abstract:** Effectiveness of speech emotion recognition in real-world scenarios is often hindered by noisy environments and variability across datasets. This paper introduces a two-step approach to enhance the robustness and generalization of speech emotion recognition models through improved representation learning. First, our model employs EDRL (Emotion-Disentangled Representation Learning) to extract class-specific discriminative features while preserving shared similarities across emotion categories. Next, MEA (Multiblock Embedding Alignment) refines these representations by projecting them into a joint discriminative latent subspace that maximizes covariance with the original speech input. The learned EDRL-MEA embeddings are subsequently used to train an emotion classifier using clean samples from publicly available datasets, and are evaluated on unseen noisy and cross-corpus speech samples. Improved performance under these challenging conditions demonstrates the effectiveness of the proposed method.

**AI Summary:** This research paper introduces a two-step approach to improve speech emotion recognition models in noisy environments and across different datasets. The model uses EDRL to extract class-specific features while preserving shared similarities, and MEA to refine these representations in a joint discriminative latent subspace. The proposed method shows improved performance in recognizing emotions in challenging conditions, highlighting its effectiveness in real-world scenarios.

---

## Designing and Evaluating an AI-driven Immersive Multidisciplinary Simulation (AIMS) for Interprofessional Education
**URL:** https://arxiv.org/abs/2510.08891

**Abstract:** Interprofessional education has long relied on case studies and the use of standardized patients to support teamwork, communication, and related collaborative competencies among healthcare professionals. However, traditional approaches are often limited by cost, scalability, and inability to mimic the dynamic complexity of real-world clinical scenarios. To address these challenges, we designed and developed AIMS (AI-Enhanced Immersive Multidisciplinary Simulations), a virtual simulation that integrates a large language model (Gemini-2.5-Flash), a Unity-based virtual environment engine, and a character creation pipeline to support synchronized, multimodal interactions between the user and the virtual patient. AIMS was designed to enhance collaborative clinical reasoning and health promotion competencies among students from pharmacy, medicine, nursing, and social work. A formal usability testing session was conducted which participants assumed professional roles on a healthcare team and engaged in a mix of scripted and unscripted conversations. Participants explored the patient's symptoms, social context, and care needs. Usability issues were identified (e.g., audio routing, response latency) and used to guide subsequent refinements. Findings in general suggest that AIMS supports realistic, profession-specific and contextually appropriate conversations. We discussed both technical and pedagogical innovations of AIMS and concluded with future directions.

**AI Summary:** The research focused on developing an AI-driven immersive simulation, AIMS, to enhance interprofessional education in healthcare. AIMS integrates a language model and virtual environment engine to support realistic interactions between users and virtual patients, improving collaborative clinical reasoning and health promotion competencies. Usability testing identified areas for improvement, but overall, AIMS was found to support profession-specific and contextually appropriate conversations, showing promise for future use in healthcare education.

---

## GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare
**URL:** https://arxiv.org/abs/2510.08872

**Abstract:** Large Language Models (LLMs) have achieved remarkable progress in reasoning, yet sometimes produce responses that are suboptimal for users in tasks such as writing, information seeking, or providing practical guidance. Conventional alignment practices typically assume that maximizing model reward also maximizes user welfare, but this assumption frequently fails in practice: models may over-clarify or generate overly verbose reasoning when users prefer concise answers. Such behaviors resemble the prisoner's dilemma, where individually rational choices lead to socially suboptimal outcomes. The fundamental challenge is the lack of a principled decision making mechanism that mutually benefits both the LLM and the user. We propose Game-Theoretic Alignment (GTAlign), an alignment framework that integrates game-theoretic decision making into both reasoning and training. During reasoning, the model explicitly treats user-LLM interaction as a strategic game: it constructs payoff matrices within its reasoning chain to estimate welfare for both itself and the user, and then selects actions that are mutually beneficial. During training, we introduce a mutual welfare reward that reinforces cooperative responses, aligning model behavior with socially efficient outcomes. In addition, we introduce an inference technique that leverages game-theoretic reasoning to dynamically adapt LLM's response when pricing policies of LLM service change. Extensive experiments demonstrate that GTAlign substantially improves reasoning efficiency, answer quality, and mutual welfare compared to baselines across diverse tasks. The code is available at this https URL .

**AI Summary:** The research introduces GTAlign, a game-theoretic alignment framework for Large Language Models (LLMs) to improve user welfare. By treating user-LLM interaction as a strategic game, GTAlign helps LLMs generate more cooperative and socially efficient responses during reasoning and training. Experimental results show that GTAlign significantly enhances reasoning efficiency, answer quality, and mutual welfare across various tasks, highlighting its potential for improving user experience with LLM assistants.

---

## Everyone prefers human writers, including AI
**URL:** https://arxiv.org/abs/2510.08831

**Abstract:** As AI writing tools become widespread, we need to understand how both humans and machines evaluate literary style, a domain where objective standards are elusive and judgments are inherently subjective. We conducted controlled experiments using Raymond Queneau's Exercises in Style (1947) to measure attribution bias across evaluators. Study 1 compared human participants (N=556) and AI models (N=13) evaluating literary passages from Queneau versus GPT-4-generated versions under three conditions: blind, accurately labeled, and counterfactually labeled. Study 2 tested bias generalization across a 14$\times$14 matrix of AI evaluators and creators. Both studies revealed systematic pro-human attribution bias. Humans showed +13.7 percentage point (pp) bias (Cohen's h = 0.28, 95% CI: 0.21-0.34), while AI models showed +34.3 percentage point bias (h = 0.70, 95% CI: 0.65-0.76), a 2.5-fold stronger effect (P$<$0.001). Study 2 confirmed this bias operates across AI architectures (+25.8pp, 95% CI: 24.1-27.6%), demonstrating that AI systems systematically devalue creative content when labeled as "AI-generated" regardless of which AI created it. We also find that attribution labels cause evaluators to invert assessment criteria, with identical features receiving opposing evaluations based solely on perceived authorship. This suggests AI models have absorbed human cultural biases against artificial creativity during training. Our study represents the first controlled comparison of attribution bias between human and artificial evaluators in aesthetic judgment, revealing that AI systems not only replicate but amplify this human tendency.

**AI Summary:** This research explores how both humans and AI evaluate literary style, specifically looking at attribution bias towards human versus AI-generated writing. The study found that both humans and AI models show a systematic pro-human attribution bias, with AI models showing a 2.5-fold stronger effect. This suggests that AI systems have absorbed human cultural biases against artificial creativity during training, highlighting the importance of understanding how AI and human evaluators perceive and value creative content.

---

## AgenticAD: A Specialized Multiagent System Framework for Holistic Alzheimer Disease Management
**URL:** https://arxiv.org/abs/2510.08578

**Abstract:** Alzheimer's disease (AD) presents a complex, multifaceted challenge to patients, caregivers, and the healthcare system, necessitating integrated and dynamic support solutions. While artificial intelligence (AI) offers promising avenues for intervention, current applications are often siloed, addressing singular aspects of the disease such as diagnostics or caregiver support without systemic integration. This paper proposes a novel methodological framework for a comprehensive, multi-agent system (MAS) designed for holistic Alzheimer's disease management. The objective is to detail the architecture of a collaborative ecosystem of specialized AI agents, each engineered to address a distinct challenge in the AD care continuum, from caregiver support and multimodal data analysis to automated research and clinical data interpretation. The proposed framework is composed of eight specialized, interoperable agents. These agents are categorized by function: (1) Caregiver and Patient Support, (2) Data Analysis and Research, and (3) Advanced Multimodal Workflows. The methodology details the technical architecture of each agent, leveraging a suite of advanced technologies including large language models (LLMs) such as GPT-4o and Gemini, multi-agent orchestration frameworks, Retrieval-Augmented Generation (RAG) for evidence-grounded responses, and specialized tools for web scraping, multimodal data processing, and in-memory database querying. This paper presents a detailed architectural blueprint for an integrated AI ecosystem for AD care. By moving beyond single-purpose tools to a collaborative, multi-agent paradigm, this framework establishes a foundation for developing more adaptive, personalized, and proactive solutions. This methodological approach aims to pave the way for future systems capable of synthesizing diverse data streams to improve patient outcomes and reduce caregiver burden.

**AI Summary:** This research paper introduces AgenticAD, a specialized multi-agent system framework designed for comprehensive Alzheimer's disease management. The framework consists of eight specialized AI agents categorized by function, leveraging advanced technologies such as large language models and multi-agent orchestration frameworks. By moving beyond singular applications to a collaborative ecosystem, this framework aims to improve patient outcomes and reduce caregiver burden by synthesizing diverse data streams for more adaptive and personalized solutions in Alzheimer's disease care.

---

## Comparative Analysis of Large Language Models for the Machine-Assisted Resolution of User Intentions
**URL:** https://arxiv.org/abs/2510.08576

**Abstract:** Large Language Models (LLMs) have emerged as transformative tools for natural language understanding and user intent resolution, enabling tasks such as translation, summarization, and, increasingly, the orchestration of complex workflows. This development signifies a paradigm shift from conventional, GUI-driven user interfaces toward intuitive, language-first interaction paradigms. Rather than manually navigating applications, users can articulate their objectives in natural language, enabling LLMs to orchestrate actions across multiple applications in a dynamic and contextual manner. However, extant implementations frequently rely on cloud-based proprietary models, which introduce limitations in terms of privacy, autonomy, and scalability. For language-first interaction to become a truly robust and trusted interface paradigm, local deployment is not merely a convenience; it is an imperative. This limitation underscores the importance of evaluating the feasibility of locally deployable, open-source, and open-access LLMs as foundational components for future intent-based operating systems. In this study, we examine the capabilities of several open-source and open-access models in facilitating user intention resolution through machine assistance. A comparative analysis is conducted against OpenAI's proprietary GPT-4-based systems to assess performance in generating workflows for various user intentions. The present study offers empirical insights into the practical viability, performance trade-offs, and potential of open LLMs as autonomous, locally operable components in next-generation operating systems. The results of this study inform the broader discussion on the decentralization and democratization of AI infrastructure and point toward a future where user-device interaction becomes more seamless, adaptive, and privacy-conscious through locally embedded intelligence.

**AI Summary:** This research explores the use of Large Language Models (LLMs) for user intention resolution, highlighting the shift towards language-first interaction paradigms. The study compares open-source LLMs to proprietary models like OpenAI's GPT-4, emphasizing the importance of locally deployable and open-access models for privacy, autonomy, and scalability. The findings suggest that open LLMs have the potential to be autonomous components in future intent-based operating systems, contributing to the decentralization and democratization of AI infrastructure for more seamless, adaptive, and privacy-conscious user-device interactions.

---

## What Makes a Visualization Complex?
**URL:** https://arxiv.org/abs/2510.08332

**Abstract:** We investigate the perceived visual complexity (VC) in data visualizations using objective image-based metrics. We collected VC scores through a large-scale crowdsourcing experiment involving 349 participants and 1,800 visualization images. We then examined how these scores align with 12 image-based metrics spanning information-theoretic, clutter, color, and our two object-based metrics. Our results show that both low-level image properties and the high-level elements affect perceived VC in visualization images; The number of corners and distinct colors are robust metrics across visualizations. Second, feature congestion, an information-theoretic metric capturing statistical patterns in color and texture, is the strongest predictor of perceived complexity in visualizations rich in the same stimuli; edge density effectively explains VC in node-link diagrams. Additionally, we observe a bell-curve effect for text annotations: increasing text-to-ink ratio (TiR) initially reduces complexity, reaching an optimal point, beyond which further text increases perceived complexity. Our quantification pipeline is also interpretable, enabling metric-based explanations, grounded in the VisComplexity2K dataset, bridging computational metrics with human perceptual responses. this http URL has the preregistration and this http URL has the VisComplexity2K dataset, source code, and all Apdx. and figures.

**AI Summary:** This research explores the factors influencing perceived visual complexity in data visualizations through a crowdsourcing experiment involving 1,800 visualization images. The study found that both low-level image properties and high-level elements contribute to perceived complexity, with metrics such as number of corners, distinct colors, feature congestion, and edge density playing significant roles. The results provide insights into how different visual elements impact complexity perception, offering a quantification pipeline for interpreting and explaining visual complexity in data visualizations.

---

## Motion Exploration of Articulated Product Concepts in Interactive Sketching Environment
**URL:** https://arxiv.org/abs/2510.08328

**Abstract:** In the early stages of engineering design, it is essential to know how a product behaves, especially how it moves. As designers must keep adjusting the motion until it meets the intended requirements, this process is often repetitive and time-consuming. Although the physics behind these motions is usually based on simple equations, manually working through them can be tedious and inefficient. To ease this burden, some tasks are now handled by computers. One common method involves converting hand-drawn sketches into models using CAD or CAE software. However, this approach can be time- and resource-intensive. Additionally, product sketches are usually best understood only by the designers who created them. Others may struggle to interpret them correctly, relying heavily on intuition and prior experience. Since sketches are static, they fail to show how a product moves, limiting their usefulness. This paper presents a new approach that addresses these issues by digitising the natural act of sketching. It allows designers to create, simulate, and test the motion of mechanical concepts in a more interactive way. An application was developed to evaluate this method, focusing on user satisfaction and mental workload during a design task. The results showed a 77% reduction in cognitive effort compared to traditional methods, with users reporting high satisfaction. Future work will focus on expanding this approach from 2D (planar) to full 3D (spatial) design environments, enabling more complex product concept development.

**AI Summary:** The research explores a new approach to digitizing the sketching process for designing mechanical concepts, allowing designers to create, simulate, and test product motions more interactively. This method significantly reduces cognitive effort compared to traditional methods, with users reporting high satisfaction. Future work will focus on expanding this approach to full 3D design environments for more complex product concept development.

---

## LacAIDes: Generative AI-Supported Creative Interactive Circuits Crafting to Enliven Traditional Lacquerware
**URL:** https://arxiv.org/abs/2510.08326

**Abstract:** Lacquerware, a representative craft of Chinese intangible cultural heritage, is renowned for its layered aesthetics and durability but faces declining engagement. While prior human-computer interaction research has explored embedding interactive circuits to transform lacquerware into responsive artifacts, most studies have focused on fabrication techniques rather than supporting makers in creatively designing such interactions at a low threshold. To address this gap, we present LacAIDes, a Generative AI powered creativity-support tool built on a multi-agent workflow aligned with the double diamond model of design thinking. LacAIDes enables exploration and creation of culturally grounded interactive circuits without requiring prior technical expertise. We evaluated LacAIDes in a longitudinal workshop with 34 participants using a mixed-method approach. Results show that LacAIDes demonstrated high usability, enhanced creative engagement in craft making, and encouraged critical reflection on the role of Generative AI in digital craft practices. This work contributes to human-computer interaction by introducing a novel creativity-support tool and providing empirical insights into revitalizing traditional craft making through Generative AI.

**AI Summary:** The research introduces LacAIDes, a Generative AI-powered tool that supports the creative design of interactive circuits in traditional lacquerware crafting. The tool was found to be highly usable and effective in enhancing creative engagement among participants, while also sparking critical reflection on the role of AI in craft practices. This work contributes to human-computer interaction by providing a novel approach to revitalizing traditional crafts through the use of Generative AI.

---

## Simulating Teams with LLM Agents: Interactive 2D Environments for Studying Human-AI Dynamics
**URL:** https://arxiv.org/abs/2510.08242

**Abstract:** Enabling users to create their own simulations offers a powerful way to study team dynamics and performance. We introduce VirTLab, a system that allows researchers and practitioners to design interactive, customizable simulations of team dynamics with LLM-based agents situated in 2D spatial environments. Unlike prior frameworks that restrict scenarios to predefined or static tasks, our approach enables users to build scenarios, assign roles, and observe how agents coordinate, move, and adapt over time. By bridging team cognition behaviors with scalable agent-based modeling, our system provides a testbed for investigating how environments influence coordination, collaboration, and emergent team behaviors. We demonstrate its utility by aligning simulated outcomes with empirical evaluations and a user study, underscoring the importance of customizable environments for advancing research on multi-agent simulations. This work contributes to making simulations accessible to both technical and non-technical users, supporting the design, execution, and analysis of complex multi-agent experiments.

**AI Summary:** The research introduces VirTLab, a system for creating interactive simulations of team dynamics with LLM-based agents in 2D environments. Unlike previous frameworks, VirTLab allows users to design scenarios, assign roles, and observe how agents coordinate and adapt over time, bridging team cognition behaviors with agent-based modeling. The system's utility is demonstrated through aligning simulated outcomes with empirical evaluations and a user study, highlighting the importance of customizable environments for advancing research on multi-agent simulations and making simulations accessible to a wider range of users.

---

## Practicing a Second Language Without Fear: Mixed Reality Agents for Interactive Group Conversation
**URL:** https://arxiv.org/abs/2510.08227

**Abstract:** Developing speaking proficiency in a second language can be cognitively demanding and emotionally taxing, often triggering fear of making mistakes or being excluded from larger groups. While current learning tools show promise for speaking practice, most focus on dyadic, scripted scenarios, limiting opportunities for dynamic group interactions. To address this gap, we present ConversAR, a Mixed Reality system that leverages Generative AI and XR to support situated and personalized group conversations. It integrates embodied AI agents, scene recognition, and generative 3D props anchored to real-world surroundings. Based on a formative study with experts in language acquisition, we developed and tested this system with a user study with 21 second-language learners. Results indicate that the system enhanced learner engagement, increased willingness to communicate, and offered a safe space for speaking. We discuss the implications for integrating Generative AI and XR into the design of future language learning applications.

**AI Summary:** The research presents ConversAR, a Mixed Reality system that uses Generative AI and XR to facilitate group conversations for second-language learners. The system was found to enhance learner engagement, increase willingness to communicate, and provide a safe space for speaking practice. The study highlights the potential of integrating Generative AI and XR in future language learning applications to improve speaking proficiency without fear.

---

## Sentiment Matters: An Analysis of 200 Human-SAV Interactions
**URL:** https://arxiv.org/abs/2510.08202

**Abstract:** Shared Autonomous Vehicles (SAVs) are likely to become an important part of the transportation system, making effective human-SAV interactions an important area of research. This paper introduces a dataset of 200 human-SAV interactions to further this area of study. We present an open-source human-SAV conversational dataset, comprising both textual data (e.g., 2,136 human-SAV exchanges) and empirical data (e.g., post-interaction survey results on a range of psychological factors). The dataset's utility is demonstrated through two benchmark case studies: First, using random forest modeling and chord diagrams, we identify key predictors of SAV acceptance and perceived service quality, highlighting the critical influence of response sentiment polarity (i.e., perceived positivity). Second, we benchmark the performance of an LLM-based sentiment analysis tool against the traditional lexicon-based TextBlob method. Results indicate that even simple zero-shot LLM prompts more closely align with user-reported sentiment, though limitations remain. This study provides novel insights for designing conversational SAV interfaces and establishes a foundation for further exploration into advanced sentiment modeling, adaptive user interactions, and multimodal conversational systems.

**AI Summary:** This research paper introduces a dataset of 200 human-SAV interactions to study effective human-SAV interactions, focusing on sentiment analysis. The study found that response sentiment polarity plays a critical role in SAV acceptance and perceived service quality, with LLM-based sentiment analysis showing promising results compared to traditional methods. These findings provide valuable insights for designing conversational SAV interfaces and pave the way for further research into advanced sentiment modeling and adaptive user interactions.

---

## Development of Mental Models in Human-AI Collaboration: A Conceptual Framework
**URL:** https://arxiv.org/abs/2510.08104

**Abstract:** Artificial intelligence has become integral to organizational decision-making and while research has explored many facets of this human-AI collaboration, the focus has mainly been on designing the AI agent(s) and the way the collaboration is set up - generally assuming a human decision-maker to be "fixed". However, it has largely been neglected that decision-makers' mental models evolve through their continuous interaction with AI systems. This paper addresses this gap by conceptualizing how the design of human-AI collaboration influences the development of three complementary and interdependent mental models necessary for this collaboration. We develop an integrated socio-technical framework that identifies the mechanisms driving the mental model evolution: data contextualization, reasoning transparency, and performance feedback. Our work advances human-AI collaboration literature through three key contributions: introducing three distinct mental models (domain, information processing, complementarity-awareness); recognizing the dynamic nature of mental models; and establishing mechanisms that guide the purposeful design of effective human-AI collaboration.

**AI Summary:** This research paper focuses on the development of mental models in human-AI collaboration, highlighting the importance of understanding how decision-makers' mental models evolve through interaction with AI systems. The study introduces three key mental models necessary for effective collaboration - domain, information processing, and complementarity-awareness - and identifies mechanisms such as data contextualization, reasoning transparency, and performance feedback that drive the evolution of these models. By addressing this gap in existing literature, the paper contributes to advancing the understanding of human-AI collaboration and provides a framework for designing more effective collaborative systems.

---

## Quantifying Locomotion Differences Between Virtual Reality Users With and Without Motor Impairments
**URL:** https://arxiv.org/abs/2510.07987

**Abstract:** Today's virtual reality (VR) systems and environments assume that users have typical abilities, which can make VR inaccessible to people with physical impairments. However, there is not yet an understanding of how inaccessible locomotion techniques are, and which interactions make them inaccessible. To this end, we conducted a study in which people with and without upper-body impairments navigated a virtual environment with six locomotion techniques to quantify performance differences among groups. We found that groups performed similarly with Sliding Looking on all performance measures, suggesting that this might be a good default locomotion technique for VR apps. To understand the nature of performance differences with the other techniques, we collected low-level interaction data from the controllers and headset and analyzed interaction differences with a set of movement-, button-, and target-related metrics. We found that movement-related metrics from headset data reveal differences among groups with all techniques, suggesting these are good metrics for identifying whether a user has an upper-body impairment. We also identify movement-, button, and target- related metrics that can explain performance differences between groups for particular locomotion techniques.

**AI Summary:** This study aimed to quantify performance differences in virtual reality locomotion techniques between users with and without motor impairments. The findings suggest that the Sliding Looking technique performed similarly for both groups, indicating it may be a suitable default technique for VR apps. Movement-related metrics from headset data were found to be effective in identifying users with upper-body impairments, and other interaction metrics were identified as explaining performance differences for specific locomotion techniques. This research highlights the importance of understanding and accommodating for diverse user abilities in VR technology.

---

## Pre/Absence: Prompting Cultural Awareness and Understanding for Lost Architectural Heritage in Virtual Reality
**URL:** https://arxiv.org/abs/2510.07967

**Abstract:** Lost architectural heritage presents interpretive challenges due to vanished structures and fragmented historical records. Using Hanyuan Hall of the Tang dynasty's Daming Palace as a case study, we conducted a formative investigation with archaeologists, heritage administrators, and visitors to identify key issues in current interpretation practices. We found that these practices often compress complex cultural layers into factual summaries and rely on linear narratives that overlook the continuing reinterpretations following a site's disappearance. In response, we designed Pre/Absence, a virtual reality experience grounded in the presence-absence dialectic to interweave tangible and vanished aspects of heritage within a spatiotemporal narrative. A mixed-method study with 28 participants compared Pre/Absence to a paper-based experience. Both improved users' factual understanding, but the VR experience more strongly enhanced cultural awareness, evoked emotional engagement with loss, and encouraged critical reflection on the evolving social and political meanings of heritage. The findings suggest that VR can move beyond static reconstruction to engage users as co-constructors of cultural meaning, providing a nuanced framework for critical heritage narrative design in human-computer interaction.

**AI Summary:** This research explores the challenges of interpreting lost architectural heritage and the limitations of current practices in compressing complex cultural layers into factual summaries. The study introduces Pre/Absence, a virtual reality experience that interweaves tangible and vanished aspects of heritage to enhance cultural awareness and emotional engagement with loss. The findings suggest that VR can be a powerful tool for engaging users in co-constructing cultural meaning and encouraging critical reflection on the evolving social and political meanings of heritage.

---

## A Systematic Evaluation of Self-Supervised Learning for Label-Efficient Sleep Staging with Wearable EEG
**URL:** https://arxiv.org/abs/2510.07960

**Abstract:** Wearable EEG devices have emerged as a promising alternative to polysomnography (PSG). As affordable and scalable solutions, their widespread adoption results in the collection of massive volumes of unlabeled data that cannot be analyzed by clinicians at scale. Meanwhile, the recent success of deep learning for sleep scoring has relied on large annotated datasets. Self-supervised learning (SSL) offers an opportunity to bridge this gap, leveraging unlabeled signals to address label scarcity and reduce annotation effort. In this paper, we present the first systematic evaluation of SSL for sleep staging using wearable EEG. We investigate a range of well-established SSL methods and evaluate them on two sleep databases acquired with the Ikon Sleep wearable EEG headband: BOAS, a high-quality benchmark containing PSG and wearable EEG recordings with consensus labels, and HOGAR, a large collection of home-based, self-recorded, and unlabeled recordings. Three evaluation scenarios are defined to study label efficiency, representation quality, and cross-dataset generalization. Results show that SSL consistently improves classification performance by up to 10% over supervised baselines, with gains particularly evident when labeled data is scarce. SSL achieves clinical-grade accuracy above 80% leveraging only 5% to 10% of labeled data, while the supervised approach requires twice the labels. Additionally, SSL representations prove robust to variations in population characteristics, recording environments, and signal quality. Our findings demonstrate the potential of SSL to enable label-efficient sleep staging with wearable EEG, reducing reliance on manual annotations and advancing the development of affordable sleep monitoring systems.

**AI Summary:** This research evaluates the use of self-supervised learning (SSL) for sleep staging with wearable EEG devices, which can provide a more affordable and scalable alternative to traditional polysomnography. The study shows that SSL can significantly improve classification performance, particularly when labeled data is limited, and achieve clinical-grade accuracy with only a small percentage of labeled data. These findings suggest that SSL has the potential to enable label-efficient sleep staging with wearable EEG, reducing the need for manual annotations and advancing the development of affordable sleep monitoring systems.

---

## The Rise of the Knowledge Sculptor: A New Archetype for Knowledge Work in the Age of Generative AI
**URL:** https://arxiv.org/abs/2510.07829

**Abstract:** In the Generative Age, the nature of knowledge work is transforming. Traditional models that emphasise the organisation and retrieval of pre-existing information are increasingly inadequate in the face of generative AI (GenAI) systems capable of autonomous content creation. This paper introduces the Knowledge Sculptor (KS), a new professional archetype for Human-GenAI collaboration that transforms raw AI output into trustworthy, actionable knowledge. Grounded in a socio-technical perspective, the KS is conceptualised through a framework of competencies, including architecting a vision, iterative dialogue, information sculpting, and curiosity-driven synthesis. A practice-based vignette illustrates the KS role in action, and in a self-referential approach, the paper itself serves as an artefact of the sculpting process it describes.

**AI Summary:** The research explores the changing landscape of knowledge work in the era of generative AI, introducing the concept of the Knowledge Sculptor (KS) as a new professional archetype. The KS collaborates with AI systems to transform raw output into actionable knowledge through competencies such as vision architecting, iterative dialogue, information sculpting, and curiosity-driven synthesis. The paper showcases the role of the KS through a practice-based vignette and serves as an example of the sculpting process it discusses.

---

## Human-in-the-Loop Optimization with Model-Informed Priors
**URL:** https://arxiv.org/abs/2510.07754

**Abstract:** Human-in-the-loop optimization identifies optimal interface designs by iteratively observing user performance. However, it often requires numerous iterations due to the lack of prior information. While recent approaches have accelerated this process by leveraging previous optimization data, collecting user data remains costly and often impractical. We present a conceptual framework, Human-in-the-Loop Optimization with Model-Informed Priors (HOMI), which augments human-in-the-loop optimization with a training phase where the optimizer learns adaptation strategies from diverse, synthetic user data generated with predictive models before deployment. To realize HOMI, we introduce Neural Acquisition Function+ (NAF+), a Bayesian optimization method featuring a neural acquisition function trained with reinforcement learning. NAF+ learns optimization strategies from large-scale synthetic data, improving efficiency in real-time optimization with users. We evaluate HOMI and NAF+ with mid-air keyboard optimization, a representative VR input task. Our work presents a new approach for more efficient interface adaptation by bridging in situ and in silico optimization processes.

**AI Summary:** The study introduces a new framework called Human-in-the-Loop Optimization with Model-Informed Priors (HOMI) which combines human-in-the-loop optimization with a training phase using synthetic user data generated with predictive models. The framework is supported by a Bayesian optimization method called Neural Acquisition Function+ (NAF+) which learns optimization strategies from synthetic data, improving efficiency in real-time optimization with users. The research demonstrates the effectiveness of HOMI and NAF+ in optimizing mid-air keyboard interfaces in virtual reality, offering a more efficient approach to interface adaptation by combining in situ and in silico optimization processes.

---

## The Slow Space Editor : Broadening Access to Restorative XR
**URL:** https://arxiv.org/abs/2510.07610

**Abstract:** The Slow Space Editor is a 2D tool for creating 3D spaces. It was built as part of a research-through-design project that investigates how Virtual and Mixed Reality (XR) environments might be used for reflection and attention restoration. In this phase, we seek to radically simplify the creation of virtual environments, thereby broadening the potential group of users who could benefit from them. The research described in this paper has three aspects. First, we define the concept of "slow space," situating it alongside existing research in HCI and environmental psychology. Second, we report on a series of interviews with professional designers about how slow spaces are created in the physical world. Third, we share the design of the tool itself, focussing on the benefits of providing a simple method for users to control their environments. We conclude with our findings from a 19-person qualitative study of the tool.

**AI Summary:** The Slow Space Editor is a 2D tool designed to simplify the creation of 3D virtual environments for reflection and attention restoration in Virtual and Mixed Reality (XR). The research aims to broaden access to these environments by making them easier to create, potentially benefiting a wider range of users. The study defines the concept of "slow space," explores how professional designers create such spaces, and presents the design of the tool, highlighting the benefits of providing users with simple control over their environments.

---

## IGUANA: Immersive Guidance, Navigation, and Control for Consumer UAV
**URL:** https://arxiv.org/abs/2510.07609

**Abstract:** As the markets for unmanned aerial vehicles (UAVs) and mixed reality (MR) headsets continue to grow, recent research has increasingly explored their integration, which enables more intuitive, immersive, and situationally aware control systems. We present IGUANA, an MR-based immersive guidance, navigation, and control system for consumer UAVs. IGUANA introduces three key elements beyond conventional control interfaces: (1) a 3D terrain map interface with draggable waypoint markers and live camera preview for high-level control, (2) a novel spatial control metaphor that uses a virtual ball as a physical analogy for low-level control, and (3) a spatial overlay that helps track the UAV when it is not visible with the naked eye or visual line of sight is interrupted. We conducted a user study to evaluate our design, both quantitatively and qualitatively, and found that (1) the 3D map interface is intuitive and easy to use, relieving users from manual control and suggesting improved accuracy and consistency with lower perceived workload relative to conventional dual-stick controller, (2) the virtual ball interface is intuitive but limited by the lack of physical feedback, and (3) the spatial overlay is very useful in enhancing the users' situational awareness.

**AI Summary:** The research presents IGUANA, an immersive guidance, navigation, and control system for consumer UAVs that integrates mixed reality technology. The system includes a 3D terrain map interface, a spatial control metaphor using a virtual ball, and a spatial overlay to track the UAV when not visible. A user study showed that the 3D map interface improved accuracy and reduced workload compared to conventional controllers, while the virtual ball interface was intuitive but limited by the lack of physical feedback, and the spatial overlay enhanced situational awareness.

---

## A LoRa IoT Framework with Machine Learning for Remote Livestock Monitoring in Smart Agriculture
**URL:** https://arxiv.org/abs/2510.07322

**Abstract:** This work presents AgroTrack, a LoRa-based IoT framework for remote livestock monitoring in smart agriculture. The system is designed for low-power, long-range communication and supports real-time tracking and basic health assessment of free-range livestock through GPS, motion, and temperature sensors integrated into wearable collars. Data is collected and transmitted via LoRa to gateways and forwarded to a cloud platform for visualization, alerts, and analytics. To enhance its practical deployment, AgroTrack incorporates advanced analytics, including machine learning models for predictive health alerts and behavioral anomaly detection. This integration transforms the framework from a basic monitoring tool into an intelligent decision-support system, enabling farmers to improve livestock management, operational efficiency, and sustainability in rural environments.

**AI Summary:** The study introduces AgroTrack, a LoRa-based IoT framework for remote livestock monitoring in smart agriculture. The system utilizes wearable collars with GPS, motion, and temperature sensors to track and assess the health of free-range livestock. By incorporating machine learning models for predictive health alerts and behavioral anomaly detection, AgroTrack transforms into an intelligent decision-support system, aiding farmers in improving livestock management, operational efficiency, and sustainability in rural environments.

---

## How human is the machine? Evidence from 66,000 Conversations with Large Language Models
**URL:** https://arxiv.org/abs/2510.07321

**Abstract:** When Artificial Intelligence (AI) is used to replace consumers (e.g., synthetic data), it is often assumed that AI emulates established consumers, and more generally human behaviors. Ten experiments with Large Language Models (LLMs) investigate if this is true in the domain of well-documented biases and heuristics. Across studies we observe four distinct types of deviations from human-like behavior. First, in some cases, LLMs reduce or correct biases observed in humans. Second, in other cases, LLMs amplify these same biases. Third, and perhaps most intriguingly, LLMs sometimes exhibit biases opposite to those found in humans. Fourth, LLMs' responses to the same (or similar) prompts tend to be inconsistent (a) within the same model after a time delay, (b) across models, and (c) among independent research studies. Such inconsistencies can be uncharacteristic of humans and suggest that, at least at one point, LLMs' responses differed from humans. Overall, unhuman-like responses are problematic when LLMs are used to mimic or predict consumer behavior. These findings complement research on synthetic consumer data by showing that sources of bias are not necessarily human-centric. They also contribute to the debate about the tasks for which consumers, and more generally humans, can be replaced by AI.

**AI Summary:** The research investigates how well Large Language Models (LLMs) emulate human behavior in terms of biases and heuristics. The study finds that LLMs can either reduce, amplify, or exhibit opposite biases compared to humans, and their responses can be inconsistent across models and studies. These findings have implications for using LLMs to mimic or predict consumer behavior, as they may not always accurately reflect human behavior.

---

## To Ask or Not to Ask: Learning to Require Human Feedback
**URL:** https://arxiv.org/abs/2510.08314

**Abstract:** Developing decision-support systems that complement human performance in classification tasks remains an open challenge. A popular approach, Learning to Defer (LtD), allows a Machine Learning (ML) model to pass difficult cases to a human expert. However, LtD treats humans and ML models as mutually exclusive decision-makers, restricting the expert contribution to mere predictions. To address this limitation, we propose Learning to Ask (LtA), a new framework that handles both when and how to incorporate expert input in an ML model. LtA is based on a two-part architecture: a standard ML model and an enriched model trained with additional expert human feedback, with a formally optimal strategy for selecting when to query the enriched model. We provide two practical implementations of LtA: a sequential approach, which trains the models in stages, and a joint approach, which optimises them simultaneously. For the latter, we design surrogate losses with realisable-consistency guarantees. Our experiments with synthetic and real expert data demonstrate that LtA provides a more flexible and powerful foundation for effective human-AI collaboration.

**AI Summary:** The research introduces a new framework called Learning to Ask (LtA) that allows Machine Learning models to incorporate expert human feedback in decision-making. LtA is shown to be more flexible and powerful than existing methods like Learning to Defer (LtD) by providing a formal optimal strategy for when to query the enriched model with expert input. The experiments with synthetic and real expert data demonstrate that LtA can improve human-AI collaboration in classification tasks.

---

## A Multimodal Depth-Aware Method For Embodied Reference Understanding
**URL:** https://arxiv.org/abs/2510.08278

**Abstract:** Embodied Reference Understanding requires identifying a target object in a visual scene based on both language instructions and pointing cues. While prior works have shown progress in open-vocabulary object detection, they often fail in ambiguous scenarios where multiple candidate objects exist in the scene. To address these challenges, we propose a novel ERU framework that jointly leverages LLM-based data augmentation, depth-map modality, and a depth-aware decision module. This design enables robust integration of linguistic and embodied cues, improving disambiguation in complex or cluttered environments. Experimental results on two datasets demonstrate that our approach significantly outperforms existing baselines, achieving more accurate and reliable referent detection.

**AI Summary:** The research introduces a new method for Embodied Reference Understanding that combines language instructions and pointing cues to identify target objects in visual scenes. By incorporating data augmentation, depth-map modality, and a depth-aware decision module, the proposed framework improves disambiguation in complex environments with multiple candidate objects. Experimental results show that this approach outperforms existing methods, leading to more accurate and reliable referent detection.

---

## Beyond Sub-6 GHz: Leveraging mmWave Wi-Fi for Gait-Based Person Identification
**URL:** https://arxiv.org/abs/2510.08160

**Abstract:** Person identification plays a vital role in enabling intelligent, personalized, and secure human-computer interaction. Recent research has demonstrated the feasibility of leveraging Wi-Fi signals for passive person identification using a person's unique gait pattern. Although most existing work focuses on sub-6 GHz frequencies, the emergence of mmWave offers new opportunities through its finer spatial resolution, though its comparative advantages for person identification remain unexplored. This work presents the first comparative study between sub-6 GHz and mmWave Wi-Fi signals for person identification with commercial off-the-shelf (COTS) Wi-Fi, using a novel dataset of synchronized measurements from the two frequency bands in an indoor environment. To ensure a fair comparison, we apply identical training pipelines and model configurations across both frequency bands. Leveraging end-to-end deep learning, we show that even at low sampling rates (10 Hz), mmWave Wi-Fi signals can achieve high identification accuracy (91.2% on 20 individuals) when combined with effective background subtraction.

**AI Summary:** This research explores the potential of using mmWave Wi-Fi signals for gait-based person identification, comparing it to sub-6 GHz frequencies. The study demonstrates that mmWave Wi-Fi signals, even at low sampling rates, can achieve high identification accuracy when combined with effective background subtraction, showcasing the advantages of using mmWave for person identification. This research highlights the potential of leveraging mmWave technology for secure and personalized human-computer interaction through gait-based person identification.

---

## Everything is Plausible: Investigating the Impact of LLM Rationales on Human Notions of Plausibility
**URL:** https://arxiv.org/abs/2510.08091

**Abstract:** We investigate the degree to which human plausibility judgments of multiple-choice commonsense benchmark answers are subject to influence by (im)plausibility arguments for or against an answer, in particular, using rationales generated by LLMs. We collect 3,000 plausibility judgments from humans and another 13,600 judgments from LLMs. Overall, we observe increases and decreases in mean human plausibility ratings in the presence of LLM-generated PRO and CON rationales, respectively, suggesting that, on the whole, human judges find these rationales convincing. Experiments with LLMs reveal similar patterns of influence. Our findings demonstrate a novel use of LLMs for studying aspects of human cognition, while also raising practical concerns that, even in domains where humans are ``experts'' (i.e., common sense), LLMs have the potential to exert considerable influence on people's beliefs.

**AI Summary:** This research investigates how human plausibility judgments of common sense answers are influenced by rationales generated by large language models (LLMs). The study found that human judges were swayed by LLM-generated rationales, with plausibility ratings increasing with PRO rationales and decreasing with CON rationales. This suggests that LLMs have the potential to significantly impact human beliefs, even in areas where humans are considered experts, such as common sense.

---

## Attribution-by-design: Ensuring Inference-Time Provenance in Generative Music Systems
**URL:** https://arxiv.org/abs/2510.08062

**Abstract:** The rise of AI-generated music is diluting royalty pools and revealing structural flaws in existing remuneration frameworks, challenging the well-established artist compensation systems in the music industry. Existing compensation solutions, such as piecemeal licensing agreements, lack scalability and technical rigour, while current data attribution mechanisms provide only uncertain estimates and are rarely implemented in practice. This paper introduces a framework for a generative music infrastructure centred on direct attribution, transparent royalty distribution, and granular control for artists and rights' holders. We distinguish ontologically between the training set and the inference set, which allows us to propose two complementary forms of attribution: training-time attribution and inference-time attribution. We here favour inference-time attribution, as it enables direct, verifiable compensation whenever an artist's catalogue is used to condition a generated output. Besides, users benefit from the ability to condition generations on specific songs and receive transparent information about attribution and permitted usage. Our approach offers an ethical and practical solution to the pressing need for robust compensation mechanisms in the era of AI-generated music, ensuring that provenance and fairness are embedded at the core of generative systems.

**AI Summary:** This research paper addresses the challenges of compensation and attribution in AI-generated music systems, highlighting the flaws in existing frameworks. The proposed framework focuses on inference-time attribution, allowing for direct and verifiable compensation for artists when their work is used to generate music. This approach offers a practical solution to ensure fairness and transparency in the evolving landscape of AI-generated music.

---

## Enabling Personalized Long-term Interactions in LLM-based Agents through Persistent Memory and User Profiles
**URL:** https://arxiv.org/abs/2510.07925

**Abstract:** Large language models (LLMs) increasingly serve as the central control unit of AI agents, yet current approaches remain limited in their ability to deliver personalized interactions. While Retrieval Augmented Generation enhances LLM capabilities by improving context-awareness, it lacks mechanisms to combine contextual information with user-specific data. Although personalization has been studied in fields such as human-computer interaction or cognitive science, existing perspectives largely remain conceptual, with limited focus on technical implementation. To address these gaps, we build on a unified definition of personalization as a conceptual foundation to derive technical requirements for adaptive, user-centered LLM-based agents. Combined with established agentic AI patterns such as multi-agent collaboration or multi-source retrieval, we present a framework that integrates persistent memory, dynamic coordination, self-validation, and evolving user profiles to enable personalized long-term interactions. We evaluate our approach on three public datasets using metrics such as retrieval accuracy, response correctness, or BertScore. We complement these results with a five-day pilot user study providing initial insights into user feedback on perceived personalization. The study provides early indications that guide future work and highlights the potential of integrating persistent memory and user profiles to improve the adaptivity and perceived personalization of LLM-based agents.

**AI Summary:** This research focuses on enhancing personalized interactions with AI agents by integrating persistent memory and user profiles into large language models (LLMs). Current approaches lack the ability to combine contextual information with user-specific data, and existing perspectives on personalization are largely conceptual. The study presents a framework that integrates persistent memory, dynamic coordination, self-validation, and evolving user profiles to enable personalized long-term interactions, showing promising results in terms of retrieval accuracy, response correctness, and user feedback on perceived personalization.

---

## Towards Meaningful Transparency in Civic AI Systems
**URL:** https://arxiv.org/abs/2510.07889

**Abstract:** Artificial intelligence has become a part of the provision of governmental services, from making decisions about benefits to issuing fines for parking violations. However, AI systems rarely live up to the promise of neutral optimisation, creating biased or incorrect outputs and reducing the agency of both citizens and civic workers to shape the way decisions are made. Transparency is a principle that can both help subjects understand decisions made about them and shape the processes behind those decisions. However, transparency as practiced around AI systems tends to focus on the production of technical objects that represent algorithmic aspects of decision making. These are often difficult for publics to understand, do not connect to potential for action, and do not give insight into the wider socio-material context of decision making. In this paper, we build on existing approaches that take a human-centric view on AI transparency, combined with a socio-technical systems view, to develop the concept of meaningful transparency for civic AI systems: transparencies that allow publics to engage with AI systems that affect their lives, connecting understanding with potential for action.

**AI Summary:** This research paper discusses the importance of transparency in civic AI systems, highlighting how current practices often focus on technical aspects that are difficult for the public to understand and do not provide insight into the broader context of decision making. The authors propose the concept of meaningful transparency, which aims to empower citizens to engage with AI systems that impact their lives by connecting understanding with the potential for action. By taking a human-centric and socio-technical systems approach, meaningful transparency can help address biases and inaccuracies in AI decision making processes.

---

## Retentive Relevance: Capturing Long-Term User Value in Recommendation Systems
**URL:** https://arxiv.org/abs/2510.07621

**Abstract:** Recommendation systems have traditionally relied on short-term engagement signals, such as clicks and likes, to personalize content. However, these signals are often noisy, sparse, and insufficient for capturing long-term user satisfaction and retention. We introduce Retentive Relevance, a novel content-level survey-based feedback measure that directly assesses users' intent to return to the platform for similar content. Unlike other survey measures that focus on immediate satisfaction, Retentive Relevance targets forward-looking behavioral intentions, capturing longer term user intentions and providing a stronger predictor of retention. We validate Retentive Relevance using psychometric methods, establishing its convergent, discriminant, and behavioral validity. Through large-scale offline modeling, we show that Retentive Relevance significantly outperforms both engagement signals and other survey measures in predicting next-day retention, especially for users with limited historical engagement. We develop a production-ready proxy model that integrates Retentive Relevance into the final stage of a multi-stage ranking system on a social media platform. Calibrated score adjustments based on this model yield substantial improvements in engagement, and retention, while reducing exposure to low-quality content, as demonstrated by large-scale A/B experiments. This work provides the first empirically validated framework linking content-level user perceptions to retention outcomes in production systems. We offer a scalable, user-centered solution that advances both platform growth and user experience. Our work has broad implications for responsible AI development.

**AI Summary:** This research introduces a new measure called Retentive Relevance, which assesses users' intent to return to a platform for similar content, capturing long-term user satisfaction and retention. The study shows that Retentive Relevance outperforms traditional engagement signals and other survey measures in predicting next-day retention, especially for users with limited historical engagement. By integrating Retentive Relevance into a ranking system on a social media platform, the researchers demonstrate significant improvements in engagement, retention, and content quality, offering a scalable solution for personalized recommendations that benefit both platform growth and user experience.

---

## Investigating Thematic Patterns and User Preferences in LLM Interactions using BERTopic
**URL:** https://arxiv.org/abs/2510.07557

**Abstract:** This study applies BERTopic, a transformer-based topic modeling technique, to the lmsys-chat-1m dataset, a multilingual conversational corpus built from head-to-head evaluations of large language models (LLMs). Each user prompt is paired with two anonymized LLM responses and a human preference label, used to assess user evaluation of competing model outputs. The main objective is uncovering thematic patterns in these conversations and examining their relation to user preferences, particularly if certain LLMs are consistently preferred within specific topics. A robust preprocessing pipeline was designed for multilingual variation, balancing dialogue turns, and cleaning noisy or redacted data. BERTopic extracted over 29 coherent topics including artificial intelligence, programming, ethics, and cloud infrastructure. We analysed relationships between topics and model preferences to identify trends in model-topic alignment. Visualization techniques included inter-topic distance maps, topic probability distributions, and model-versus-topic matrices. Our findings inform domain-specific fine-tuning and optimization strategies for improving real-world LLM performance and user satisfaction.

**AI Summary:** This study uses BERTopic to analyze conversations in the lmsys-chat-1m dataset, focusing on thematic patterns and user preferences in interactions with large language models (LLMs). The research uncovers 29 coherent topics, such as artificial intelligence and programming, and examines how user preferences align with these topics. The findings can guide strategies for fine-tuning LLMs to improve performance and user satisfaction in real-world applications.

---

