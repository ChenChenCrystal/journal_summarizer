# arXiv cs.AI Summary – 2025-12-15

## From Signal to Turn: Interactional Friction in Modular Speech-to-Speech Pipelines
**URL:** https://arxiv.org/abs/2512.11724

**Abstract:** While voice-based AI systems have achieved remarkable generative capabilities, their interactions often feel conversationally broken. This paper examines the interactional friction that emerges in modular Speech-to-Speech Retrieval-Augmented Generation (S2S-RAG) pipelines. By analyzing a representative production system, we move beyond simple latency metrics to identify three recurring patterns of conversational breakdown: (1) Temporal Misalignment, where system delays violate user expectations of conversational rhythm; (2) Expressive Flattening, where the loss of paralinguistic cues leads to literal, inappropriate responses; and (3) Repair Rigidity, where architectural gating prevents users from correcting errors in real-time. Through system-level analysis, we demonstrate that these friction points should not be understood as defects or failures, but as structural consequences of a modular design that prioritizes control over fluidity. We conclude that building natural spoken AI is an infrastructure design challenge, requiring a shift from optimizing isolated components to carefully choreographing the seams between them.

**AI Summary:** This research paper explores the interactional friction that occurs in modular Speech-to-Speech Retrieval-Augmented Generation (S2S-RAG) pipelines used in voice-based AI systems. The study identifies three common patterns of conversational breakdown: Temporal Misalignment, Expressive Flattening, and Repair Rigidity, which result from the design prioritizing control over fluidity. The findings suggest that building natural spoken AI systems requires a shift towards carefully choreographing the interactions between components rather than just optimizing individual parts.

---

## Natural Language Interaction for Editing Visual Knowledge Graphs
**URL:** https://arxiv.org/abs/2512.11674

**Abstract:** Knowledge graphs are often visualized using node-link diagrams that reveal relationships and structure. In many applications using graphs, it is desirable to allow users to edit graphs to ensure data accuracy or provides updates. Commonly in graph visualization, users can interact directly with the visual elements by clicking and typing updates to specific items through traditional interaction methods in the graphical user interface. However, it can become tedious to make many updates due to the need to individually select and change numerous items in a graph. Our research investigates natural language input as an alternative method for editing network graphs. We present a user study comparing GUI graph editing with two natural language alternatives to contribute novel empirical data of the trade-offs of the different interaction methods. The findings show natural language methods to be significantly more effective than traditional GUI interaction.

**AI Summary:** This research explores the use of natural language input as an alternative method for editing visual knowledge graphs, comparing it to traditional GUI interaction. The study found that natural language methods were significantly more effective in editing network graphs, providing valuable insights into the trade-offs between different interaction methods. This research highlights the potential of natural language interaction for improving the efficiency and user experience of editing visual knowledge graphs.

---

## From Verification Burden to Trusted Collaboration: Design Goals for LLM-Assisted Literature Reviews
**URL:** https://arxiv.org/abs/2512.11661

**Abstract:** Large Language Models (LLMs) are increasingly embedded in academic writing practices. Although numerous studies have explored how researchers employ these tools for scientific writing, their concrete implementation, limitations, and design challenges within the literature review process remain underexplored. In this paper, we report a user study with researchers across multiple disciplines to characterize current practices, benefits, and \textit{pain points} in using LLMs to investigate related work. We identified three recurring gaps: (i) lack of trust in outputs, (ii) persistent verification burden, and (iii) requiring multiple tools. This motivates our proposal of six design goals and a high-level framework that operationalizes them through improved related papers visualization, verification at every step, and human-feedback alignment with generation-guided explanations. Overall, by grounding our work in the practical, day-to-day needs of researchers, we designed a framework that addresses these limitations and models real-world LLM-assisted writing, advancing trust through verifiable actions and fostering practical collaboration between researchers and AI systems.

**AI Summary:** This research paper explores the challenges and benefits of using Large Language Models (LLMs) in literature reviews. The study identified three key gaps in current practices: lack of trust in outputs, verification burden, and the need for multiple tools. The researchers propose six design goals and a framework to address these limitations, aiming to improve visualization of related papers, verification processes, and alignment with human feedback, ultimately fostering trusted collaboration between researchers and AI systems in academic writing.

---

## Say it or AI it: Evaluating Hands-Free Text Correction in Virtual Reality
**URL:** https://arxiv.org/abs/2512.11564

**Abstract:** Text entry in Virtual Reality (VR) is challenging, even when accounting for the use of controllers. Prior work has tackled this challenge head-on, improving the efficiency of input methods. These techniques have the advantage of allowing for relatively straightforward text correction. However, text correction without the use of controllers is a topic that has not received the same amount of attention, even though it can be desirable in several scenarios, and can even be the source of frustration. Large language models have been adopted and evaluated as a corrective methodology, given their high power for predictions. Nevertheless, their predictions are not always correct, which can lead to lower usability. In this paper, we investigate whether, for text correction in VR that is hands-free, the use of AI could surpass in terms of usability and efficiency. We observed better usability for AI text correction when compared to voice input.

**AI Summary:** This research explores the effectiveness of using AI for hands-free text correction in Virtual Reality (VR) environments, compared to traditional voice input methods. The study found that AI-based text correction showed better usability and efficiency than voice input, indicating the potential for AI to improve text entry in VR. This research highlights the importance of exploring alternative input methods in VR to enhance user experience and efficiency.

---

## Mirror Skin: In Situ Visualization of Robot Touch Intent on Robotic Skin
**URL:** https://arxiv.org/abs/2512.11472

**Abstract:** Effective communication of robotic touch intent is a key factor in promoting safe and predictable physical human-robot interaction (pHRI). While intent communication has been widely studied, existing approaches lack the spatial specificity and semantic depth necessary to convey robot touch actions. We present Mirror Skin, a cephalopod-inspired concept that utilizes high-resolution, mirror-like visual feedback on robotic skin. By mapping in-situ visual representations of a human's body parts onto the corresponding robot's touch region, Mirror Skin communicates who shall initiate touch, where it will occur, and when it is imminent. To inform the design of Mirror Skin, we conducted a structured design exploration with experts in virtual reality (VR), iteratively refining six key dimensions. A subsequent controlled user study demonstrated that Mirror Skin significantly enhances accuracy and reduces response times for interpreting touch intent. These findings highlight the potential of visual feedback on robotic skin to communicate human-robot touch interactions.

**AI Summary:** The research introduces Mirror Skin, a concept inspired by cephalopods, which uses high-resolution visual feedback on robotic skin to effectively communicate touch intent in human-robot interactions. By mapping visual representations of a human's body parts onto the robot's touch region, Mirror Skin conveys who will initiate touch, where it will occur, and when it is imminent. A user study showed that Mirror Skin enhances accuracy and reduces response times in interpreting touch intent, emphasizing the potential of visual feedback on robotic skin for promoting safe and predictable physical human-robot interaction.

---

## AI Autonomy or Human Dependency? Defining the Boundary in Responsible AI with the $α$-Coefficient
**URL:** https://arxiv.org/abs/2512.11295

**Abstract:** The integrity of contemporary AI systems is undermined by a critical design flaw: the misappropriation of Human-in-the-Loop (HITL) models to mask systems that are fundamentally reliant on human labor. We term this structural reliance Human-Instead-of-AI (HISOAI). HISOAI systems represent an ethical failure and an unsustainable economic dependency, where human workers function as hidden operational fallbacks rather than strategic collaborators. To rectify this, we propose the AI-First, Human-Empowered (AFHE) paradigm. AFHE mandates a technological design where the AI component must achieve a minimum, quantifiable level of functional independence prior to deployment. This standard is formalized through the AI Autonomy Coefficient (alpha), a metric that determines the proportion of tasks that the AI successfully processes without mandatory human substitution. We introduce the AFHE Deployment Algorithm, an algorithmic gate that requires the system to meet a specified alpha threshold across both offline and shadow testing. By enforcing this structural separation, the AFHE framework redefines the human's role to focus exclusively on high-value tasks, including ethical oversight, boundary pushing, and strategic model tuning, thereby ensuring true system transparency and operational independence. This work advocates for a critical shift toward metric-driven, structurally sound AI architecture, moving the industry beyond deceptive human dependency toward verifiable autonomy.

**AI Summary:** The research highlights the issue of AI systems relying on human labor to function, termed as Human-Instead-of-AI (HISOAI). The proposed AI-First, Human-Empowered (AFHE) paradigm introduces the AI Autonomy Coefficient (alpha) to measure the level of functional independence of AI systems. By enforcing a minimum alpha threshold, the AFHE framework aims to redefine the human's role in AI systems to focus on high-value tasks, promoting true system transparency and operational independence.

---

## Words to Describe What I'm Feeling: Exploring the Potential of AI Agents for High Subjectivity Decisions in Advance Care Planning
**URL:** https://arxiv.org/abs/2512.11276

**Abstract:** Serious illness can deprive patients of the capacity to speak for themselves. As populations age and caregiver networks shrink, the need for reliable support in Advance Care Planning (ACP) grows. To probe this fraught design space of using proxy agents for high-risk, high-subjectivity decisions, we built an experience prototype (\acpagent{}) and asked 15 participants in 4 workshops to train it to be their personal proxy in ACP decisions. We analysed their coping strategies and feature requests and mapped the results onto axes of agent autonomy and human control. Our findings argue for a potential new role of AI in ACP where agents act as personal advocates for individuals, building mutual intelligibility over time. We conclude with design recommendations to balance the risks and benefits of such an agent.

**AI Summary:** The research explores the potential of AI agents to assist individuals in making high-subjectivity decisions in Advance Care Planning when they are unable to speak for themselves. Through workshops with 15 participants, the study found that AI agents could serve as personal advocates for individuals, building mutual understanding over time. The findings suggest a new role for AI in ACP and provide design recommendations to balance the risks and benefits of using AI agents in this context.

---

## Breast-Rehab: A Postoperative Breast Cancer Rehabilitation Training Assessment System Based on Human Action Recognition
**URL:** https://arxiv.org/abs/2512.11245

**Abstract:** Postoperative upper limb dysfunction is prevalent among breast cancer survivors, yet their adherence to at-home rehabilitation exercises is low amidst limited nursing resources. The hardware overhead of commonly adopted VR-based mHealth solutions further hinders their widespread clinical application. Therefore, we developed Breast-Rehab, a novel, low-cost mHealth system to provide patients with out-of-hospital upper limb rehabilitation management. Breast-Rehab integrates a bespoke human action recognition algorithm with a retrieval-augmented generation (RAG) framework. By fusing visual and 3D skeletal data, our model accurately segments exercise videos recorded in uncontrolled home environments, outperforming standard models. These segmented clips, combined with a domain-specific knowledge base, guide a multi-modal large language model to generate clinically relevant assessment reports. This approach significantly reduces computational overhead and mitigates model hallucinations. We implemented the system as a WeChat Mini Program and a nurse-facing dashboard. A preliminary clinical study validated the system's feasibility and user acceptance, with patients achieving an average exercise frequency of 0.59 sessions/day over a two-week period. This work thus presents a complete, validated pipeline for AI-driven, at-home rehabilitation monitoring.

**AI Summary:** The study introduces Breast-Rehab, a low-cost mHealth system for postoperative breast cancer rehabilitation that integrates human action recognition and a retrieval-augmented generation framework. The system accurately segments exercise videos recorded at home, generates clinically relevant assessment reports, and reduces computational overhead. A preliminary clinical study showed the system's feasibility and user acceptance, with patients achieving an average exercise frequency of 0.59 sessions/day over a two-week period, demonstrating the potential of AI-driven at-home rehabilitation monitoring.

---

## Supporting Medicinal Chemists in Iterative Hypothesis Generation for Drug Target Identification
**URL:** https://arxiv.org/abs/2512.11105

**Abstract:** While drug discovery is vital for human health, the process remains inefficient. Medicinal chemists must navigate a vast protein space to identify target proteins that meet three criteria: physical and functional interactions, therapeutic impact, and docking potential. Prior approaches have provided fragmented support for each criterion, limiting the generation of promising hypotheses for wet-lab experiments. We present HAPPIER, an AI-powered tool that supports hypothesis generation with integrated multi-criteria support for target identification. HAPPIER enables medicinal chemists to 1) efficiently explore and verify proteins in a single integrated graph component showing multi-criteria satisfaction and 2) validate AI suggestions with domain knowledge. These capabilities facilitate iterative cycles of divergent and convergent thinking, essential for hypothesis generation. We evaluated HAPPIER with ten medicinal chemists, finding that it increased the number of high-confidence hypotheses and support for the iterative cycle, and further demonstrated the relationship between engaging in such cycles and confidence in outputs.

**AI Summary:** The research introduces HAPPIER, an AI-powered tool designed to support medicinal chemists in generating hypotheses for drug target identification. HAPPIER integrates multiple criteria for target protein selection, allowing for efficient exploration and verification of proteins in a single graph component. The tool was evaluated with ten medicinal chemists, showing an increase in high-confidence hypotheses and support for iterative cycles of hypothesis generation, highlighting the importance of AI support in enhancing the drug discovery process.

---

## Your plan may succeed, but what about failure? Investigating how people use ChatGPT for long-term life task planning
**URL:** https://arxiv.org/abs/2512.11096

**Abstract:** Long-term life task planning is inherently complex and uncertain, yet little is known about how emerging AI systems support this process. This study investigates how people use ChatGPT for such planning tasks, focusing on user practices, uncertainties, and perceptions of AI assistance. We conducted an interview study with 14 participants who engaged in long-term planning activities using ChatGPT, combining analysis of their prompts and interview responses. The task topics across diverse domains, including personal well-being, event planning, and professional learning, along with prompts to initiate, refine, and contextualize plans. ChatGPT helped structure complex goals into manageable steps, generate ideas, and sustain motivation, serving as a reflective partner. Yet its outputs were often generic or idealized, lacking personalization, contextual realism, and adaptability, requiring users to actively adapt and verify results. Participants expressed a need for AI systems that provide adaptive and trustworthy guidance while acknowledging uncertainty and potential failure in long-term planning. Our findings show how AI supports long-term life task planning under evolving uncertainty and highlight design implications for systems that are adaptive, uncertainty-aware, and capable of supporting long-term planning as an evolving human-AI collaboration.

**AI Summary:** This study investigates how people use ChatGPT for long-term life task planning and found that while the AI system helped structure goals and generate ideas, its outputs were often generic and lacked personalization. Users had to actively adapt and verify results, expressing a need for AI systems that provide adaptive and trustworthy guidance while acknowledging uncertainty and potential failure in planning. The findings highlight the importance of designing AI systems that are adaptive, uncertainty-aware, and capable of supporting long-term planning as a collaboration between humans and AI.

---

## Immutable Explainability: Towards Verifiable and Auditable Affective AI
**URL:** https://arxiv.org/abs/2512.11065

**Abstract:** Affective artificial intelligence has made substantial advances in recent years; yet two critical issues persist, particularly in sensitive applications. First, these systems frequently operate as 'black boxes', leaving their decision-making processes opaque. Second, audit logs often lack reliability, as the entity operating the system may alter them. In this work, we introduce the concept of Immutable Explainability, an architecture designed to address both challenges simultaneously. Our approach combines an interpretable inference engine - implemented through fuzzy logic to produce a transparent trace of each decision - with a cryptographic anchoring mechanism that records this trace on a blockchain, ensuring that it is tamper-evident and independently verifiable. To validate the approach, we implemented a heuristic pipeline integrating lexical and prosodic analysis within an explicit Mamdani-type multimodal fusion engine. Each inference generates an auditable record that is subsequently anchored on a public blockchain (Sepolia Testnet). We evaluated the system using the Spanish MEACorpus 2023, employing both the original corpus transcriptions and those generated by Whisper. The results show that our fuzzy-fusion approach outperforms baseline methods (linear and unimodal fusion). Beyond these quantitative outcomes, our primary objective is to establish a foundation for affective AI systems that offer transparent explanations, trustworthy audit trails, and greater user control over personal data.

**AI Summary:** This research introduces the concept of Immutable Explainability in affective artificial intelligence, addressing the issues of opacity in decision-making processes and unreliable audit logs. The proposed architecture combines an interpretable inference engine with a cryptographic anchoring mechanism on a blockchain to ensure transparency and verifiability. The results of the study show that the fuzzy-fusion approach outperforms baseline methods, aiming to establish a foundation for affective AI systems with transparent explanations and trustworthy audit trails.

---

## AI as Cognitive Amplifier: Rethinking Human Judgment in the Age of Generative AI
**URL:** https://arxiv.org/abs/2512.10961

**Abstract:** Through extensive experience training professionals and individual users in AI tool adoption since the GPT-3 era, I have observed a consistent pattern: the same AI tool produces dramatically different results depending on who uses it. While some frame AI as a replacement for human intelligence, and others warn of cognitive decline, this position paper argues for a third perspective grounded in practical observation: AI as a cognitive amplifier that magnifies existing human capabilities rather than substituting for them. Drawing on research in human-computer interaction, cognitive augmentation theory, and educational technology, alongside field observations from corporate training across writing, software development, and data analysis domains, I present a framework positioning AI tools as intelligence amplification systems where output quality depends fundamentally on user expertise and judgment. Through analysis of empirical studies on expert-novice differences and systematic observations from professional training contexts, I demonstrate that domain knowledge, quality judgment, and iterative refinement capabilities create substantial performance gaps between users. I propose a three-level model of AI engagement -- from passive acceptance through iterative collaboration to cognitive direction -- and argue that the transition between levels requires not technical training but development of domain expertise and metacognitive skills. This position has critical implications for workforce development and AI system design. Rather than focusing solely on AI literacy or technical prompt engineering, I advocate for integrated approaches that strengthen domain expertise, evaluative judgment, and reflective practice.

**AI Summary:** The author argues that AI should be viewed as a cognitive amplifier, enhancing human capabilities rather than replacing them. The quality of AI output is heavily influenced by user expertise and judgment, with significant performance gaps between users based on domain knowledge and refinement capabilities. The author proposes a three-level model of AI engagement and emphasizes the importance of developing domain expertise and metacognitive skills in order to effectively utilize AI tools. This perspective has important implications for workforce development and AI system design, advocating for integrated approaches that focus on strengthening domain expertise, evaluative judgment, and reflective practice.

---

## Measuring skill-based uplift from AI in a real biological laboratory
**URL:** https://arxiv.org/abs/2512.10960

**Abstract:** Understanding how AI systems are used by people in real situations that mirror aspects of both legitimate and illegitimate use is key to predicting the risks and benefits of AI systems. This is especially true in biological applications, where skill rather than knowledge is often the primary barrier for an untrained person. The challenge is that these studies are difficult to execute well and can take months to plan and run.
Here we report the results of a pilot study that attempted to empirically measure the magnitude of \emph{skills-based uplift} caused by access to an AI reasoning model, compared with a control group that had only internet access. Participants -- drawn from a diverse pool of Los Alamos National Laboratory employees with no prior wet-lab experience -- were asked to transform \ecoli{} with a provided expression construct, induce expression of a reporter peptide, and have expression confirmed by mass spectrometry.
We recorded quantitative outcomes (e.g., successful completion of experimental segments) and qualitative observations about how participants interacted with the AI system, the internet, laboratory equipment, and one another. We present the results of the study and lessons learned in designing and executing this type of study, and we discuss these results in the context of future studies of the evolving relationship between AI and global biosecurity.

**AI Summary:** This pilot study aimed to measure the impact of using an AI reasoning model on skill improvement in a biological laboratory setting. Participants with no prior wet-lab experience were tasked with a complex experiment, and those with access to the AI system showed a significant increase in successful completion of experimental segments compared to a control group with only internet access. The findings suggest that AI can provide valuable skill-based uplift in biological applications, highlighting the importance of understanding the relationship between AI and global biosecurity.

---

## Toward a Decision Support System for Energy-Efficient Ferry Operation on Lake Constance based on Optimal Control
**URL:** https://arxiv.org/abs/2512.11786

**Abstract:** The maritime sector is undergoing a disruptive technological change driven by three main factors: autonomy, decarbonization, and digital transformation. Addressing these factors necessitates a reassessment of inland vessel operations. This paper presents the design and development of a decision support system for ferry operations based on a shrinking-horizon optimal control framework. The problem formulation incorporates a mathematical model of the ferry's dynamics and environmental disturbances, specifically water currents and wind, which can significantly influence the dynamics. Real-world data and illustrative scenarios demonstrate the potential of the proposed system to effectively support ferry crews by providing real-time guidance. This enables enhanced operational efficiency while maintaining predefined maneuver durations. The findings suggest that optimal control applications hold substantial promise for advancing future ferry operations on inland waters. A video of the real-world ferry MS Insel Mainau operating on Lake Constance is available at: this https URL

**AI Summary:** This research paper focuses on developing a decision support system for energy-efficient ferry operations on Lake Constance, considering factors like autonomy, decarbonization, and digital transformation. By incorporating a mathematical model of the ferry's dynamics and environmental disturbances, such as water currents and wind, the proposed system can provide real-time guidance to ferry crews for enhanced operational efficiency while maintaining predefined maneuver durations. The findings suggest that optimal control applications have the potential to advance future ferry operations on inland waters, showcasing the significance of integrating AI technology in the maritime sector.

---

## The Influence of Human-like Appearance on Expected Robot Explanations
**URL:** https://arxiv.org/abs/2512.11746

**Abstract:** A robot's appearance is a known factor influencing user's mental model and human-robot interaction, that has not been studied in the context of its influence in expected robot explanations. In this study, we investigate whether and to what extent the human-like appearance of robots elicits anthropomorphism, which is conceptualised as an attribution of mental capacities, and how the level of anthropomorphism is revealed in explanations that people expect to receive. We designed a between-subject study comprising conditions with visual stimuli of three domestic service robots with varying human-like appearance, and we prompted respondents to provide explanations they would expect to receive from the robot for the same robot actions. We found that most explanations were anthropomorphic across all conditions. However, there is a positive correlation between the anthropomorphic explanations and human-like appearance. We also report on more nuanced trends observed in non-anthropomorphic explanations and trends in robot descriptions.

**AI Summary:** This study explores the impact of a robot's human-like appearance on the expectations people have for explanations provided by the robot. The research found that there is a positive correlation between anthropomorphic explanations and robots with a more human-like appearance. This suggests that the design of a robot's appearance can influence how users perceive and interact with the robot, highlighting the importance of considering human-like features in robotics design for effective communication and interaction.

---

## Few-Shot VLM-Based G-Code and HMI Verification in CNC Machining
**URL:** https://arxiv.org/abs/2512.11296

**Abstract:** Manual generation of G-code is important for learning the operation of CNC machines. Prior work in G-code verification uses Large-Language Models (LLMs), which primarily examine errors in the written programming. However, CNC machining requires extensive use and knowledge of the Human-Machine Interface (HMI), which displays machine status and errors. LLMs currently lack the capability to leverage knowledge of HMIs due to their inability to access the vision modality. This paper proposes a few-shot VLM-based verification approach that simultaneously evaluates the G-code and the HMI display for errors and safety status. The input dataset includes paired G-code text and associated HMI screenshots from a 15-slant-PRO lathe, including both correct and error-prone cases. To enable few-shot learning, the VLM is provided with a structured JSON schema based on prior heuristic knowledge. After determining the prompts, instances of G-code and HMI that either contain errors or are error free are used as few-shot examples to guide the VLM. The model was then evaluated in comparison to a zero-shot VLM through multiple scenarios of incorrect G-code and HMI errors with respect to per-slot accuracy. The VLM showed that few-shot prompting led to overall enhancement of detecting HMI errors and discrepancies with the G-code for more comprehensive debugging. Therefore, the proposed framework was demonstrated to be suitable for verification of manually generated G-code that is typically developed in CNC training.

**AI Summary:** This research proposes a few-shot VLM-based approach for verifying G-code and HMI in CNC machining, addressing the limitations of LLMs in understanding HMIs. The model was trained on paired G-code text and HMI screenshots from a lathe, and showed improved accuracy in detecting errors and discrepancies between G-code and HMI compared to a zero-shot VLM. This framework has the potential to enhance the verification process of manually generated G-code in CNC training.

---

## Agent-Based Modular Learning for Multimodal Emotion Recognition in Human-Agent Systems
**URL:** https://arxiv.org/abs/2512.10975

**Abstract:** Effective human-agent interaction (HAI) relies on accurate and adaptive perception of human emotional states. While multimodal deep learning models - leveraging facial expressions, speech, and textual cues - offer high accuracy in emotion recognition, their training and maintenance are often computationally intensive and inflexible to modality changes. In this work, we propose a novel multi-agent framework for training multimodal emotion recognition systems, where each modality encoder and the fusion classifier operate as autonomous agents coordinated by a central supervisor. This architecture enables modular integration of new modalities (e.g., audio features via emotion2vec), seamless replacement of outdated components, and reduced computational overhead during training. We demonstrate the feasibility of our approach through a proof-of-concept implementation supporting vision, audio, and text modalities, with the classifier serving as a shared decision-making agent. Our framework not only improves training efficiency but also contributes to the design of more flexible, scalable, and maintainable perception modules for embodied and virtual agents in HAI scenarios.

**AI Summary:** This research introduces a novel multi-agent framework for training emotion recognition systems in human-agent interaction scenarios. The framework allows for modular integration of new modalities, seamless replacement of outdated components, and reduced computational overhead during training. The approach improves training efficiency and contributes to the design of more flexible, scalable, and maintainable perception modules for embodied and virtual agents in HAI scenarios.

---

## Emotion-Driven Personalized Recommendation for AI-Generated Content Using Multi-Modal Sentiment and Intent Analysis
**URL:** https://arxiv.org/abs/2512.10963

**Abstract:** With the rapid growth of AI-generated content (AIGC) across domains such as music, video, and literature, the demand for emotionally aware recommendation systems has become increasingly important. Traditional recommender systems primarily rely on user behavioral data such as clicks, views, or ratings, while neglecting users' real-time emotional and intentional states during content interaction. To address this limitation, this study proposes a Multi-Modal Emotion and Intent Recognition Model (MMEI) based on a BERT-based Cross-Modal Transformer with Attention-Based Fusion, integrated into a cloud-native personalized AIGC recommendation framework. The proposed system jointly processes visual (facial expression), auditory (speech tone), and textual (comments or utterances) modalities through pretrained encoders ViT, Wav2Vec2, and BERT, followed by an attention-based fusion module to learn emotion-intent representations. These embeddings are then used to drive personalized content recommendations through a contextual matching layer. Experiments conducted on benchmark emotion datasets (AIGC-INT, MELD, and CMU-MOSEI) and an AIGC interaction dataset demonstrate that the proposed MMEI model achieves a 4.3% improvement in F1-score and a 12.3% reduction in cross-entropy loss compared to the best fusion-based transformer baseline. Furthermore, user-level online evaluations reveal that emotion-driven recommendations increase engagement time by 15.2% and enhance satisfaction scores by 11.8%, confirming the model's effectiveness in aligning AI-generated content with users' affective and intentional states. This work highlights the potential of cross-modal emotional intelligence for next-generation AIGC ecosystems, enabling adaptive, empathetic, and context-aware recommendation experiences.

**AI Summary:** This research focuses on developing a Multi-Modal Emotion and Intent Recognition Model (MMEI) to improve personalized recommendations for AI-generated content by incorporating users' emotional and intentional states. The proposed model outperforms existing fusion-based transformer baselines in terms of F1-score and cross-entropy loss, leading to increased user engagement time and satisfaction scores. The study emphasizes the importance of integrating emotional intelligence into recommendation systems to create more adaptive and empathetic content experiences in next-generation AI ecosystems.

---

## CompanionCast: A Multi-Agent Conversational AI Framework with Spatial Audio for Social Co-Viewing Experiences
**URL:** https://arxiv.org/abs/2512.10918

**Abstract:** Social presence is central to the enjoyment of watching content together, yet modern media consumption is increasingly solitary. We investigate whether multi-agent conversational AI systems can recreate the dynamics of shared viewing experiences across diverse content types. We present CompanionCast, a general framework for orchestrating multiple role-specialized AI agents that respond to video content using multimodal inputs, speech synthesis, and spatial audio. Distinctly, CompanionCast integrates an LLM-as-a-Judge module that iteratively scores and refines conversations across five dimensions (relevance, authenticity, engagement, diversity, personality consistency). We validate this framework through sports viewing, a domain with rich dynamics and strong social traditions, where a pilot study with soccer fans suggests that multi-agent interaction improves perceived social presence compared to solo viewing. We contribute: (1) a generalizable framework for orchestrating multi-agent conversations around multimodal video content, (2) a novel evaluator-agent pipeline for conversation quality control, and (3) exploratory evidence of increased social presence in AI-mediated co-viewing. We discuss challenges and future directions for applying this approach to diverse viewing contexts including entertainment, education, and collaborative watching experiences.

**AI Summary:** The research explores the use of multi-agent conversational AI systems to recreate shared viewing experiences in a solitary media consumption environment. The CompanionCast framework integrates specialized AI agents that respond to video content using various inputs and spatial audio, with an LLM-as-a-Judge module to evaluate conversation quality. A pilot study with soccer fans suggests that multi-agent interaction improves perceived social presence compared to solo viewing, highlighting the potential for this framework in various viewing contexts such as entertainment and education.

---

## Reject or Not?: A Benchmark for Voice Assistant Query Rejection in Smart Home Scenario and an Improved Method Based on LLMs
**URL:** https://arxiv.org/abs/2512.10257

**Abstract:** In smart-home voice assistant scenario, deciding whether to accept or reject a user query is the first step before any downstream processing. To address the limited query-rejection capability of current voice assistants, this paper presents the first Chinese-oriented open-source benchmark and evaluation suite for smart homes, together with a personalized query-rejection method based on large language models. On the data side, we construct the first multimodal query-rejection dataset tailored for domestic scenarios, containing 11,913 manually labeled text-speech pairs that systematically cover twelve typical dialogue types (e.g., chit-chat, non-human sounds, valid commands, ambiguous references, device-irrelevant requests). Fine-grained labels, conversational context and multi-turn information are provided to support both zero-shot and fine-tuning evaluations across language and multimodal large models. On the method side, we propose a three-tier collaborative architecture: first, a Qwen-2.5-3B adapter fine-tuned to model family-agnostic semantic boundaries; second, a dynamic household-level historical dialogue module to capture personalized habits; third, a household-specific RAG knowledge base that explicitly memorizes and revises past false-rejection cases. Experiments show that the proposed approach significantly outperforms zero-shot and fine-tuned general LLMs on the constructed dataset, with pronounced gains in rejection accuracy for family-specific expressions and complex multi-turn scenarios. This work provides a reproducible data foundation, evaluation standard and extensible technical framework for reliability research in smart-home voice interaction.

**AI Summary:** This research paper introduces a Chinese-oriented benchmark and evaluation suite for smart home voice assistants to improve query rejection capabilities. The study includes a multimodal dataset with manually labeled text-speech pairs covering various dialogue types and proposes a personalized query-rejection method based on large language models. The proposed approach outperforms general models in rejecting family-specific expressions and complex multi-turn scenarios, providing a foundation for reliability research in smart-home voice interaction.

---

## InFerActive: Towards Scalable Human Evaluation of Large Language Models through Interactive Inference
**URL:** https://arxiv.org/abs/2512.10234

**Abstract:** Human evaluation remains the gold standard for evaluating outputs of Large Language Models (LLMs). The current evaluation paradigm reviews numerous individual responses, leading to significant scalability challenges. LLM outputs can be more efficiently represented as a tree structure, reflecting their autoregressive generation process and stochastic token selection. However, conventional tree visualization cannot scale to the exponentially large trees generated by modern sampling methods of LLMs. To address this problem, we present InFerActive, an interactive inference system for scalable human evaluation. InFerActive enables on-demand exploration through probability-based filtering and evaluation features, while bridging the semantic gap between computational tokens and human-readable text through adaptive visualization techniques. Through a technical evaluation and user study (N=12), we demonstrate that InFerActive significantly improves evaluation efficiency and enables more comprehensive assessment of model behavior. We further conduct expert case studies that demonstrate InFerActive's practical applicability and potential for transforming LLM evaluation workflows.

**AI Summary:** The research introduces InFerActive, an interactive inference system designed to improve the human evaluation of Large Language Models (LLMs). By representing LLM outputs as tree structures and enabling on-demand exploration through probability-based filtering and evaluation features, InFerActive significantly improves evaluation efficiency and enables more comprehensive assessment of model behavior. The system has the potential to transform LLM evaluation workflows by bridging the semantic gap between computational tokens and human-readable text, making it easier to evaluate outputs at scale.

---

## HyFinBall: a Hybrid User Interface for Coordinated 2D+3D Visualization in Semi-Immersive VR
**URL:** https://arxiv.org/abs/2512.10196

**Abstract:** Sophisticated 3D visualization applications usually provide coordinated 2D and 3D views. Normally 3D input device is used for 3D tasks since they perform better than traditional 2D input devices. However, they do not perform better for 2D tasks. This paper presents a bimanual hybrid user interface that supports four interaction modes: a dual 6-degree-of-freedom (DOF) input device mode, a dual planar constrained 3DOF input device mode, a dual 2-finger multi-touch mode, and 3D hand and finger gestures. The application is a multi-dimensional visualization with coordinated 3D and 2D views on a desktop VR system. The input devices are buttonballs with seamless switching between 3D and 2D device modes, as well as between free-hand finger input and device usage. The 3D and 2D device mode switch automatically switches a buttonball's visual representation between a 3D cursor and a 2D cursor while changing the available user interaction techniques between 3D and 2D interaction techniques to interact with the coordinated views. The paper also provides two formal user studies to evaluate HyFinBall for various dimensional tasks, including 3D, 2D, and cross-dimensional tasks. Our experimental results show the benefits of the HyFinBall interface for cross-dimensional tasks that require 3D and 2D interactions.

**AI Summary:** The research paper presents a hybrid user interface called HyFinBall that supports multiple interaction modes for coordinated 2D and 3D visualization in a desktop VR system. The interface allows seamless switching between 3D and 2D input devices, as well as between free-hand finger input and device usage, improving user interaction for cross-dimensional tasks. Formal user studies demonstrate the benefits of the HyFinBall interface for tasks that require both 3D and 2D interactions.

---

## Offscript: Automated Auditing of Instruction Adherence in LLMs
**URL:** https://arxiv.org/abs/2512.10172

**Abstract:** Large Language Models (LLMs) and generative search systems are increasingly used for information seeking by diverse populations with varying preferences for knowledge sourcing and presentation. While users can customize LLM behavior through custom instructions and behavioral prompts, no mechanism exists to evaluate whether these instructions are being followed effectively. We present Offscript, an automated auditing tool that efficiently identifies potential instruction following failures in LLMs. In a pilot study analyzing custom instructions sourced from Reddit, Offscript detected potential deviations from instructed behavior in 86.4% of conversations, 22.2% of which were confirmed as material violations through human review. Our findings suggest that automated auditing serves as a viable approach for evaluating compliance to behavioral instructions related to information seeking.

**AI Summary:** The research introduces Offscript, an automated auditing tool designed to identify potential instruction following failures in Large Language Models (LLMs). The tool was able to detect deviations from instructed behavior in 86.4% of conversations sourced from Reddit, with 22.2% confirmed as material violations through human review. These findings highlight the importance of automated auditing in evaluating compliance to behavioral instructions in information seeking tasks using LLMs.

---

## Agile Deliberation: Concept Deliberation for Subjective Visual Classification
**URL:** https://arxiv.org/abs/2512.10821

**Abstract:** From content moderation to content curation, applications requiring vision classifiers for visual concepts are rapidly expanding. Existing human-in-the-loop approaches typically assume users begin with a clear, stable concept understanding to be able to provide high-quality supervision. In reality, users often start with a vague idea and must iteratively refine it through "concept deliberation", a practice we uncovered through structured interviews with content moderation experts. We operationalize the common strategies in deliberation used by real content moderators into a human-in-the-loop framework called "Agile Deliberation" that explicitly supports evolving and subjective concepts. The system supports users in defining the concept for themselves by exposing them to borderline cases. The system does this with two deliberation stages: (1) concept scoping, which decomposes the initial concept into a structured hierarchy of sub-concepts, and (2) concept iteration, which surfaces semantically borderline examples for user reflection and feedback to iteratively align an image classifier with the user's evolving intent. Since concept deliberation is inherently subjective and interactive, we painstakingly evaluate the framework through 18 user sessions, each 1.5h long, rather than standard benchmarking datasets. We find that Agile Deliberation achieves 7.5% higher F1 scores than automated decomposition baselines and more than 3% higher than manual deliberation, while participants reported clearer conceptual understanding and lower cognitive effort.

**AI Summary:** This research introduces a new human-in-the-loop framework called "Agile Deliberation" for subjective visual classification, which supports users in defining and refining concepts through iterative feedback and exposure to borderline cases. The framework outperforms automated decomposition baselines and manual deliberation in terms of F1 scores, while also leading to clearer conceptual understanding and lower cognitive effort for users. This approach is significant as it addresses the common challenge of users starting with vague concepts and needing to iteratively refine them in applications requiring vision classifiers for visual concepts.

---

## Developing and Evaluating a Large Language Model-Based Automated Feedback System Grounded in Evidence-Centered Design for Supporting Physics Problem Solving
**URL:** https://arxiv.org/abs/2512.10785

**Abstract:** Generative AI offers new opportunities for individualized and adaptive learning, particularly through large language model (LLM)-based feedback systems. While LLMs can produce effective feedback for relatively straightforward conceptual tasks, delivering high-quality feedback for tasks that require advanced domain expertise, such as physics problem solving, remains a substantial challenge. This study presents the design of an LLM-based feedback system for physics problem solving grounded in evidence-centered design (ECD) and evaluates its performance within the German Physics Olympiad. Participants assessed the usefulness and accuracy of the generated feedback, which was generally perceived as useful and highly accurate. However, an in-depth analysis revealed that the feedback contained factual errors in 20% of cases; errors that often went unnoticed by the students. We discuss the risks associated with uncritical reliance on LLM-based feedback systems and outline potential directions for generating more adaptive and reliable LLM-based feedback in the future.

**AI Summary:** This study developed and evaluated a large language model (LLM)-based feedback system for physics problem solving, grounded in evidence-centered design (ECD). While participants found the feedback to be useful and accurate, an analysis revealed factual errors in 20% of cases. The study highlights the importance of critically evaluating and improving LLM-based feedback systems for tasks that require advanced domain expertise.

---

## Opportunities and Challenges in Harnessing Digital Technology for Effective Teaching and Learning
**URL:** https://arxiv.org/abs/2512.10777

**Abstract:** Most of today's educators are in no shortage of digital and online learning technologies available at their fingertips, ranging from Learning Management Systems such as Canvas, Blackboard, or Moodle, online meeting tools, online homework, and tutoring systems, exam proctoring platforms, computer simulations, and even virtual reality/augmented reality technologies. Furthermore, with the rapid development and wide availability of generative artificial intelligence (GenAI) services such as ChatGPT, we are just at the beginning of harnessing their potential to transform higher education. Yet, facing the large number of available options provided by cutting-edge technology, an imminent question on the mind of most educators is the following: how should I choose the technologies and integrate them into my teaching process so that they would best support student learning? We contemplate over these types of important and timely questions and share our reflections on evidence-based approaches to harnessing digital learning tools using a Self-regulated Engaged Learning Framework we have employed in our research in physics education that can be valuable for educators in other disciplines.

**AI Summary:** This research explores the opportunities and challenges of using digital technology in teaching and learning, including the wide range of available tools and the potential of artificial intelligence services like GenAI. The study emphasizes the importance of choosing the right technologies and integrating them effectively to support student learning, offering evidence-based approaches using a Self-regulated Engaged Learning Framework from physics education research that can be applied across disciplines. The findings highlight the need for educators to carefully consider how to leverage digital tools to enhance the teaching and learning experience.

---

## Enhancing Large Language Models for End-to-End Circuit Analysis Problem Solving
**URL:** https://arxiv.org/abs/2512.10159

**Abstract:** Large language models (LLMs) have shown strong performance in data-rich domains such as programming, but their reliability in engineering tasks remains limited. Circuit analysis -- requiring multimodal understanding and precise mathematical reasoning -- highlights these challenges. Although Gemini 2.5 Pro improves diagram interpretation and analog-circuit reasoning, it still struggles to consistently produce correct solutions when given both text and circuit diagrams. At the same time, engineering education needs scalable AI tools capable of generating accurate solutions for tasks such as automated homework feedback and question-answering. This paper presents an enhanced, end-to-end circuit problem solver built on Gemini 2.5 Pro. We first benchmark Gemini on a representative set of undergraduate circuit problems and identify two major failure modes: 1) circuit-recognition hallucinations, particularly incorrect source polarity detection, and 2) reasoning-process hallucinations, such as incorrect current directions. To address recognition errors, we integrate a fine-tuned YOLO detector and OpenCV processing to isolate voltage and current sources, enabling Gemini to re-identify source polarities from cropped images with near-perfect accuracy. To reduce reasoning errors, we introduce an ngspice-based verification loop in which Gemini generates a .cir file, ngspice simulates the circuit, and discrepancies trigger iterative regeneration with optional human-in-the-loop review. Across 83 problems, the proposed pipeline achieves a 97.59% success rate (81 correct solutions), substantially outperforming Gemini 2.5 Pro's original 79.52% accuracy. This system extends LLM capabilities for multimodal engineering problem-solving and supports the creation of high-quality educational datasets and AI-powered instructional tools.

**AI Summary:** This research paper addresses the limitations of large language models (LLMs) in engineering tasks, specifically circuit analysis. The study introduces an enhanced, end-to-end circuit problem solver built on Gemini 2.5 Pro, which significantly improves accuracy in generating correct solutions for undergraduate circuit problems by addressing recognition and reasoning errors. The proposed pipeline achieves a 97.59% success rate, showcasing the potential of LLMs in multimodal engineering problem-solving and educational applications.

---

## Dark Personality Traits and Online Toxicity: Linking Self-Reports to Reddit Activity
**URL:** https://arxiv.org/abs/2512.10113

**Abstract:** Dark personality traits have been linked to online misbehavior such as trolling, incivility, and toxic speech. Yet the relationship between these traits and actual online conduct remains understudied. Here we investigate the associations between dark traits, online toxicity, and the socio-linguistic characteristics of online user activity. To explore this relationship, we developed a Web application that integrates validated psychological questionnaires from Amazon Mechanical Turk users to their Reddit activity data. This allowed collecting nearly 57K Reddit comments, including 2.2M tokens and 152.7K sentences from 114 users, that we systematically represent through 224 linguistic and behavioral features. We then examined their relationship to questionnaire-based trait measures via multiple correlation analyses. Among our findings is that dark traits primarily influence the production rather than the perception of online incivility. Sadistic and psychopathic tendencies are most strongly associated with overtly toxic language, whereas other dark dispositions manifest more subtly, often eluding simple textual proxies. Self-reported engagement in hostile behavior mirrors actual online activity, while existing hand-crafted textual proxies for dark triad traits show limited correspondence with our validated measures. Finally, bright and dark traits interact in nuanced ways, with extraversion reducing trolling tendencies and conscientiousness showing modest associations with entitlement and callousness. These findings deepen understanding of how personality shapes toxic online behavior and highlight both opportunities and challenges for developing reliable computational tools and targeted, effective moderation strategies.

**AI Summary:** This research explores the relationship between dark personality traits and online toxicity by analyzing Reddit user activity and self-reported traits. The study found that traits like sadism and psychopathy are strongly linked to overtly toxic language, while other dark traits manifest more subtly. The findings suggest that personality influences online behavior, and understanding these relationships can help in developing effective moderation strategies for addressing toxic online conduct.

---

## Generate-Then-Validate: A Novel Question Generation Approach Using Small Language Models
**URL:** https://arxiv.org/abs/2512.10110

**Abstract:** We explore the use of small language models (SLMs) for automatic question generation as a complement to the prevalent use of their large counterparts in learning analytics research. We present a novel question generation pipeline that leverages both the text generation and the probabilistic reasoning abilities of SLMs to generate high-quality questions. Adopting a "generate-then-validate" strategy, our pipeline first performs expansive generation to create an abundance of candidate questions and refine them through selective validation based on novel probabilistic reasoning. We conducted two evaluation studies, one with seven human experts and the other with a large language model (LLM), to assess the quality of the generated questions. Most judges (humans or LLMs) agreed that the generated questions had clear answers and generally aligned well with the intended learning objectives. Our findings suggest that an SLM can effectively generate high-quality questions when guided by a well-designed pipeline that leverages its strengths.

**AI Summary:** This research explores using small language models (SLMs) for automatic question generation, presenting a novel pipeline that combines text generation and probabilistic reasoning to create high-quality questions. By employing a "generate-then-validate" strategy, the pipeline generates a large number of candidate questions and refines them through selective validation. Evaluation studies with human experts and a large language model showed that the generated questions had clear answers and aligned with learning objectives, indicating that SLMs can effectively generate high-quality questions with the right guidance.

---

## Linear socio-demographic representations emerge in Large Language Models from indirect cues
**URL:** https://arxiv.org/abs/2512.10065

**Abstract:** We investigate how LLMs encode sociodemographic attributes of human conversational partners inferred from indirect cues such as names and occupations. We show that LLMs develop linear representations of user demographics within activation space, wherein stereotypically associated attributes are encoded along interpretable geometric directions. We first probe residual streams across layers of four open transformer-based LLMs (Magistral 24B, Qwen3 14B, GPT-OSS 20B, OLMo2-1B) prompted with explicit demographic disclosure. We show that the same probes predict demographics from implicit cues: names activate census-aligned gender and race representations, while occupations trigger representations correlated with real-world workforce statistics. These linear representations allow us to explain demographic inferences implicitly formed by LLMs during conversation. We demonstrate that these implicit demographic representations actively shape downstream behavior, such as career recommendations. Our study further highlights that models that pass bias benchmark tests may still harbor and leverage implicit biases, with implications for fairness when applied at scale.

**AI Summary:** This research investigates how large language models (LLMs) encode sociodemographic attributes of human conversational partners using indirect cues such as names and occupations. The study shows that LLMs develop linear representations of user demographics within activation space, allowing for the prediction of demographics from implicit cues. These implicit demographic representations can influence downstream behavior, such as career recommendations, and may have implications for fairness when applied at scale.

---

## Mind the Gap! Pathways Towards Unifying AI Safety and Ethics Research
**URL:** https://arxiv.org/abs/2512.10058

**Abstract:** While much research in artificial intelligence (AI) has focused on scaling capabilities, the accelerating pace of development makes countervailing work on producing harmless, "aligned" systems increasingly urgent. Yet research on alignment has diverged along two largely parallel tracks: safety--centered on scaled intelligence, deceptive or scheming behaviors, and existential risk--and ethics--focused on present harms, the reproduction of social bias, and flaws in production pipelines. Although both communities warn of insufficient investment in alignment, they disagree on what alignment means or ought to mean. As a result, their efforts have evolved in relative isolation, shaped by distinct methodologies, institutional homes, and disciplinary genealogies.
We present a large-scale, quantitative study showing the structural split between AI safety and AI ethics. Using a bibliometric and co-authorship network analysis of 6,442 papers from twelve major ML and NLP conferences (2020-2025), we find that over 80% of collaborations occur within either the safety or ethics communities, and cross-field connectivity is highly concentrated: roughly 5% of papers account for more than 85% of bridging links. Removing a small number of these brokers sharply increases segregation, indicating that cross-disciplinary exchange depends on a handful of actors rather than broad, distributed collaboration. These results show that the safety-ethics divide is not only conceptual but institutional, with implications for research agendas, policy, and venues. We argue that integrating technical safety work with normative ethics--via shared benchmarks, cross-institutional venues, and mixed-method methodologies--is essential for building AI systems that are both robust and just.

**AI Summary:** The abstract discusses the divide between AI safety and AI ethics research, highlighting the need for collaboration between the two fields to ensure the development of harmless and aligned AI systems. A quantitative study shows that the majority of collaborations in AI research occur within either the safety or ethics communities, with only a small percentage of papers bridging the gap between the two. The findings suggest that integrating technical safety work with normative ethics is essential for building AI systems that are both robust and just.

---

## Suzume-chan: Your Personal Navigator as an Embodied Information Hub
**URL:** https://arxiv.org/abs/2512.09932

**Abstract:** Access to expert knowledge often requires real-time human communication. Digital tools improve access to information but rarely create the sense of connection needed for deep understanding. This study addresses this issue using Social Presence Theory, which explains how a feeling of "being together" enhances communication. An "Embodied Information Hub" is proposed as a new way to share knowledge through physical and conversational interaction. The prototype, Suzume-chan, is a small, soft AI agent running locally with a language model and retrieval-augmented generation (RAG). It learns from spoken explanations and responds through dialogue, reducing psychological distance and making knowledge sharing warmer and more human-centered.

**AI Summary:** The study introduces Suzume-chan, an Embodied Information Hub AI prototype designed to enhance knowledge sharing through physical and conversational interaction. By incorporating Social Presence Theory, which emphasizes the importance of feeling connected during communication, Suzume-chan aims to create a warmer and more human-centered experience for users. The use of a language model and retrieval-augmented generation (RAG) allows Suzume-chan to learn from spoken explanations and respond through dialogue, reducing psychological distance and improving the depth of understanding in knowledge sharing.

---

## ExaCraft: Dynamic Learning Context Adaptation for Personalized Educational Examples
**URL:** https://arxiv.org/abs/2512.09931

**Abstract:** Learning is most effective when it's connected to relevant, relatable examples that resonate with learners on a personal level. However, existing educational AI tools don't focus on generating examples or adapting to learners' changing understanding, struggles, or growing skills. We've developed ExaCraft, an AI system that generates personalized examples by adapting to the learner's dynamic context. Through the Google Gemini AI and Python Flask API, accessible via a Chrome extension, ExaCraft combines user-defined profiles (including location, education, profession, and complexity preferences) with real-time analysis of learner behavior. This ensures examples are both culturally relevant and tailored to individual learning needs. The system's core innovation is its ability to adapt to five key aspects of the learning context: indicators of struggle, mastery patterns, topic progression history, session boundaries, and learning progression signals. Our demonstration will show how ExaCraft's examples evolve from basic concepts to advanced technical implementations, responding to topic repetition, regeneration requests, and topic progression patterns in different use cases.

**AI Summary:** The research introduces ExaCraft, an AI system that generates personalized educational examples by adapting to learners' changing understanding and skills. The system combines user-defined profiles with real-time analysis of learner behavior to ensure examples are culturally relevant and tailored to individual learning needs. ExaCraft's ability to adapt to key aspects of the learning context, such as indicators of struggle and topic progression history, makes it a valuable tool for personalized education.

---

## Building a Data Dashboard for Magic: The Gathering: Initial Design Considerations
**URL:** https://arxiv.org/abs/2512.09802

**Abstract:** This paper presents the initial stages of a design study aimed at developing a dashboard to visualize gameplay data of the Commander format from Magic: The Gathering. We conducted a user-task analysis to identify requirements for a data visualization dashboard tailored to the Commander format. Afterwards, we proposed a design for the dashboard leveraging visualizations to address players' needs and pain points for typical data analysis tasks in the context domain. Then, we followed-up with a structured user test to evaluate players' comprehension and preferences of data visualizations. Results show that players prioritize contextually relevant, outcome-driven metrics over peripheral ones, and that canonical charts like heatmaps and line charts support higher comprehension than complex ones such as scatterplots or icicle plots. Our findings also highlight the importance of localized views, user customization, and progressive disclosure, emphasizing that adaptability and contextual relevance are as essential as accuracy in effective dashboard design. Our study contributes practical design guidelines for data visualization in gaming contexts and highlights broader implications for engagement-driven dashboards.

**AI Summary:** This research paper focuses on designing a data dashboard for visualizing gameplay data of the Commander format in Magic: The Gathering. Through user-task analysis and a structured user test, the study found that players prioritize contextually relevant metrics and prefer canonical charts like heatmaps and line charts for data analysis. The findings emphasize the importance of adaptability, user customization, and contextual relevance in effective dashboard design, providing practical guidelines for data visualization in gaming contexts.

---

## Smart, simple, sincere - Why and how we should rethink connected things in our smart homes
**URL:** https://arxiv.org/abs/2512.09755

**Abstract:** More and more smart connected things and services turn our homes into smart environments. They promise comfort, efficiency and security. These devices often integrate simple sensors, e.g. for temperature, light or humidity, etc. However, these smart but yet simple sensors can pose a sincere privacy risk. The sensor data enables sense-making of home attendance, domestic activities and even health conditions, often a fact that neither users nor developers are aware of or do not know how to address. Nevertheless, not all is lost or evil. This article makes a plea for how we, the ThingsCon community, might rethink smart connected things and services in our homes. We show this in our approaches and research projects that we initiated.

**AI Summary:** This research explores the potential privacy risks posed by simple sensors in smart connected devices in our homes. The study highlights the importance of rethinking how these devices are designed and used to address these risks. The research suggests that by being more mindful and intentional in our approach to smart home technology, we can create safer and more secure environments for users.

---

## ImageTalk: Designing a Multimodal AAC Text Generation System Driven by Image Recognition and Natural Language Generation
**URL:** https://arxiv.org/abs/2512.09610

**Abstract:** People living with Motor Neuron Disease (plwMND) frequently encounter speech and motor impairments that necessitate a reliance on augmentative and alternative communication (AAC) systems. This paper tackles the main challenge that traditional symbol-based AAC systems offer a limited vocabulary, while text entry solutions tend to exhibit low communication rates. To help plwMND articulate their needs about the system efficiently and effectively, we iteratively design and develop a novel multimodal text generation system called ImageTalk through a tailored proxy-user-based and an end-user-based design phase. The system demonstrates pronounced keystroke savings of 95.6%, coupled with consistent performance and high user satisfaction. We distill three design guidelines for AI-assisted text generation systems design and outline four user requirement levels tailored for AAC purposes, guiding future research in this field.

**AI Summary:** The research paper focuses on designing a multimodal AAC text generation system, ImageTalk, to assist people living with Motor Neuron Disease in communicating efficiently. The system shows significant keystroke savings of 95.6% and high user satisfaction, addressing the limitations of traditional AAC systems. The study provides valuable design guidelines for AI-assisted text generation systems and outlines user requirements tailored for AAC purposes, paving the way for future research in this area.

---

## Auto-BenchmarkCard: Automated Synthesis of Benchmark Documentation
**URL:** https://arxiv.org/abs/2512.09577

**Abstract:** We present Auto-BenchmarkCard, a workflow for generating validated descriptions of AI benchmarks. Benchmark documentation is often incomplete or inconsistent, making it difficult to interpret and compare benchmarks across tasks or domains. Auto-BenchmarkCard addresses this gap by combining multi-agent data extraction from heterogeneous sources (e.g., Hugging Face, Unitxt, academic papers) with LLM-driven synthesis. A validation phase evaluates factual accuracy through atomic entailment scoring using the FactReasoner tool. This workflow has the potential to promote transparency, comparability, and reusability in AI benchmark reporting, enabling researchers and practitioners to better navigate and evaluate benchmark choices.

**AI Summary:** Auto-BenchmarkCard is a new automated workflow that generates accurate descriptions of AI benchmarks by extracting data from various sources and using LLM-driven synthesis. This tool addresses the issue of incomplete and inconsistent benchmark documentation, promoting transparency and comparability in AI benchmark reporting. The validation phase ensures factual accuracy, making it easier for researchers and practitioners to navigate and evaluate benchmark choices.

---

## Exploring Community-Powered Conversational Agent for Health Knowledge Acquisition: A Case Study in Colorectal Cancer
**URL:** https://arxiv.org/abs/2512.09511

**Abstract:** Online communities have become key platforms where young adults, actively seek and share information, including health knowledge. However, these users often face challenges when browsing these communities, such as fragmented content, varying information quality and unfamiliar terminology. Based on a survey with 56 participants and follow-up interviews, we identify common challenges and expected features for learning health knowledge. In this paper, we develop a computational workflow that integrates community content into a conversational agent named CanAnswer to facilitate health knowledge acquisition. Using colorectal cancer as a case study, we evaluate CanAnswer through a lab study with 24 participants and interviews with six medical experts. Results show that CanAnswer improves the recalled gained knowledge and reduces the task workload of the learning session. Our expert interviews (N=6) further confirm the reliability and usefulness of CanAnswer. We discuss the generality of CanAnswer and provide design considerations for enhancing the usefulness and credibility of community-powered learning tools.

**AI Summary:** This research explores the use of a community-powered conversational agent, CanAnswer, to facilitate health knowledge acquisition, focusing on colorectal cancer. The study found that CanAnswer improved participants' recalled knowledge and reduced task workload during learning sessions. Medical experts also confirmed the reliability and usefulness of CanAnswer, suggesting its potential as a tool for enhancing health knowledge acquisition in online communities.

---

## An Efficient Interaction Human-AI Synergy System Bridging Visual Awareness and Large Language Model for Intensive Care Units
**URL:** https://arxiv.org/abs/2512.09473

**Abstract:** Intensive Care Units (ICUs) are critical environments characterized by high-stakes monitoring and complex data management. However, current practices often rely on manual data transcription and fragmented information systems, introducing potential risks to patient safety and operational efficiency. To address these issues, we propose a human-AI synergy system based on a cloud-edge-end architecture, which integrates visual-aware data extraction and semantic interaction mechanisms. Specifically, a visual-aware edge module non-invasively captures real-time physiological data from bedside monitors, reducing manual entry errors. To improve accessibility to fragmented data sources, a semantic interaction module, powered by a Large Language Model (LLM), enables physicians to perform efficient and intuitive voice-based queries over structured patient data. The hierarchical cloud-edge-end deployment ensures low-latency communication and scalable system performance. Our system reduces the cognitive burden on ICU nurses and physicians and demonstrates promising potential for broader applications in intelligent healthcare systems.

**AI Summary:** The research proposes a human-AI synergy system for Intensive Care Units that integrates visual-aware data extraction and semantic interaction mechanisms to improve patient safety and operational efficiency. The system uses a cloud-edge-end architecture to capture real-time physiological data and enable voice-based queries over structured patient data using a Large Language Model. This system reduces manual entry errors, improves accessibility to fragmented data sources, and reduces cognitive burden on ICU nurses and physicians, showing potential for broader applications in intelligent healthcare systems.

---

## Advancing Mathematical Research via Human-AI Interactive Theorem Proving
**URL:** https://arxiv.org/abs/2512.09443

**Abstract:** We investigate how large language models can be used as research tools in scientific computing while preserving mathematical rigor. We propose a human-in-the-loop workflow for interactive theorem proving and discovery with LLMs. Human experts retain control over problem formulation and admissible assumptions, while the model searches for proofs or contradictions, proposes candidate properties and theorems, and helps construct structures and parameters that satisfy explicit constraints, supported by numerical experiments and simple verification checks. Experts treat these outputs as raw material, further refine them, and organize the results into precise statements and rigorous proofs. We instantiate this workflow in a case study on the connection between manifold optimization and Grover's quantum search algorithm, where the pipeline helps identify invariant subspaces, explore Grover-compatible retractions, and obtain convergence guarantees for the retraction-based gradient method. The framework provides a practical template for integrating large language models into frontier mathematical research, enabling faster exploration of proof space and algorithm design while maintaining transparent reasoning responsibilities. Although illustrated on manifold optimization problems in quantum computing, the principles extend to other core areas of scientific computing.

**AI Summary:** This research explores how large language models can be used in scientific computing to advance mathematical research while maintaining rigor. The proposed human-in-the-loop workflow allows experts to guide the model in theorem proving and discovery, leading to faster exploration of proof space and algorithm design. The case study on manifold optimization and Grover's quantum search algorithm demonstrates the framework's effectiveness in identifying invariant subspaces, exploring retractions, and obtaining convergence guarantees, with potential applications in other core areas of scientific computing.

---

## Understanding Mental States in Active and Autonomous Driving with EEG
**URL:** https://arxiv.org/abs/2512.09190

**Abstract:** Understanding how driver mental states differ between active and autonomous driving is critical for designing safe human-vehicle interfaces. This paper presents the first EEG-based comparison of cognitive load, fatigue, valence, and arousal across the two driving modes. Using data from 31 participants performing identical tasks in both scenarios of three different complexity levels, we analyze temporal patterns, task-complexity effects, and channel-wise activation differences. Our findings show that although both modes evoke similar trends across complexity levels, the intensity of mental states and the underlying neural activation differ substantially, indicating a clear distribution shift between active and autonomous driving. Transfer-learning experiments confirm that models trained on active driving data generalize poorly to autonomous driving and vice versa. We attribute this distribution shift primarily to differences in motor engagement and attentional demands between the two driving modes, which lead to distinct spatial and temporal EEG activation patterns. Although autonomous driving results in lower overall cortical activation, participants continue to exhibit measurable fluctuations in cognitive load, fatigue, valence, and arousal associated with readiness to intervene, task-evoked emotional responses, and monotony-related passive fatigue. These results emphasize the need for scenario-specific data and models when developing next-generation driver monitoring systems for autonomous vehicles.

**AI Summary:** This research compares mental states such as cognitive load, fatigue, valence, and arousal between active and autonomous driving using EEG data. The study found that while both driving modes show similar trends in mental states across complexity levels, there are significant differences in the intensity of these states and neural activation patterns. The findings suggest the importance of developing scenario-specific data and models for next-generation driver monitoring systems in autonomous vehicles.

---

## Mental Models of Autonomy and Sentience Shape Reactions to AI
**URL:** https://arxiv.org/abs/2512.09085

**Abstract:** Narratives about artificial intelligence (AI) entangle autonomy, the capacity to self-govern, with sentience, the capacity to sense and feel. AI agents that perform tasks autonomously and companions that recognize and express emotions may activate mental models of autonomy and sentience, respectively, provoking distinct reactions. To examine this possibility, we conducted three pilot studies (N = 374) and four preregistered vignette experiments describing an AI as autonomous, sentient, both, or neither (N = 2,702). Activating a mental model of sentience increased general mind perception (cognition and emotion) and moral consideration more than autonomy, but autonomy increased perceived threat more than sentience. Sentience also increased perceived autonomy more than vice versa. Based on a within-paper meta-analysis, sentience changed reactions more than autonomy on average. By disentangling different mental models of AI, we can study human-AI interaction with more precision to better navigate the detailed design of anthropomorphized AI and prompting interfaces.

**AI Summary:** The research explores how narratives about AI intertwine autonomy and sentience, and how these concepts shape reactions to AI. Findings suggest that activating a mental model of sentience increases mind perception and moral consideration more than autonomy, while autonomy increases perceived threat more than sentience. Understanding these mental models can help improve human-AI interaction and design more effective anthropomorphized AI and prompting interfaces.

---

## Prototyping and Evaluating a Real-time Neuro-Adaptive Virtual Reality Flight Training System
**URL:** https://arxiv.org/abs/2512.09014

**Abstract:** Real-time adjustments to task difficulty during flight training are crucial for optimizing performance and managing pilot workload. This study evaluated the functionality of a pre-trained brain-computer interface (BCI) that adapts training difficulty based on real-time estimations of workload from brain signals. Specifically, an EEG-based neuro-adaptive training system was developed and tested in Virtual Reality (VR) flight simulations with military student pilots. The neuro-adaptive system was compared to a fixed sequence that progressively increased in difficulty, in terms of self-reported user engagement, workload, and simulator sickness (subjective measures), as well as flight performance (objective metric). Additionally, we explored the relationships between subjective workload and flight performance in the VR simulator for each condition. The experiments concluded with semi-structured interviews to elicit the pilots' experience with the neuro-adaptive prototype. Results revealed no significant differences between the adaptive and fixed sequence conditions in subjective measures or flight performance. In both conditions, flight performance decreased as subjective workload increased. The semi-structured interviews indicated that, upon briefing, the pilots preferred the neuro-adaptive VR training system over the system with a fixed sequence, although individual differences were observed in the perception of difficulty and the order of changes in difficulty. Even though this study shows performance does not change, BCI-based flight training systems hold the potential to provide a more personalized and varied training experience.

**AI Summary:** This study evaluated a neuro-adaptive virtual reality flight training system that adjusts task difficulty in real-time based on brain signals. The results showed no significant differences in performance between the adaptive system and a fixed sequence, but pilots preferred the neuro-adaptive system for its personalized and varied training experience. Overall, the study highlights the potential of BCI-based systems in improving training effectiveness and user engagement in flight simulations.

---

## PoultryTalk: A Multi-modal Retrieval-Augmented Generation (RAG) System for Intelligent Poultry Management and Decision Support
**URL:** https://arxiv.org/abs/2512.08995

**Abstract:** The Poultry industry plays a vital role in global food security, yet small- and medium-scale farmers frequently lack timely access to expert-level support for disease diagnosis, nutrition planning, and management decisions. With rising climate stress, unpredictable feed prices, and persistent disease threats, poultry producers often struggle to make quick, informed decisions. Therefore, there is a critical need for intelligent, data-driven systems that can deliver reliable, on-demand consultation. This paper presents PoultryTalk, a novel multi-modal Retrieval-Augmented Generation (RAG) system designed to provide real-time expert guidance through text and image-based interaction. PoultryTalk uses OpenAI's text-embedding-3-small and GPT-4o to provide smart, context-aware poultry management advice from text, images, or questions. System usability and performance were evaluated using 200 expert-verified queries and feedback from 34 participants who submitted 267 queries to the PoultryTalk prototype. The expert-verified benchmark queries confirmed strong technical performance, achieving a semantic similarity of 84.0% and an average response latency of 3.6 seconds. Compared with OpenAI's GPT-4o, PoultryTalk delivered more accurate and reliable information related to poultry. Based on participants' evaluations, PoultryTalk achieved a response accuracy of 89.9%, with about 9.1% of responses rated as incorrect. A post-use survey indicated high user satisfaction: 95.6% of participants reported that the chatbot provided "always correct" and "mostly correct" answers. 82.6% indicated they would recommend the tool, and 17.4% responded "maybe." These results collectively demonstrate that PoultryTalk not only delivers accurate, contextually relevant information but also demonstrates strong user acceptance and scalability potential.

**AI Summary:** The research paper introduces PoultryTalk, a multi-modal Retrieval-Augmented Generation (RAG) system aimed at providing real-time expert guidance for poultry management through text and image-based interactions. The system, utilizing OpenAI's text-embedding-3-small and GPT-4o, demonstrated strong technical performance with an 84.0% semantic similarity and an average response latency of 3.6 seconds. User evaluations indicated high satisfaction and accuracy rates, showcasing the system's potential to deliver reliable information and gain user acceptance in the poultry industry.

---

## SimClinician: A Multimodal Simulation Testbed for Reliable Psychologist AI Collaboration in Mental Health Diagnosis
**URL:** https://arxiv.org/abs/2512.08953

**Abstract:** AI based mental health diagnosis is often judged by benchmark accuracy, yet in practice its value depends on how psychologists respond whether they accept, adjust, or reject AI suggestions. Mental health makes this especially challenging: decisions are continuous and shaped by cues in tone, pauses, word choice, and nonverbal behaviors of patients. Current research rarely examines how AI diagnosis interface design influences these choices, leaving little basis for reliable testing before live studies. We present SimClinician, an interactive simulation platform, to transform patient data into psychologist AI collaborative diagnosis. Contributions include: (1) a dashboard integrating audio, text, and gaze-expression patterns; (2) an avatar module rendering de-identified dynamics for analysis; (3) a decision layer that maps AI outputs to multimodal evidence, letting psychologists review AI reasoning, and enter a diagnosis. Tested on the E-DAIC corpus (276 clinical interviews, expanded to 480,000 simulations), SimClinician shows that a confirmation step raises acceptance by 23%, keeping escalations below 9%, and maintaining smooth interaction flow.

**AI Summary:** The research introduces SimClinician, a simulation platform for psychologist AI collaboration in mental health diagnosis. The platform incorporates audio, text, and gaze-expression patterns to allow psychologists to review AI reasoning and make informed decisions. Testing on a large dataset shows that a confirmation step increases acceptance rates and maintains smooth interaction flow, highlighting the significance of interface design in AI-based mental health diagnosis.

---

## Beyond Technical Debt: How AI-Assisted Development Creates Comprehension Debt in Resource-Constrained Indie Teams
**URL:** https://arxiv.org/abs/2512.08942

**Abstract:** Junior indie game developers in distributed, part-time teams lack production frameworks suited to their specific context, as traditional methodologies are often inaccessible. This study introduces the CIGDI (Co-Intelligence Game Development Ideation) Framework, an alternative approach for integrating AI tools to address persistent challenges of technical debt, coordination, and burnout.
The framework emerged from a three-month reflective practice and autoethnographic study of a three-person distributed team developing the 2D narrative game "The Worm's Memoirs". Based on analysis of development data (N=157 Jira tasks, N=333 GitHub commits, N=13+ Miro boards, N=8 reflection sessions), CIGDI is proposed as a seven-stage iterative process structured around human-in-the-loop decision points (Priority Criteria and Timeboxing).
While AI support democratized knowledge access and reduced cognitive load, our analysis identified a significant challenge: "comprehension debt." We define this as a novel form of technical debt where AI helps teams build systems more sophisticated than their independent skill level can create or maintain. This paradox (possessing functional systems the team incompletely understands) creates fragility and AI dependency, distinct from traditional code quality debt.
This work contributes a practical production framework for resource-constrained teams and identifies critical questions about whether AI assistance constitutes a learning ladder or a dependency trap for developer skill.

**AI Summary:** The study introduces the CIGDI Framework, which integrates AI tools to address technical debt, coordination, and burnout in indie game development teams. The framework, developed through a reflective study of a distributed team creating a narrative game, highlights the concept of "comprehension debt," where AI assistance can lead to systems that surpass the team's skill level, creating fragility and dependency. This research provides a practical approach for resource-constrained teams and raises important questions about the impact of AI on developer skill development.

---

## One Size Fits None: A Personalized Framework for Urban Accessibility Using Exponential Decay
**URL:** https://arxiv.org/abs/2512.08941

**Abstract:** This study develops a personalized accessibility framework that integrates exponential decay functions with user-customizable weighting systems. The framework enables real-time, personalized urban evaluation based on individual priorities and lifestyle requirements. The methodology employs grid-based discretization and a two-stage computational architecture that separates intensive preprocessing from lightweight real-time calculations. The computational architecture demonstrates that accessibility modelling can be made accessible to non-technical users through interactive interfaces, enabling fine-grained spatial analysis and identification of accessibility variations within neighbourhoods. The research contributes to Sustainable Development Goal 11's vision of inclusive, sustainable cities by providing tools for understanding how different populations experience identical urban spaces, supporting evidence-based policy development that addresses accessibility gaps.

**AI Summary:** This study introduces a personalized framework for urban accessibility using exponential decay functions and customizable weighting systems. The framework allows for real-time evaluation of urban spaces based on individual needs and preferences, with a two-stage computational architecture making the process accessible to non-technical users. This research contributes to Sustainable Development Goal 11 by providing tools for identifying and addressing accessibility disparities within cities, supporting evidence-based policy development for inclusive and sustainable urban environments.

---

## Psychlysis: Towards the Creation of a Questionnaire-based Machine Learning Tool to Analyze States of Mind
**URL:** https://arxiv.org/abs/2512.08940

**Abstract:** This paper describes the development of Psychlysis, a work-in-progress questionnaire-based machine learning application analyzing the user's current state of mind and suggesting ways to improve their mood using Machine Learning. The application utilizes the OCEAN model to understand the user's personality traits and make customized suggestions to enhance their well-being. The proposed application focus on improving the user's mood rather than just detecting their emotions. Preliminary results of the model are presented, showing the potential of the application in predicting the user's mood and providing personalized recommendations. The paper concludes by highlighting the potential benefits of such an application for various societal segments, including doctors, individuals, and mental health organizations, in improving emotional well-being and reducing the negative impact of mental health issues on daily life.

**AI Summary:** The paper introduces Psychlysis, a questionnaire-based machine learning tool that analyzes the user's state of mind and provides personalized suggestions to improve their mood based on the OCEAN model of personality traits. The application focuses on enhancing well-being rather than just detecting emotions, with preliminary results showing promise in predicting mood and offering tailored recommendations. The potential benefits of Psychlysis include aiding doctors, individuals, and mental health organizations in improving emotional well-being and mitigating the effects of mental health issues on daily life.

---

## Assessing the Human-Likeness of LLM-Driven Digital Twins in Simulating Health Care System Trust
**URL:** https://arxiv.org/abs/2512.08939

**Abstract:** Serving as an emerging and powerful tool, Large Language Model (LLM)-driven Human Digital Twins are showing great potential in healthcare system research. However, its actual simulation ability for complex human psychological traits, such as distrust in the healthcare system, remains unclear. This research gap particularly impacts health professionals' trust and usage of LLM-based Artificial Intelligence (AI) systems in assisting their routine work. In this study, based on the Twin-2K-500 dataset, we systematically evaluated the simulation results of the LLM-driven human digital twin using the Health Care System Distrust Scale (HCSDS) with an established human-subject sample, analyzing item-level distributions, summary statistics, and demographic subgroup patterns. Results showed that the simulated responses by the digital twin were significantly more centralized with lower variance and had fewer selections of extreme options (all p<0.001). While the digital twin broadly reproduces human results in major demographic patterns, such as age and gender, it exhibits relatively low sensitivity in capturing minor differences in education levels. The LLM-based digital twin simulation has the potential to simulate population trends, but it also presents challenges in making detailed, specific distinctions in subgroups of human beings. This study suggests that the current LLM-driven Digital Twins have limitations in modeling complex human attitudes, which require careful calibration and validation before applying them in inferential analyses or policy simulations in health systems engineering. Future studies are necessary to examine the emotional reasoning mechanism of LLMs before their use, particularly for studies that involve simulations sensitive to social topics, such as human-automation trust.

**AI Summary:** This research evaluates the ability of Large Language Model (LLM)-driven Human Digital Twins to simulate distrust in the healthcare system. The study found that while the digital twin broadly reproduces human results in major demographic patterns, it has limitations in capturing minor differences in education levels. The findings suggest that LLM-driven Digital Twins have potential for simulating population trends but may require careful calibration and validation before being used in inferential analyses or policy simulations in health systems engineering.

---

## The Impact of Artificial Intelligence on Strategic Technology Management: A Mixed-Methods Analysis of Resources, Capabilities, and Human-AI Collaboration
**URL:** https://arxiv.org/abs/2512.08938

**Abstract:** This paper investigates how artificial intelligence (AI) can be effectively integrated into Strategic Technology Management (STM) practices to enhance the strategic alignment and effectiveness of technology investments. Through a mixed-methods approach combining quantitative survey data (n=230) and qualitative expert interviews (n=14), this study addresses three critical research questions: what success factors AI innovates for STM roadmap formulation under uncertainty; what resources and capabilities organizations require for AI-enhanced STM; and how human-AI interaction should be designed for complex STM tasks. The findings reveal that AI fundamentally transforms STM through data-driven strategic alignment and continuous adaptation, while success depends on cultivating proprietary data ecosystems, specialized human talent, and robust governance capabilities. The study introduces the AI-based Strategic Technology Management (AIbSTM) conceptual framework, which synthesizes technical capabilities with human and organizational dimensions across three layers: strategic alignment, resource-based view, and human-AI interaction. Contrary to visions of autonomous AI leadership, the research demonstrates that the most viable trajectory is human-centric augmentation, where AI serves as a collaborative partner rather than a replacement for human judgment. This work contributes to theory by extending the Resource-Based View to AI contexts and addressing cognitive and socio-technical chasms in AI adoption, while offering practitioners a prescriptive framework for navigating AI integration in strategic technology management.

**AI Summary:** This research explores how artificial intelligence can be integrated into Strategic Technology Management practices to enhance strategic alignment and effectiveness of technology investments. The study identifies success factors, resources, and capabilities needed for AI-enhanced STM, and emphasizes the importance of human-AI collaboration in complex tasks. The findings suggest that AI transforms STM through data-driven alignment and continuous adaptation, highlighting the need for organizations to cultivate data ecosystems, human talent, and governance capabilities.

---

