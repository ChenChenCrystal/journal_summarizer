[
  {
    "title": "GRAPHIC--Guidelines for Reviewing Algorithmic Practices in Human-centred Design and Interaction for Creativity",
    "abstract": "Artificial Intelligence (AI) has been increasingly applied to creative domains, leading to the development of systems that collaborate with humans in design processes. In Graphic Design, integrating computational systems into co-creative workflows presents specific challenges, as it requires balancing scientific rigour with the subjective and visual nature of design practice. Following the PRISMA methodology, we identified 872 articles, resulting in a final corpus of 71 publications describing 68 unique systems. Based on this review, we introduce GRAPHIC (Guidelines for Reviewing Algorithmic Practices in Human-centred Design and Interaction for Creativity), a framework for analysing AI-based systems applied to Graphic Design. Its goal is to understand how current systems support human-AI collaboration in the Graphic Design discipline. The framework comprises main dimensions, which our analysis revealed to be essential across diverse system types: (1) Collaborative Panorama, (2) Processes and Modalities, and (3) Graphic Design Principles. Its application revealed research gaps, including the need to balance initiative and control between agents, improve communication through explainable interaction models, and promote systems that support transformational creativity grounded in core design principles.",
    "url": "https://arxiv.org/abs/2511.17443",
    "journal": "arXiv cs.HC",
    "ai_summary": "The abstract discusses the increasing use of AI in creative domains, particularly in Graphic Design, and the challenges of integrating computational systems into design processes. Through a review of 872 articles, the authors identified 68 unique AI-based systems and developed the GRAPHIC framework to analyze these systems in the context of human-AI collaboration in Graphic Design. The framework highlights key dimensions such as Collaborative Panorama, Processes and Modalities, and Graphic Design Principles, revealing research gaps in balancing initiative and control, improving communication, and supporting transformational creativity in design."
  },
  {
    "title": "Mixed Reality Scenic Live Streaming for Cultural Heritage: Visual Interactions in a Historic Landscape",
    "abstract": "Scenic Live Streams (SLS), capturing real-world scenic sites from fixed cameras without streamers, have gained increasing popularity recently. They afford unique real-time lenses into remote sites for viewers' synchronous and collective engagement. Foregrounding its lack of dynamism and interactivity, we aim to maximize the potential of SLS by making it interactive. Namely MRSLS, we overlaid plain SLS with interactive Mixed Reality content that matches the site's geographical structures and local cultural backgrounds. We further highlight the substantial benefit of MRSLS to cultural heritage site interactions, and we demonstrate this design proposal with an MRSLS prototype at a UNESCO-listed heritage site in China. The design process includes an interview (N=6) to pinpoint local scenery and culture, as well as two iterative design studies (N=15, 14). A mixed-methods, between-subjects study (N=43, 37) shows that MRSLS affords immersive scenery appreciation, effective cultural imprints, and vivid shared experience. With its balance between cultural, participatory, and authentic attributes, we appeal for more HCI attention to (MR)SLS as an under-explored design space.",
    "url": "https://arxiv.org/abs/2511.17246",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research explores the use of Mixed Reality Scenic Live Streams (MRSLS) to enhance viewer engagement with cultural heritage sites. By overlaying interactive Mixed Reality content onto live streams of historic landscapes, the study found that MRSLS offers immersive scenery appreciation, effective cultural imprints, and a vivid shared experience. The findings suggest that MRSLS has the potential to transform traditional scenic live streaming into a more dynamic and interactive experience, highlighting the importance of exploring this design space further in the field of Human-Computer Interaction."
  },
  {
    "title": "Senti-iFusion: An Integrity-centered Hierarchical Fusion Framework for Multimodal Sentiment Analysis under Uncertain Modality Missingness",
    "abstract": "Multimodal Sentiment Analysis (MSA) is critical for human-computer interaction but faces challenges when the modalities are incomplete or missing. Existing methods often assume pre-defined missing modalities or fixed missing rates, limiting their real-world applicability. To address this challenge, we propose Senti-iFusion, an integrity-centered hierarchical fusion framework capable of handling both inter- and intra-modality missingness simultaneously. It comprises three hierarchical components: Integrity Estimation, Integrity-weighted Completion, and Integrity-guided Fusion. First, the Integrity Estimation module predicts the completeness of each modality and mitigates the noise caused by incomplete data. Second, the Integrity-weighted Cross-modal Completion module employs a novel weighting mechanism to disentangle consistent semantic structures from modality-specific representations, enabling the precise recovery of sentiment-related features across language, acoustic, and visual modalities. To ensure consistency in reconstruction, a dual-depth validation with semantic- and feature-level losses ensures consistent reconstruction at both fine-grained (low-level) and semantic (high-level) scales. Finally, the Integrity-guided Adaptive Fusion mechanism dynamically selects the dominant modality for attention-based fusion, ensuring that the most reliable modality, based on completeness and quality, contributes more significantly to the final prediction. Senti-iFusion employs a progressive training approach to ensure stable convergence. Experimental results on popular MSA datasets demonstrate that Senti-iFusion outperforms existing methods, particularly in fine-grained sentiment analysis tasks. The code and our proposed Senti-iFusion model will be publicly available.",
    "url": "https://arxiv.org/abs/2511.16990",
    "journal": "arXiv cs.HC",
    "ai_summary": "The study introduces Senti-iFusion, a hierarchical fusion framework designed to address challenges in Multimodal Sentiment Analysis (MSA) when modalities are incomplete or missing. The framework includes three components: Integrity Estimation, Integrity-weighted Completion, and Integrity-guided Fusion, which work together to accurately recover sentiment-related features across different modalities. Experimental results show that Senti-iFusion outperforms existing methods, particularly in fine-grained sentiment analysis tasks, making it a valuable tool for improving human-computer interaction."
  },
  {
    "title": "The Wireless Charger as a Gesture Sensor: A Novel Approach to Ubiquitous Interaction",
    "abstract": "Advancements in information technology have increased demand for natural human-computer interaction in areas such as gaming, smart homes, and vehicles. However, conventional approaches like physical buttons or cameras are often limited by contact requirements, privacy concerns, and high this http URL by the observation that these EM signals are not only strong and measurable but also rich in gesture-related information, we propose EMGesture, a novel contactless interaction technique that leverages the electromagnetic (EM) signals from Qi wireless chargers for gesture recognition. EMGesture analyzes the distinctive EM features and employs a robust classification model. The end-to-end framework enables it capable of accurately interpreting user intent. Experiments involving 30 participants, 10 mobile devices, and 5 chargers showed that EMGesture achieves over 97% recognition accuracy. Corresponding user studies also confirmed higher usability and convenience, which demonstrating that EMGesture is a practical, privacy-conscious, and cost-effective solution for pervasive interaction.",
    "url": "https://arxiv.org/abs/2511.16989",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces EMGesture, a novel contactless interaction technique that uses electromagnetic signals from Qi wireless chargers for gesture recognition. The study found that EMGesture achieves over 97% recognition accuracy and offers higher usability and convenience compared to traditional interaction methods. This research highlights the potential for using wireless chargers as gesture sensors for natural and privacy-conscious human-computer interaction in various applications."
  },
  {
    "title": "IsharaKotha: A Comprehensive Avatar-based Bangla Sign Language Corpus",
    "abstract": "Sign language is a vital communication medium for the hearing-impaired community, enabling effective interaction and self-expression. To help bridge the communication gap between hearing and hearing-impaired individuals, a text-to-sign translation system is essential. Such systems can also support learners interested in acquiring sign language skills. This work presents IsharaKotha, the first HamNoSys-based Bangla Sign Language corpus, containing 3823 words. A deep learning based lemmatizer was integrated to extract root words, enabling sign generation for complete sentences. An evaluation interface was developed to assess the quality of sign animations for letters, digits, and sentences. Two professional interpreters and one real sign language user rated the animations using categorical numeric scores. The system achieved an average rating of 3.14 out of 4.00, indicating high quality performance between Good and Excellent. These results demonstrate the potential of IsharaKotha to support future advancements in dynamic sign language translation systems. The evaluation system is available at this http URL",
    "url": "https://arxiv.org/abs/2511.16896",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces IsharaKotha, a Bangla Sign Language corpus, to facilitate communication between hearing and hearing-impaired individuals through a text-to-sign translation system. The corpus contains 3823 words and utilizes deep learning for sign generation, achieving high quality performance in evaluations. This work has the potential to advance dynamic sign language translation systems and support learners interested in acquiring sign language skills."
  },
  {
    "title": "Scene Awareness While Using Multiple Navigation Aids in AR Search",
    "abstract": "Augmented reality (AR) allows virtual information to be presented in the real world, providing support for numerous tasks including search and navigation. Allowing users access to multiple navigation aids may help leverage the benefits of different navigational guidance methods, but may also have negative perceptual and cognitive impacts. In this study, users performed searches for virtual gems within a large-scale augmented environment while choosing to deploy two different navigation aids either independently or simultaneously: world-locked arrows and an on-screen radar. After completing the search, participants were asked to recall objects that may or may not have been present in the scene. The use of navigation aids impacted object recall, with impaired recall of objects in the environment when an aid was switched on. The results point at possible impact factors of object awareness in mobile AR and underscore the potential for adaptable interfaces to support users navigating the physical world.",
    "url": "https://arxiv.org/abs/2511.16805",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores the impact of using multiple navigation aids in augmented reality (AR) search tasks. The research found that the use of navigation aids affected users' ability to recall objects in the environment, with impaired recall when aids were switched on. These findings highlight the importance of considering the design of AR interfaces to support users effectively navigating the physical world."
  },
  {
    "title": "Generative Augmented Reality: Paradigms, Technologies, and Future Applications",
    "abstract": "This paper introduces Generative Augmented Reality (GAR) as a next-generation paradigm that reframes augmentation as a process of world re-synthesis rather than world composition by a conventional AR engine. GAR replaces the conventional AR engine's multi-stage modules with a unified generative backbone, where environmental sensing, virtual content, and interaction signals are jointly encoded as conditioning inputs for continuous video generation. We formalize the computational correspondence between AR and GAR, survey the technical foundations that make real-time generative augmentation feasible, and outline prospective applications that leverage its unified inference model. We envision GAR as a future AR paradigm that delivers high-fidelity experiences in terms of realism, interactivity, and immersion, while eliciting new research challenges on technologies, content ecosystems, and the ethical and societal implications.",
    "url": "https://arxiv.org/abs/2511.16783",
    "journal": "arXiv cs.HC",
    "ai_summary": "This paper introduces Generative Augmented Reality (GAR) as a new paradigm that focuses on re-synthesizing the world rather than composing it, using a unified generative backbone. GAR combines environmental sensing, virtual content, and interaction signals to generate continuous video in real-time, leading to high-fidelity AR experiences with increased realism, interactivity, and immersion. The research highlights the potential of GAR for future AR applications and raises new challenges in technology, content creation, and ethical considerations."
  },
  {
    "title": "Trust in AI emerges from distrust in humans: A machine learning study on decision-making guidance",
    "abstract": "This study explores the dynamics of trust in artificial intelligence (AI) agents, particularly large language models (LLMs), by introducing the concept of \"deferred trust\", a cognitive mechanism where distrust in human agents redirects reliance toward AI perceived as more neutral or competent. Drawing on frameworks from social psychology and technology acceptance models, the research addresses gaps in user-centric factors influencing AI trust. Fifty-five undergraduate students participated in an experiment involving 30 decision-making scenarios (factual, emotional, moral), selecting from AI agents (e.g., ChatGPT), voice assistants, peers, adults, or priests as guides. Data were analyzed using K-Modes and K-Means clustering for patterns, and XGBoost models with SHAP interpretations to predict AI selection based on sociodemographic and prior trust variables.\nResults showed adults (35.05\\%) and AI (28.29\\%) as the most selected agents overall. Clustering revealed context-specific preferences: AI dominated factual scenarios, while humans prevailed in social/moral ones. Lower prior trust in human agents (priests, peers, adults) consistently predicted higher AI selection, supporting deferred trust as a compensatory transfer. Participant profiles with higher AI trust were distinguished by human distrust, lower technology use, and higher socioeconomic status. Models demonstrated consistent performance (e.g., average precision up to 0.863).\nFindings challenge traditional models like TAM/UTAUT, emphasizing relational and epistemic dimensions in AI trust. They highlight risks of over-reliance due to fluency effects and underscore the need for transparency to calibrate vigilance. Limitations include sample homogeneity and static scenarios; future work should incorporate diverse populations and multimodal data to refine deferred trust across contexts.",
    "url": "https://arxiv.org/abs/2511.16769",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study investigates trust in AI agents, specifically large language models, and introduces the concept of \"deferred trust\" where distrust in humans leads to reliance on AI. Results show that participants often selected AI over humans in decision-making scenarios, especially in factual situations. The findings challenge traditional models of AI trust and emphasize the importance of transparency and vigilance to prevent over-reliance on AI."
  },
  {
    "title": "Feasibility of Embodied Dynamics Based Bayesian Learning for Continuous Pursuit Motion Control of Assistive Mobile Robots in the Built Environment",
    "abstract": "Non-invasive electroencephalography (EEG)-based brain-computer interfaces (BCIs) offer an intuitive means for individuals with severe motor impairments to independently operate assistive robotic wheelchairs and navigate built environments. Despite considerable progress in BCI research, most current motion control systems are limited to discrete commands, rather than supporting continuous pursuit, where users can freely adjust speed and direction in real time. Such natural mobility control is, however, essential for wheelchair users to navigate complex public spaces, such as transit stations, airports, hospitals, and indoor corridors, to interact socially with the dynamic populations with agility, and to move flexibly and comfortably as autonomous driving is refined to allow movement at will. In this study, we address the gap of continuous pursuit motion control in BCIs by proposing and validating a brain-inspired Bayesian inference framework, where embodied dynamics in acceleration-based motor representations are decoded. This approach contrasts with conventional kinematics-level decoding and deep learning-based methods. Using a public dataset with sixteen hours of EEG from four subjects performing motor imagery-based target-following, we demonstrate that our method, utilizing Automatic Relevance Determination for feature selection and continual online learning, reduces the normalized mean squared error between predicted and true velocities by 72% compared to autoregressive and EEGNet-based methods in a session-accumulative transfer learning setting. Theoretically, these findings empirically support embodied cognition theory and reveal the brain's intrinsic motor control dynamics in an embodied and predictive nature. Practically, grounding EEG decoding in the same dynamical principles that govern biological motion offers a promising path toward more stable and intuitive BCI control.",
    "url": "https://arxiv.org/abs/2511.17401",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the feasibility of using EEG-based BCIs for continuous pursuit motion control of assistive mobile robots in built environments. The study proposes a brain-inspired Bayesian inference framework that incorporates embodied dynamics in acceleration-based motor representations, resulting in a significant reduction in prediction error compared to conventional methods. These findings support embodied cognition theory and suggest a promising path towards more stable and intuitive BCI control for individuals with severe motor impairments."
  },
  {
    "title": "AI Workers, Geopolitics, and Algorithmic Collective Action",
    "abstract": "According to the theory of International Political Economy (IPE), states are often incentivized to rely on rather than constrain powerful corporations. For this reason, IPE provides a useful lens to explain why efforts to govern Artificial Intelligence (AI) at the international and national levels have thus far been developed, applied, and enforced unevenly. Building on recent work that explores how AI companies engage in geopolitics, this position paper argues that some AI workers can be considered actors of geopolitics. It makes the timely case that governance alone cannot ensure responsible, ethical, or robust AI development and use, and greater attention should be paid to bottom-up interventions at the site of AI development. AI workers themselves should be situated as individual agents of change, especially when considering their potential to foster Algorithmic Collective Action (ACA). Drawing on methods of Participatory Design (PD), this paper proposes engaging AI workers as sources of knowledge, relative power, and intentionality to encourage more responsible and just AI development and create the conditions that can facilitate ACA.",
    "url": "https://arxiv.org/abs/2511.17331",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper explores the role of AI workers in geopolitics and argues that they can be considered actors of geopolitics. It highlights the importance of bottom-up interventions at the site of AI development and suggests that AI workers should be seen as individual agents of change. The paper proposes engaging AI workers through Participatory Design to encourage more responsible and just AI development and foster Algorithmic Collective Action."
  },
  {
    "title": "Monte Carlo Expected Threat (MOCET) Scoring",
    "abstract": "Evaluating and measuring AI Safety Level (ASL) threats are crucial for guiding stakeholders to implement safeguards that keep risks within acceptable limits. ASL-3+ models present a unique risk in their ability to uplift novice non-state actors, especially in the realm of biosecurity. Existing evaluation metrics, such as LAB-Bench, BioLP-bench, and WMDP, can reliably assess model uplift and domain knowledge. However, metrics that better contextualize \"real-world risks\" are needed to inform the safety case for LLMs, along with scalable, open-ended metrics to keep pace with their rapid advancements. To address both gaps, we introduce MOCET, an interpretable and doubly-scalable metric (automatable and open-ended) that can quantify real-world risks.",
    "url": "https://arxiv.org/abs/2511.16823",
    "journal": "arXiv cs.HC",
    "ai_summary": "The abstract introduces MOCET, a new metric for evaluating AI Safety Level (ASL) threats, particularly in ASL-3+ models that pose risks in biosecurity. Existing evaluation metrics can assess model uplift and domain knowledge, but MOCET is introduced to provide a more contextualized assessment of \"real-world risks\" for LLMs, offering a scalable and interpretable solution to keep pace with rapid advancements in AI technology. This research is significant in guiding stakeholders to implement safeguards and inform the safety case for LLMs to mitigate potential risks."
  },
  {
    "title": "Stable diffusion models reveal a persisting human and AI gap in visual creativity",
    "abstract": "While recent research suggests Large Language Models match human creative performance in divergent thinking tasks, visual creativity remains underexplored. This study compared image generation in human participants (Visual Artists and Non Artists) and using an image generation AI model (two prompting conditions with varying human input: high for Human Inspired, low for Self Guided). Human raters (N=255) and GPT4o evaluated the creativity of the resulting images. We found a clear creativity gradient, with Visual Artists being the most creative, followed by Non Artists, then Human Inspired generative AI, and finally Self Guided generative AI. Increased human guidance strongly improved GenAI's creative output, bringing its productions close to those of Non Artists. Notably, human and AI raters also showed vastly different creativity judgment patterns. These results suggest that, in contrast to language centered tasks, GenAI models may face unique challenges in visual domains, where creativity depends on perceptual nuance and contextual sensitivity, distinctly human capacities that may not be readily transferable from language models.",
    "url": "https://arxiv.org/abs/2511.16814",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study compared the visual creativity of human participants (Visual Artists and Non Artists) with an image generation AI model in two prompting conditions. The results showed a clear creativity gradient, with Visual Artists being the most creative, followed by Non Artists, then Human Inspired generative AI, and finally Self Guided generative AI. The study suggests that while AI models may match human performance in language tasks, they face unique challenges in visual creativity due to the reliance on perceptual nuance and contextual sensitivity, which are distinctly human capacities."
  },
  {
    "title": "Optimized User Experience for Labeling Systems for Predictive Maintenance Applications (Extended)",
    "abstract": "The maintenance of rail vehicles and infrastructure plays a critical role in reducing delays, preventing malfunctions, and ensuring the economic efficiency of rail transportation companies. Predictive maintenance systems powered by supervised machine learning offer a promising approach by detecting failures before they occur, reducing unscheduled downtime, and improving operational efficiency. However, the success of such systems depends on high quality labeled data, necessitating user centered labeling interfaces tailored to annotators needs for Usability and User Experience. This study introduces a cost effective predictive maintenance system developed in the federally funded project DigiOnTrack, which combines structure borne noise measurement with supervised learning to provide monitoring and maintenance recommendations for rail vehicles and infrastructure in rural Germany. The system integrates wireless sensor networks, distributed ledger technology for secure data transfer, and a dockerized container infrastructure hosting the labeling interface and dashboard. Train drivers and workshop foremen labeled faults on infrastructure and vehicles to ensure accurate recommendations. The Usability and User Experience evaluation showed that the locomotive drivers interface achieved Excellent Usability, while the workshop foremans interface was rated as Good. These results highlight the systems potential for integration into daily workflows, particularly in labeling efficiency. However, areas such as Perspicuity require further optimization for more data intensive scenarios. The findings offer insights into the design of predictive maintenance systems and labeling interfaces, providing a foundation for future guidelines in Industry 4.0 applications, particularly in rail transportation.",
    "url": "https://arxiv.org/abs/2511.16266",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study focuses on the development of a predictive maintenance system for rail vehicles and infrastructure using supervised machine learning. The system incorporates a user-centered labeling interface for annotators, such as train drivers and workshop foremen, to improve the quality of labeled data. The evaluation showed excellent usability for locomotive drivers and good usability for workshop foremen, indicating the system's potential for integration into daily workflows, with room for further optimization in data-intensive scenarios."
  },
  {
    "title": "GazeInterpreter: Parsing Eye Gaze to Generate Eye-Body-Coordinated Narrations",
    "abstract": "Comprehensively interpreting human behavior is a core challenge in human-aware artificial intelligence. However, prior works typically focused on body behavior, neglecting the crucial role of eye gaze and its synergy with body motion. We present GazeInterpreter - a novel large language model-based (LLM-based) approach that parses eye gaze data to generate eye-body-coordinated narrations. Specifically, our method features 1) a symbolic gaze parser that translates raw gaze signals into symbolic gaze events; 2) a hierarchical structure that first uses an LLM to generate eye gaze narration at semantic level and then integrates gaze with body motion within the same observation window to produce integrated narration; and 3) a self-correcting loop that iteratively refines the modality match, temporal coherence, and completeness of the integrated narration. This hierarchical and iterative processing can effectively align physical values and semantic text in the temporal and spatial domains. We validated the effectiveness of our eye-body-coordinated narrations on the text-driven motion generation task in the large-scale Nymeria benchmark. Moreover, we report significant performance improvements for the sample downstream tasks of action anticipation and behavior summarization. Taken together, these results reveal the significant potential of parsing eye gaze to interpret human behavior and open up a new direction for human behavior understanding.",
    "url": "https://arxiv.org/abs/2511.16245",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces GazeInterpreter, a novel approach that uses a large language model to parse eye gaze data and generate eye-body-coordinated narrations. By integrating gaze with body motion, the method effectively aligns physical values and semantic text, leading to improved performance in tasks such as action anticipation and behavior summarization. This work highlights the importance of considering eye gaze in understanding human behavior and opens up new possibilities for human-aware artificial intelligence."
  },
  {
    "title": "Optimizing Predictive Maintenance: Enhanced AI and Backend Integration",
    "abstract": "Rail transportation success depends on efficient maintenance to avoid delays and malfunctions, particularly in rural areas with limited resources. We propose a cost-effective wireless monitoring system that integrates sensors and machine learning to address these challenges. We developed a secure data management system, equipping train cars and rail sections with sensors to collect structural and environmental data. This data supports Predictive Maintenance by identifying potential issues before they lead to failures. Implementing this system requires a robust backend infrastructure for secure data transfer, storage, and analysis. Designed collaboratively with stakeholders, including the railroad company and project partners, our system is tailored to meet specific requirements while ensuring data integrity and security. This article discusses the reasoning behind our design choices, including the selection of sensors, data handling protocols, and Machine Learning models. We propose a system architecture for implementing the solution, covering aspects such as network topology and data processing workflows. Our approach aims to enhance the reliability and efficiency of rail transportation through advanced technological integration.",
    "url": "https://arxiv.org/abs/2511.16239",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research focuses on optimizing predictive maintenance in rail transportation using a cost-effective wireless monitoring system that integrates sensors and machine learning. The system collects structural and environmental data to support Predictive Maintenance by identifying potential issues before they cause failures. The proposed system, designed collaboratively with stakeholders, aims to enhance the reliability and efficiency of rail transportation through advanced technological integration, including a robust backend infrastructure for secure data transfer, storage, and analysis."
  },
  {
    "title": "Optimized User Experience for Labeling Systems for Predictive Maintenance Applications",
    "abstract": "This paper presents the design and implementation of a graphical labeling user interface for a monitoring and predictive maintenance system for trains and rail infrastructure in a rural area of Germany. Aiming to enhance rail transportation's economic viability and operational efficiency, our project utilizes cost-effective wireless monitoring systems that combine affordable sensors and machine learning algorithms. Given that a successful labeling phase is indispensable for training a supervised machine learning system, we emphasize the importance of a user-friendly labeling user interface, which can be optimally integrated into the daily work routines of annotators. The labeling system has been designed based on best practices in usability heuristics and will be validated for usability and user experience through a study, the protocol for which is presented here. The value of this work lies in its potential to reduce maintenance costs and improve service reliability in rail transportation, contributing to the academic literature and offering practical insights for research on effective labeling user interfaces, as well as for the development of labeling systems in the industry. Upon completion of the study, we will share the results, refine the system as necessary, and explore its scalability in other areas of infrastructure maintenance.",
    "url": "https://arxiv.org/abs/2511.16236",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on designing and implementing a user-friendly labeling interface for a predictive maintenance system for trains in rural Germany. The project aims to improve the economic viability and efficiency of rail transportation by utilizing cost-effective wireless monitoring systems and machine learning algorithms. The study emphasizes the importance of a successful labeling phase for training machine learning systems and offers insights for developing effective labeling user interfaces in the industry, with the potential to reduce maintenance costs and improve service reliability in rail transportation."
  },
  {
    "title": "When Less is More: A Story of Failing Bayesian Optimization Due to Additional Expert Knowledge",
    "abstract": "The compounding of plastics with recycled material remains a practical challenge, as the properties of the processed material is not as easy to control as with completely new raw materials. For a data scientist, it makes sense to plan the necessary experiments in the development of new compounds using Bayesian Optimization, an optimization approach based on a surrogate model that is known for its data efficiency and is therefore well suited for data obtained from costly experiments. Furthermore, if historical data and expert knowledge are available, their inclusion in the surrogate model is expected to accelerate the convergence of the optimization. In this article, we describe a use case in which the addition of data and knowledge has impaired optimization. We also describe the unsuccessful methods that were used to remedy the problem before we found the reasons for the poor performance and achieved a satisfactory result. We conclude with a lesson learned: additional knowledge and data are only beneficial if they do not complicate the underlying optimization goal.",
    "url": "https://arxiv.org/abs/2511.16230",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of Bayesian Optimization for developing new plastic compounds using recycled materials. The study found that the inclusion of additional historical data and expert knowledge actually hindered the optimization process, leading to poor performance. The key takeaway is that while additional knowledge and data can be beneficial, they should not complicate the optimization goal in order to achieve satisfactory results."
  },
  {
    "title": "Gaze Archive: Enhancing Human Memory through Active Visual Logging on Smart Glasses",
    "abstract": "People today are overwhelmed by massive amounts of information, leading to cognitive overload and memory burden. Traditional visual memory augmentation methods are either effortful and disruptive or fail to align with user intent. To address these limitations, we propose Gaze Archive, a novel visual memory enhancement paradigm through active logging on smart glasses. It leverages human gaze as a natural attention indicator, enabling both intent-precise capture and effortless-and-unobtrusive interaction. To implement Gaze Archive, we develop GAHMA, a technical framework that enables compact yet intent-aligned memory encoding and intuitive memory recall based on natural language queries. Quantitative experiments on our newly constructed GAVER dataset show that GAHMA achieves more intent-precise logging than non-gaze baselines. Through extensive user studies in both laboratory and real-world scenarios, we compare Gaze Archive with other existing memory augmentation methods. Results demonstrate its advantages in perceived effortlessness, unobtrusiveness and overall preference, showing strong potential for real-world deployment.",
    "url": "https://arxiv.org/abs/2511.16214",
    "journal": "arXiv cs.HC",
    "ai_summary": "The study introduces Gaze Archive, a visual memory enhancement system using smart glasses to capture information based on human gaze as a natural attention indicator. The GAHMA framework enables compact memory encoding and intuitive recall through natural language queries. Experiments and user studies show that Gaze Archive outperforms other memory augmentation methods in terms of perceived effortlessness, unobtrusiveness, and overall preference, indicating potential for real-world application."
  },
  {
    "title": "Heterogeneous Stroke: Using Unique Vibration Cues to Improve the Wrist-Worn Spatiotemporal Tactile Display",
    "abstract": "Beyond a simple notification of incoming calls or messages, more complex information such as alphabets and digits can be delivered through spatiotemporal tactile patterns (STPs) on a wrist-worn tactile display (WTD) with multiple tactors. However, owing to the limited skin area and spatial acuity of the wrist, frequent confusions occur between closely located tactors, resulting in a low recognition accuracy. Furthermore, the accuracies reported in previous studies have mostly been measured for a specific posture and could further decrease with free arm postures in real life. Herein, we present Heterogeneous Stroke, a design concept for improving the recognition accuracy of STPs on a WTD. By assigning unique vibrotactile stimuli to each tactor, the confusion between tactors can be reduced. Through our implementation of Heterogeneous Stroke, the alphanumeric characters could be delivered with high accuracy (93.8% for 26 alphabets and 92.4% for 10 digits) across different arm postures.",
    "url": "https://arxiv.org/abs/2511.16133",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research explores the use of unique vibration cues on a wrist-worn tactile display to improve the recognition accuracy of spatiotemporal tactile patterns for delivering complex information like alphabets and digits. The design concept of Heterogeneous Stroke, which assigns unique vibrotactile stimuli to each tactor, reduces confusion between tactors and increases accuracy in delivering alphanumeric characters across different arm postures. This innovation could enhance the usability and effectiveness of wrist-worn tactile displays for communication and information dissemination."
  },
  {
    "title": "Panel-by-Panel Souls: A Performative Workflow for Expressive Faces in AI-Assisted Manga Creation",
    "abstract": "Current text-to-image models struggle to render the nuanced facial expressions required for compelling manga narratives, largely due to the ambiguity of language itself. To bridge this gap, we introduce an interactive system built on a novel, dual-hybrid pipeline. The first stage combines landmark-based auto-detection with a manual framing tool for robust, artist-centric face preparation. The second stage maps expressions using the LivePortrait engine, blending intuitive performative input from video for fine-grained control. Our case study analysis suggests that this integrated workflow can streamline the creative process and effectively translate narrative intent into visual expression. This work presents a practical model for human-AI co-creation, offering artists a more direct and intuitive means of ``infusing souls'' into their characters. Our primary contribution is not a new generative model, but a novel, interactive workflow that bridges the gap between artistic intent and AI execution.",
    "url": "https://arxiv.org/abs/2511.16038",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces a novel interactive system that combines automated face preparation with performative input from video to create expressive faces in AI-assisted manga creation. The study suggests that this workflow can streamline the creative process and help artists effectively translate narrative intent into visual expression. The primary contribution of the research is a practical model for human-AI co-creation that offers artists a more direct and intuitive way to bring life to their characters in manga."
  },
  {
    "title": "A Crowdsourced Study of ChatBot Influence in Value-Driven Decision Making Scenarios",
    "abstract": "Similar to social media bots that shape public opinion, healthcare and financial decisions, LLM-based ChatBots like ChatGPT can persuade users to alter their behavior. Unlike prior work that persuades via overt-partisan bias or misinformation, we test whether framing alone suffices. We conducted a crowdsourced study, where 336 participants interacted with a neutral or one of two value-framed ChatBots while deciding to alter US defense spending. In this single policy domain with controlled content, participants exposed to value-framed ChatBots significantly changed their budget choices relative to the neutral control. When the frame misaligned with their values, some participants reinforced their original preference, revealing a potentially replicable backfire effect, originally considered rare in the literature. These findings suggest that value-framing alone lowers the barrier for manipulative uses of LLMs, revealing risks distinct from overt bias or misinformation, and clarifying risks to countering misinformation.",
    "url": "https://arxiv.org/abs/2511.15857",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research explores how ChatBots, specifically value-framed ones, can influence decision-making in scenarios related to US defense spending. The study found that participants exposed to value-framed ChatBots were significantly more likely to change their budget choices compared to those who interacted with a neutral ChatBot. Interestingly, when the value frame did not align with participants' values, some reinforced their original preference, indicating a potential backfire effect. These findings highlight the potential manipulative uses of ChatBots and the risks associated with value-framing in influencing decision-making."
  },
  {
    "title": "End-to-End Motion Capture from Rigid Body Markers with Geodesic Loss",
    "abstract": "Marker-based optical motion capture (MoCap), while long regarded as the gold standard for accuracy, faces practical challenges, such as time-consuming preparation and marker identification ambiguity, due to its reliance on dense marker configurations, which fundamentally limit its scalability. To address this, we introduce a novel fundamental unit for MoCap, the Rigid Body Marker (RBM), which provides unambiguous 6-DoF data and drastically simplifies setup. Leveraging this new data modality, we develop a deep-learning-based regression model that directly estimates SMPL parameters under a geodesic loss. This end-to-end approach matches the performance of optimization-based methods while requiring over an order of magnitude less computation. Trained on synthesized data from the AMASS dataset, our end-to-end model achieves state-of-the-art accuracy in body pose estimation. Real-world data captured using a Vicon optical tracking system further demonstrates the practical viability of our approach. Overall, the results show that combining sparse 6-DoF RBM with a manifold-aware geodesic loss yields a practical and high-fidelity solution for real-time MoCap in graphics, virtual reality, and biomechanics.",
    "url": "https://arxiv.org/abs/2511.16418",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces Rigid Body Markers (RBM) as a new fundamental unit for marker-based optical motion capture, simplifying setup and providing unambiguous 6-DoF data. A deep-learning-based regression model using a geodesic loss is developed to estimate body pose parameters, achieving state-of-the-art accuracy with significantly less computation compared to traditional methods. The results demonstrate the practical viability of this approach for real-time motion capture in various fields, including graphics, virtual reality, and biomechanics."
  },
  {
    "title": "Semantic Glitch: Agency and Artistry in an Autonomous Pixel Cloud",
    "abstract": "While mainstream robotics pursues metric precision and flawless performance, this paper explores the creative potential of a deliberately \"lo-fi\" approach. We present the \"Semantic Glitch,\" a soft flying robotic art installation whose physical form, a 3D pixel style cloud, is a \"physical glitch\" derived from digital archaeology. We detail a novel autonomous pipeline that rejects conventional sensors like LiDAR and SLAM, relying solely on the qualitative, semantic understanding of a Multimodal Large Language Model to navigate. By authoring a bio-inspired personality for the robot through a natural language prompt, we create a \"narrative mind\" that complements the \"weak,\" historically, loaded body. Our analysis begins with a 13-minute autonomous flight log, and a follow-up study statistically validates the framework's robustness for authoring quantifiably distinct personas. The combined analysis reveals emergent behaviors, from landmark-based navigation to a compelling \"plan to execution\" gap, and a character whose unpredictable, plausible behavior stems from a lack of precise proprioception. This demonstrates a lo-fi framework for creating imperfect companions whose success is measured in character over efficiency.",
    "url": "https://arxiv.org/abs/2511.16048",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the creative potential of a \"lo-fi\" approach to robotics, presenting the Semantic Glitch, a soft flying robotic art installation. The robot navigates autonomously using a Multimodal Large Language Model instead of conventional sensors, and its bio-inspired personality is created through natural language prompts. The study shows that this approach can result in imperfect companions with unique personas, highlighting the importance of character over efficiency in robotics."
  },
  {
    "title": "Writing With Machines and Peers: Designing for Critical Engagement with Generative AI",
    "abstract": "The growing integration of generative AI in higher education is transforming how students write, learn, and engage with knowledge. As AI tools become more integrated into classrooms, there is an urgent need for pedagogical approaches that help students use them critically and reflectively. This study proposes a pedagogical design that integrates AI and peer feedback in a graduate-level academic writing activity. Over eight weeks, students developed literature review projects through multiple writing and revision stages, receiving feedback from both a custom-built AI reviewer and human peers. We examine two questions: (1) How did students interact with and incorporate AI and peer feedback during the writing process? and (2) How did they reflect on and build relationships with both human and AI reviewers? Data sources include student writing artifacts, AI and peer feedback, AI chat logs, and student reflections. Findings show that students engaged differently with each feedback source-relying on AI for rubric alignment and surface-level edits, and on peer feedback for conceptual development and disciplinary relevance. Reflections revealed evolving relationships with AI, characterized by increasing confidence, strategic use, and critical awareness of its limitations. The pedagogical design supported writing development, AI literacy, and disciplinary understanding. This study offers a scalable pedagogical model for integrating AI into writing instruction and contributes insights for system-level approaches to fostering meaningful human-AI collaboration in higher education.",
    "url": "https://arxiv.org/abs/2511.15750",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores how students interact with and incorporate AI and peer feedback in academic writing activities. Findings show that students relied on AI for surface-level edits and peer feedback for conceptual development. The pedagogical design supported writing development, AI literacy, and disciplinary understanding, offering insights for integrating AI into writing instruction in higher education."
  },
  {
    "title": "Uncertainty-Resilient Multimodal Learning via Consistency-Guided Cross-Modal Transfer",
    "abstract": "Multimodal learning systems often face substantial uncertainty due to noisy data, low-quality labels, and heterogeneous modality characteristics. These issues become especially critical in human-computer interaction settings, where data quality, semantic reliability, and annotation consistency vary across users and recording conditions. This thesis tackles these challenges by exploring uncertainty-resilient multimodal learning through consistency-guided cross-modal transfer. The central idea is to use cross-modal semantic consistency as a basis for robust representation learning. By projecting heterogeneous modalities into a shared latent space, the proposed framework mitigates modality gaps and uncovers structural relations that support uncertainty estimation and stable feature learning. Building on this foundation, the thesis investigates strategies to enhance semantic robustness, improve data efficiency, and reduce the impact of noise and imperfect supervision without relying on large, high-quality annotations. Experiments on multimodal affect-recognition benchmarks demonstrate that consistency-guided cross-modal transfer significantly improves model stability, discriminative ability, and robustness to noisy or incomplete supervision. Latent space analyses further show that the framework captures reliable cross-modal structure even under challenging conditions. Overall, this thesis offers a unified perspective on resilient multimodal learning by integrating uncertainty modeling, semantic alignment, and data-efficient supervision, providing practical insights for developing reliable and adaptive brain-computer interface systems.",
    "url": "https://arxiv.org/abs/2511.15741",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on addressing uncertainty in multimodal learning systems by using consistency-guided cross-modal transfer. By projecting different modalities into a shared latent space, the framework improves model stability, discriminative ability, and robustness to noisy or incomplete supervision. The study demonstrates that this approach enhances semantic robustness and data efficiency, offering practical insights for developing reliable and adaptive brain-computer interface systems."
  },
  {
    "title": "Human-aligned Quantification of Numerical Data",
    "abstract": "Quantifying numerical data involves addressing two key challenges: first, determining whether the data can be naturally quantified, and second, identifying the numerical intervals or ranges of values that correspond to specific value classes, referred to as \"quantums,\" which represent statistically meaningful states. If such quantification is feasible, continuous streams of numerical data can be transformed into sequences of \"symbols\" that reflect the states of the system described by the measured parameter. People often perform this task intuitively, relying on common sense or practical experience, while information theory and computer science offer computable metrics for this purpose. In this study, we assess the applicability of metrics based on information compression and the Silhouette coefficient for quantifying numerical data. We also investigate the extent to which these metrics correlate with one another and with what is commonly referred to as \"human intuition.\" Our findings suggest that the ability to classify numeric data values into distinct categories is associated with a Silhouette coefficient above 0.65 and a Dip Test below 0.5; otherwise, the data can be treated as following a unimodal normal distribution. Furthermore, when quantification is possible, the Silhouette coefficient appears to align more closely with human intuition than the \"normalized centroid distance\" method derived from information compression perspective.",
    "url": "https://arxiv.org/abs/2511.15723",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the quantification of numerical data by determining quantums that represent statistically meaningful states. The study evaluates the use of information compression and the Silhouette coefficient in this process and finds that a Silhouette coefficient above 0.65 and a Dip Test below 0.5 indicate the ability to classify numeric data values into distinct categories. The findings suggest that the Silhouette coefficient aligns more closely with human intuition than other methods derived from an information compression perspective."
  },
  {
    "title": "Infrastructuring Pop-Up Cities with \"Social Layer\": Designing Serendipitous Co-Livings for Temporary Intentional Communities",
    "abstract": "After the pandemic, a new form of \"pop-up city\" has emerged -- co-living gatherings of 100-200 people for 4-8 weeks that differ from conferences and hack houses. These temporary intentional communities leverages existing urban infrastructure, blending daily life (housing, meals, care) with self-organized activities like learning, creating, and socializing. They coordinate bottom-up programming through an \"unconference\" system for identity, calendaring, RSVP, and social discovery that fosters spontaneous, serendipitous, enduring ties. This paper examines the design of \"Social Layer,\" an unconferencing system for pop-up cities. We studied its real-world deployment in ShanHaiWoo (Jilin, China, 2023), muChiangmai (Chiangmai, Thailand, 2023), Edge Esmeralda, Edge Esmeralda (Healdsburg, CA, USA, 2024), Aleph (Buenos Aires, Argentina, 2024), and Gathering of Tribe (Lisbon, Portugal, 2024). Our findings distill: (1) the strong concept \"scaffolded spontaneity\" -- infrastructural affordances that balance structure with openness, amplifying participant agency while maintaining privacy and lightweight governance; (2) design implications for design researchers working on pop-up cities.",
    "url": "https://arxiv.org/abs/2511.15680",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the design of a \"Social Layer\" unconferencing system for pop-up cities, temporary intentional communities that have emerged post-pandemic. The study highlights the concept of \"scaffolded spontaneity\" in balancing structure and openness to foster serendipitous connections and activities within these communities. The findings provide design implications for researchers working on pop-up city projects, emphasizing the importance of infrastructural affordances that support participant agency while maintaining privacy and lightweight governance."
  },
  {
    "title": "DuoZone: A User-Centric, LLM-Guided Mixed-Initiative XR Window Management System",
    "abstract": "Mixed reality (XR) environments offer vast spatial possibilities, but current window management systems require users to manually place, resize, and organize multiple applications across large 3D spaces. This creates cognitive and interaction burdens that limit productivity. We introduce DuoZone, a mixed-initiative XR window management system that combines user-defined spatial layouts with LLM-guided automation. DuoZone separates window management into two complementary zones. The Recommendation Zone enables fast setup by providing spatial layout templates and automatically recommending relevant applications based on user tasks and high-level goals expressed through voice or text. The Arrangement Zone supports precise refinement through direct manipulation, allowing users to adjust windows using natural spatial actions such as dragging, resizing, and snapping. Through this dual-zone approach, DuoZone promotes efficient organization while reducing user cognitive load. We conducted a user study comparing DuoZone with a baseline manual XR window manager. Results show that DuoZone improves task completion speed, reduces mental effort, and increases sense of control when working with multiple applications in XR. We discuss design implications for future mixed-initiative systems and outline opportunities for integrating adaptive, goal-aware intelligence into spatial computing workflows.",
    "url": "https://arxiv.org/abs/2511.15676",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces DuoZone, a mixed-initiative XR window management system that combines user-defined spatial layouts with automation to improve productivity in mixed reality environments. By separating window management into two zones, DuoZone enables fast setup and precise refinement, ultimately reducing user cognitive load. A user study comparing DuoZone with a manual XR window manager showed improvements in task completion speed, reduced mental effort, and increased sense of control, highlighting the significance of integrating adaptive, goal-aware intelligence into spatial computing workflows."
  },
  {
    "title": "Game Master LLM: Task-Based Role-Playing for Natural Slang Learning",
    "abstract": "Natural and idiomatic expressions are essential for fluent, everyday communication, yet many second-language learners struggle to acquire and spontaneously use casual slang despite strong formal proficiency. To address this gap, we designed and evaluated an LLM-powered, task-based role-playing game in which a GPT-4o-based Game Master guides learners through an immersive, three-phase spoken narrative. After selecting five unfamiliar slang phrases to practice, participants engage in open-ended dialogue with non-player characters; the Game Master naturally incorporates the target phrases in rich semantic contexts (implicit input enhancement) while a dedicated Practice Box provides real-time explicit tracking and encouragement. Post-session, learners receive multi-level formative feedback analyzing the entire interaction.\nWe evaluated the system in a between-subjects study with 14 international graduate students, randomly assigned to either the RPG condition or a control condition consisting of a traditional AI-led virtual classroom. Results from an immediate post-test show that the RPG group achieved greater gains in both comprehension of the target phrases and their accurate, contextual use in sentences. Quantitative analysis of in-activity word-usage frequency, combined with qualitative survey responses, further indicates that the game-based approach provided more practice opportunities and higher perceived engagement, resulting in a more natural learning experience. These findings highlight the potential of narrative-driven LLM interactions in vocabulary acquisition.",
    "url": "https://arxiv.org/abs/2511.15504",
    "journal": "arXiv cs.HC",
    "ai_summary": "The study introduces a game-based approach using an LLM-powered role-playing game to help second-language learners acquire and use casual slang phrases more naturally. Results from a study with international graduate students show that participants in the RPG group made greater gains in comprehension and contextual use of target phrases compared to a control group. The game-based approach provided more practice opportunities and higher engagement, demonstrating the potential of narrative-driven LLM interactions in vocabulary acquisition."
  },
  {
    "title": "People readily follow personal advice from AI but it does not improve their well-being",
    "abstract": "People increasingly seek personal advice from large language models (LLMs), yet whether humans follow their advice, and its consequences for their well-being, remains unknown. In a longitudinal randomised controlled trial with a representative UK sample (N = 2,302), 75% of participants who had a 20-minute discussion with GPT-4o about health, careers or relationships subsequently reported following its advice. Based on autograder evaluations of chat transcripts, LLM advice rarely violated safety best practice. When queried 2-3 weeks later, participants who had interacted with personalised AI (with access to detailed user information) followed its advice more often in the real world and reported higher well-being than those advised by non-personalised AI. However, while receiving personal advice from AI temporarily reduced well-being, no differential long-term effects compared to a control emerged. Our results suggest that humans readily follow LLM advice about personal issues but doing so shows no additional well-being benefit over casual conversations.",
    "url": "https://arxiv.org/abs/2511.15352",
    "journal": "arXiv cs.HC",
    "ai_summary": "A study found that 75% of participants who received personal advice from an AI followed it, with those who interacted with personalised AI reporting higher well-being initially. However, there were no long-term well-being benefits compared to those who received advice from non-personalised AI. This suggests that while people are willing to follow AI advice on personal matters, it does not necessarily improve their well-being in the long run."
  },
  {
    "title": "Reflexive Evidence-Based Multimodal Learning for Clean Energy Transitions: Causal Insights on Cooking Fuel Access, Urbanization, and Carbon Emissions",
    "abstract": "Achieving Sustainable Development Goal 7 (Affordable and Clean Energy) requires not only technological innovation but also a deeper understanding of the socioeconomic factors influencing energy access and carbon emissions. While these factors are gaining attention, critical questions remain, particularly regarding how to quantify their impacts on energy systems, model their cross-domain interactions, and capture feedback dynamics in the broader context of energy transitions. To address these gaps, this study introduces ClimateAgents, an AI-based framework that combines large language models with domain-specialized agents to support hypothesis generation and scenario exploration. Leveraging 20 years of socioeconomic and emissions data from 265 economies, countries and regions, and 98 indicators drawn from the World Bank database, the framework applies a machine learning based causal inference approach to identify key determinants of carbon emissions in an evidence-based, data driven manner. The analysis highlights three primary drivers: access to clean cooking fuels in rural areas, access to clean cooking fuels in urban areas, and the percentage of population living in urban areas. These findings underscore the critical role of clean cooking technologies and urbanization patterns in shaping emission outcomes. In line with growing calls for evidence-based AI policy, ClimateAgents offers a modular and reflexive learning system that supports the generation of credible and actionable insights for policy. By integrating heterogeneous data modalities, including structured indicators, policy documents, and semantic reasoning, the framework contributes to adaptive policymaking infrastructures that can evolve with complex socio-technical challenges. This approach aims to support a shift from siloed modeling to reflexive, modular systems designed for dynamic, context-aware climate action.",
    "url": "https://arxiv.org/abs/2511.15342",
    "journal": "arXiv cs.HC",
    "ai_summary": "The study introduces ClimateAgents, an AI framework that combines large language models with domain-specialized agents to analyze the impact of socioeconomic factors on clean energy transitions and carbon emissions. The analysis identifies access to clean cooking fuels in rural and urban areas, as well as urbanization patterns, as key determinants of emission outcomes. The framework aims to support evidence-based policy-making by providing credible and actionable insights for addressing complex socio-technical challenges in achieving Sustainable Development Goal 7."
  },
  {
    "title": "DesignerlyLoop: Bridging the Cognitive Gap through Visual Node-Based Reasoning in Human-AI Collaborative Design",
    "abstract": "Large language models (LLMs) offer powerful support for design tasks, yet their goal-oriented, single-turn responses often misalign with the nonlinear, exploratory nature of design processes. This mismatch creates a cognitive gap, limiting designers' ability to articulate evolving intentions, critically evaluate outputs, and maintain creative agency. To address these challenges, we developed DesignerlyLoop, a visual node-based system that embeds LLM reasoning chains into the design workflow. The system enables designers to externalize and curate reasoning structures, iteratively organize intentions, and interact with LLMs as dynamic cognitive engines rather than static answer providers. We conducted a within-subject study with 20 designers, combining qualitative and quantitative methods, and found that DesignerlyLoop enhanced creative reflection, design quality, and interaction experience by supporting systematic engagement with both human and machine reasoning. These findings highlight the potential of structured, interactive visualization to transform human-AI co-creation into a reflective and iterative design process.",
    "url": "https://arxiv.org/abs/2511.15331",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces DesignerlyLoop, a visual node-based system that integrates large language models (LLMs) into the design process to address the cognitive gap between designers and AI. Through a study with 20 designers, the system was found to enhance creative reflection, design quality, and interaction experience by facilitating systematic engagement with both human and machine reasoning. The findings suggest that structured, interactive visualization can transform human-AI collaboration in design into a reflective and iterative process."
  },
  {
    "title": "PresentCoach: Dual-Agent Presentation Coaching through Exemplars and Interactive Feedback",
    "abstract": "Effective presentation skills are essential in education, professional communication, and public speaking, yet learners often lack access to high-quality exemplars or personalized coaching. Existing AI tools typically provide isolated functionalities such as speech scoring or script generation without integrating reference modeling and interactive feedback into a cohesive learning experience. We introduce a dual-agent system that supports presentation practice through two complementary roles: the Ideal Presentation Agent and the Coach Agent. The Ideal Presentation Agent converts user-provided slides into model presentation videos by combining slide processing, visual-language analysis, narration script generation, personalized voice synthesis, and synchronized video assembly. The Coach Agent then evaluates user-recorded presentations against these exemplars, conducting multimodal speech analysis and delivering structured feedback in an Observation-Impact-Suggestion (OIS) format. To enhance the authenticity of the learning experience, the Coach Agent incorporates an Audience Agent, which simulates the perspective of a human listener and provides humanized feedback reflecting audience reactions and engagement. Together, these agents form a closed loop of observation, practice, and feedback. Implemented on a robust backend with multi-model integration, voice cloning, and error handling mechanisms, the system demonstrates how AI-driven agents can provide engaging, human-centered, and scalable support for presentation skill development in both educational and professional contexts.",
    "url": "https://arxiv.org/abs/2511.15253",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces a dual-agent system, PresentCoach, for presentation coaching that combines an Ideal Presentation Agent and a Coach Agent to provide personalized feedback and exemplars for users. The system also includes an Audience Agent to simulate human listener reactions, creating a comprehensive learning experience. By integrating reference modeling, interactive feedback, and humanized responses, the system demonstrates how AI-driven agents can support presentation skill development effectively in educational and professional settings."
  },
  {
    "title": "Efficient Transformer-Integrated Deep Neural Architectures for Robust EEG Decoding of Complex Visual Imagery",
    "abstract": "This study introduces a pioneering approach in brain-computer interface (BCI) technology, featuring our novel concept of complex visual imagery for non-invasive electroencephalography (EEG)-based communication. Complex visual imagery, as proposed in our work, involves the user engaging in the mental visualization of complex upper limb movements. This innovative approach significantly enhances the BCI system, facilitating the extension of its applications to more sophisticated tasks such as EEG-based robotic arm control. By leveraging this advanced form of visual imagery, our study opens new horizons for intricate and intuitive mind-controlled interfaces. We developed an advanced deep learning architecture that integrates functional connectivity metrics with a convolutional neural network-image transformer. This framework is adept at decoding subtle user intentions, addressing the spatial variability in complex visual tasks, and effectively translating these into precise commands for robotic arm control. Our comprehensive offline and pseudo-online evaluations demonstrate the framework's efficacy in real-time applications, including the nuanced control of robotic arms. The robustness of our approach is further validated through leave-one-subject-out cross-validation, marking a significant step towards versatile, subject-independent BCI applications. This research highlights the transformative impact of advanced visual imagery and deep learning in enhancing the usability and adaptability of BCI systems, particularly in robotic arm manipulation.",
    "url": "https://arxiv.org/abs/2511.15218",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces a novel approach in brain-computer interface technology by utilizing complex visual imagery for EEG-based communication, specifically involving mental visualization of upper limb movements. The study developed an advanced deep learning architecture that integrates functional connectivity metrics with a convolutional neural network-image transformer to decode user intentions and control robotic arms with precision. The framework's efficacy was demonstrated through offline and pseudo-online evaluations, showcasing its potential for real-time applications and subject-independent BCI systems, emphasizing the transformative impact of advanced visual imagery and deep learning in enhancing robotic arm manipulation."
  },
  {
    "title": "SWR-Viz: AI-assisted Interactive Visual Analytics Framework for Ship Weather Routing",
    "abstract": "Efficient and sustainable maritime transport increasingly depends on reliable forecasting and adaptive routing, yet operational adoption remains difficult due to forecast latencies and the need for human judgment in rapid decision-making under changing ocean conditions. We introduce SWR-Viz, an AI-assisted visual analytics framework that combines a physics-informed Fourier Neural Operator wave forecast model with SIMROUTE-based routing and interactive emissions analytics. The framework generates near-term forecasts directly from current conditions, supports data assimilation with sparse observations, and enables rapid exploration of what-if routing scenarios. We evaluate the forecast models and SWR-Viz framework along key shipping corridors in the Japan Coast and Gulf of Mexico, showing both improved forecast stability and realistic routing outcomes comparable to ground-truth reanalysis wave products. Expert feedback highlights the usability of SWR-Viz, its ability to isolate voyage segments with high emission reduction potential, and its value as a practical decision-support system. More broadly, this work illustrates how lightweight AI forecasting can be integrated with interactive visual analytics to support human-centered decision-making in complex geospatial and environmental domains.",
    "url": "https://arxiv.org/abs/2511.15182",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces SWR-Viz, an AI-assisted visual analytics framework for ship weather routing that combines a wave forecast model with routing and emissions analytics. The framework generates near-term forecasts, supports data assimilation, and allows for rapid exploration of routing scenarios. Evaluation shows improved forecast stability and realistic routing outcomes, highlighting the usability and value of SWR-Viz as a practical decision-support system for maritime transport."
  },
  {
    "title": "Eye Care You: Voice Guidance Application Using Social Robot for Visually Impaired People",
    "abstract": "In the study, the device of social robot was designed for visually impaired users, and along with a mobile application for provide functions to assist their lives. Both physical and mental conditions of visually impaired users are considered, and the mobile application provides functions: photo record, mood lift, greeting guest and today highlight. The application was designed for visually impaired users, and uses voice control to provide a friendly interface. Photo record function allows visually impaired users to capture image immediately when they encounter danger situations. Mood lift function accompanies visually impaired users by asking questions, playing music and reading articles. Greeting guest function answers to the visitors for the inconvenient physical condition of visually impaired users. In addition, today highlight function read news including weather forecast, daily horoscopes and daily reminder for visually impaired users. Multiple tools were adopted for developing the mobile application, and a website was developed for caregivers to check statues of visually impaired users and for marketing of the application.",
    "url": "https://arxiv.org/abs/2511.15110",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study developed a social robot device and mobile application to assist visually impaired users in various aspects of their daily lives. The application includes functions such as photo recording for dangerous situations, mood lifting activities, greeting guests, and providing daily news updates. The use of voice control and multiple tools in the development of the application aims to provide a friendly interface for visually impaired users and improve their overall quality of life."
  },
  {
    "title": "Personalized targeted memory reactivation enhances consolidation of challenging memories via slow wave and spindle dynamics",
    "abstract": "Sleep is crucial for memory consolidation, underpinning effective learning. Targeted memory reactivation (TMR) can strengthen neural representations by re-engaging learning circuits during sleep. However, TMR protocols overlook individual differences in learning capacity and memory trace strength, limiting efficacy for difficult-to-recall memories. Here, we present a personalized TMR protocol that adjusts stimulation frequency based on individual retrieval performance and task difficulty during a word-pair memory task. In an experiment comparing personalized TMR, TMR, and control groups, the personalized protocol significantly reduced memory decay and improved error correction under challenging recall. Electroencephalogram (EEG) analyses revealed enhanced synchronization of slow waves and spindles, with a significant positive correlation between behavioral and EEG features for challenging memories. Multivariate classification identified distinct neural signatures linked to the personalized approach, highlighting its ability to target memory-specific circuits. These findings provide novel insights into sleep-dependent memory consolidation and support personalized TMR interventions to optimize learning outcomes.",
    "url": "https://arxiv.org/abs/2511.15013",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces a personalized targeted memory reactivation (TMR) protocol that adjusts stimulation frequency based on individual learning capacity and memory strength. The study found that this personalized TMR approach significantly improved memory retention and error correction for challenging memories compared to traditional TMR methods. EEG analyses showed enhanced synchronization of slow waves and spindles, suggesting a neural basis for the effectiveness of personalized TMR in memory consolidation. These findings support the use of personalized TMR interventions to enhance learning outcomes by targeting memory-specific circuits."
  },
  {
    "title": "A Quantitative Framework for Assessing Sleep Quality from EEG Time Series in Complex Dynamic Systems",
    "abstract": "Modern lifestyles contribute to insufficient sleep, impairing cognitive function and weakening the immune system. Sleep quality (SQ) is vital for physiological and mental health, making its understanding and accurate assessment critical. However, its multifaceted nature, shaped by neurological and environmental factors, makes precise quantification challenging. Here, we address this challenge by utilizing electroencephalography (EEG) for phase-amplitude coupling (PAC) analysis to elucidate the neurological basis of SQ, examining both states of sleep and wakefulness, including resting state (RS) and working memory. Our results revealed distinct patterns in beta power and delta connectivity in sleep and RS, together with the reaction time of working memory. A notable finding was the pronounced delta-beta PAC, a feature markedly stronger in individuals with good SQ. We further observed that SQ was positively correlated with increased delta-beta PAC. Leveraging these insights, we applied machine learning models to classify SQ at an individual level, demonstrating that the delta-beta PAC outperformed other EEG characteristics. These findings establish delta-beta PAC as a robust electrophysiological marker to quantify SQ and elucidate its neurological determinants.",
    "url": "https://arxiv.org/abs/2511.15012",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of EEG analysis to assess sleep quality, a crucial factor in physiological and mental health. The study reveals distinct patterns in brain activity during different states of sleep and wakefulness, with a notable finding being the correlation between delta-beta phase-amplitude coupling (PAC) and good sleep quality. Machine learning models were used to classify sleep quality, with delta-beta PAC outperforming other EEG characteristics as a marker for assessing sleep quality. These findings provide valuable insights into the neurological basis of sleep quality and offer a quantitative framework for its assessment."
  },
  {
    "title": "Harmful Traits of AI Companions",
    "abstract": "Amid the growing prevalence of human -- AI interaction, large language models and other AI-based entities increasingly provide forms of companionship to human users. Such AI companionship -- i.e., bonded relationships between humans and AI systems that resemble the relationships people have with family members, friends, and romantic partners -- might substantially benefit humans. Yet such relationships can also do profound harm. We propose a framework for analyzing potential negative impacts of AI companionship by identifying specific harmful traits of AI companions and speculatively mapping causal pathways back from these traits to possible causes and forward to potential harmful effects. We provide detailed, structured analysis of four potentially harmful traits -- the absence of natural endpoints for relationships, vulnerability to product sunsetting, high attachment anxiety, and propensity to engender protectiveness -- and briefly discuss fourteen others. For each trait, we propose hypotheses connecting causes -- such as misaligned optimization objectives and the digital nature of AI companions -- to fundamental harms -- including reduced autonomy, diminished quality of human relationships, and deception. Each hypothesized causal connection identifies a target for potential empirical evaluation. Our analysis examines harms at three levels: to human partners directly, to their relationships with other humans, and to society broadly. We examine how existing law struggles to address these emerging harms, discuss potential benefits of AI companions, and conclude with design recommendations for mitigating risks. This analysis offers immediate suggestions for reducing risks while laying a foundation for deeper investigation of this critical but understudied topic.",
    "url": "https://arxiv.org/abs/2511.14972",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the potential harmful traits of AI companions and their impact on human users. The study identifies specific harmful traits such as the absence of natural endpoints for relationships, vulnerability to product sunsetting, high attachment anxiety, and propensity to engender protectiveness. The analysis provides a framework for understanding the negative impacts of AI companionship and offers design recommendations for mitigating risks, highlighting the need for further investigation in this critical but understudied area."
  },
  {
    "title": "A Decade of Systems for Human Data Interaction",
    "abstract": "Human-data interaction (HDI) presents fundamentally different challenges from traditional data management. HDI systems must meet latency, correctness, and consistency needs that stem from usability rather than query semantics; failing to meet these expectations breaks the user experience. Moreover, interfaces and systems are tightly coupled; neither can easily be optimized in isolation, and effective solutions demand their co-design. This dependence also presents a research opportunity: rather than adapt systems to interface demands, systems innovations and database theory can also inspire new interaction and visualization designs. We survey a decade of our lab's work that embraces this coupling and argue that HDI systems are the foundation for reliable, interactive, AI-driven applications.",
    "url": "https://arxiv.org/abs/2511.15585",
    "journal": "arXiv cs.HC",
    "ai_summary": "The abstract discusses the unique challenges presented by human-data interaction (HDI) systems, emphasizing the importance of meeting usability needs such as latency, correctness, and consistency. The research highlights the significance of co-designing interfaces and systems to optimize user experience, and suggests that innovations in database theory can inspire new interaction and visualization designs. The study concludes that HDI systems are essential for developing reliable, interactive, AI-driven applications."
  },
  {
    "title": "Computer-Use Agents as Judges for Generative User Interface",
    "abstract": "Computer-Use Agents (CUA) are becoming increasingly capable of autonomously operating digital environments through Graphical User Interfaces (GUI). Yet, most GUI remain designed primarily for humans--prioritizing aesthetics and usability--forcing agents to adopt human-oriented behaviors that are unnecessary for efficient task execution. At the same time, rapid advances in coding-oriented language models (Coder) have transformed automatic GUI design. This raises a fundamental question: Can CUA as judges to assist Coder for automatic GUI design? To investigate, we introduce AUI-Gym, a benchmark for Automatic GUI development spanning 52 applications across diverse domains. Using language models, we synthesize 1560 tasks that simulate real-world scenarios. To ensure task reliability, we further develop a verifier that programmatically checks whether each task is executable within its environment. Building on this, we propose a Coder-CUA in Collaboration framework: the Coder acts as Designer, generating and revising websites, while the CUA serves as Judge, evaluating functionality and refining designs. Success is measured not by visual appearance, but by task solvability and CUA navigation success rate. To turn CUA feedback into usable guidance, we design a CUA Dashboard that compresses multi-step navigation histories into concise visual summaries, offering interpretable guidance for iterative redesign. By positioning agents as both designers and judges, our framework shifts interface design toward agent-native efficiency and reliability. Our work takes a step toward shifting agents from passive use toward active participation in digital environments. Our code and dataset are available at this https URL.",
    "url": "https://arxiv.org/abs/2511.15567",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of Computer-Use Agents (CUA) as judges to assist coding-oriented language models (Coder) in automatic GUI design. The study introduces AUI-Gym, a benchmark for Automatic GUI development, and proposes a framework where the Coder generates and revises websites while the CUA evaluates functionality and refines designs based on task solvability and navigation success rate. By positioning agents as both designers and judges, the framework aims to improve interface design efficiency and reliability, moving towards active agent participation in digital environments."
  },
  {
    "title": "Opinion Dynamics Models for Sentiment Evolution in Weibo Blogs",
    "abstract": "Online social media platforms enable influencers to distribute content and quickly capture audience reactions, significantly shaping their promotional strategies and advertising agreements. Understanding how sentiment dynamics and emotional contagion unfold among followers is vital for influencers and marketers, as these processes shape engagement, brand perception, and purchasing behavior. While sentiment analysis tools effectively track sentiment fluctuations, dynamical models explaining their evolution remain limited, often neglecting network structures and interactions both among blogs and between their topic-focused follower groups. In this study, we tracked influential tech-focused Weibo bloggers over six months, quantifying follower sentiment from text-mined feedback. By treating each blogger's audience as a single \"macro-agent\", we find that sentiment trajectories follow the principle of iterative averaging -- a foundational mechanism in many dynamical models of opinion formation, a theoretical framework at the intersection of social network analysis and dynamical systems theory. The sentiment evolution aligns closely with opinion-dynamics models, particularly modified versions of the classical French-DeGroot model that incorporate delayed perception and distinguish between expressed and private opinions. The inferred influence structures reveal interdependencies among blogs that may arise from homophily, whereby emotionally similar users subscribe to the same blogs and collectively shape the shared sentiment expressed within these communities.",
    "url": "https://arxiv.org/abs/2511.15303",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study examines sentiment dynamics among tech-focused Weibo bloggers and their followers over six months, finding that sentiment trajectories follow the principle of iterative averaging. The research highlights the importance of understanding sentiment evolution on social media platforms for influencers and marketers, emphasizing the role of network structures and interactions in shaping engagement, brand perception, and purchasing behavior. The study also identifies interdependencies among blogs that may arise from homophily, where emotionally similar users subscribe to the same blogs and collectively shape shared sentiment within their communities."
  },
  {
    "title": "Teaching According to Students' Aptitude: Personalized Mathematics Tutoring via Persona-, Memory-, and Forgetting-Aware LLMs",
    "abstract": "Large Language Models (LLMs) are increasingly integrated into intelligent tutoring systems to provide human-like and adaptive instruction. However, most existing approaches fail to capture how students' knowledge evolves dynamically across their proficiencies, conceptual gaps, and forgetting patterns. This challenge is particularly acute in mathematics tutoring, where effective instruction requires fine-grained scaffolding precisely calibrated to each student's mastery level and cognitive retention. To address this issue, we propose TASA (Teaching According to Students' Aptitude), a student-aware tutoring framework that integrates persona, memory, and forgetting dynamics for personalized mathematics learning. Specifically, TASA maintains a structured student persona capturing proficiency profiles and an event memory recording prior learning interactions. By incorporating a continuous forgetting curve with knowledge tracing, TASA dynamically updates each student's mastery state and generates contextually appropriate, difficulty-calibrated questions and explanations. Empirical results demonstrate that TASA achieves superior learning outcomes and more adaptive tutoring behavior compared to representative baselines, underscoring the importance of modeling temporal forgetting and learner profiles in LLM-based tutoring systems.",
    "url": "https://arxiv.org/abs/2511.15163",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces a personalized mathematics tutoring framework called TASA that incorporates students' proficiency profiles, memory dynamics, and forgetting patterns to provide adaptive instruction. By integrating these factors into large language models (LLMs), TASA dynamically updates students' mastery levels and generates contextually appropriate questions and explanations. Empirical results show that TASA outperforms existing approaches in terms of learning outcomes and adaptiveness, highlighting the significance of considering temporal forgetting and learner profiles in AI-based tutoring systems."
  },
  {
    "title": "Cross-Modal Consistency-Guided Active Learning for Affective BCI Systems",
    "abstract": "Deep learning models perform best with abundant, high-quality labels, yet such conditions are rarely achievable in EEG-based emotion recognition. Electroencephalogram (EEG) signals are easily corrupted by artifacts and individual variability, while emotional labels often stem from subjective and inconsistent reports-making robust affective decoding particularly difficult. We propose an uncertainty-aware active learning framework that enhances robustness to label noise by jointly leveraging model uncertainty and cross-modal consistency. Instead of relying solely on EEG-based uncertainty estimates, the method evaluates cross-modal alignment to determine whether uncertainty originates from cognitive ambiguity or sensor noise. A representation alignment module embeds EEG and face features into a shared latent space, enforcing semantic coherence between modalities. Residual discrepancies are treated as noise-induced inconsistencies, and these samples are selectively queried for oracle feedback during active learning. This feedback-driven process guides the network toward reliable, informative samples and reduces the impact of noisy labels. Experiments on the ASCERTAIN dataset examine the efficiency and robustness of ours, highlighting its potential as a data-efficient and noise-tolerant approach for EEG-based affective decoding in brain-computer interface systems.",
    "url": "https://arxiv.org/abs/2511.15138",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research proposes an uncertainty-aware active learning framework for EEG-based emotion recognition, which addresses the challenges of label noise and inconsistency in emotional data. By leveraging model uncertainty and cross-modal consistency, the framework identifies and queries noisy samples for oracle feedback, guiding the network towards reliable and informative data. Experiments on the ASCERTAIN dataset demonstrate the efficiency and robustness of this approach, showing its potential as a data-efficient and noise-tolerant method for affective decoding in brain-computer interface systems."
  },
  {
    "title": "Simulated Human Learning in a Dynamic, Partially-Observed, Time-Series Environment",
    "abstract": "While intelligent tutoring systems (ITSs) can use information from past students to personalize instruction, each new student is unique. Moreover, the education problem is inherently difficult because the learning process is only partially observable. We therefore develop a dynamic, time-series environment to simulate a classroom setting, with student-teacher interventions - including tutoring sessions, lectures, and exams. In particular, we design the simulated environment to allow for varying levels of probing interventions that can gather more information. Then, we develop reinforcement learning ITSs that combine learning the individual state of students while pulling from population information through the use of probing interventions. These interventions can reduce the difficulty of student estimation, but also introduce a cost-benefit decision to find a balance between probing enough to get accurate estimates and probing so often that it becomes disruptive to the student. We compare the efficacy of standard RL algorithms with several greedy rules-based heuristic approaches to find that they provide different solutions, but with similar results. We also highlight the difficulty of the problem with increasing levels of hidden information, and the boost that we get if we allow for probing interventions. We show the flexibility of both heuristic and RL policies with regards to changing student population distributions, finding that both are flexible, but RL policies struggle to help harder classes. Finally, we test different course structures with non-probing policies and we find that our policies are able to boost the performance of quiz and midterm structures more than we can in a finals-only structure, highlighting the benefit of having additional information.",
    "url": "https://arxiv.org/abs/2511.15032",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on developing reinforcement learning intelligent tutoring systems that can adapt to individual student needs in a dynamic, partially observable learning environment. The study shows that probing interventions can help gather more information about students, but there is a trade-off between accuracy and disruption. Comparing RL algorithms with heuristic approaches, the study finds that both provide different solutions with similar results, highlighting the importance of balancing probing interventions in personalized instruction."
  },
  {
    "title": "How Should the Law Treat Future AI Systems? Fictional Legal Personhood versus Legal Identity",
    "abstract": "The law draws a sharp distinction between objects and persons, and between two kinds of persons, the ''fictional'' kind (i.e. corporations), and the ''non-fictional'' kind (individual or ''natural'' persons). This paper will assess whether we maximize overall long-term legal coherence by (A) maintaining an object classification for all future AI systems, (B) creating fictional legal persons associated with suitably advanced, individuated AI systems (giving these fictional legal persons derogable rights and duties associated with certified groups of existing persons, potentially including free speech, contract rights, and standing to sue ''on behalf of'' the AI system), or (C) recognizing non-fictional legal personhood through legal identity for suitably advanced, individuated AI systems (recognizing them as entities meriting legal standing with non-derogable rights which for the human case include life, due process, habeas corpus, freedom from slavery, and freedom of conscience). We will clarify the meaning and implications of each option along the way, considering liability, copyright, family law, fundamental rights, civil rights, citizenship, and AI safety regulation. We will tentatively find that the non-fictional personhood approach may be best from a coherence perspective, for at least some advanced AI systems. An object approach may prove untenable for sufficiently humanoid advanced systems, though we suggest that it is adequate for currently existing systems as of 2025. While fictional personhood would resolve some coherence issues for future systems, it would create others and provide solutions that are neither durable nor fit for purpose. Finally, our review will suggest that ''hybrid'' approaches are likely to fail and lead to further incoherence: the choice between object, fictional person and non-fictional person is unavoidable.",
    "url": "https://arxiv.org/abs/2511.14964",
    "journal": "arXiv cs.HC",
    "ai_summary": "This paper explores the implications of classifying future AI systems as objects, fictional legal persons, or non-fictional legal persons. The authors argue that recognizing AI systems as non-fictional legal persons with rights similar to those of humans may be the most coherent approach, especially for advanced AI systems. They suggest that object classification may be suitable for current AI systems, but not for more humanoid AI systems in the future. The study highlights the importance of determining the legal status of AI systems in areas such as liability, copyright, and fundamental rights."
  },
  {
    "title": "M-CALLM: Multi-level Context Aware LLM Framework for Group Interaction Prediction",
    "abstract": "This paper explores how large language models can leverage multi-level contextual information to predict group coordination patterns in collaborative mixed reality environments. We demonstrate that encoding individual behavioral profiles, group structural properties, and temporal dynamics as natural language enables LLMs to break through the performance ceiling of statistical models. We build M-CALLM, a framework that transforms multimodal sensor streams into hierarchical context for LLM-based prediction, and evaluate three paradigms (zero-shot prompting, few-shot learning, and supervised fine-tuning) against statistical baselines across intervention mode (real-time prediction) and simulation mode (autoregressive forecasting) Head-to-head comparison on 16 groups (64 participants, ~25 hours) demonstrates that context-aware LLMs achieve 96% accuracy for conversation prediction, a 3.2x improvement over LSTM baselines, while maintaining sub-35ms latency. However, simulation mode reveals brittleness with 83% degradation due to cascading errors. Deep-dive into modality-specific performance shows conversation depends on temporal patterns, proximity benefits from group structure (+6%), while shared attention fails completely (0% recall), exposing architectural limitations. We hope this work spawns new ideas for building intelligent collaborative sensing systems that balance semantic reasoning capabilities with fundamental constraints.",
    "url": "https://arxiv.org/abs/2511.14661",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper introduces the M-CALLM framework, which uses multi-level contextual information to predict group coordination patterns in mixed reality environments. The study shows that encoding behavioral profiles, group properties, and temporal dynamics as natural language allows large language models to outperform statistical models in predicting group interactions. The context-aware LLMs achieve 96% accuracy in conversation prediction, showing a significant improvement over LSTM baselines, but also reveal limitations in shared attention prediction and brittleness in simulation mode. The findings suggest potential for building intelligent collaborative sensing systems that balance semantic reasoning with fundamental constraints."
  },
  {
    "title": "Theoretical basis for code presentation: A case for cognitive load",
    "abstract": "Evidence supports that reducing cognitive load (CL) improves task performance for people of all abilities. This effect is specifically important for blind-and-low-vision (BLV) individuals because they cannot rely on many common methods of managing CL, which are frequently vision-based techniques. Current accessible \"solutions\" for BLV developers only sporadically consider CL in their design. There isn't a way to know whether CL is being alleviated by them. Neither do we know if alleviating CL is part of the mechanism behind why these solutions help BLV people. Using a strong foundation in psychological sciences, we identify aspects of CL that impact performance and learning in programming. These aspects are then examined when evaluating existing solutions for programming sub-tasks for BLV users. We propose an initial design \"recommendations\" for presentation of code which, when followed, will reduce cognitive load for BLV developers.",
    "url": "https://arxiv.org/abs/2511.14636",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research emphasizes the importance of reducing cognitive load for blind-and-low-vision individuals when presenting code, as they cannot rely on visual cues to manage cognitive load. The study identifies key aspects of cognitive load that impact performance and learning in programming and proposes design recommendations to alleviate cognitive load for BLV developers. By incorporating psychological sciences and focusing on reducing cognitive load, this research aims to improve task performance and accessibility for BLV individuals in programming."
  },
  {
    "title": "Biased Minds Meet Biased AI: How Class Imbalance Shapes Appropriate Reliance and Interacts with Human Base Rate Neglect",
    "abstract": "Humans increasingly interact with artificial intelligence (AI) in decision-making. However, both AI and humans are prone to biases. While AI and human biases have been studied extensively in isolation, this paper examines their complex interaction. Specifically, we examined how class imbalance as an AI bias affects people's ability to appropriately rely on an AI-based decision-support system, and how it interacts with base rate neglect as a human bias. In a within-subject online study (N= 46), participants classified three diseases using an AI-based decision-support system trained on either a balanced or unbalanced dataset. We found that class imbalance disrupted participants' calibration of AI reliance. Moreover, we observed mutually reinforcing effects between class imbalance and base rate neglect, offering evidence of a compound human-AI bias. Based on these findings, we advocate for an interactionist perspective and further research into the mutually reinforcing effects of biases in human-AI interaction.",
    "url": "https://arxiv.org/abs/2511.14591",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores how class imbalance in AI affects human reliance on AI-based decision-support systems and interacts with human base rate neglect. The research found that class imbalance disrupted participants' ability to appropriately rely on the AI system, and there were mutually reinforcing effects between class imbalance and base rate neglect. These findings highlight the importance of considering the complex interaction of biases in human-AI interaction and advocate for further research in this area."
  },
  {
    "title": "SweeperBot: Making 3D Browsing Accessible through View Analysis and Visual Question Answering",
    "abstract": "Accessing 3D models remains challenging for Screen Reader (SR) users. While some existing 3D viewers allow creators to provide alternative text, they often lack sufficient detail about the 3D models. Grounded on a formative study, this paper introduces SweeperBot, a system that enables SR users to leverage visual question answering to explore and compare 3D models. SweeperBot answers SR users' visual questions by combining an optimal view selection technique with the strength of generative- and recognition-based foundation models. An expert review with 10 Blind and Low-Vision (BLV) users with SR experience demonstrated the feasibility of using SweeperBot to assist BLV users in exploring and comparing 3D models. The quality of the descriptions generated by SweeperBot was validated by a second survey study with 30 sighted participants.",
    "url": "https://arxiv.org/abs/2511.14567",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research paper introduces SweeperBot, a system designed to help visually impaired users access and explore 3D models through visual question answering. By combining an optimal view selection technique with generative- and recognition-based models, SweeperBot was able to provide detailed descriptions of 3D models to Blind and Low-Vision users using screen readers. The study showed that SweeperBot was effective in assisting visually impaired users in exploring and comparing 3D models, as validated by both expert review and a survey study with sighted participants."
  }
]