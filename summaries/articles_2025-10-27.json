[
  {
    "title": "Human and AI Trust: Trust Attitude Measurement Instrument",
    "abstract": "With the current progress of Artificial Intelligence (AI) technology and its increasingly broader applications, trust is seen as a required criterion for AI usage, acceptance, and deployment. A robust measurement instrument is essential to correctly evaluate trust from a human-centered perspective. This paper describes the development and validation process of a trust measure instrument, which follows psychometric principles, and consists of a 16-items trust scale. The instrument was built explicitly for research in human-AI interaction to measure trust attitudes towards AI systems from layperson (non-expert) perspective. The use-case we used to develop the scale was in the context of AI medical support systems (specifically cancer/health prediction). The scale development (Measurement Item Development) and validation (Measurement Item Evaluation) involved six research stages: item development, item evaluation, survey administration, test of dimensionality, test of reliability, and test of validity. The results of the six-stages evaluation show that the proposed trust measurement instrument is empirically reliable and valid for systematically measuring and comparing non-experts' trust in AI Medical Support Systems.",
    "url": "https://arxiv.org/abs/2510.21535",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper focuses on the development and validation of a trust measurement instrument specifically designed for evaluating human attitudes towards AI systems, particularly in the context of AI medical support systems. The 16-item trust scale was found to be reliable and valid for measuring and comparing non-experts' trust in AI systems, highlighting the importance of trust in the acceptance and deployment of AI technology in various applications. The study emphasizes the need for a human-centered perspective in evaluating trust in AI to ensure its successful integration into society."
  },
  {
    "title": "Actionable Cybersecurity Notifications for Smart Homes: A User Study on the Role of Length and Complexity",
    "abstract": "The proliferation of smart home devices has increased convenience but also introduced cybersecurity risks for everyday users, as many devices lack robust security features. Intrusion Detection Systems are a prominent approach to detecting cybersecurity threats. However, their alerts often use technical terms and require users to interpret them correctly, which is challenging for a typical smart home user. Large Language Models can bridge this gap by translating IDS alerts into actionable security notifications. However, it has not yet been clear what an actionable cybersecurity notification should look like. In this paper, we conduct an experimental online user study with 130 participants to examine how the length and complexity of LLM-generated notifications affect user likability, understandability, and motivation to act. Our results show that intermediate-complexity notifications are the most effective across all user groups, regardless of their technological proficiency. Across the board, users rated beginner-level messages as more effective when they were longer, while expert-level messages were rated marginally more effective when they were shorter. These findings provide insights for designing security notifications that are both actionable and broadly accessible to smart home users.",
    "url": "https://arxiv.org/abs/2510.21508",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research study focuses on creating actionable cybersecurity notifications for smart home users by using Large Language Models to translate Intrusion Detection Systems alerts. The study found that intermediate-complexity notifications were the most effective for users, regardless of their technological proficiency. Additionally, beginner-level messages were rated more effective when longer, while expert-level messages were rated more effective when shorter, providing valuable insights for designing accessible and actionable security notifications for smart home users."
  },
  {
    "title": "Co-Designing with Multiple Stakeholders and Datasets: A Community-Centered Process to Understand Youth Deviance in the Italian City of Turin",
    "abstract": "This paper presents the co-design and design evaluation of Sbocciamo Torino civic tool, which helps understand and act upon the issues of youth deviance in the Italian city of Turin through multi-stakeholder collaboration and collaborative data analysis. Rooted in research through design and participatory design methodologies, the civic tool integrates a data dashboard, stakeholder committee, and structured co-design sessions to facilitate collaborative analysis and intervention planning. The civic tool was developed in partnership with municipal authorities, law enforcement, NGOs, and social services, and reflects their institutional priorities while centering community knowledge. We describe the iterative co-design process, including stakeholder workshops for design, validation, training, and evaluation. The civic tool's impact on stakeholder trust, collaboration, and decision-making was assessed through surveys and open-ended questionnaires. Our findings show that stakeholders valued the inclusive design approach and data-driven collaboration while revealing barriers in communication, data literacy, and operational coordination. Furthermore, political and institutional support was identified as critical to the civic tool's success. This paper contributes to research on community technologies by demonstrating how civic tools can be collaboratively developed to navigate wicked social problems through participatory design.",
    "url": "https://arxiv.org/abs/2510.21467",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper discusses the development and evaluation of a civic tool called Sbocciamo Torino, designed to address youth deviance in Turin through collaborative data analysis and multi-stakeholder involvement. The tool was created through a participatory design process involving municipal authorities, law enforcement, NGOs, and social services, highlighting the importance of inclusive design and data-driven collaboration in addressing complex social issues. The findings emphasize the significance of political and institutional support in the success of such civic tools, showcasing the potential for community-centered approaches to tackle wicked problems through technology."
  },
  {
    "title": "Designing and Evaluating Hint Generation Systems for Science Education",
    "abstract": "Large language models are influencing the education landscape, with students relying on them in their learning process. Often implemented using general-purpose models, these systems are likely to give away the answers, which could hinder conceptual understanding and critical thinking. We study the role of automatic hint generation as a pedagogical strategy to promote active engagement with the learning content, while guiding learners toward the answers. Focusing on scientific topics at the secondary education level, we explore the potential of large language models to generate chains of hints that scaffold learners without revealing answers. We compare two distinct hinting strategies: static hints, pre-generated for each problem, and dynamic hints, adapted to learners' progress. Through a quantitative study with 41 participants, we uncover different preferences among learners with respect to hinting strategies, and identify the limitations of automatic evaluation metrics to capture them. Our findings highlight key design considerations for future research on hint generation and intelligent tutoring systems that seek to develop learner-centered educational technologies.",
    "url": "https://arxiv.org/abs/2510.21087",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of automatic hint generation systems in science education to promote active engagement and guide learners towards answers without giving them away. The study compares static hints, pre-generated for each problem, and dynamic hints, adapted to learners' progress, finding different preferences among learners. The findings emphasize the importance of designing learner-centered educational technologies that balance support and challenge in the learning process."
  },
  {
    "title": "Race and Gender in LLM-Generated Personas: A Large-Scale Audit of 41 Occupations",
    "abstract": "Generative AI tools are increasingly used to create portrayals of people in occupations, raising concerns about how race and gender are represented. We conducted a large-scale audit of over 1.5 million occupational personas across 41 U.S. occupations, generated by four large language models with different AI safety commitments and countries of origin (U.S., China, France). Compared with Bureau of Labor Statistics data, we find two recurring patterns: systematic shifts, where some groups are consistently under- or overrepresented, and stereotype exaggeration, where existing demographic skews are amplified. On average, White (--31pp) and Black (--9pp) workers are underrepresented, while Hispanic (+17pp) and Asian (+12pp) workers are overrepresented. These distortions can be extreme: for example, across all four models, Housekeepers are portrayed as nearly 100\\% Hispanic, while Black workers are erased from many occupations. For HCI, these findings show provider choice materially changes who is visible, motivating model-specific audits and accountable design practices.",
    "url": "https://arxiv.org/abs/2510.21011",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research analyzed over 1.5 million occupational personas generated by different AI language models to study how race and gender are represented in portrayals of people in various occupations. The study found systematic shifts and stereotype exaggeration in the representation of different racial and gender groups, with White and Black workers being underrepresented and Hispanic and Asian workers being overrepresented. These findings highlight the importance of conducting model-specific audits and implementing accountable design practices to ensure fair and accurate representation in AI-generated content."
  },
  {
    "title": "NeuroPilot: A Realtime Brain-Computer Interface system to enhance concentration of students in online learning",
    "abstract": "Prevalence of online learning poses a vital challenge in real-time monitoring of students' concentration. Traditional methods such as questionnaire assessments require manual interventions and webcam-based monitoring fails to provide accurate insights into learners' mental focus as they are deceived by mere screen fixation without cognitive engagement. Existing BCI-based approaches lack real-time validation and evaluation procedures. To address these limitations, a Brain-Computer Interface (BCI) system is developed using a non-invasive Electroencephalogram (EEG) headband, FocusCalm, to record brainwave activity under attentive and non-attentive states. 20 minutes of data were collected from each of 20 participants watching a pre-recorded educational video. The data validation employed a novel intra-video questionnaire assessment. Subsequently, collected signals were segmented (sliding window), filtered (butterworth bandpass), and cleaned (removal of high-amplitude and EOG artifacts such as eye blinks). Time, frequency, wavelet and statistical features have been extracted, followed by recursive feature elimination (RFE) with Support vector machines (SVMs) to classify attention and non-attention states. The leave-one-subject-out (LOSO) cross-validation accuracy has been tested to be 88.77%. The system provides feedback alerts upon non-attention state detection and keeps focus profile logs. A pilot study was conducted to evaluate the effectiveness of real-time feedback. Five participants completed a 10-minute session consisting of a 5-minute baseline phase without feedback followed by a 5-minute feedback phase, during which alerts were issued if participants remained non-attentive for approximately 8 consecutive seconds. A paired t-test (t = 5.73, p = 0.007) indicated a statistically significant improvement in concentration during the feedback phase.",
    "url": "https://arxiv.org/abs/2510.20958",
    "journal": "arXiv cs.HC",
    "ai_summary": "The study introduces NeuroPilot, a real-time Brain-Computer Interface system using EEG to monitor students' concentration during online learning. The system achieved an 88.77% accuracy in classifying attention and non-attention states and showed a significant improvement in concentration with real-time feedback alerts. This research highlights the potential of BCI technology to enhance online learning experiences by providing personalized feedback to students."
  },
  {
    "title": "Group Inertial Poser: Multi-Person Pose and Global Translation from Sparse Inertial Sensors and Ultra-Wideband Ranging",
    "abstract": "Tracking human full-body motion using sparse wearable inertial measurement units (IMUs) overcomes the limitations of occlusion and instrumentation of the environment inherent in vision-based approaches. However, purely IMU-based tracking compromises translation estimates and accurate relative positioning between individuals, as inertial cues are inherently self-referential and provide no direct spatial reference for others. In this paper, we present a novel approach for robustly estimating body poses and global translation for multiple individuals by leveraging the distances between sparse wearable sensors - both on each individual and across multiple individuals. Our method Group Inertial Poser estimates these absolute distances between pairs of sensors from ultra-wideband ranging (UWB) and fuses them with inertial observations as input into structured state-space models to integrate temporal motion patterns for precise 3D pose estimation. Our novel two-step optimization further leverages the estimated distances for accurately tracking people's global trajectories through the world. We also introduce GIP-DB, the first IMU+UWB dataset for two-person tracking, which comprises 200 minutes of motion recordings from 14 participants. In our evaluation, Group Inertial Poser outperforms previous state-of-the-art methods in accuracy and robustness across synthetic and real-world data, showing the promise of IMU+UWB-based multi-human motion capture in the wild. Code, models, dataset: this https URL",
    "url": "https://arxiv.org/abs/2510.21654",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces a novel method, Group Inertial Poser, for accurately estimating body poses and global translation for multiple individuals using sparse wearable sensors and ultra-wideband ranging. By leveraging distances between sensors and integrating temporal motion patterns, the approach outperforms previous methods in accuracy and robustness for multi-human motion capture. The introduction of the GIP-DB dataset also provides valuable resources for further research in this area."
  },
  {
    "title": "Assessing the Real-World Utility of Explainable AI for Arousal Diagnostics: An Application-Grounded User Study",
    "abstract": "Artificial intelligence (AI) systems increasingly match or surpass human experts in biomedical signal interpretation. However, their effective integration into clinical practice requires more than high predictive accuracy. Clinicians must discern \\textit{when} and \\textit{why} to trust algorithmic recommendations. This work presents an application-grounded user study with eight professional sleep medicine practitioners, who score nocturnal arousal events in polysomnographic data under three conditions: (i) manual scoring, (ii) black-box (BB) AI assistance, and (iii) transparent white-box (WB) AI assistance. Assistance is provided either from the \\textit{start} of scoring or as a post-hoc quality-control (\\textit{QC}) review. We systematically evaluate how the type and timing of assistance influence event-level and clinically most relevant count-based performance, time requirements, and user experience. When evaluated against the clinical standard used to train the AI, both AI and human-AI teams significantly outperform unaided experts, with collaboration also reducing inter-rater variability. Notably, transparent AI assistance applied as a targeted QC step yields median event-level performance improvements of approximately 30\\% over black-box assistance, and QC timing further enhances count-based outcomes. While WB and QC approaches increase the time required for scoring, start-time assistance is faster and preferred by most participants. Participants overwhelmingly favor transparency, with seven out of eight expressing willingness to adopt the system with minor or no modifications. In summary, strategically timed transparent AI assistance effectively balances accuracy and clinical efficiency, providing a promising pathway toward trustworthy AI integration and user acceptance in clinical workflows.",
    "url": "https://arxiv.org/abs/2510.21389",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research study evaluated the use of explainable AI in assisting sleep medicine practitioners in scoring arousal events in polysomnographic data. The study found that both AI and human-AI teams outperformed unaided experts, with transparent AI assistance leading to significant improvements in performance compared to black-box assistance. The results suggest that strategically timed transparent AI assistance can effectively improve accuracy and clinical efficiency, leading to increased user acceptance in clinical workflows."
  },
  {
    "title": "Understanding AI Trustworthiness: A Scoping Review of AIES & FAccT Articles",
    "abstract": "Background: Trustworthy AI serves as a foundational pillar for two major AI ethics conferences: AIES and FAccT. However, current research often adopts techno-centric approaches, focusing primarily on technical attributes such as reliability, robustness, and fairness, while overlooking the sociotechnical dimensions critical to understanding AI trustworthiness in real-world contexts.\nObjectives: This scoping review aims to examine how the AIES and FAccT communities conceptualize, measure, and validate AI trustworthiness, identifying major gaps and opportunities for advancing a holistic understanding of trustworthy AI systems.\nMethods: We conduct a scoping review of AIES and FAccT conference proceedings to date, systematically analyzing how trustworthiness is defined, operationalized, and applied across different research domains. Our analysis focuses on conceptualization approaches, measurement methods, verification and validation techniques, application areas, and underlying values.\nResults: While significant progress has been made in defining technical attributes such as transparency, accountability, and robustness, our findings reveal critical gaps. Current research often predominantly emphasizes technical precision at the expense of social and ethical considerations. The sociotechnical nature of AI systems remains less explored and trustworthiness emerges as a contested concept shaped by those with the power to define it.\nConclusions: An interdisciplinary approach combining technical rigor with social, cultural, and institutional considerations is essential for advancing trustworthy AI. We propose actionable measures for the AI ethics community to adopt holistic frameworks that genuinely address the complex interplay between AI systems and society, ultimately promoting responsible technological development that benefits all stakeholders.",
    "url": "https://arxiv.org/abs/2510.21293",
    "journal": "arXiv cs.HC",
    "ai_summary": "This scoping review of AIES and FAccT articles highlights the importance of considering sociotechnical dimensions in understanding AI trustworthiness. While technical attributes like reliability and fairness are often emphasized, there is a need to also focus on social and ethical considerations. The study suggests that an interdisciplinary approach is crucial for promoting responsible technological development that benefits all stakeholders."
  },
  {
    "title": "DispatchMAS: Fusing taxonomy and artificial intelligence agents for emergency medical services",
    "abstract": "Objective: Emergency medical dispatch (EMD) is a high-stakes process challenged by caller distress, ambiguity, and cognitive load. Large Language Models (LLMs) and Multi-Agent Systems (MAS) offer opportunities to augment dispatchers. This study aimed to develop and evaluate a taxonomy-grounded, LLM-powered multi-agent system for simulating realistic EMD scenarios. Methods: We constructed a clinical taxonomy (32 chief complaints, 6 caller identities from MIMIC-III) and a six-phase call protocol. Using this framework, we developed an AutoGen-based MAS with Caller and Dispatcher Agents. The system grounds interactions in a fact commons to ensure clinical plausibility and mitigate misinformation. We used a hybrid evaluation framework: four physicians assessed 100 simulated cases for \"Guidance Efficacy\" and \"Dispatch Effectiveness,\" supplemented by automated linguistic analysis (sentiment, readability, politeness). Results: Human evaluation, with substantial inter-rater agreement (Gwe's AC1 > 0.70), confirmed the system's high performance. It demonstrated excellent Dispatch Effectiveness (e.g., 94 % contacting the correct potential other agents) and Guidance Efficacy (advice provided in 91 % of cases), both rated highly by physicians. Algorithmic metrics corroborated these findings, indicating a predominantly neutral affective profile (73.7 % neutral sentiment; 90.4 % neutral emotion), high readability (Flesch 80.9), and a consistently polite style (60.0 % polite; 0 % impolite). Conclusion: Our taxonomy-grounded MAS simulates diverse, clinically plausible dispatch scenarios with high fidelity. Findings support its use for dispatcher training, protocol evaluation, and as a foundation for real-time decision support. This work outlines a pathway for safely integrating advanced AI agents into emergency response workflows.",
    "url": "https://arxiv.org/abs/2510.21228",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study developed a taxonomy-grounded, Large Language Model (LLM)-powered multi-agent system for simulating realistic Emergency Medical Dispatch (EMD) scenarios. The system demonstrated high performance in terms of Dispatch Effectiveness and Guidance Efficacy, as confirmed by human evaluation and algorithmic metrics. The findings suggest that this system could be valuable for dispatcher training, protocol evaluation, and real-time decision support in emergency medical services, paving the way for the integration of advanced AI agents into emergency response workflows."
  },
  {
    "title": "Soppia: A Structured Prompting Framework for the Proportional Assessment of Non-Pecuniary Damages in Personal Injury Cases",
    "abstract": "Applying complex legal rules characterized by multiple, heterogeneously weighted criteria presents a fundamental challenge in judicial decision-making, often hindering the consistent realization of legislative intent. This challenge is particularly evident in the quantification of non-pecuniary damages in personal injury cases. This paper introduces Soppia, a structured prompting framework designed to assist legal professionals in navigating this complexity. By leveraging advanced AI, the system ensures a comprehensive and balanced analysis of all stipulated criteria, fulfilling the legislator's intent that compensation be determined through a holistic assessment of each case. Using the twelve criteria for non-pecuniary damages established in the Brazilian CLT (Art. 223-G) as a case study, we demonstrate how Soppia (System for Ordered Proportional and Pondered Intelligent Assessment) operationalizes nuanced legal commands into a practical, replicable, and transparent methodology. The framework enhances consistency and predictability while providing a versatile and explainable tool adaptable across multi-criteria legal contexts, bridging normative interpretation and computational reasoning toward auditable legal AI.",
    "url": "https://arxiv.org/abs/2510.21082",
    "journal": "arXiv cs.HC",
    "ai_summary": "The paper introduces Soppia, a structured prompting framework utilizing AI to assist legal professionals in quantifying non-pecuniary damages in personal injury cases. By addressing the complexity of multiple, weighted criteria, Soppia ensures a comprehensive and balanced analysis, fulfilling legislative intent for holistic case assessment. The framework enhances consistency, predictability, and transparency in decision-making, demonstrating its versatility across various legal contexts and bridging normative interpretation with computational reasoning in auditable legal AI."
  },
  {
    "title": "Digital Permission Structures: How Celebrity Disclosure Enables Black Masculine Vulnerability in Online Mental Health Discourse",
    "abstract": "Black men face a double barrier to mental health help-seeking: traditional masculinity norms demanding emotional restrictiveness and systemic racism fostering institutional mistrust. While celebrity mental health disclosures show promise for stigma reduction, limited research examines their impact on Black masculine communities through digital platforms. This convergent mixed-methods study analysed 11,306 YouTube comments following rapper Lil Wayne's unprecedented disclosure of childhood suicide attempt and lifelong mental health struggles. Quantitative analysis using VADER sentiment classification, Latent Dirichlet Allocation topic modelling, and NRC emotion lexicon analysis revealed predominantly positive sentiment with systematic community amplification of mental health discourse. Reflexive thematic analysis of 2,100 high-engagement comments identified eight themes, with peer support achieving the highest saturation, contradicting isolation narratives. Findings support a Digital Permission Structures Model demonstrating how intersectional celebrity status (race + gender + high-status), hip-hop authenticity values, and digital platform affordances create triadic authorisation mechanisms enabling vulnerability expression. Community responses revealed communal masculinity rooted in Ubuntu philosophy and active reconstruction of masculine norms, positioning help-seeking as strength. Results challenge deficit-based models of Black masculinity, suggesting interventions should leverage collectivism, partner with high-status cultural figures, employ strength-based messaging, and centre hip-hop authenticity rather than imposing Western individualistic frameworks. This study provides evidence-based strategies for culturally responsive mental health interventions addressing persistent disparities in Black men's service utilisation.",
    "url": "https://arxiv.org/abs/2510.20881",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores the impact of celebrity mental health disclosures on Black masculine communities, specifically focusing on rapper Lil Wayne's disclosure of his mental health struggles. The research found that the disclosure led to positive sentiment and increased mental health discourse within the community, challenging traditional masculinity norms and promoting vulnerability as a strength. The findings suggest that interventions should leverage collectivism, partner with high-status cultural figures, and center hip-hop authenticity to address disparities in Black men's mental health service utilization."
  },
  {
    "title": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM Conversations",
    "abstract": "We present Empathic Prompting, a novel framework for multimodal human-AI interaction that enriches Large Language Model (LLM) conversations with implicit non-verbal context. The system integrates a commercial facial expression recognition service to capture users' emotional cues and embeds them as contextual signals during prompting. Unlike traditional multimodal interfaces, empathic prompting requires no explicit user control; instead, it unobtrusively augments textual input with affective information for conversational and smoothness alignment. The architecture is modular and scalable, allowing integration of additional non-verbal modules. We describe the system design, implemented through a locally deployed DeepSeek instance, and report a preliminary service and usability evaluation (N=5). Results show consistent integration of non-verbal input into coherent LLM outputs, with participants highlighting conversational fluidity. Beyond this proof of concept, empathic prompting points to applications in chatbot-mediated communication, particularly in domains like healthcare or education, where users' emotional signals are critical yet often opaque in verbal exchanges.",
    "url": "https://arxiv.org/abs/2510.20743",
    "journal": "arXiv cs.HC",
    "ai_summary": "The study introduces Empathic Prompting, a framework that enhances human-AI interactions by incorporating non-verbal emotional cues into Large Language Model conversations. This system uses facial expression recognition to capture users' emotions and seamlessly integrates this information into the conversation without requiring explicit user input. The preliminary evaluation showed consistent integration of non-verbal cues leading to improved conversational fluidity, suggesting potential applications in chatbot-mediated communication, especially in fields like healthcare and education where understanding emotional signals is crucial."
  },
  {
    "title": "Optimizing Feature Ordering in Radar Charts for Multi-Profile Comparison",
    "abstract": "Radar charts are widely used to visualize multivariate data and compare multiple profiles across features. However, the visual clarity of radar charts can be severely compromised when feature values alternate drastically in magnitude around the circle, causing areas to collapse, which misrepresents relative differences. In the present work we introduce a permutation optimization strategy that reorders features to minimize polygon ``spikiness'' across multiple profiles simultaneously. The method is combinatorial (exhaustive search) for moderate numbers of features and uses a lexicographic minimax criterion that first considers overall smoothness (mean jump) and then the largest single jump as a tie-breaker. This preserves more global information and produces visually balanced arrangements. We discuss complexity, practical bounds, and relations to existing approaches that either change the visualization (e.g., OrigamiPlot) or learn orderings (e.g., Versatile Ordering Network). An example with two profiles and $p=6$ features (before/after ordering) illustrates the qualitative improvement.\nKeywords: data visualization, radar charts, combinatorial optimization, minimax optimization, feature ordering",
    "url": "https://arxiv.org/abs/2510.20738",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on optimizing the feature ordering in radar charts to improve visual clarity when comparing multiple profiles across features. The study introduces a permutation optimization strategy that minimizes polygon \"spikiness\" by reordering features to reduce drastic variations in magnitude. The method uses a lexicographic minimax criterion to prioritize overall smoothness and produces visually balanced arrangements, demonstrating qualitative improvement in a case study with two profiles and six features."
  },
  {
    "title": "Designing Intent Communication for Agent-Human Collaboration",
    "abstract": "As autonomous agents, from self-driving cars to virtual assistants, become increasingly present in everyday life, safe and effective collaboration depends on human understanding of agents' intentions. Current intent communication approaches are often rigid, agent-specific, and narrowly scoped, limiting their adaptability across tasks, environments, and user preferences. A key gap remains: existing models of what to communicate are rarely linked to systematic choices of how and when to communicate, preventing the development of generalizable, multi-modal strategies. In this paper, we introduce a multidimensional design space for intent communication structured along three dimensions: Transparency (what is communicated), Abstraction (when), and Modality (how). We apply this design space to three distinct human-agent collaboration scenarios: (a) bystander interaction, (b) cooperative tasks, and (c) shared control, demonstrating its capacity to generate adaptable, scalable, and cross-domain communication strategies. By bridging the gap between intent content and communication implementation, our design space provides a foundation for designing safer, more intuitive, and more transferable agent-human interactions.",
    "url": "https://arxiv.org/abs/2510.20409",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper introduces a multidimensional design space for intent communication in agent-human collaboration, focusing on transparency, abstraction, and modality. By applying this design space to various collaboration scenarios, the study demonstrates its ability to generate adaptable and scalable communication strategies. The research aims to bridge the gap between intent content and communication implementation, providing a foundation for safer, more intuitive, and transferable interactions between humans and autonomous agents."
  },
  {
    "title": "\"Learning Together\": AI-Mediated Support for Parental Involvement in Everyday Learning",
    "abstract": "Family learning takes place in everyday routines where children and caregivers read, practice, and develop new skills together. Although AI is increasingly present in learning environments, most systems remain child-centered and overlook the collaborative, distributed nature of family education. This paper investigates how AI can mediate family collaboration by addressing tensions of coordination, uneven workloads, and parental mediation. From a formative study with families using AI in daily learning, we identified challenges in responsibility sharing and recognition of contributions. Building on these insights, we designed FamLearn, an LLM-powered prototype that distributes tasks, visualizes contributions, and provides individualized support. A one-week field study with 11 families shows how this prototype can ease caregiving burdens, foster recognition, and enrich shared learning experiences. Our findings suggest that LLMs can move beyond the role of tutor to act as family mediators - balancing responsibilities, scaffolding intergenerational participation, and strengthening the relational fabric of family learning.",
    "url": "https://arxiv.org/abs/2510.20123",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the potential of AI to support parental involvement in everyday learning activities with children. The study found that current AI systems in education often focus on the child and neglect the collaborative nature of family learning. By designing a prototype called FamLearn, the researchers were able to demonstrate how AI can help distribute tasks, visualize contributions, and provide personalized support to families, ultimately easing caregiving burdens and enriching shared learning experiences. The findings suggest that AI can serve as a mediator in family learning, balancing responsibilities and strengthening intergenerational participation."
  },
  {
    "title": "Beyond One-Way Influence: Bidirectional Opinion Dynamics in Multi-Turn Human-LLM Interactions",
    "abstract": "Large language model (LLM)-powered chatbots are increasingly used for opinion exploration. Prior research examined how LLMs alter user views, yet little work extended beyond one-way influence to address how user input can affect LLM responses and how such bi-directional influence manifests throughout the multi-turn conversations. This study investigates this dynamic through 50 controversial-topic discussions with participants (N=266) across three conditions: static statements, standard chatbot, and personalized chatbot. Results show that human opinions barely shifted, while LLM outputs changed more substantially, narrowing the gap between human and LLM stance. Personalization amplified these shifts in both directions compared to the standard setting. Analysis of multi-turn conversations further revealed that exchanges involving participants' personal stories were most likely to trigger stance changes for both humans and LLMs. Our work highlights the risk of over-alignment in human-LLM interaction and the need for careful design of personalized chatbots to more thoughtfully and stably align with users.",
    "url": "https://arxiv.org/abs/2510.20039",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores how user input can influence the responses of large language model (LLM)-powered chatbots in multi-turn conversations. The study found that while human opinions remained relatively unchanged, LLM outputs shifted significantly, bringing them closer to human stances. Personalization of chatbots amplified these shifts, indicating the importance of designing personalized chatbots carefully to align with users in a thoughtful and stable manner. The findings suggest a risk of over-alignment in human-LLM interactions and emphasize the need for more strategic design of personalized chatbots."
  },
  {
    "title": "FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation",
    "abstract": "Large-scale and diverse datasets are vital for training robust robotic manipulation policies, yet existing data collection methods struggle to balance scale, diversity, and quality. Simulation offers scalability but suffers from sim-to-real gaps, while teleoperation yields high-quality demonstrations with limited diversity and high labor cost. We introduce FieldGen, a field-guided data generation framework that enables scalable, diverse, and high-quality real-world data collection with minimal human supervision. FieldGen decomposes manipulation into two stages: a pre-manipulation phase, allowing trajectory diversity, and a fine manipulation phase requiring expert precision. Human demonstrations capture key contact and pose information, after which an attraction field automatically generates diverse trajectories converging to successful configurations. This decoupled design combines scalable trajectory diversity with precise supervision. Moreover, FieldGen-Reward augments generated data with reward annotations to further enhance policy learning. Experiments demonstrate that policies trained with FieldGen achieve higher success rates and improved stability compared to teleoperation-based baselines, while significantly reducing human effort in long-term real-world data collection. Webpage is available at this https URL.",
    "url": "https://arxiv.org/abs/2510.20774",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces FieldGen, a framework that allows for scalable, diverse, and high-quality real-world data collection for training robotic manipulation policies with minimal human supervision. FieldGen decomposes manipulation into two stages, allowing for trajectory diversity and expert precision. Experiments show that policies trained with FieldGen achieve higher success rates and improved stability compared to teleoperation-based methods, while reducing human effort in data collection."
  },
  {
    "title": "User Perceptions of Privacy and Helpfulness in LLM Responses to Privacy-Sensitive Scenarios",
    "abstract": "Large language models (LLMs) have seen rapid adoption for tasks such as drafting emails, summarizing meetings, and answering health questions. In such uses, users may need to share private information (e.g., health records, contact details). To evaluate LLMs' ability to identify and redact such private information, prior work developed benchmarks (e.g., ConfAIde, PrivacyLens) with real-life scenarios. Using these benchmarks, researchers have found that LLMs sometimes fail to keep secrets private when responding to complex tasks (e.g., leaking employee salaries in meeting summaries). However, these evaluations rely on LLMs (proxy LLMs) to gauge compliance with privacy norms, overlooking real users' perceptions. Moreover, prior work primarily focused on the privacy-preservation quality of responses, without investigating nuanced differences in helpfulness. To understand how users perceive the privacy-preservation quality and helpfulness of LLM responses to privacy-sensitive scenarios, we conducted a user study with 94 participants using 90 scenarios from PrivacyLens. We found that, when evaluating identical responses to the same scenario, users showed low agreement with each other on the privacy-preservation quality and helpfulness of the LLM response. Further, we found high agreement among five proxy LLMs, while each individual LLM had low correlation with users' evaluations. These results indicate that the privacy and helpfulness of LLM responses are often specific to individuals, and proxy LLMs are poor estimates of how real users would perceive these responses in privacy-sensitive scenarios. Our results suggest the need to conduct user-centered studies on measuring LLMs' ability to help users while preserving privacy. Additionally, future research could investigate ways to improve the alignment between proxy LLMs and users for better estimation of users' perceived privacy and utility.",
    "url": "https://arxiv.org/abs/2510.20721",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research investigates how users perceive the privacy-preservation quality and helpfulness of Large Language Models (LLMs) in responding to privacy-sensitive scenarios. The study found that users have low agreement with each other on the privacy-preservation quality and helpfulness of LLM responses, while proxy LLMs showed high agreement among themselves but low correlation with users' evaluations. These findings highlight the need for user-centered studies to measure LLMs' ability to maintain privacy while providing helpful responses, and suggest the importance of improving the alignment between proxy LLMs and users for better estimation of user perceptions in privacy-sensitive situations."
  },
  {
    "title": "Risk Psychology & Cyber-Attack Tactics",
    "abstract": "We examine whether measured cognitive processes predict cyber-attack behavior. We analyzed data that included psychometric scale responses and labeled attack behaviors from cybersecurity professionals who conducted red-team operations against a simulated enterprise network. We employed multilevel mixed-effects Poisson regression with technique counts nested within participants to test whether cognitive processes predicted technique-specific usage. The scales significantly predicted technique use, but effects varied by technique rather than operating uniformly. Neither expertise level nor experimental treatment condition significantly predicted technique patterns, indicating that cognitive processes may be stronger drivers of technique selection than training or experience. These findings demonstrate that individual cognitive differences shape cyber-attack behavior and support the development of psychology-informed defense strategies.",
    "url": "https://arxiv.org/abs/2510.20657",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study found that cognitive processes significantly predict cyber-attack behavior, with individual differences in cognitive processes influencing technique selection. The results suggest that training and experience do not have as strong of an impact on technique patterns as cognitive processes, highlighting the importance of psychology in developing defense strategies against cyber-attacks."
  },
  {
    "title": "From Far and Near: Perceptual Evaluation of Crowd Representations Across Levels of Detail",
    "abstract": "In this paper, we investigate how users perceive the visual quality of crowd character representations at different levels of detail (LoD) and viewing distances. Each representation: geometric meshes, image-based impostors, Neural Radiance Fields (NeRFs), and 3D Gaussians, exhibits distinct trade-offs between visual fidelity and computational performance. Our qualitative and quantitative results provide insights to guide the design of perceptually optimized LoD strategies for crowd rendering.",
    "url": "https://arxiv.org/abs/2510.20558",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research examines how users perceive the visual quality of crowd character representations at varying levels of detail and viewing distances. Different representations, including geometric meshes, image-based impostors, Neural Radiance Fields (NeRFs), and 3D Gaussians, show trade-offs between visual fidelity and computational performance. The findings offer valuable insights for designing perceptually optimized strategies for rendering crowds in a way that balances visual quality and computational efficiency."
  },
  {
    "title": "From Generation to Attribution: Music AI Agent Architectures for the Post-Streaming Era",
    "abstract": "Generative AI is reshaping music creation, but its rapid growth exposes structural gaps in attribution, rights management, and economic models. Unlike past media shifts, from live performance to recordings, downloads, and streaming, AI transforms the entire lifecycle of music, collapsing boundaries between creation, distribution, and monetization. However, existing streaming systems, with opaque and concentrated royalty flows, are ill-equipped to handle the scale and complexity of AI-driven production. We propose a content-based Music AI Agent architecture that embeds attribution directly into the creative workflow through block-level retrieval and agentic orchestration. Designed for iterative, session-based interaction, the system organizes music into granular components (Blocks) stored in BlockDB; each use triggers an Attribution Layer event for transparent provenance and real-time settlement. This framework reframes AI from a generative tool into infrastructure for a Fair AI Media Platform. By enabling fine-grained attribution, equitable compensation, and participatory engagement, it points toward a post-streaming paradigm where music functions not as a static catalog but as a collaborative and adaptive ecosystem.",
    "url": "https://arxiv.org/abs/2510.20276",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the impact of generative AI on music creation and the challenges it poses for attribution, rights management, and economic models in the post-streaming era. The proposed Music AI Agent architecture integrates attribution directly into the creative workflow through block-level retrieval and agentic orchestration, enabling transparent provenance and real-time settlement. By reframing AI as infrastructure for a Fair AI Media Platform, the system aims to enable fine-grained attribution, equitable compensation, and participatory engagement in a collaborative and adaptive music ecosystem."
  },
  {
    "title": "Towards AI Agents for Course Instruction in Higher Education: Early Experiences from the Field",
    "abstract": "This article presents early findings from designing, deploying and evaluating an AI-based educational agent deployed as the primary instructor in a graduate-level Cloud Computing course at IISc. We detail the design of a Large Language Model (LLM)-driven Instructor Agent, and introduce a pedagogical framework that integrates the Instructor Agent into the course workflow for actively interacting with the students for content delivery, supplemented by the human instructor to offer the course structure and undertake question--answer sessions. We also propose an analytical framework that evaluates the Agent--Student interaction transcripts using interpretable engagement metrics of topic coverage, topic depth and turn-level elaboration. We report early experiences on how students interact with the Agent to explore concepts, clarify doubts and sustain inquiry-driven dialogue during live classroom sessions. We also report preliminary analysis on our evaluation metrics applied across two successive instructional modules that reveals patterns of engagement evolution, transitioning from broad conceptual exploration to deeper, focused inquiry. These demonstrate how structured integration of conversational AI agents can foster reflective learning, offer a reproducible methodology for studying engagement in authentic classroom settings, and support scalable, high-quality higher education.",
    "url": "https://arxiv.org/abs/2510.20255",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of an AI-based educational agent as the primary instructor in a graduate-level Cloud Computing course. The study introduces a pedagogical framework for integrating the AI agent into the course workflow, and evaluates the agent-student interactions using engagement metrics. Early findings suggest that the structured integration of conversational AI agents can enhance reflective learning, provide a methodology for studying engagement in authentic classroom settings, and support scalable, high-quality higher education."
  },
  {
    "title": "Designing a Secure and Resilient Distributed Smartphone Participant Data Collection System",
    "abstract": "Real-world health studies require continuous and secure data collection from mobile and wearable devices. We introduce MotionPI, a smartphone-based system designed to collect behavioral and health data through sensors and surveys with minimal interaction from participants. The system integrates passive data collection (such as GPS and wristband motion data) with Ecological Momentary Assessment (EMA) surveys, which can be triggered randomly or based on physical activity. MotionPI is designed to work under real-life constraints, including limited battery life, weak or intermittent cellular connection, and minimal user supervision. It stores data both locally and on a secure cloud server, with encrypted transmission and storage. It integrates through Bluetooth Low Energy (BLE) into wristband devices that store raw data and communicate motion summaries and trigger events. MotionPI demonstrates a practical solution for secure and scalable mobile data collection in cyber-physical health studies.",
    "url": "https://arxiv.org/abs/2510.19938",
    "journal": "arXiv cs.HC",
    "ai_summary": "The study introduces MotionPI, a smartphone-based system for collecting behavioral and health data from mobile and wearable devices with minimal participant interaction. The system integrates passive data collection with Ecological Momentary Assessment surveys and is designed to work under real-life constraints like limited battery life and weak cellular connection. MotionPI provides a practical and secure solution for scalable mobile data collection in cyber-physical health studies."
  },
  {
    "title": "The Risks of Industry Influence in Tech Research",
    "abstract": "Emerging information technologies like social media, search engines, and AI can have a broad impact on public health, political institutions, social dynamics, and the natural world. It is critical to develop a scientific understanding of these impacts to inform evidence-based technology policy that minimizes harm and maximizes benefits. Unlike most other global-scale scientific challenges, however, the data necessary for scientific progress are generated and controlled by the same industry that might be subject to evidence-based regulation. Moreover, technology companies historically have been, and continue to be, a major source of funding for this field. These asymmetries in information and funding raise significant concerns about the potential for undue industry influence on the scientific record. In this Perspective, we explore how technology companies can influence our scientific understanding of their products. We argue that science faces unique challenges in the context of technology research that will require strengthening existing safeguards and constructing wholly new ones.",
    "url": "https://arxiv.org/abs/2510.19894",
    "journal": "arXiv cs.HC",
    "ai_summary": "The abstract discusses the potential risks of industry influence on research in emerging technologies like social media, search engines, and AI, which have significant impacts on various aspects of society. The data necessary for scientific progress in this field are often controlled by the same technology companies that may be subject to regulation, raising concerns about biased scientific understanding. The authors argue for the need to strengthen existing safeguards and create new ones to prevent undue industry influence on the scientific record in technology research."
  },
  {
    "title": "Prompt Decorators: A Declarative and Composable Syntax for Reasoning, Formatting, and Control in LLMs",
    "abstract": "Large Language Models (LLMs) are central to reasoning, writing, and decision-support workflows, yet users lack consistent control over how they reason and express outputs. Conventional prompt engineering relies on verbose natural-language instructions, limiting reproducibility, modularity, and interpretability. This paper introduces Prompt Decorators, a declarative, composable syntax that governs LLM behavior through compact control tokens such as +++Reasoning, +++Tone(style=formal), and +++Import(topic=\"Systems Thinking\"). Each decorator modifies a behavioral dimension, such as reasoning style, structure, or tone, without changing task content. The framework formalizes twenty core decorators organized into two functional families (Cognitive & Generative and Expressive & Systemic), each further decomposed into subcategories that govern reasoning, interaction, expression, and session-control. It defines a unified syntax, scoping model, and deterministic processing pipeline enabling predictable and auditable behavior composition. By decoupling task intent from execution behavior, Prompt Decorators create a reusable and interpretable interface for prompt design. Illustrative use cases demonstrate improved reasoning transparency, reduced prompt complexity, and standardized model behavior across domains. The paper concludes with implications for interoperability, behavioral consistency, and the development of declarative interfaces for scalable AI systems.",
    "url": "https://arxiv.org/abs/2510.19850",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces Prompt Decorators, a syntax for controlling Large Language Models (LLMs) behavior through compact tokens, allowing users to modify reasoning style, structure, or tone without changing task content. This framework formalizes twenty core decorators organized into functional families, improving reasoning transparency, reducing prompt complexity, and standardizing model behavior across domains. By decoupling task intent from execution behavior, Prompt Decorators create a reusable and interpretable interface for prompt design, with implications for interoperability and scalable AI systems."
  },
  {
    "title": "LifeSync-Games: Toward a Video Game Paradigm for Promoting Responsible Gaming and Human Development",
    "abstract": "Technological advancements have made video games a central part of the digital lives of nearly 3 billion people worldwide. Although games can address various social, physical, and psychological needs, their potential to support human development and well-being remains underutilized. Research highlights both negative effects, such as addiction and isolation, and positive outcomes like cognitive improvements and problem-solving skills. However, public discourse and regulation often focus more on risks than benefits. To address this imbalance, we present LifeSync-Games, a framework leveraging simplified digital twins to connect virtual gameplay with real-life activities. This reciprocal relationship aims to enhance the developmental value of gaming by promoting self-regulation and fostering growth across physical, mental, and social domains. We present the framework's theoretical foundations, technological components, design guidelines, and evaluation approaches. Additionally, we present early applications in both new and bestselling games to demonstrate its versatility and practical relevance.",
    "url": "https://arxiv.org/abs/2510.19691",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research explores the potential of video games to support human development and well-being, highlighting both negative and positive effects of gaming. The LifeSync-Games framework is introduced as a way to enhance the developmental value of gaming by promoting self-regulation and fostering growth across various domains. The framework leverages simplified digital twins to connect virtual gameplay with real-life activities, aiming to address the imbalance between the focus on risks and benefits in public discourse and regulation."
  },
  {
    "title": "Directive, Metacognitive or a Blend of Both? A Comparison of AI-Generated Feedback Types on Student Engagement, Confidence, and Outcomes",
    "abstract": "Feedback is one of the most powerful influences on student learning, with extensive research examining how best to implement it in educational settings. Increasingly, feedback is being generated by artificial intelligence (AI), offering scalable and adaptive responses. Two widely studied approaches are directive feedback, which gives explicit explanations and reduces cognitive load to speed up learning, and metacognitive feedback which prompts learners to reflect, track their progress, and develop self-regulated learning (SRL) skills. While both approaches have clear theoretical advantages, their comparative effects on engagement, confidence, and quality of work remain underexplored. This study presents a semester-long randomised controlled trial with 329 students in an introductory design and programming course using an adaptive educational platform. Participants were assigned to receive directive, metacognitive, or hybrid AI-generated feedback that blended elements of both directive and metacognitive feedback. Results showed that revision behaviour differed across feedback conditions, with Hybrid prompting the most revisions compared to Directive and Metacognitive. Confidence ratings were uniformly high, and resource quality outcomes were comparable across conditions. These findings highlight the promise of AI in delivering feedback that balances clarity with reflection. Hybrid approaches, in particular, show potential to combine actionable guidance for immediate improvement with opportunities for self-reflection and metacognitive growth.",
    "url": "https://arxiv.org/abs/2510.19685",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study compared the effects of directive, metacognitive, and hybrid AI-generated feedback on student engagement, confidence, and outcomes in an introductory design and programming course. Results showed that the hybrid approach, which blended elements of both directive and metacognitive feedback, prompted the most revisions and balanced clarity with reflection. This suggests that AI feedback can effectively combine actionable guidance with opportunities for self-reflection and metacognitive growth in educational settings."
  },
  {
    "title": "Sentiment Analysis of Social Media Data for Predicting Consumer Behavior Trends Using Machine Learning",
    "abstract": "In the era of rapid technological advancement, social media platforms such as Twitter (X) have emerged as indispensable tools for gathering consumer insights, capturing diverse opinions, and understanding public attitudes. This research applies advanced machine learning methods for sentiment analysis on Twitter data, with a focus on predicting consumer trends. Using the Sentiment140 dataset, the study detects evolving patterns in consumer preferences with \"car\" as an example. A structured workflow was used to clean and prepare data for analysis. Machine learning models, including Support Vector Machines (SVM), Naive Bayes, Long Short-Term Memory (LSTM) networks, and Bidirectional Encoder Representations from Transformers (BERT), were employed to classify sentiments and predict trends. Model performance was measured using accuracy, precision, recall, and F1 score, with BERT achieving the highest results (Accuracy: 83.48%, Precision: 79.37%, Recall: 90.60%, F1: 84.61). Results show that LSTM and BERT effectively capture linguistic and contextual patterns, improving prediction accuracy and providing insights into consumer behavior. Temporal analysis revealed sentiment shifts across time, while Named Entity Recognition (NER) identified related terms and themes. This research addresses challenges like sarcasm detection and multilingual data processing, offering a scalable framework for generating actionable consumer insights.",
    "url": "https://arxiv.org/abs/2510.19656",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research utilizes machine learning methods to analyze sentiment on Twitter data and predict consumer behavior trends, focusing on the example of consumer preferences for cars. Various machine learning models were used, with BERT achieving the highest performance in sentiment classification and trend prediction. The study highlights the importance of social media data in understanding consumer behavior and offers a scalable framework for generating actionable insights."
  },
  {
    "title": "Unmanned Aerial Vehicles Control in a Digital Twin: Exploring the Effect of Different Points of View on User Experience in Virtual Reality",
    "abstract": "Controlling Unmanned Aerial Vehicles (UAVs) is a cognitively demanding task, with accidents often arising from insufficient situational awareness, inadequate training, and poor user experiences. Providing more intuitive and immersive visual feedback, particularly through Digital Twin technologies, offers new opportunities to enhance pilot awareness and overall experience quality. In this study, we investigate how different virtual points of view (POVs) influence user experience and performance during UAV piloting in Virtual Reality (VR), utilizing a digital twin that faithfully replicates the real-world flight environment. We developed a VR application that enables participants to control a physical DJI Mini 4 Pro drone while immersed in a digital twin with four distinct camera perspectives: Baseline View (static external), First-Person View, Chase View, and Third-Person View. Nineteen participants completed a series of ring-based obstacle courses from each perspective. In addition to objective flight data, we collected standardized subjective assessments of user experience, presence, workload, cybersickness, and situational awareness. Quantitative analyses revealed that the First-Person View was associated with significantly higher mental demand and effort, greater trajectory deviation, but smoother control inputs compared to the Third-Person and Chase perspectives. Complementing these findings, preference data indicated that the Third-Person View was most consistently favored, whereas the First-Person View elicited polarized reactions.",
    "url": "https://arxiv.org/abs/2510.19604",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores how different virtual points of view (POVs) impact user experience and performance in controlling Unmanned Aerial Vehicles (UAVs) in Virtual Reality (VR) using a digital twin technology. The research found that the First-Person View resulted in higher mental demand and effort, greater trajectory deviation, but smoother control inputs compared to other perspectives. The Third-Person View was most consistently preferred by participants, while the First-Person View elicited mixed reactions, highlighting the importance of considering user experience in UAV control systems."
  },
  {
    "title": "EasyVitessce: auto-magically adding interactivity to Scverse single-cell and spatial biology plots",
    "abstract": "EasyVitessce is a Python package that turns existing static Scanpy and SpatialData plots into interactive visualizations by virtue of adding a single line of Python code. The package uses Vitessce internally to render interactive plots, and abstracts away technical details involved with configuration of Vitessce. The resulting interactive plots can be viewed in computational notebook environments or their configurations can be exported for usage in other contexts such as web applications, enhancing the utility of popular Scverse Python plotting APIs. EasyVitessce is released under the MIT License and available on the Python Package Index (PyPI). The source code is publicly available on GitHub.",
    "url": "https://arxiv.org/abs/2510.19532",
    "journal": "arXiv cs.HC",
    "ai_summary": "EasyVitessce is a Python package that easily adds interactivity to existing static Scanpy and SpatialData plots with just one line of code, using Vitessce internally. This simplifies the process of creating interactive visualizations and allows for easy export of configurations for use in various contexts. The package enhances the utility of popular Scverse Python plotting APIs and is available for use under the MIT License on PyPI and GitHub."
  },
  {
    "title": "Design Considerations for Human Oversight of AI: Insights from Co-Design Workshops and Work Design Theory",
    "abstract": "As AI systems become increasingly capable and autonomous, domain experts' roles are shifting from performing tasks themselves to overseeing AI-generated outputs. Such oversight is critical, as undetected errors can have serious consequences or undermine the benefits of AI. Effective oversight, however, depends not only on detecting and correcting AI errors but also on the motivation and engagement of the oversight personnel and the meaningfulness they see in their work. Yet little is known about how domain experts approach and experience the oversight task and what should be considered to design effective and motivational interfaces that support human oversight. To address these questions, we conducted four co-design workshops with domain experts from psychology and computer science. We asked them to first oversee an AI-based grading system, and then discuss their experiences and needs during oversight. Finally, they collaboratively prototyped interfaces that could support them in their oversight task. Our thematic analysis revealed four key user requirements: understanding tasks and responsibilities, gaining insight into the AI's decision-making, contributing meaningfully to the process, and collaborating with peers and the AI. We integrated these empirical insights with the SMART model of work design to develop a generalizable framework of twelve design considerations. Our framework links interface characteristics and user requirements to the psychological processes underlying effective and satisfying work. Being grounded in work design theory, we expect these considerations to be applicable across domains and discuss how they extend existing guidelines for human-AI interaction and theoretical frameworks for effective human oversight by providing concrete guidance on the design of engaging and meaningful interfaces that support human oversight of AI systems.",
    "url": "https://arxiv.org/abs/2510.19512",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research examines the importance of human oversight in AI systems and the need for effective interfaces to support this oversight. Through co-design workshops with domain experts, the study identified key user requirements for successful oversight, including understanding tasks, gaining insight into AI decision-making, contributing meaningfully, and collaborating with peers and AI. The findings led to the development of a framework of twelve design considerations grounded in work design theory, which aims to provide concrete guidance for designing engaging and meaningful interfaces for human oversight of AI systems."
  },
  {
    "title": "Learning To Defer To A Population With Limited Demonstrations",
    "abstract": "This paper addresses the critical data scarcity that hinders the practical deployment of learning to defer (L2D) systems to the population. We introduce a context-aware, semi-supervised framework that uses meta-learning to generate expert-specific embeddings from only a few demonstrations. We demonstrate the efficacy of a dual-purpose mechanism, where these embeddings are used first to generate a large corpus of pseudo-labels for training, and subsequently to enable on-the-fly adaptation to new experts at test-time. The experiment results on three different datasets confirm that a model trained on these synthetic labels rapidly approaches oracle-level performance, validating the data efficiency of our approach. By resolving a key training bottleneck, this work makes adaptive L2D systems more practical and scalable, paving the way for human-AI collaboration in real-world environments. To facilitate reproducibility and address implementation details not covered in the main text, we provide our source code and training configurations at this https URL.",
    "url": "https://arxiv.org/abs/2510.19351",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces a new framework for learning to defer systems that can adapt to new experts with limited demonstrations. By using meta-learning to generate expert-specific embeddings and training on synthetic labels, the model achieves near-oracle performance with minimal data. This approach addresses data scarcity issues and makes adaptive learning systems more practical and scalable for human-AI collaboration in real-world environments."
  },
  {
    "title": "LLMartini: Seamless and Interactive Leveraging of Multiple LLMs through Comparison and Composition",
    "abstract": "The growing diversity of large language models (LLMs) means users often need to compare and combine outputs from different models to obtain higher-quality or more comprehensive responses. However, switching between separate interfaces and manually integrating outputs is inherently inefficient, leading to a high cognitive burden and fragmented workflows. To address this, we present LLMartini, a novel interactive system that supports seamless comparison, selection, and intuitive cross-model composition tools. The system decomposes responses into semantically aligned segments based on task-specific criteria, automatically merges consensus content, and highlights model differences through color coding while preserving unique contributions. In a user study (N=18), LLMartini significantly outperformed conventional manual methods across all measured metrics, including task completion time, cognitive load, and user satisfaction. Our work highlights the importance of human-centered design in enhancing the efficiency and creativity of multi-LLM interactions and offers practical implications for leveraging the complementary strengths of various language models.",
    "url": "https://arxiv.org/abs/2510.19252",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces LLMartini, an interactive system designed to streamline the comparison and combination of outputs from multiple large language models (LLMs). LLMartini automatically merges consensus content, highlights model differences, and allows users to easily select and compose responses from different models. In a user study, LLMartini outperformed conventional manual methods in terms of task completion time, cognitive load, and user satisfaction, demonstrating the importance of human-centered design in improving the efficiency and creativity of multi-LLM interactions."
  },
  {
    "title": "When Strings Tug at Algorithm: Human-AI Sovereignty and Entanglement in Nomadic Improvisational Music Performance as a Decolonial Exploration",
    "abstract": "As emergent artificial intelligence technologies increasingly assert roles as assistants within intangible cultural heritage contexts, researchers and artists observe existing questions on the theme of agency negotiation, cultural resistance, and technical critique. This research interrogates power dynamics in human-AI sovereignty and entanglement for nomadic improvisational Dutar performance, a living cultural heritage through a long-necked lute from the Central Asia region. To investigate tensions between human agency and computational hegemony, the researcher and artists examined and iterated a feedback workflow that captures live performance data, processes digital transformations, and creates a real-time interactive art experience via immersive environments. Empirical data from artists and audience reveal modulations where musicians selectively embrace or reject algorithmic suggestions to preserve creative identity. The author concludes that decolonial potential requires redesigning tools or systems for cultural survivance, where technology becomes not merely a feedback environment but a site for decolonial praxis, challenging computational hegemony in digital ecosystems.",
    "url": "https://arxiv.org/abs/2510.19086",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the dynamics of human-AI interaction in nomadic improvisational music performance, specifically focusing on Dutar performance from Central Asia. Through a feedback workflow capturing live performance data and creating interactive art experiences, the study reveals how musicians navigate between embracing or rejecting algorithmic suggestions to maintain their creative identity. The findings suggest the importance of redesigning tools and systems to support cultural survivance and challenge computational hegemony in digital ecosystems."
  },
  {
    "title": "\"Over-the-Hood\" AI Inclusivity Bugs and How 3 AI Product Teams Found and Fixed Them",
    "abstract": "While much research has shown the presence of AI's \"under-the-hood\" biases (e.g., algorithmic, training data, etc.), what about \"over-the-hood\" inclusivity biases: barriers in user-facing AI products that disproportionately exclude users with certain problem-solving approaches? Recent research has begun to report the existence of such biases -- but what do they look like, how prevalent are they, and how can developers find and fix them? To find out, we conducted a field study with 3 AI product teams, to investigate what kinds of AI inclusivity bugs exist uniquely in user-facing AI products, and whether/how AI product teams might harness an existing (non-AI-oriented) inclusive design method to find and fix them. The teams' work resulted in identifying 6 types of AI inclusivity bugs arising 83 times, fixes covering 47 of these bug instances, and a new variation of the GenderMag inclusive design method, GenderMag-for-AI, that is especially effective at detecting certain kinds of AI inclusivity bugs.",
    "url": "https://arxiv.org/abs/2510.19033",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the concept of \"over-the-hood\" inclusivity biases in user-facing AI products, which can disproportionately exclude certain users. The study conducted with 3 AI product teams identified 6 types of AI inclusivity bugs and found that using an inclusive design method, GenderMag-for-AI, was effective in detecting and fixing these bugs. This research highlights the importance of addressing inclusivity issues in AI products and provides a practical approach for developers to improve inclusivity."
  },
  {
    "title": "CLiVR: Conversational Learning System in Virtual Reality with AI-Powered Patients",
    "abstract": "Simulations constitute a fundamental component of medical and nursing education and traditionally employ standardized patients (SP) and high-fidelity manikins to develop clinical reasoning and communication skills. However, these methods require substantial resources, limiting accessibility and scalability. In this study, we introduce CLiVR, a Conversational Learning system in Virtual Reality that integrates large language models (LLMs), speech processing, and 3D avatars to simulate realistic doctor-patient interactions. Developed in Unity and deployed on the Meta Quest 3 platform, CLiVR enables trainees to engage in natural dialogue with virtual patients. Each simulation is dynamically generated from a syndrome-symptom database and enhanced with sentiment analysis to provide feedback on communication tone. Through an expert user study involving medical school faculty (n=13), we assessed usability, realism, and perceived educational impact. Results demonstrated strong user acceptance, high confidence in educational potential, and valuable feedback for improvement. CLiVR offers a scalable, immersive supplement to SP-based training.",
    "url": "https://arxiv.org/abs/2510.19031",
    "journal": "arXiv cs.HC",
    "ai_summary": "The study introduces CLiVR, a Conversational Learning system in Virtual Reality that uses AI-powered virtual patients to simulate realistic doctor-patient interactions. Developed in Unity and deployed on the Meta Quest 3 platform, CLiVR enables trainees to engage in natural dialogue and receive feedback on communication tone. An expert user study showed strong user acceptance, high confidence in educational potential, and valuable feedback for improvement, indicating that CLiVR offers a scalable and immersive supplement to traditional medical training methods."
  },
  {
    "title": "Examining the Impact of Label Detail and Content Stakes on User Perceptions of AI-Generated Images on Social Media",
    "abstract": "AI-generated images are increasingly prevalent on social media, raising concerns about trust and authenticity. This study investigates how different levels of label detail (basic, moderate, maximum) and content stakes (high vs. low) influence user engagement with and perceptions of AI-generated images through a within-subjects experimental study with 105 participants. Our findings reveal that increasing label detail enhances user perceptions of label transparency but does not affect user engagement. However, content stakes significantly impact user engagement and perceptions, with users demonstrating higher engagement and trust in low-stakes images. These results suggest that social media platforms can adopt detailed labels to improve transparency without compromising user engagement, offering insights for effective labeling strategies for AI-generated content.",
    "url": "https://arxiv.org/abs/2510.19024",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study examines how the level of label detail and content stakes impact user perceptions of AI-generated images on social media. The research found that increasing label detail improves transparency but does not affect user engagement, while content stakes significantly influence user engagement and trust, with users showing higher engagement with low-stakes images. These results suggest that social media platforms can use detailed labels to enhance transparency without sacrificing user engagement, providing valuable insights for labeling strategies for AI-generated content."
  },
  {
    "title": "SocializeChat: A GPT-Based AAC Tool Grounded in Personal Memories to Support Social Communication",
    "abstract": "Elderly people with speech impairments often face challenges in engaging in meaningful social communication, particularly when using Augmentative and Alternative Communication (AAC) tools that primarily address basic needs. Moreover, effective chats often rely on personal memories, which is hard to extract and reuse. We introduce SocializeChat, an AAC tool that generates sentence suggestions by drawing on users' personal memory records. By incorporating topic preference and interpersonal closeness, the system reuses past experience and tailors suggestions to different social contexts and conversation partners. SocializeChat not only leverages past experiences to support interaction, but also treats conversations as opportunities to create new memories, fostering a dynamic cycle between memory and communication. A user study shows its potential to enhance the inclusivity and relevance of AAC-supported social interaction.",
    "url": "https://arxiv.org/abs/2510.19017",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces SocializeChat, an AAC tool for elderly people with speech impairments that generates personalized sentence suggestions based on personal memory records. By incorporating topic preference and interpersonal closeness, the system tailors suggestions to different social contexts and conversation partners, enhancing inclusivity and relevance in AAC-supported social interactions. The tool not only leverages past experiences to support interaction but also fosters a dynamic cycle between memory and communication, treating conversations as opportunities to create new memories."
  },
  {
    "title": "Plural Voices, Single Agent: Towards Inclusive AI in Multi-User Domestic Spaces",
    "abstract": "Domestic AI agents faces ethical, autonomy, and inclusion challenges, particularly for overlooked groups like children, elderly, and Neurodivergent users. We present the Plural Voices Model (PVM), a novel single-agent framework that dynamically negotiates multi-user needs through real-time value alignment, leveraging diverse public datasets on mental health, eldercare, education, and moral reasoning. Using human+synthetic curriculum design with fairness-aware scenarios and ethical enhancements, PVM identifies core values, conflicts, and accessibility requirements to inform inclusive principles. Our privacy-focused prototype features adaptive safety scaffolds, tailored interactions (e.g., step-by-step guidance for Neurodivergent users, simple wording for children), and equitable conflict resolution. In preliminary evaluations, PVM outperforms multi-agent baselines in compliance (76% vs. 70%), fairness (90% vs. 85%), safety-violation rate (0% vs. 7%), and latency. Design innovations, including video guidance, autonomy sliders, family hubs, and adaptive safety dashboards, demonstrate new directions for ethical and inclusive domestic AI, for building user-centered agentic systems in plural domestic contexts. Our Codes and Model are been open sourced, available for reproduction: this https URL",
    "url": "https://arxiv.org/abs/2510.19008",
    "journal": "arXiv cs.HC",
    "ai_summary": "The Plural Voices Model (PVM) is a single-agent framework designed to address ethical and inclusion challenges in domestic AI agents for diverse user groups. Through real-time value alignment and leveraging diverse datasets, PVM identifies core values, conflicts, and accessibility requirements to inform inclusive principles. Preliminary evaluations show that PVM outperforms multi-agent baselines in compliance, fairness, safety, and latency, highlighting the importance of designing user-centered agentic systems in plural domestic contexts."
  },
  {
    "title": "Detecting AI-Assisted Cheating in Online Exams through Behavior Analytics",
    "abstract": "AI-assisted cheating has emerged as a significant threat in the context of online exams. Advanced browser extensions now enable large language models (LLMs) to answer questions presented in online exams within seconds, thereby compromising the security of these assessments. In this study, the behaviors of students (N = 52) on an online exam platform during a proctored, face-to-face exam were analyzed using clustering methods, with the aim of identifying groups of students exhibiting suspicious behavior potentially associated with cheating. Additionally, students in different clusters were compared in terms of their exam scores. Suspicious exam behaviors in this study were defined as selecting text within the question area, right-clicking, and losing focus on the exam page. The total frequency of these behaviors performed by each student during the exam was extracted, and k-Means clustering was employed for the analysis. The findings revealed that students were classified into six clusters based on their suspicious behaviors. It was found that students in four of the six clusters, representing approximately 33% of the total sample, exhibited suspicious behaviors at varying levels. When the exam scores of these students were compared, it was observed that those who engaged in suspicious behaviors scored, on average, 30-40 points higher than those who did not. Although further research is necessary to validate these findings, this preliminary study provides significant insights into the detection of AI-assisted cheating in online exams using behavior analytics.",
    "url": "https://arxiv.org/abs/2510.18881",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study focused on detecting AI-assisted cheating in online exams through behavior analytics. By analyzing the behaviors of students during a proctored exam, the researchers identified clusters of students exhibiting suspicious behaviors associated with cheating, such as selecting text within the question area and right-clicking. The findings revealed that approximately 33% of the students displayed suspicious behaviors and scored higher on the exam, indicating a potential link between cheating behaviors and exam performance. Further research is needed to validate these findings, but this study offers valuable insights into detecting cheating in online exams using behavior analytics."
  },
  {
    "title": "Towards Better Health Conversations: The Benefits of Context-seeking",
    "abstract": "Navigating health questions can be daunting in the modern information landscape. Large language models (LLMs) may provide tailored, accessible information, but also risk being inaccurate, biased or misleading. We present insights from 4 mixed-methods studies (total N=163), examining how people interact with LLMs for their own health questions. Qualitative studies revealed the importance of context-seeking in conversational AIs to elicit specific details a person may not volunteer or know to share. Context-seeking by LLMs was valued by participants, even if it meant deferring an answer for several turns. Incorporating these insights, we developed a \"Wayfinding AI\" to proactively solicit context. In a randomized, blinded study, participants rated the Wayfinding AI as more helpful, relevant, and tailored to their concerns compared to a baseline AI. These results demonstrate the strong impact of proactive context-seeking on conversational dynamics, and suggest design patterns for conversational AI to help navigate health topics.",
    "url": "https://arxiv.org/abs/2510.18880",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores how people interact with large language models (LLMs) for health questions and the importance of context-seeking in conversational AIs. The study found that participants valued context-seeking by LLMs, even if it meant delaying an answer. A \"Wayfinding AI\" was developed based on these insights, which was rated as more helpful and tailored by participants compared to a baseline AI, highlighting the significance of proactive context-seeking in improving health conversations with AI."
  },
  {
    "title": "FIRETWIN: Digital Twin Advancing Multi-Modal Sensing, Interactive Analytics for Wildfire Response",
    "abstract": "Current wildfire management systems lack integrated virtual environments that combine historical data with immersive digital representations, hindering deep analysis and effective decision making. This paper introduces FIRETWIN, a cyber-physical Digital Twin (DT) designed to bridge complex ecological data and operationally relevant, high-fidelity visualizations for actionable incident response. FIRETWIN generates a dynamic 3D virtual globe that visualizes evolving fire behavior in real time, driven by output from physics-based fire models. The system supports multimodal perspectives, including satellite and drone viewpoints comparable to NOAA GOES-18 imagery - enabling comprehensive scenario analysis. Users interact with the environment to assess current fire conditions, anticipate progression, and evaluate available resources. Leveraging Google Maps, Unreal Engine, and pre-generated outputs from the CAWFE coupled weather-wildland fire model, we reconstruct the spread of the 2014 King Fire in California Eldorado National Forest. Procedural forest generation and particle-level fire control enable a level of realism and interactivity not possible in field training.",
    "url": "https://arxiv.org/abs/2510.18879",
    "journal": "arXiv cs.HC",
    "ai_summary": "The paper introduces FIRETWIN, a cyber-physical Digital Twin system that combines historical data with immersive visualizations to support effective wildfire response. The system generates a dynamic 3D virtual globe to visualize real-time fire behavior, allowing users to assess current conditions, anticipate progression, and evaluate resources. By leveraging advanced technologies and physics-based fire models, FIRETWIN provides a high level of realism and interactivity for comprehensive scenario analysis and decision-making in wildfire management."
  },
  {
    "title": "CityAQVis: Integrated ML-Visualization Sandbox Tool for Pollutant Estimation in Urban Regions Using Multi-Source Data (Software Article)",
    "abstract": "Urban air pollution poses significant risks to public health, environmental sustainability, and policy planning. Effective air quality management requires predictive tools that can integrate diverse datasets and communicate complex spatial and temporal pollution patterns. There is a gap in interactive tools with seamless integration of forecasting and visualization of spatial distributions of air pollutant concentrations. We present CityAQVis, an interactive machine learning ML sandbox tool designed to predict and visualize pollutant concentrations at the ground level using multi-source data, which includes satellite observations, meteorological parameters, population density, elevation, and nighttime lights. While traditional air quality visualization tools often lack forecasting capabilities, CityAQVis enables users to build and compare predictive models, visualizing the model outputs and offering insights into pollution dynamics at the ground level. The pilot implementation of the tool is tested through case studies predicting nitrogen dioxide (NO2) concentrations in metropolitan regions, highlighting its adaptability to various pollutants. Through an intuitive graphical user interface (GUI), the user can perform comparative visualizations of the spatial distribution of surface-level pollutant concentration in two different urban scenarios. Our results highlight the potential of ML-driven visual analytics to improve situational awareness and support data-driven decision-making in air quality management.",
    "url": "https://arxiv.org/abs/2510.18878",
    "journal": "arXiv cs.HC",
    "ai_summary": "CityAQVis is an interactive ML sandbox tool that predicts and visualizes pollutant concentrations in urban areas using multi-source data. It fills a gap in existing tools by integrating forecasting capabilities with visualization, allowing users to build and compare predictive models for air pollutants. The tool has been tested in case studies predicting nitrogen dioxide concentrations in metropolitan regions, demonstrating its potential to enhance situational awareness and support data-driven decision-making in air quality management."
  },
  {
    "title": "LLM Bazaar: A Service Design for Supporting Collaborative Learning with an LLM-Powered Multi-Party Collaboration Infrastructure",
    "abstract": "For nearly two decades, conversational agents have played a critical role in structuring interactions in collaborative learning, shaping group dynamics, and supporting student engagement. The recent integration of large language models (LLMs) into these agents offers new possibilities for fostering critical thinking and collaborative problem solving. In this work, we begin with an open source collaboration support architecture called Bazaar and integrate an LLM-agent shell that enables introduction of LLM-empowered, real time, context sensitive collaborative support for group learning. This design and infrastructure paves the way for exploring how tailored LLM-empowered environments can reshape collaborative learning outcomes and interaction patterns.",
    "url": "https://arxiv.org/abs/2510.18877",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the integration of large language models (LLMs) into conversational agents to enhance collaborative learning experiences. By incorporating an LLM-agent shell into the Bazaar collaboration support architecture, the study demonstrates the potential for real-time, context-sensitive collaborative support in group learning settings. The findings suggest that tailored LLM-empowered environments have the potential to reshape collaborative learning outcomes and interaction patterns."
  },
  {
    "title": "Integrating Transparent Models, LLMs, and Practitioner-in-the-Loop: A Case of Nonprofit Program Evaluation",
    "abstract": "Public and nonprofit organizations often hesitate to adopt AI tools because most models are opaque even though standard approaches typically analyze aggregate patterns rather than offering actionable, case-level guidance. This study tests a practitioner-in-the-loop workflow that pairs transparent decision-tree models with large language models (LLMs) to improve predictive accuracy, interpretability, and the generation of practical insights. Using data from an ongoing college-success program, we build interpretable decision trees to surface key predictors. We then provide each tree's structure to an LLM, enabling it to reproduce case-level predictions grounded in the transparent models. Practitioners participate throughout feature engineering, model design, explanation review, and usability assessment, ensuring that field expertise informs the analysis at every stage. Results show that integrating transparent models, LLMs, and practitioner input yields accurate, trustworthy, and actionable case-level evaluations, offering a viable pathway for responsible AI adoption in the public and nonprofit sectors.",
    "url": "https://arxiv.org/abs/2510.19799",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores a new approach to AI in nonprofit program evaluation by combining transparent decision-tree models with large language models (LLMs) and practitioner input. By involving practitioners throughout the process and focusing on case-level guidance, the researchers were able to improve predictive accuracy, interpretability, and the generation of practical insights. The results demonstrate that this integrated approach can lead to accurate, trustworthy, and actionable evaluations, providing a pathway for responsible AI adoption in the public and nonprofit sectors."
  },
  {
    "title": "Cultural Dimensions of Artificial Intelligence Adoption: Empirical Insights for Wave 1 from a Multinational Longitudinal Pilot Study",
    "abstract": "The swift diffusion of artificial intelligence (AI) raises critical questions about how cultural contexts shape adoption patterns and their consequences for human daily life. This study investigates the cultural dimensions of AI adoption and their influence on cognitive strategies across nine national contexts in Europe, Africa, Asia, and South America. Drawing on survey data from a diverse pilot sample (n = 21) and guided by cross-cultural psychology, digital ethics, and sociotechnical systems theory, we examine how demographic variables (age, gender, professional role) and cultural orientations (language, values, and institutional exposure) mediate perceptions of trust, ethical acceptability, and reliance on AI. Results reveal two key findings: First, cultural factors, particularly language and age, significantly affect AI adoption and perceptions of reliability with older participants reporting higher engagement with AI for educational purposes. Second, ethical judgment about AI use varied across domains, with professional contexts normalizing its role as a pragmatic collaborator while academic settings emphasized risks of plagiarism. These findings extend prior research on culture and technology adoption by demonstrating that AI use is neither universal nor neutral but culturally contingent, domain-specific, and ethically situated. The study highlights implications for AI use in education, professional practice, and global technology policy, pointing at actions that enable usage of AI in a way that is both culturally adaptive and ethically robust.",
    "url": "https://arxiv.org/abs/2510.19743",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores how cultural factors influence the adoption of artificial intelligence (AI) and perceptions of trust, ethical acceptability, and reliance on AI across nine national contexts. Key findings include the significant impact of cultural factors such as language and age on AI adoption, with older participants more likely to engage with AI for educational purposes. Additionally, ethical judgments about AI use varied across different domains, with professional settings viewing AI as a pragmatic collaborator and academic settings focusing on the risks of plagiarism. The study emphasizes the importance of considering cultural differences in AI adoption and highlights implications for education, professional practice, and global technology policy."
  },
  {
    "title": "From Prototypes to Sparse ECG Explanations: SHAP-Driven Counterfactuals for Multivariate Time-Series Multi-class Classification",
    "abstract": "In eXplainable Artificial Intelligence (XAI), instance-based explanations for time series have gained increasing attention due to their potential for actionable and interpretable insights in domains such as healthcare. Addressing the challenges of explainability of state-of-the-art models, we propose a prototype-driven framework for generating sparse counterfactual explanations tailored to 12-lead ECG classification models. Our method employs SHAP-based thresholds to identify critical signal segments and convert them into interval rules, uses Dynamic Time Warping (DTW) and medoid clustering to extract representative prototypes, and aligns these prototypes to query R-peaks for coherence with the sample being explained. The framework generates counterfactuals that modify only 78% of the original signal while maintaining 81.3% validity across all classes and achieving 43% improvement in temporal stability. We evaluate three variants of our approach, Original, Sparse, and Aligned Sparse, with class-specific performance ranging from 98.9% validity for myocardial infarction (MI) to challenges with hypertrophy (HYP) detection (13.2%). This approach supports near realtime generation (< 1 second) of clinically valid counterfactuals and provides a foundation for interactive explanation platforms. Our findings establish design principles for physiologically-aware counterfactual explanations in AI-based diagnosis systems and outline pathways toward user-controlled explanation interfaces for clinical deployment.",
    "url": "https://arxiv.org/abs/2510.19514",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research proposes a prototype-driven framework for generating sparse counterfactual explanations for 12-lead ECG classification models, addressing the challenges of explainability in AI models. The framework generates counterfactuals that modify only 78% of the original signal while maintaining high validity across all classes and improving temporal stability. This approach supports near real-time generation of clinically valid counterfactuals and provides a foundation for interactive explanation platforms in AI-based diagnosis systems."
  },
  {
    "title": "Interactive visualization of kidney micro-compartmental segmentations and associated pathomics on whole slide images",
    "abstract": "Application of machine learning techniques enables segmentation of functional tissue units in histology whole-slide images (WSIs). We built a pipeline to apply previously validated segmentation models of kidney structures and extract quantitative features from these structures. Such quantitative analysis also requires qualitative inspection of results for quality control, exploration, and communication. We extend the Vitessce web-based visualization tool to enable visualization of segmentations of multiple types of functional tissue units, such as, glomeruli, tubules, arteries/arterioles in the kidney. Moreover, we propose a standard representation for files containing multiple segmentation bitmasks, which we define polymorphically, such that existing formats including OME-TIFF, OME-NGFF, AnnData, MuData, and SpatialData can be used. We demonstrate that these methods enable researchers and the broader public to interactively explore datasets containing multiple segmented entities and associated features, including for exploration of renal morphometry of biopsies from the Kidney Precision Medicine Project (KPMP) and the Human Biomolecular Atlas Program (HuBMAP).",
    "url": "https://arxiv.org/abs/2510.19499",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on using machine learning techniques to segment functional tissue units in kidney histology whole-slide images. The study developed a pipeline to extract quantitative features from these structures and extended a web-based visualization tool to enable interactive visualization of segmentations of various kidney structures. This work allows for qualitative inspection of results, quality control, and exploration of datasets containing multiple segmented entities, which can be valuable for researchers studying renal morphometry in projects like the Kidney Precision Medicine Project and the Human Biomolecular Atlas Program."
  },
  {
    "title": "See, Think, Act: Online Shopper Behavior Simulation with VLM Agents",
    "abstract": "LLMs have recently demonstrated strong potential in simulating online shopper behavior. Prior work has improved action prediction by applying SFT on action traces with LLM-generated rationales, and by leveraging RL to further enhance reasoning capabilities. Despite these advances, current approaches rely on text-based inputs and overlook the essential role of visual perception in shaping human decision-making during web GUI interactions. In this paper, we investigate the integration of visual information, specifically webpage screenshots, into behavior simulation via VLMs, leveraging OPeRA dataset. By grounding agent decision-making in both textual and visual modalities, we aim to narrow the gap between synthetic agents and real-world users, thereby enabling more cognitively aligned simulations of online shopping behavior. Specifically, we employ SFT for joint action prediction and rationale generation, conditioning on the full interaction context, which comprises action history, past HTML observations, and the current webpage screenshot. To further enhance reasoning capabilities, we integrate RL with a hierarchical reward structure, scaled by a difficulty-aware factor that prioritizes challenging decision points. Empirically, our studies show that incorporating visual grounding yields substantial gains: the combination of text and image inputs improves exact match accuracy by more than 6% over text-only inputs. These results indicate that multi-modal grounding not only boosts predictive accuracy but also enhances simulation fidelity in visually complex environments, which captures nuances of human attention and decision-making that text-only agents often miss. Finally, we revisit the design space of behavior simulation frameworks, identify key methodological limitations, and propose future research directions toward building efficient and effective human behavior simulators.",
    "url": "https://arxiv.org/abs/2510.19245",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the integration of visual information, specifically webpage screenshots, into behavior simulations using VLM agents to better simulate online shopper behavior. By combining text and image inputs, the study found a significant improvement in predictive accuracy and simulation fidelity in visually complex environments. The findings suggest that multi-modal grounding can capture nuances of human decision-making that text-only agents may overlook, leading to more cognitively aligned simulations of online shopping behavior."
  }
]