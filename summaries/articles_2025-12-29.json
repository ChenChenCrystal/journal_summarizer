[
  {
    "title": "Context-Aware Intelligent Chatbot Framework Leveraging Mobile Sensing",
    "abstract": "With the rapid advancement of large language models (LLMs), intelligent conversational assistants have demonstrated remarkable capabilities across various domains. However, they still mainly rely on explicit textual input and do not know the real world behaviors of users. This paper proposes a context-sensitive conversational assistant framework grounded in mobile sensing data. By collecting user behavior and environmental data through smartphones, we abstract these signals into 16 contextual scenarios and translate them into natural language prompts, thus improving the model's understanding of the user's state. We design a structured prompting system to guide the LLM in generating a more personalized and contextually relevant dialogue. This approach integrates mobile sensing with large language models, demonstrating the potential of passive behavioral data in intelligent conversation and offering a viable path toward digital health and personalized interaction.",
    "url": "https://arxiv.org/abs/2512.22032",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper introduces a context-aware chatbot framework that uses mobile sensing data to enhance the understanding of user behavior and environment. By collecting and analyzing data from smartphones, the framework can generate personalized and contextually relevant prompts for intelligent conversation. This integration of mobile sensing with large language models shows promise for applications in digital health and personalized interaction."
  },
  {
    "title": "SketchPlay: Intuitive Creation of Physically Realistic VR Content with Gesture-Driven Sketching",
    "abstract": "Creating physically realistic content in VR often requires complex modeling tools or predefined 3D models, textures, and animations, which present significant barriers for non-expert users. In this paper, we propose SketchPlay, a novel VR interaction framework that transforms humans' air-drawn sketches and gestures into dynamic, physically realistic scenes, making content creation intuitive and playful like drawing. Specifically, sketches capture the structure and spatial arrangement of objects and scenes, while gestures convey physical cues such as velocity, direction, and force that define movement and behavior. By combining these complementary forms of input, SketchPlay captures both the structure and dynamics of user-created content, enabling the generation of a wide range of complex physical phenomena, such as rigid body motion, elastic deformation, and cloth dynamics. Experimental results demonstrate that, compared to traditional text-driven methods, SketchPlay offers significant advantages in expressiveness, and user experience. By providing an intuitive and engaging creation process, SketchPlay lowers the entry barrier for non-expert users and shows strong potential for applications in education, art, and immersive storytelling.",
    "url": "https://arxiv.org/abs/2512.22016",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces SketchPlay, a VR interaction framework that allows users to create physically realistic content through air-drawn sketches and gestures. This approach simplifies content creation for non-expert users by capturing both structure and dynamics of objects and scenes, enabling the generation of complex physical phenomena. Experimental results show that SketchPlay offers significant advantages in expressiveness and user experience, making it a promising tool for applications in education, art, and immersive storytelling."
  },
  {
    "title": "Positive Narrativity Enhances Sense of Agency toward a VR Avatar",
    "abstract": "The full-body illusion (FBI) refers to the experience of perceiving a virtual avatar as one's own body. In virtual reality (VR) environments, inducing the FBI has been shown to modulate users' bodily experiences and behavior. Previous studies have demonstrated that embodying avatars with specific characteristics can influence users' actions, largely through the activation of implicit stereotypes. However, few studies have explicitly manipulated users' impressions of an avatar by introducing narrative context. The present study investigated how avatar narrativity, induced through contextual narratives, affects the FBI. Healthy participants embodied a powerful artificial lifeform avatar in VR after listening to either a positive narrative, in which the avatar used its abilities to protect others, or a negative narrative, in which it misused its power. Participants' impressions of the avatar and indices of bodily self-consciousness were subsequently assessed. The results showed that positive narratives significantly enhanced the sense of agency (SoA), and that SoA was positively correlated with participants' perceived personal familiarity with the avatar. These findings suggest that the avatar narrativity can modulate embodiment in VR.",
    "url": "https://arxiv.org/abs/2512.21968",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores how introducing positive or negative narratives about a virtual avatar can influence users' sense of agency and embodiment in virtual reality environments. The results show that positive narratives significantly enhance the sense of agency, and that this is correlated with participants' perceived familiarity with the avatar. This suggests that avatar narrativity can play a significant role in shaping users' experiences and interactions in VR."
  },
  {
    "title": "Generative Lecture: Making Lecture Videos Interactive with LLMs and AI Clone Instructors",
    "abstract": "We introduce Generative Lecture, a concept that makes existing lecture videos interactive through generative AI and AI clone instructors. By leveraging interactive avatars powered by HeyGen, ElevenLabs, and GPT-5, we embed an AI instructor into the video and augment the video content in response to students' questions. This allows students to personalize the lecture material, directly ask questions in the video, and receive tailored explanations generated and delivered by the AI-cloned instructor. From a design elicitation study (N=8), we identified four goals that guided the development of eight system features: 1) on-demand clarification, 2) enhanced visuals, 3) interactive example, 4) personalized explanation, 5) adaptive quiz, 6) study summary, 7) automatic highlight, and 8) adaptive break. We then conducted a user study (N=12) to evaluate the usability and effectiveness of the system and collected expert feedback (N=5). The results suggest that our system enables effective two-way communication and supports personalized learning.",
    "url": "https://arxiv.org/abs/2512.21796",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces Generative Lecture, a concept that uses generative AI and AI clone instructors to make existing lecture videos interactive. By embedding an AI instructor into the video, students can personalize the lecture material, ask questions, and receive tailored explanations. The study identified four goals and developed eight system features to enhance the interactive experience, with results suggesting that the system enables effective two-way communication and supports personalized learning."
  },
  {
    "title": "Modified TSception for Analyzing Driver Drowsiness and Mental Workload from EEG",
    "abstract": "Driver drowsiness remains a primary cause of traffic accidents, necessitating the development of real-time, reliable detection systems to ensure road safety. This study presents a Modified TSception architecture designed for the robust assessment of driver fatigue using Electroencephalography (EEG). The model introduces a novel hierarchical architecture that surpasses the original TSception by implementing a five-layer temporal refinement strategy to capture multi-scale brain dynamics. A key innovation is the use of Adaptive Average Pooling, which provides the structural flexibility to handle varying EEG input dimensions, and a two - stage fusion mechanism that optimizes the integration of spatiotemporal features for improved stability. When evaluated on the SEED-VIG dataset and compared against established methods - including SVM, Transformer, EEGNet, ConvNeXt, LMDA-Net, and the original TSception - the Modified TSception achieves a comparable accuracy of 83.46% (vs. 83.15% for the original). Critically, the proposed model exhibits a substantially reduced confidence interval (0.24 vs. 0.36), signifying a marked improvement in performance stability. Furthermore, the architecture's generalizability is validated on the STEW mental workload dataset, where it achieves state-of-the-art results with 95.93% and 95.35% accuracy for 2-class and 3-class classification, respectively. These improvements in consistency and cross-task generalizability underscore the effectiveness of the proposed modifications for reliable EEG-based monitoring of drowsiness and mental workload.",
    "url": "https://arxiv.org/abs/2512.21747",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study introduces a Modified TSception architecture for detecting driver drowsiness using EEG, which outperforms the original TSception model by incorporating a five-layer temporal refinement strategy and Adaptive Average Pooling. The model achieves a comparable accuracy of 83.46% with improved stability and generalizability, as demonstrated on the SEED-VIG and STEW datasets. These enhancements highlight the potential of the Modified TSception for reliable EEG-based monitoring of drowsiness and mental workload in real-time driving scenarios."
  },
  {
    "title": "Ghostcrafting AI: Under the Rug of Platform Labor",
    "abstract": "Platform laborers play an indispensable yet hidden role in building and sustaining AI systems. Drawing on an eight-month ethnography of Bangladesh's platform labor industry and inspired by Gray and Suri, we conceptualize Ghostcrafting AI to describe how workers materially enable AI while remaining invisible or erased from recognition. Workers pursue platform labor as a path to prestige and mobility but sustain themselves through resourceful, situated learning - renting cyber-cafe computers, copying gig templates, following tutorials in unfamiliar languages, and relying on peer networks. At the same time, they face exploitative wages, unreliable payments, biased algorithms, and governance structures that make their labor precarious and invisible. To cope, they develop tactical repertoires such as identity masking, bypassing platform fees, and pirated tools. These practices reveal both AI's dependency on ghostcrafted labor and the urgent need for design, policy, and governance interventions that ensure fairness, recognition, and sustainability in platform futures.",
    "url": "https://arxiv.org/abs/2512.21649",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research highlights the hidden role of platform laborers in building and sustaining AI systems, termed Ghostcrafting AI. Despite their invisibility, these workers play a crucial role in enabling AI through resourceful learning methods and coping strategies. The study emphasizes the exploitative conditions faced by these workers and calls for interventions to ensure fairness, recognition, and sustainability in platform labor."
  },
  {
    "title": "Emotion-Aware Smart Home Automation Based on the eBICA Model",
    "abstract": "Smart home automation that adapts to a user's emotional state can enhance psychological safety in daily living environments. This study proposes an emotion-aware automation framework guided by the emotional Biologically Inspired Cognitive Architecture (eBICA), which integrates appraisal, somatic responses, and behavior selection. We conducted a proof-of-concept experiment in a pseudo-smart-home environment, where participants were exposed to an anxiety-inducing event followed by a comfort-inducing automation. State anxiety (STAI-S) was measured throughout the task sequence. The results showed a significant reduction in STAI-S immediately after introducing the avoidance automation, demonstrating that emotion-based control can effectively promote psychological safety. Furthermore, an analysis of individual characteristics suggested that personality and anxiety-related traits modulate the degree of relief, indicating the potential for personalized emotion-adaptive automation. Overall, this study provides empirical evidence that eBICA-based emotional control can function effectively in smart home environments and offers a foundation for next-generation affective home automation systems.",
    "url": "https://arxiv.org/abs/2512.21589",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores the use of emotion-aware smart home automation based on the eBICA model to enhance psychological safety in daily living environments. The experiment conducted in a pseudo-smart-home environment showed a significant reduction in state anxiety after introducing emotion-based automation. The findings suggest that personalized emotion-adaptive automation guided by eBICA can effectively promote psychological safety and offer a foundation for future affective home automation systems."
  },
  {
    "title": "Human-AI Interaction Alignment: Designing, Evaluating, and Evolving Value-Centered AI For Reciprocal Human-AI Futures",
    "abstract": "The rapid integration of generative AI into everyday life underscores the need to move beyond unidirectional alignment models that only adapt AI to human values. This workshop focuses on bidirectional human-AI alignment, a dynamic, reciprocal process where humans and AI co-adapt through interaction, evaluation, and value-centered design. Building on our past CHI 2025 BiAlign SIG and ICLR 2025 Workshop, this workshop will bring together interdisciplinary researchers from HCI, AI, social sciences and more domains to advance value-centered AI and reciprocal human-AI collaboration. We focus on embedding human and societal values into alignment research, emphasizing not only steering AI toward human values but also enabling humans to critically engage with and evolve alongside AI systems. Through talks, interdisciplinary discussions, and collaborative activities, participants will explore methods for interactive alignment, frameworks for societal impact evaluation, and strategies for alignment in dynamic contexts. This workshop aims to bridge the disciplines' gaps and establish a shared agenda for responsible, reciprocal human-AI futures.",
    "url": "https://arxiv.org/abs/2512.21551",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on bidirectional human-AI alignment, where humans and AI co-adapt through interaction, evaluation, and value-centered design. The workshop aims to bring together researchers from various disciplines to advance value-centered AI and reciprocal human-AI collaboration by embedding human and societal values into alignment research. The goal is to establish a shared agenda for responsible, reciprocal human-AI futures through interactive alignment methods, societal impact evaluation frameworks, and strategies for alignment in dynamic contexts."
  },
  {
    "title": "StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars",
    "abstract": "Real-time, streaming interactive avatars represent a critical yet challenging goal in digital human research. Although diffusion-based human avatar generation methods achieve remarkable success, their non-causal architecture and high computational costs make them unsuitable for streaming. Moreover, existing interactive approaches are typically limited to head-and-shoulder region, limiting their ability to produce gestures and body motions. To address these challenges, we propose a two-stage autoregressive adaptation and acceleration framework that applies autoregressive distillation and adversarial refinement to adapt a high-fidelity human video diffusion model for real-time, interactive streaming. To ensure long-term stability and consistency, we introduce three key components: a Reference Sink, a Reference-Anchored Positional Re-encoding (RAPR) strategy, and a Consistency-Aware Discriminator. Building on this framework, we develop a one-shot, interactive, human avatar model capable of generating both natural talking and listening behaviors with coherent gestures. Extensive experiments demonstrate that our method achieves state-of-the-art performance, surpassing existing approaches in generation quality, real-time efficiency, and interaction naturalness. Project page: this https URL .",
    "url": "https://arxiv.org/abs/2512.22065",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research proposes a new framework for generating real-time interactive human avatars that can produce natural gestures and body motions. The framework includes autoregressive adaptation and acceleration techniques to adapt a high-fidelity human video diffusion model for streaming. The proposed method outperforms existing approaches in terms of generation quality, real-time efficiency, and interaction naturalness, making significant advancements in the field of digital human research."
  },
  {
    "title": "Conserved active information",
    "abstract": "We introduce conserved active information $I^\\oplus$, a symmetric extension of active information that quantifies net information gain/loss across the entire search space, respecting No-Free-Lunch conservation. Through Bernoulli and uniform-baseline examples, we show $I^\\oplus$ reveals regimes hidden from KL divergence, such as when strong knowledge reduces global disorder. Such regimes are proven formally under uniform baseline, distinguishing disorder (increasing mild knowledge from order-imposing strong knowledge. We further illustrate these regimes with examples from Markov chains and cosmological fine-tuning. This resolves a longstanding critique of active information while enabling applications in search, optimization, and beyond.",
    "url": "https://arxiv.org/abs/2512.21834",
    "journal": "arXiv cs.HC",
    "ai_summary": "The researchers introduce a new metric called conserved active information $I^\\oplus, which quantifies net information gain/loss across the entire search space while respecting No-Free-Lunch conservation. Through examples and formal proofs, they demonstrate that $I^\\oplus can reveal hidden regimes that are not captured by KL divergence, particularly when strong knowledge reduces global disorder. This new metric addresses a longstanding critique of active information and has potential applications in search, optimization, and other fields."
  },
  {
    "title": "Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning",
    "abstract": "Between 2021 and 2025, the SciCap project grew from a small seed-funded idea at The Pennsylvania State University (Penn State) into one of the central efforts shaping the scientific figure-captioning landscape. Supported by a Penn State seed grant, Adobe, and the Alfred P. Sloan Foundation, what began as our attempt to test whether domain-specific training, which was successful in text models like SciBERT, could also work for figure captions expanded into a multi-institution collaboration. Over these five years, we curated, released, and continually updated a large collection of figure-caption pairs from arXiv papers, conducted extensive automatic and human evaluations on both generated and author-written captions, navigated the rapid rise of large language models (LLMs), launched annual challenges, and built interactive systems that help scientists write better captions. In this piece, we look back at the first five years of SciCap and summarize the key technical and methodological lessons we learned. We then outline five major unsolved challenges and propose directions for the next phase of research in scientific figure captioning.",
    "url": "https://arxiv.org/abs/2512.21789",
    "journal": "arXiv cs.HC",
    "ai_summary": "The SciCap project, which started as a small idea at Penn State, has grown into a significant effort in scientific figure captioning with support from various organizations. Over five years, the project curated a large collection of figure-caption pairs, conducted evaluations, and developed interactive systems to help scientists write better captions. The research highlights key technical lessons learned, outlines unsolved challenges, and proposes future directions for scientific figure captioning research."
  },
  {
    "title": "Bidirectional Human-AI Alignment in Education for Trustworthy Learning Environments",
    "abstract": "Artificial intelligence (AI) is transforming education, offering unprecedented opportunities to personalize learning, enhance assessment, and support educators. Yet these opportunities also introduce risks related to equity, privacy, and student autonomy. This chapter develops the concept of bidirectional human-AI alignment in education, emphasizing that trustworthy learning environments arise not only from embedding human values into AI systems but also from equipping teachers, students, and institutions with the skills to interpret, critique, and guide these technologies. Drawing on emerging research and practical case examples, we explore AI's evolution from support tool to collaborative partner, highlighting its impacts on teacher roles, student agency, and institutional governance. We propose actionable strategies for policymakers, developers, and educators to ensure that AI advances equity, transparency, and human flourishing rather than eroding them. By reframing AI adoption as an ongoing process of mutual adaptation, the chapter envisions a future in which humans and intelligent systems learn, innovate, and grow together.",
    "url": "https://arxiv.org/abs/2512.21552",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the concept of bidirectional human-AI alignment in education, emphasizing the importance of not only embedding human values into AI systems but also equipping teachers, students, and institutions with the skills to interpret, critique, and guide these technologies. The study highlights the evolution of AI from a support tool to a collaborative partner in education, impacting teacher roles, student agency, and institutional governance. The proposed actionable strategies aim to ensure that AI advances equity, transparency, and human flourishing in education, envisioning a future where humans and intelligent systems learn, innovate, and grow together."
  },
  {
    "title": "MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs for Health and Behavioral Understanding",
    "abstract": "As wearable sensing becomes increasingly pervasive, a key challenge remains: how can we generate natural language summaries from raw physiological signals such as actigraphy - minute-level movement data collected via accelerometers? In this work, we introduce MotionTeller, a generative framework that natively integrates minute-level wearable activity data with large language models (LLMs). MotionTeller combines a pretrained actigraphy encoder with a lightweight projection module that maps behavioral embeddings into the token space of a frozen decoder-only LLM, enabling free-text, autoregressive generation of daily behavioral summaries. We construct a novel dataset of 54383 (actigraphy, text) pairs derived from real-world NHANES recordings, and train the model using cross-entropy loss with supervision only on the language tokens. MotionTeller achieves high semantic fidelity (BERTScore-F1 = 0.924) and lexical accuracy (ROUGE-1 = 0.722), outperforming prompt-based baselines by 7 percent in ROUGE-1. The average training loss converges to 0.38 by epoch 15, indicating stable optimization. Qualitative analysis confirms that MotionTeller captures circadian structure and behavioral transitions, while PCA plots reveal enhanced cluster alignment in embedding space post-training. Together, these results position MotionTeller as a scalable, interpretable system for transforming wearable sensor data into fluent, human-centered descriptions, introducing new pathways for behavioral monitoring, clinical review, and personalized health interventions.",
    "url": "https://arxiv.org/abs/2512.21506",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces MotionTeller, a framework that integrates wearable activity data with large language models to generate natural language summaries of daily behavioral patterns. The model achieves high semantic fidelity and lexical accuracy, outperforming baseline models. MotionTeller is shown to accurately capture circadian structure and behavioral transitions, making it a valuable tool for behavioral monitoring and personalized health interventions."
  },
  {
    "title": "Learning Factors in AI-Augmented Education: A Comparative Study of Middle and High School Students",
    "abstract": "The increasing integration of AI tools in education has led prior research to explore their impact on learning processes. Nevertheless, most existing studies focus on higher education and conventional instructional contexts, leaving open questions about how key learning factors are related in AI-mediated learning environments and how these relationships may vary across different age groups. Addressing these gaps, our work investigates whether four critical learning factors, experience, clarity, comfort, and motivation, maintain coherent interrelationships in AI-augmented educational settings, and how the structure of these relationships differs between middle and high school students. The study was conducted in authentic classroom contexts where students interacted with AI tools as part of programming learning activities to collect data on the four learning factors and students' perceptions. Using a multimethod quantitative analysis, which combined correlation analysis and text mining, we revealed markedly different dimensional structures between the two age groups. Middle school students exhibit strong positive correlations across all dimensions, indicating holistic evaluation patterns whereby positive perceptions in one dimension generalise to others. In contrast, high school students show weak or near-zero correlations between key dimensions, suggesting a more differentiated evaluation process in which dimensions are assessed independently. These findings reveal that perception dimensions actively mediate AI-augmented learning and that the developmental stage moderates their interdependencies. This work establishes a foundation for the development of AI integration strategies that respond to learners' developmental levels and account for age-specific dimensional structures in student-AI interactions.",
    "url": "https://arxiv.org/abs/2512.21246",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research study compares the relationships between key learning factors (experience, clarity, comfort, and motivation) in AI-augmented educational settings for middle and high school students. The study found that middle school students exhibit strong positive correlations across all dimensions, while high school students show weak or near-zero correlations between key dimensions. These findings suggest that perception dimensions play a significant role in AI-augmented learning and that the developmental stage of students influences how these dimensions interact. This research provides valuable insights for developing AI integration strategies that cater to students' developmental levels and consider age-specific dimensional structures in student-AI interactions."
  },
  {
    "title": "Volatile Organic Compounds for Stress Detection: A Scoping Review and Exploratory Feasibility Study with Low-Cost Sensors",
    "abstract": "Volatile organic compounds (VOCs) represent a novel but underexplored modality for emotion recognition. This paper presents a systematic evidence synthesis and exploratory investigation of VOC-based affective computing using low-cost sensors. Study 1, a systematic scoping review following PRISMA-ScR guidelines, analyzed 16 studies from 610 records across breath, sweat, skin, and urine biosources. Evidence indicates that stress and affective states are reflected in VOC signatures (aldehydes, ketones, fatty acids, sulfur compounds), though with considerable heterogeneity. Current research relies predominantly on laboratory-grade GC-MS or PTR-MS, while wearable sensors provide pattern-level outputs without compound-specific identification - a critical gap for practical systems. Study 2 (n=25) investigated whether low-cost TVOC sensors (BME688, ENS160) combined with physiological monitoring (HR, HRV, GSR) can detect laboratory-induced stress. Exploratory analysis revealed that high cardiovascular reactors exhibited elevated TVOC during arithmetic stress (d=1.38), though requiring replication in larger samples. Substantial interindividual variability emerged (CV>80%), with coupling patterns moderated by baseline emission levels and temporal lags of 30-80 seconds. Random Forest-based multimodal classification achieved 77.3% accuracy (5-fold CV). SHAP analysis indicated VOC sensors contributed 24.9% of model performance. Leave-one-subject-out validation yielded 65.3% accuracy, highlighting the need for individual calibration. This work provides three contributions: (1) comprehensive mapping of VOC biomarker evidence and technological gaps, (2) initial demonstration that low-cost sensors can capture stress-related VOC patterns in multimodal fusion, and (3) identification of key implementation challenges. Findings require replication in larger samples (n>=50).",
    "url": "https://arxiv.org/abs/2512.21105",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of volatile organic compounds (VOCs) as a potential modality for emotion recognition, specifically in detecting stress and affective states. The study conducted a scoping review of existing literature and an exploratory feasibility study using low-cost VOC sensors combined with physiological monitoring to detect stress. The findings suggest that VOC patterns can reflect stress, but there is a need for further research to address technological gaps and challenges in implementing practical systems for stress detection using VOCs."
  },
  {
    "title": "When LLMs fall short in Deductive Coding: Model Comparison and Human AI Collaboration Workflow Design",
    "abstract": "With generative artificial intelligence driving the growth of dialogic data in education, automated coding is a promising direction for learning analytics to improve efficiency. This surge highlights the need to understand the nuances of student-AI interactions, especially those rare yet crucial. However, automated coding may struggle to capture these rare codes due to imbalanced data, while human coding remains time-consuming and labour-intensive. The current study examined the potential of large language models (LLMs) to approximate or replace humans in deductive, theory-driven coding, while also exploring how human-AI collaboration might support such coding tasks at scale. We compared the coding performance of small transformer classifiers (e.g., BERT) and LLMs in two datasets, with particular attention to imbalanced head-tail distributions in dialogue codes. Our results showed that LLMs did not outperform BERT-based models and exhibited systematic errors and biases in deductive coding tasks. We designed and evaluated a human-AI collaborative workflow that improved coding efficiency while maintaining coding reliability. Our findings reveal both the limitations of LLMs -- especially their difficulties with semantic similarity and theoretical interpretations and the indispensable role of human judgment -- while demonstrating the practical promise of human-AI collaborative workflows for coding.",
    "url": "https://arxiv.org/abs/2512.21041",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research study compared the performance of large language models (LLMs) and small transformer classifiers in deductive coding tasks in education data. The results showed that LLMs did not outperform smaller models like BERT and had systematic errors and biases. The study also proposed a human-AI collaborative workflow to improve coding efficiency and reliability, highlighting the importance of human judgment in complex coding tasks."
  },
  {
    "title": "A Design Study Process Model for Medical Visualization",
    "abstract": "We introduce a design study process model for medical visualization based on the analysis of existing medical visualization and visual analysis works, and our own interdisciplinary research experience. With a literature review of related works covering various data types and applications, we identify features of medical visualization and visual analysis research and formulate our model thereafter. Compared to previous design study process models, our new model emphasizes: distinguishing between different stakeholders and target users before initiating specific designs, distinguishing design stages according to analytic logic or cognitive habits, and classifying task types as inferential or descriptive, and further hypothesis-based or hypothesis-free based on whether they involve multiple subgroups. In addition, our model refines previous models according to the characteristics of medical problems and provides referable guidance for each step. These improvements make the visualization design targeted, generalizable, and operational, which can adapt to the complexity and diversity of medical problems. We apply this model to guide the design of a visual analysis method and reanalyze three medical visualization-related works. These examples suggest that the new process model can provide a systematic theoretical framework and practical guidance for interdisciplinary medical visualization research. We give recommendations that future researchers can refer to, report on reflections on the model, and delineate it from existing models.",
    "url": "https://arxiv.org/abs/2512.21034",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces a new design study process model for medical visualization based on existing works and interdisciplinary research. The model emphasizes distinguishing between stakeholders and users, different design stages, and classifying task types. The model provides targeted, generalizable, and operational guidance for interdisciplinary medical visualization research, improving the design process and providing a systematic theoretical framework for future researchers."
  },
  {
    "title": "Pioneering Multimodal Emotion Recognition in the Era of Large Models: From Closed Sets to Open Vocabularies",
    "abstract": "Recent advances in multimodal large language models (MLLMs) have demonstrated remarkable multi- and cross-modal integration capabilities. However, their potential for fine-grained emotion understanding remains systematically underexplored. While open-vocabulary multimodal emotion recognition (MER-OV) has emerged as a promising direction to overcome the limitations of closed emotion sets, no comprehensive evaluation of MLLMs in this context currently exists. To address this, our work presents the first large-scale benchmarking study of MER-OV on the OV-MERD dataset, evaluating 19 mainstream MLLMs, including general-purpose, modality-specialized, and reasoning-enhanced architectures. Through systematic analysis of model reasoning capacity, fusion strategies, contextual utilization, and prompt design, we provide key insights into the capabilities and limitations of current MLLMs for MER-OV. Our evaluation reveals that a two-stage, trimodal (audio, video, and text) fusion approach achieves optimal performance in MER-OV, with video emerging as the most critical modality. We further identify a surprisingly narrow gap between open- and closed-source LLMs. These findings establish essential benchmarks and offer practical guidelines for advancing open-vocabulary and fine-grained affective computing, paving the way for more nuanced and interpretable emotion AI systems. Associated code will be made publicly available upon acceptance.",
    "url": "https://arxiv.org/abs/2512.20938",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the potential of large language models (LLMs) in understanding emotions through multimodal inputs. The study evaluates 19 mainstream LLMs on an open-vocabulary multimodal emotion recognition dataset, finding that a two-stage trimodal fusion approach with video as the most critical modality achieves optimal performance. The findings provide essential benchmarks and guidelines for advancing fine-grained affective computing, leading to more nuanced and interpretable emotion AI systems."
  },
  {
    "title": "Cooperation Through Indirect Reciprocity in Child-Robot Interactions",
    "abstract": "Social interactions increasingly involve artificial agents, such as conversational or collaborative bots. Understanding trust and prosociality in these settings is fundamental to improve human-AI teamwork. Research in biology and social sciences has identified mechanisms to sustain cooperation among humans. Indirect reciprocity (IR) is one of them. With IR, helping someone can enhance an individual's reputation, nudging others to reciprocate in the future. Transposing IR to human-AI interactions is however challenging, as differences in human demographics, moral judgements, and agents' learning dynamics can affect how interactions are assessed. To study IR in human-AI groups, we combine laboratory experiments and theoretical modelling. We investigate whether 1) indirect reciprocity can be transposed to children-robot interactions; 2) artificial agents can learn to cooperate given children's strategies; and 3) how differences in learning algorithms impact human-AI cooperation. We find that IR extends to children and robots solving coordination dilemmas. Furthermore, we observe that the strategies revealed by children provide a sufficient signal for multi-armed bandit algorithms to learn cooperative actions. Beyond the experimental scenarios, we observe that cooperating through multi-armed bandit algorithms is highly dependent on the strategies revealed by humans.",
    "url": "https://arxiv.org/abs/2512.20621",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the concept of indirect reciprocity in child-robot interactions, aiming to understand how cooperation can be sustained in human-AI teamwork. The study finds that indirect reciprocity can be applied to children and robots working together to solve coordination dilemmas. Additionally, the research highlights the importance of human strategies in guiding artificial agents to learn cooperative actions in these interactions."
  },
  {
    "title": "Uncovering Patterns of Brain Activity from EEG Data Consistently Associated with Cybersickness Using Neural Network Interpretability Maps",
    "abstract": "Cybersickness poses a serious challenge for users of virtual reality (VR) technology. Consequently, there has been significant effort to track its occurrence during VR use with brain activity through electroencephalography (EEG). However, a significant confound in current methods for detecting sickness from EEG is they do not account for the simultaneous processing of the sickening visual stimulus that is present in the brain data from VR. Using event-related potentials (ERPs) from an auditory stimulus shown to reflect cybersickness impacts, we can more precisely target EEG cybersickness features and use those to achieve better performance in online cybersickness classification. In this article, we introduce a method utilizing trained convolutional neural networks and transformer models and plot interpretability maps from integrated gradients and class activation to give a visual representation of what the model determined was most useful in sickness classification from an EEG dataset consisting of ERPs recorded during the elicitation of cybersickness. Across 12 runs of our method with three different neural networks, the models consistently pointed to a surprising finding: that amplitudes recorded at an electrode placed on the scalp near the left prefrontal cortex were important in the classification of cybersickness. These results help clarify a hidden pattern in other related research and point to exciting opportunities for future investigation: that this scalp location could be used as a tagged feature for better real-time cybersickness classification with EEG. We provide our code at: [anonymized].",
    "url": "https://arxiv.org/abs/2512.20620",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on identifying patterns of brain activity associated with cybersickness using EEG data. By analyzing event-related potentials from an auditory stimulus, the study found that amplitudes recorded near the left prefrontal cortex were important in classifying cybersickness. The use of convolutional neural networks and interpretability maps provided insights into the neural correlates of cybersickness, offering potential for improved real-time classification and future research opportunities."
  },
  {
    "title": "Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Consulting, Data Analyst, and Management Tasks",
    "abstract": "This paper derives `Scaling Laws for Economic Impacts' -- empirical relationships between the training compute of Large Language Models (LLMs) and professional productivity. In a preregistered experiment, over 500 consultants, data analysts, and managers completed professional tasks using one of 13 LLMs. We find that each year of AI model progress reduced task time by 8%, with 56% of gains driven by increased compute and 44% by algorithmic progress. However, productivity gains were significantly larger for non-agentic analytical tasks compared to agentic workflows requiring tool use. These findings suggest continued model scaling could boost U.S. productivity by approximately 20% over the next decade.",
    "url": "https://arxiv.org/abs/2512.21316",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the relationship between the training compute of Large Language Models (LLMs) and professional productivity in consulting, data analysis, and management tasks. The study found that AI model progress reduced task time by 8% per year, with gains driven by increased compute and algorithmic progress. Productivity gains were higher for non-agentic analytical tasks compared to tasks requiring tool use, suggesting that continued model scaling could significantly boost U.S. productivity in the next decade."
  },
  {
    "title": "Quadrupped-Legged Robot Movement Plan Generation using Large Language Model",
    "abstract": "Traditional control interfaces for quadruped robots often impose a high barrier to entry, requiring specialized technical knowledge for effective operation. To address this, this paper presents a novel control framework that integrates Large Language Models (LLMs) to enable intuitive, natural language-based navigation. We propose a distributed architecture where high-level instruction processing is offloaded to an external server to overcome the onboard computational constraints of the DeepRobotics Jueying Lite 3 platform. The system grounds LLM-generated plans into executable ROS navigation commands using real-time sensor fusion (LiDAR, IMU, and Odometry). Experimental validation was conducted in a structured indoor environment across four distinct scenarios, ranging from single-room tasks to complex cross-zone navigation. The results demonstrate the system's robustness, achieving an aggregate success rate of over 90\\% across all scenarios, validating the feasibility of offloaded LLM-based planning for autonomous quadruped deployment in real-world settings.",
    "url": "https://arxiv.org/abs/2512.21293",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper introduces a control framework for quadruped robots that utilizes Large Language Models (LLMs) for natural language-based navigation, aiming to make robot operation more intuitive for users without specialized technical knowledge. By offloading high-level instruction processing to an external server, the system overcomes computational constraints and successfully translates LLM-generated plans into executable commands using real-time sensor fusion. Experimental validation in various scenarios shows the system's robustness and high success rate, indicating the feasibility of using offloaded LLM-based planning for autonomous quadruped deployment in real-world environments."
  },
  {
    "title": "Agentic Explainable Artificial Intelligence (Agentic XAI) Approach To Explore Better Explanation",
    "abstract": "Explainable artificial intelligence (XAI) enables data-driven understanding of factor associations with response variables, yet communicating XAI outputs to laypersons remains challenging, hindering trust in AI-based predictions. Large language models (LLMs) have emerged as promising tools for translating technical explanations into accessible narratives, yet the integration of agentic AI, where LLMs operate as autonomous agents through iterative refinement, with XAI remains unexplored. This study proposes an agentic XAI framework combining SHAP-based explainability with multimodal LLM-driven iterative refinement to generate progressively enhanced explanations. As a use case, we tested this framework as an agricultural recommendation system using rice yield data from 26 fields in Japan. The Agentic XAI initially provided a SHAP result and explored how to improve the explanation through additional analysis iteratively across 11 refinement rounds (Rounds 0-10). Explanations were evaluated by human experts (crop scientists) (n=12) and LLMs (n=14) against seven metrics: Specificity, Clarity, Conciseness, Practicality, Contextual Relevance, Cost Consideration, and Crop Science Credibility. Both evaluator groups confirmed that the framework successfully enhanced recommendation quality with an average score increase of 30-33% from Round 0, peaking at Rounds 3-4. However, excessive refinement showed a substantial drop in recommendation quality, indicating a bias-variance trade-off where early rounds lacked explanation depth (bias) while excessive iteration introduced verbosity and ungrounded abstraction (variance), as revealed by metric-specific analysis. These findings suggest that strategic early stopping (regularization) is needed for optimizing practical utility, challenging assumptions about monotonic improvement and providing evidence-based design principles for agentic XAI systems.",
    "url": "https://arxiv.org/abs/2512.21066",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study introduces an Agentic Explainable Artificial Intelligence (Agentic XAI) framework that combines SHAP-based explainability with large language models (LLMs) for generating enhanced explanations. The framework was tested in an agricultural recommendation system using rice yield data, and results showed a significant improvement in recommendation quality through iterative refinement. However, excessive refinement led to a drop in quality, highlighting the need for strategic early stopping to optimize practical utility in agentic XAI systems."
  },
  {
    "title": "Making AI Work: An Autoethnography of a Workaround in Higher Education",
    "abstract": "Research on the implementation of Generative Artificial Intelligence (GenAI) in higher education often focuses on strategic goals, overlooking the hidden, and often politically charged, labour required to make it functional. This paper provides an insider's account of the sociotechnical friction that arises when an institutional goal of empowering non-technical staff conflicts with the technical limitations of enterprise Large Language Models (LLMs). Through analytic autoethnography, this study examines a GenAI project pushed to an impasse, focusing on a workaround developed to navigate not only technical constraints but also the combined challenge of organisational territoriality and assertions of positional power. Drawing upon Alter's (2014) theory of workarounds, the analysis interprets \"articulation work\" as a form of \"invisible labour\". By engaging with the Information Systems (IS) domains of user innovation and technology-in-practice, this study argues that such user-driven workarounds should be understood not as deviations, but as integral acts of sociotechnical integration. This integration, however, highlights the central paradoxes of modern GenAI where such workarounds for \"unfinished\" systems can simultaneously create unofficial \"shadow\" systems and obscure the crucial, yet invisible, sociotechnical labour involved. The findings suggest that the invisible labour required to integrate GenAI within complex organisational politics is an important, rather than peripheral, component of how it becomes functional in practice.",
    "url": "https://arxiv.org/abs/2512.21055",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper explores the challenges and hidden labor involved in implementing Generative Artificial Intelligence (GenAI) in higher education, particularly when non-technical staff are empowered to use enterprise Large Language Models (LLMs). The study highlights the sociotechnical friction and organizational power dynamics that arise, leading to the development of workarounds to navigate technical constraints and territoriality issues. The findings emphasize the importance of understanding user-driven workarounds as integral to the integration of GenAI within complex organizational politics, shedding light on the invisible labor required for its functional implementation."
  },
  {
    "title": "DexAvatar: 3D Sign Language Reconstruction with Hand and Body Pose Priors",
    "abstract": "The trend in sign language generation is centered around data-driven generative methods that require vast amounts of precise 2D and 3D human pose data to achieve an acceptable generation quality. However, currently, most sign language datasets are video-based and limited to automatically reconstructed 2D human poses (i.e., keypoints) and lack accurate 3D information. Furthermore, existing state-of-the-art for automatic 3D human pose estimation from sign language videos is prone to self-occlusion, noise, and motion blur effects, resulting in poor reconstruction quality. In response to this, we introduce DexAvatar, a novel framework to reconstruct bio-mechanically accurate fine-grained hand articulations and body movements from in-the-wild monocular sign language videos, guided by learned 3D hand and body priors. DexAvatar achieves strong performance in the SGNify motion capture dataset, the only benchmark available for this task, reaching an improvement of 35.11% in the estimation of body and hand poses compared to the state-of-the-art. The official website of this work is: this https URL.",
    "url": "https://arxiv.org/abs/2512.21054",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces DexAvatar, a framework designed to reconstruct accurate 3D hand and body poses from sign language videos using learned priors. This approach improves upon existing methods by addressing issues such as self-occlusion and motion blur, resulting in a significant improvement in pose estimation performance compared to the state-of-the-art. DexAvatar's success in the SGNify motion capture dataset highlights its potential to advance sign language generation technology."
  },
  {
    "title": "From Human Bias to Robot Choice: How Occupational Contexts and Racial Priming Shape Robot Selection",
    "abstract": "As artificial agents increasingly integrate into professional environments, fundamental questions have emerged about how societal biases influence human-robot selection decisions. We conducted two comprehensive experiments (N = 1,038) examining how occupational contexts and stereotype activation shape robotic agent choices across construction, healthcare, educational, and athletic domains. Participants made selections from artificial agents that varied systematically in skin tone and anthropomorphic characteristics. Our study revealed distinct context-dependent patterns. Healthcare and educational scenarios demonstrated strong favoritism toward lighter-skinned artificial agents, while construction and athletic contexts showed greater acceptance of darker-toned alternatives. Participant race was associated with systematic differences in selection patterns across professional domains. The second experiment demonstrated that exposure to human professionals from specific racial backgrounds systematically shifted later robotic agent preferences in stereotype-consistent directions. These findings show that occupational biases and color-based discrimination transfer directly from human-human to human-robot evaluation contexts. The results highlight mechanisms through which robotic deployment may unintentionally perpetuate existing social inequalities.",
    "url": "https://arxiv.org/abs/2512.20951",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores how societal biases influence human-robot selection decisions in professional environments. The study found that preferences for artificial agents varied based on occupational contexts, with healthcare and educational scenarios showing favoritism toward lighter-skinned robots, while construction and athletic contexts showed greater acceptance of darker-toned robots. Participant race also influenced selection patterns, and exposure to human professionals of specific racial backgrounds influenced later robotic agent preferences. The findings suggest that occupational biases and color-based discrimination can transfer from human-human to human-robot evaluation contexts, potentially perpetuating existing social inequalities."
  },
  {
    "title": "YCB-Handovers Dataset: Analyzing Object Weight Impact on Human Handovers to Adapt Robotic Handover Motion",
    "abstract": "This paper introduces the YCB-Handovers dataset, capturing motion data of 2771 human-human handovers with varying object weights. The dataset aims to bridge a gap in human-robot collaboration research, providing insights into the impact of object weight in human handovers and readiness cues for intuitive robotic motion planning. The underlying dataset for object recognition and tracking is the YCB (Yale-CMU-Berkeley) dataset, which is an established standard dataset used in algorithms for robotic manipulation, including grasping and carrying objects. The YCB-Handovers dataset incorporates human motion patterns in handovers, making it applicable for data-driven, human-inspired models aimed at weight-sensitive motion planning and adaptive robotic behaviors. This dataset covers an extensive range of weights, allowing for a more robust study of handover behavior and weight variation. Some objects also require careful handovers, highlighting contrasts with standard handovers. We also provide a detailed analysis of the object's weight impact on the human reaching motion in these handovers.",
    "url": "https://arxiv.org/abs/2512.20847",
    "journal": "arXiv cs.HC",
    "ai_summary": "The YCB-Handovers dataset captures human-human handovers with varying object weights, aiming to provide insights into the impact of weight on handover motions for robotic applications. This dataset, based on the YCB dataset, offers valuable data for developing weight-sensitive motion planning and adaptive robotic behaviors. The analysis of the dataset reveals the significance of object weight on human reaching motions during handovers, highlighting the need for careful and intuitive robotic motion planning."
  },
  {
    "title": "From Pilots to Practices: A Scoping Review of GenAI-Enabled Personalization in Computer Science Education",
    "abstract": "Generative AI enables personalized computer science education at scale, yet questions remain about whether such personalization supports or undermines learning. This scoping review synthesizes 32 studies (2023-2025) purposively sampled from 259 records to map personalization mechanisms and effectiveness signals in higher-education computer science contexts. We identify five application domains: intelligent tutoring, personalized materials, formative feedback, AI-augmented assessment, and code review, and analyze how design choices shape learning outcomes. Designs incorporating explanation-first guidance, solution withholding, graduated hint ladders, and artifact grounding (student code, tests, and rubrics) consistently show more positive learning processes than unconstrained chat interfaces. Successful implementations share four patterns: context-aware tutoring anchored in student artifacts, multi-level hint structures requiring reflection, composition with traditional CS infrastructure (autograders and rubrics), and human-in-the-loop quality assurance. We propose an exploration-first adoption framework emphasizing piloting, instrumentation, learning-preserving defaults, and evidence-based scaling. Recurrent risks include academic integrity, privacy, bias and equity, and over-reliance, and we pair these with operational mitigation. The evidence supports generative AI as a mechanism for precision scaffolding when embedded in audit-ready workflows that preserve productive struggle while scaling personalized support.",
    "url": "https://arxiv.org/abs/2512.20714",
    "journal": "arXiv cs.HC",
    "ai_summary": "This scoping review examines the use of generative AI in personalized computer science education, analyzing 32 studies to identify key application domains and design choices that impact learning outcomes. The research found that designs incorporating explanation-first guidance, solution withholding, graduated hint ladders, and artifact grounding were more effective in supporting learning processes compared to unconstrained chat interfaces. The study highlights the importance of context-aware tutoring, multi-level hint structures, integration with traditional CS infrastructure, and human-in-the-loop quality assurance in successful implementations of generative AI for personalized education."
  },
  {
    "title": "Signal, Noise, and Burnout: A Human-Information Interaction Analysis of Voter Verification in a High-Volatility Environment",
    "abstract": "The 2024 U.S. Presidential Election unfolded within an information environment of unprecedented volatility, challenging citizens to navigate a torrent of rapidly evolving, often contradictory information while determining what to believe. This study investigates the cognitive mechanisms underlying epistemic self-efficacy - the perceived ability to distinguish accurate news from misinformation - across different information channels during this high-stakes election cycle. Drawing on data from the Pew Research Center's American Trends Panel (Wave 155, September 2024, N = 9,360), we test three hypotheses: (H1) whether reliance on social media predicts lower epistemic self-efficacy compared to mainstream news sources; (H2) whether perceived exposure to inaccurate information mediates this relationship; and (H3) whether information fatigue moderates the cognitive burden of verification across platforms. Contrary to expectations rooted in algorithmic filtering theory, we find no significant differences in reported difficulty determining truth between social media and mainstream news users. Instead, epistemic burden is driven by demographics (age, education) and universal information fatigue, suggesting a \"leveling\" of the information landscape during periods of extreme volatility. This finding challenges platform-deterministic theories and suggests that interventions to support informed citizenship must address cognitive resilience and attention management rather than platform choice alone.",
    "url": "https://arxiv.org/abs/2512.20679",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study examines the cognitive mechanisms underlying the ability to distinguish accurate news from misinformation during the 2024 U.S. Presidential Election, a time of high information volatility. The research finds that factors such as demographics (age, education) and information fatigue play a significant role in individuals' ability to verify information, challenging the idea that reliance on social media leads to lower epistemic self-efficacy compared to mainstream news sources. The findings suggest that interventions to support informed citizenship should focus on cognitive resilience and attention management rather than solely on platform choice."
  },
  {
    "title": "A human-centered approach to reframing job satisfaction in the BIM-enabled construction industry",
    "abstract": "As the construction industry undergoes rapid digital transformation, ensuring that new technologies enhance rather than hinder human experience has become essential. The inclusion of Building Information Modeling (BIM) plays a central role in this shift, yet its influence on job satisfaction remains underexplored. In response, this study developed a human-centered measurement model for evaluating job satisfaction in BIM work environments by adapting Hackman and Oldham's Job Characteristics Model for the architecture, engineering, and construction (AEC) industry to create a survey that captured industry perspectives on BIM use and job satisfaction. The model uses Partial Least Squares Structural Equation Modeling to analyze the survey results and identify what dimensions of BIM-related work affect job satisfaction. While it was hypothesized that BIM use increases job satisfaction, the results show that only some dimensions of BIM use positively impact BIM job satisfaction; the use of BIM does not guarantee an increase in overall job satisfaction. Additionally, more frequent BIM use was not associated with higher satisfaction levels. These findings suggest that in the AEC industry, sustainable job satisfaction depends less on technological autonomy and more on human-centric factors, particularly collaboration and meaningful engagement within digital workflows.",
    "url": "https://arxiv.org/abs/2512.20584",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores the impact of Building Information Modeling (BIM) on job satisfaction in the construction industry. The research found that while some dimensions of BIM use can positively impact job satisfaction, overall job satisfaction is not guaranteed by BIM implementation. The findings highlight the importance of human-centric factors, such as collaboration and meaningful engagement, in ensuring job satisfaction in BIM-enabled work environments."
  },
  {
    "title": "Structured Visualization Design Knowledge for Grounding Generative Reasoning and Situated Feedback",
    "abstract": "Automated visualization design navigates a tension between symbolic systems and generative models. Constraint solvers enforce structural and perceptual validity, but the rules they require are difficult to author and too rigid to capture situated design knowledge. Large language models require no formal rules and can reason about contextual nuance, but they prioritize popular conventions over empirically grounded best practices. We address this tension by proposing a cataloging scheme that structures visualization design knowledge as natural-language guidelines with semantically typed metadata. This allows experts to author knowledge that machines can query. An expert study ($N=18$) indicates that practitioners routinely adapt heuristics to situational factors such as audience and communicative intent. To capture this reasoning, guideline sections specify not only advice but also the contexts where it applies, exceptions that invalidate it, and the sources from which it derives. We demonstrate the scheme's expressiveness by cataloging 744 guidelines drawn from cognitive science, accessibility standards, data journalism, and research on rhetorical aspects of visual communication. We embed guideline sections in a vector space, opening the knowledge itself to structural analysis. This reveals conflicting advice across sources and transferable principles between domains. Rather than replacing constraint-based tools, our scheme provides what they lack: situated guidance that generative systems can retrieve to ground their reasoning, users can verify against cited sources, and experts can author as knowledge evolves.",
    "url": "https://arxiv.org/abs/2512.20306",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research addresses the tension between constraint solvers and large language models in automated visualization design by proposing a cataloging scheme that structures design knowledge as natural-language guidelines with metadata. An expert study shows that practitioners adapt heuristics based on situational factors, and the proposed scheme allows for the capture of reasoning behind design guidelines. By embedding guideline sections in a vector space, conflicting advice across sources and transferable principles between domains can be identified, providing situated guidance for generative systems."
  },
  {
    "title": "The Effect of Empathic Expression Levels in Virtual Human Interaction: A Controlled Experiment",
    "abstract": "As artificial intelligence (AI) systems become increasingly embedded in everyday life, the ability of interactive agents to express empathy has become critical for effective human-AI interaction, particularly in emotionally sensitive contexts. Rather than treating empathy as a binary capability, this study examines how different levels of empathic expression in virtual human interaction influence user experience. We conducted a between-subject experiment (n = 70) in a counseling-style interaction context, comparing three virtual human conditions: a neutral dialogue-based agent, a dialogue-based empathic agent, and a video-based empathic agent that incorporates users' facial cues. Participants engaged in a 15-minute interaction and subsequently evaluated their experience using subjective measures of empathy and interaction quality. Results from analysis of variance (ANOVA) revealed significant differences across conditions in affective empathy, perceived naturalness of facial movement, and appropriateness of facial expression. The video-based empathic expression condition elicited significantly higher affective empathy than the neutral baseline (p < .001) and marginally higher levels than the dialogue-based condition (p < .10). In contrast, cognitive empathy did not differ significantly across conditions. These findings indicate that empathic expression in virtual humans should be conceptualized as a graded design variable, rather than a binary capability, with visually grounded cues playing a decisive role in shaping affective user experience.",
    "url": "https://arxiv.org/abs/2512.20221",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores the impact of different levels of empathic expression in virtual human interaction on user experience in emotionally sensitive contexts. The results show that video-based empathic expression, incorporating users' facial cues, elicits higher affective empathy compared to neutral or dialogue-based agents. The findings suggest that empathic expression in virtual humans should be considered as a graded design variable, with visually grounded cues playing a crucial role in shaping affective user experience."
  },
  {
    "title": "Competing or Collaborating? The Role of Hackathon Formats in Shaping Team Dynamics and Project Choices",
    "abstract": "Hackathons have emerged as dynamic platforms for fostering innovation, collaboration, and skill development in the technology sector. Structural differences across hackathon formats raise important questions about how event design can shape student learning experiences and engagement. This study examines two distinct hackathon formats: a gender-specific hackathon (GS) and a regular institutional hackathon (RI). Using a mixed-methods approach, we analyze variations in team dynamics, project themes, role assignments, and environmental settings. Our findings indicate that GS hackathon foster a collaborative and supportive atmosphere, emphasizing personal growth and community learning, with projects often centered on health and well-being. In contrast, RI hackathon tend to promote a competitive, outcome-driven environment, with projects frequently addressing entertainment and environmental sustainability. Based on these insights, we propose a hybrid hackathon model that combines the strengths of both formats to balance competition with inclusivity. This work contributes to the design of more engaging, equitable, and pedagogically effective hackathon experiences.",
    "url": "https://arxiv.org/abs/2512.20181",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study compares the dynamics and project choices in gender-specific hackathons (GS) and regular institutional hackathons (RI). The findings show that GS hackathons promote collaboration and personal growth, focusing on health and well-being projects, while RI hackathons tend to be more competitive and outcome-driven, with projects addressing entertainment and environmental sustainability. The study suggests a hybrid hackathon model that combines the strengths of both formats to create more engaging and inclusive hackathon experiences."
  },
  {
    "title": "RESPOND: Risk-Enhanced Structured Pattern for LLM-driven Online Node-level Decision-making",
    "abstract": "Current LLM-based driving agents that rely on unstructured plain-text memory suffer from low-precision scene retrieval and inefficient reflection. To address this limitation, we present RESPOND, a structured decision-making framework for LLM-driven agents grounded in explicit risk patterns. RESPOND represents each ego-centric scene using a unified 5 by 3 matrix that encodes spatial topology and road constraints, enabling consistent and reliable retrieval of spatial risk configurations. Based on this representation, a hybrid rule and LLM decision pipeline is developed with a two-tier memory mechanism. In high-risk contexts, exact pattern matching enables rapid and safe reuse of verified actions, while in low-risk contexts, sub-pattern matching supports personalized driving style adaptation. In addition, a pattern-aware reflection mechanism abstracts tactical corrections from crash and near-miss frames to update structured memory, achieving one-crash-to-generalize learning. Extensive experiments demonstrate the effectiveness of RESPOND. In highway-env, RESPOND outperforms state-of-the-art LLM-based and reinforcement learning based driving agents while producing substantially fewer collisions. With step-wise human feedback, the agent acquires a Sporty driving style within approximately 20 decision steps through sub-pattern abstraction. For real-world validation, RESPOND is evaluated on 53 high-risk cut-in scenarios extracted from the HighD dataset. For each event, intervention is applied immediately before the cut-in and RESPOND re-decides the driving action. Compared to recorded human behavior, RESPOND reduces subsequent risk in 84.9 percent of scenarios, demonstrating its practical feasibility under real-world driving conditions. These results highlight RESPONDs potential for autonomous driving, personalized driving assistance, and proactive hazard mitigation.",
    "url": "https://arxiv.org/abs/2512.20179",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces RESPOND, a structured decision-making framework for LLM-driven driving agents that improves scene retrieval precision and reflection efficiency. RESPOND utilizes a unified matrix representation of ego-centric scenes to enable consistent and reliable retrieval of spatial risk configurations, leading to better decision-making in high and low-risk contexts. Experimental results show that RESPOND outperforms existing LLM-based driving agents in highway scenarios and reduces risk in real-world cut-in scenarios, demonstrating its potential for autonomous driving and personalized driving assistance."
  },
  {
    "title": "Dreamcrafter: Immersive Editing of 3D Radiance Fields Through Flexible, Generative Inputs and Outputs",
    "abstract": "Authoring 3D scenes is a central task for spatial computing applications. Competing visions for lowering existing barriers are (1) focus on immersive, direct manipulation of 3D content or (2) leverage AI techniques that capture real scenes (3D Radiance Fields such as, NeRFs, 3D Gaussian Splatting) and modify them at a higher level of abstraction, at the cost of high latency. We unify the complementary strengths of these approaches and investigate how to integrate generative AI advances into real-time, immersive 3D Radiance Field editing. We introduce Dreamcrafter, a VR-based 3D scene editing system that: (1) provides a modular architecture to integrate generative AI algorithms; (2) combines different levels of control for creating objects, including natural language and direct manipulation; and (3) introduces proxy representations that support interaction during high-latency operations. We contribute empirical findings on control preferences and discuss how generative AI interfaces beyond text input enhance creativity in scene editing and world building.",
    "url": "https://arxiv.org/abs/2512.20129",
    "journal": "arXiv cs.HC",
    "ai_summary": "The study focuses on combining immersive, direct manipulation of 3D content with AI techniques like 3D Radiance Fields to enable real-time, immersive 3D scene editing. The researchers developed a VR-based system called Dreamcrafter that integrates generative AI algorithms, provides different levels of control for object creation, and introduces proxy representations to support interaction during high-latency operations. The findings suggest that incorporating generative AI interfaces beyond text input can enhance creativity in scene editing and world building."
  },
  {
    "title": "/UnmuteAll: Modeling Verbal Communication Patterns of Collaborative Contexts in MOBA Games",
    "abstract": "Team communication plays a vital role in supporting collaboration in multiplayer online games. Therefore, numerous studies were conducted to examine communication patterns in esports teams. While non-verbal communication has been extensively investigated, research on assessing voice-based verbal communication patterns remains relatively understudied. In this study, we propose a framework that automatically assesses verbal communication patterns by constructing networks with utterances transcribed from voice recordings. Through a data collection study, we obtained 84 game sessions from five League of Legends teams and subsequently investigated how verbal communication patterns varied across different conditions. As a result, we revealed that esports players exhibited broader and more balanced participation in collaborative situations, increased utterances over time with the largest rise in decision making, and team-level differences that were contingent on effective professional training. Building upon these findings, this study provides a generalizable tool for analyzing effective team communication.",
    "url": "https://arxiv.org/abs/2512.20116",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study focuses on analyzing verbal communication patterns in esports teams during multiplayer online games, specifically in MOBA games like League of Legends. The researchers developed a framework to automatically assess these patterns by analyzing voice recordings and constructing networks of utterances. The study found that esports players exhibited broader and more balanced participation in collaborative situations, increased their utterances over time with a focus on decision making, and team-level differences were influenced by professional training. Overall, this research provides a tool for analyzing effective team communication in esports contexts."
  },
  {
    "title": "Stories That Teach: Eastern Wisdom for Human-AI Creative Partnerships",
    "abstract": "This workshop explores innovative human-AI collaboration methodologies in HCI visual storytelling education through our established \"gap-and-fill\" approach. Drawing on Eastern aesthetic philosophies of intentional emptiness, including Chinese negative-space traditions, Japanese \"ma\" concepts, and contemporary design minimalism, we demonstrate how educators can teach students to maintain creative agency while strategically leveraging AI assistance. During this workshop, participants will experience a structured three-phase methodology: creating a human-led narrative foundation, identifying strategic gaps, and collaborating on AI enhancements. The workshop combines theoretical foundations with intensive hands-on practice, enabling participants to create compelling HCI visual narratives that demonstrate effective human-AI partnership. Through sequential art techniques, storyboarding exercises, and guided AI integration, attendees learn to communicate complex interactive concepts, accessibility solutions, and user experience flows while preserving narrative coherence and creative vision. Building on our successful workshops at ACM C&C 2025, this session specifically addresses the needs of the Chinese HCI community for culturally informed and pedagogically sound approaches to AI integration in creative education.",
    "url": "https://arxiv.org/abs/2512.19999",
    "journal": "arXiv cs.HC",
    "ai_summary": "This workshop explores innovative methodologies for human-AI collaboration in HCI visual storytelling education, drawing on Eastern aesthetic philosophies of intentional emptiness. Participants learn to maintain creative agency while strategically leveraging AI assistance through a structured three-phase methodology. The workshop enables attendees to create compelling HCI visual narratives that demonstrate effective human-AI partnership, addressing the needs of the Chinese HCI community for culturally informed and pedagogically sound approaches to AI integration in creative education."
  },
  {
    "title": "Developers' Experience with Generative AI -- First Insights from an Empirical Mixed-Methods Field Study",
    "abstract": "With the rise of AI-powered coding assistants, firms and programmers are exploring how to optimize their interaction with them. Research has so far mainly focused on evaluating output quality and productivity gains, leaving aside the developers' experience during the interaction. In this study, we take a multimodal, developer-centered approach to gain insights into how professional developers experience the interaction with Generative AI (GenAI) in their natural work environment in a firm. The aim of this paper is (1) to demonstrate a feasible mixed-method study design with controlled and uncontrolled study periods within a firm setting, (2) to give first insights from complementary behavioral and subjective experience data on developers' interaction with GitHub Copilot and (3) to compare the impact of interaction types (no Copilot use, in-code suggestions, chat prompts or both in-code suggestions and chat prompts) on efficiency, accuracy and perceived workload whilst working on different task categories. Results of the controlled sessions in this study indicate that moderate use of either in-code suggestions or chat prompts improves efficiency (task duration) and reduces perceived workload compared to not using Copilot, while excessive or combined use lessens these benefits. Accuracy (task completion) profits from chat interaction. In general, subjective perception of workload aligns with objective behavioral data in this study. During the uncontrolled period of the study, both higher cognitive load and productivity were perceived when interacting with AI during everyday working tasks. This study motivates the use of comparable study designs, in e.g. workshop or hackathon settings, to evaluate GenAI tools holistically and realistically with a focus on the developers' experience.",
    "url": "https://arxiv.org/abs/2512.19926",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores how professional developers experience interacting with Generative AI (GenAI) in their natural work environment, specifically focusing on GitHub Copilot. The results show that moderate use of in-code suggestions or chat prompts can improve efficiency and reduce perceived workload, while excessive or combined use may lessen these benefits. The study highlights the importance of considering developers' experience when evaluating AI tools and suggests using comparable study designs in workshop or hackathon settings for a more holistic evaluation."
  },
  {
    "title": "Detecting cyberbullying in Spanish texts through deep learning techniques",
    "abstract": "Recent recollected data suggests that it is possible to automatically detect events that may negatively affect the most vulnerable parts of our society, by using any communication technology like social networks or messaging applications. This research consolidates and prepares a corpus with Spanish bullying expressions taken from Twitter in order to use them as an input to train a convolutional neuronal network through deep learning techniques. As a result of this training, a predictive model was created, which can identify Spanish cyberbullying expressions such as insults, racism, homophobic attacks, and so on.",
    "url": "https://arxiv.org/abs/2512.19899",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on detecting cyberbullying in Spanish texts using deep learning techniques. By training a convolutional neuronal network on a corpus of Spanish bullying expressions from Twitter, the researchers were able to create a predictive model that can identify cyberbullying expressions such as insults, racism, and homophobic attacks. This study highlights the importance of using AI to automatically detect and address harmful online behavior that can negatively impact vulnerable populations."
  },
  {
    "title": "Free-Will vs Free-Wheel: Understanding Community Accessibility Requirements of Wheelchair Users through Interviews, Participatory Action, and Modeling",
    "abstract": "Community participation is an important aspect of an individuals physical and mental well-being. This participation is often limited for persons with disabilities, especially those with ambulatory impairments due to the inability to optimally navigate the community. Accessibility is a multi-faceted problem and varies from person to person. Moreover, it depends on various personal and environmental factors. Despite significant research conducted to understand challenges faced by wheelchair users, developing an accessibility model for wheelchair users by identifying various characteristic features has not been thoroughly studied. In this research, we propose a three-dimensional model of accessibility and validate it through in-depth qualitative analysis involving semi-structured interviews and participatory action research. The outcomes of our studies validated many of our hypotheses about community access for wheelchair users and identified a need for more accessible path planning tools and resources. Overall, this research strengthened our three-dimensional User-Wheelchair-Environment model of accessibility.",
    "url": "https://arxiv.org/abs/2512.19898",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on understanding the community accessibility requirements of wheelchair users through interviews, participatory action, and modeling. The study highlights the importance of community participation for individuals with disabilities and identifies the need for more accessible path planning tools and resources. The proposed three-dimensional model of accessibility was validated through qualitative analysis, strengthening the understanding of challenges faced by wheelchair users in navigating the community."
  },
  {
    "title": "Visualizing a Collective Student Model for Procedural Training Environments",
    "abstract": "Visualization plays a relevant role for discovering patterns in big sets of data. In fact, the most common way to help a human with a pattern interpretation is through a graphic. In 2D/3D virtual environments for procedural training the student interaction is more varied and complex than in traditional e-learning environments. Therefore, the visualization and interpretation of students' behaviors becomes a challenge. This motivated us to design the visualization of a collective student model built from student logs taken from 2D/3D virtual environments for procedural training. This paper presents the design decisions that enable a suitable visualization of this model to instructors as well as a web tool that implements this visualization and is intended: to help instructors to improve their own teaching; and to enhance the tutoring strategy of an Intelligent Tutoring System. Then, this paper illustrates, with three detailed examples, how this tool can be used to those educational purposes. Next, the paper presents an experiment for validating the utility of the tool. In this experiment we show how the tool can help to modify the tutoring strategy of a 3D virtual laboratory. In this way, it is shown that the proposed visualization of the model can serve to improve the performance of students in 2D/3D virtual environments for procedural training.",
    "url": "https://arxiv.org/abs/2512.19885",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research focuses on designing a visualization tool for a collective student model built from student logs in 2D/3D virtual environments for procedural training. The tool aims to help instructors improve their teaching and enhance the tutoring strategy of an Intelligent Tutoring System. The paper presents design decisions, examples of tool usage, and an experiment validating its utility in modifying the tutoring strategy of a 3D virtual laboratory to improve student performance in procedural training environments."
  },
  {
    "title": "How Tech Workers Contend with Hazards of Humanlikeness in Generative AI",
    "abstract": "Generative AI's humanlike qualities are driving its rapid adoption in professional domains. However, this anthropomorphic appeal raises concerns from HCI and responsible AI scholars about potential hazards and harms, such as overtrust in system outputs. To investigate how technology workers navigate these humanlike qualities and anticipate emergent harms, we conducted focus groups with 30 professionals across six job functions (ML engineering, product policy, UX research and design, product management, technology writing, and communications). Our findings reveal an unsettled knowledge environment surrounding humanlike generative AI, where workers' varying perspectives illuminate a range of potential risks for individuals, knowledge work fields, and society. We argue that workers require comprehensive support, including clearer conceptions of ``humanlikeness'' to effectively mitigate these risks. To aid in mitigation strategies, we provide a conceptual map articulating the identified hazards and their connection to conflated notions of ``humanlikeness.''",
    "url": "https://arxiv.org/abs/2512.19832",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores how technology workers perceive and navigate the humanlike qualities of generative AI, which are driving its rapid adoption in professional domains. The study conducted focus groups with 30 professionals across various job functions to uncover a range of potential risks associated with overtrust in system outputs and other hazards. The findings highlight the need for comprehensive support and clearer conceptions of \"humanlikeness\" to effectively mitigate these risks in the use of generative AI in knowledge work fields and society."
  },
  {
    "title": "Predicting Student Actions in a Procedural Training Environment",
    "abstract": "Data mining is known to have a potential for predicting user performance. However, there are few studies that explore its potential for predicting student behavior in a procedural training environment. This paper presents a collective student model, which is built from past student logs. These logs are firstly grouped into clusters. Then an extended automaton is created for each cluster based on the sequences of events found in the cluster logs. The main objective of this model is to predict the actions of new students for improving the tutoring feedback provided by an intelligent tutoring system. The proposed model has been validated using student logs collected in a 3D virtual laboratory for teaching biotechnology. As a result of this validation, we concluded that the model can provide reasonably good predictions and can support tutoring feedback that is better adapted to each student type.",
    "url": "https://arxiv.org/abs/2512.19810",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of data mining to predict student behavior in a procedural training environment. By creating a collective student model based on past student logs, the study found that the model can provide reasonably good predictions and improve tutoring feedback in an intelligent tutoring system. The validation of the model using student logs from a virtual laboratory for teaching biotechnology suggests that it can support personalized tutoring feedback for different types of students."
  },
  {
    "title": "Bidirectional human-AI collaboration in brain tumour assessments improves both expert human and AI agent performance",
    "abstract": "The benefits of artificial intelligence (AI) human partnerships-evaluating how AI agents enhance expert human performance-are increasingly studied. Though rarely evaluated in healthcare, an inverse approach is possible: AI benefiting from the support of an expert human agent. Here, we investigate both human-AI clinical partnership paradigms in the magnetic resonance imaging-guided characterisation of patients with brain tumours. We reveal that human-AI partnerships improve accuracy and metacognitive ability not only for radiologists supported by AI, but also for AI agents supported by radiologists. Moreover, the greatest patient benefit was evident with an AI agent supported by a human one. Synergistic improvements in agent accuracy, metacognitive performance, and inter-rater agreement suggest that AI can create more capable, confident, and consistent clinical agents, whether human or model-based. Our work suggests that the maximal value of AI in healthcare could emerge not from replacing human intelligence, but from AI agents that routinely leverage and amplify it.",
    "url": "https://arxiv.org/abs/2512.19707",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the benefits of bidirectional human-AI collaboration in assessing brain tumours using MRI. The study found that partnerships between human radiologists and AI agents improved accuracy and metacognitive ability for both parties, with the greatest patient benefit seen when an AI agent was supported by a human one. The findings suggest that AI can enhance the capabilities of clinical agents by leveraging and amplifying human intelligence, rather than replacing it."
  },
  {
    "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent",
    "abstract": "Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns. We tested whether chain-of-thought reasoning improves agentic planning in a retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS. We developed SAGE (Secure Agent for Generative Dose Expertise), an LLM-based planning agent for automated SRS treatment planning. Two variants generated plans for each case: one using a non-reasoning model, one using a reasoning model. The reasoning variant showed comparable plan dosimetry relative to human planners on primary endpoints (PTV coverage, maximum dose, conformity index, gradient index; all p > 0.21) while reducing cochlear dose below human baselines (p = 0.022). When prompted to improve conformity, the reasoning model demonstrated systematic planning behaviors including prospective constraint verification (457 instances) and trade-off deliberation (609 instances), while the standard model exhibited none of these deliberative processes (0 and 7 instances, respectively). Content analysis revealed that constraint verification and causal explanation concentrated in the reasoning agent. The optimization traces serve as auditable logs, offering a path toward transparent automated planning.",
    "url": "https://arxiv.org/abs/2512.20586",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of a human-in-the-loop reasoning large language model agent, SAGE, for automated stereotactic radiosurgery treatment planning. The study found that the reasoning variant of the agent showed comparable plan dosimetry to human planners while reducing cochlear dose, demonstrating systematic planning behaviors such as constraint verification and trade-off deliberation. This approach offers a path towards transparent automated planning in SRS, addressing concerns about the opacity of black-box AI systems in clinical settings."
  },
  {
    "title": "Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives",
    "abstract": "Growing reliance on LLMs for psychiatric self-assessment raises questions about their ability to interpret qualitative patient narratives. We present the first direct comparison between state-of-the-art LLMs and mental health professionals in diagnosing Borderline (BPD) and Narcissistic (NPD) Personality Disorders utilizing Polish-language first-person autobiographical accounts. We show that the top-performing Gemini Pro models surpassed human professionals in overall diagnostic accuracy by 21.91 percentage points (65.48% vs. 43.57%). While both models and human experts excelled at identifying BPD (F1 = 83.4 & F1 = 80.0, respectively), models severely underdiagnosed NPD (F1 = 6.7 vs. 50.0), showing a reluctance toward the value-laden term \"narcissism.\" Qualitatively, models provided confident, elaborate justifications focused on patterns and formal categories, while human experts remained concise and cautious, emphasizing the patient's sense of self and temporal experience. Our findings demonstrate that while LLMs are highly competent at interpreting complex first-person clinical data, they remain subject to critical reliability and bias issues.",
    "url": "https://arxiv.org/abs/2512.20298",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research compared the diagnostic accuracy of state-of-the-art language models (LLMs) and mental health professionals in identifying Borderline and Narcissistic Personality Disorders using first-person narratives in Polish. The study found that the LLMs outperformed human professionals in overall diagnostic accuracy, particularly in identifying BPD. However, the LLMs struggled with diagnosing NPD, showing a reluctance towards the term \"narcissism.\" The findings highlight the competency of LLMs in interpreting complex clinical data but also raise concerns about reliability and bias issues."
  },
  {
    "title": "Bias Beneath the Tone: Empirical Characterisation of Tone Bias in LLM-Driven UX Systems",
    "abstract": "Large Language Models are increasingly used in conversational systems such as digital personal assistants, shaping how people interact with technology through language. While their responses often sound fluent and natural, they can also carry subtle tone biases such as sounding overly polite, cheerful, or cautious even when neutrality is expected. These tendencies can influence how users perceive trust, empathy, and fairness in dialogue. In this study, we explore tone bias as a hidden behavioral trait of large language models. The novelty of this research lies in the integration of controllable large language model based dialogue synthesis with tone classification models, enabling robust and ethical emotion recognition in personal assistant interactions. We created two synthetic dialogue datasets, one generated from neutral prompts and another explicitly guided to produce positive or negative tones. Surprisingly, even the neutral set showed consistent tonal skew, suggesting that bias may stem from the model's underlying conversational style. Using weak supervision through a pretrained DistilBERT model, we labeled tones and trained several classifiers to detect these patterns. Ensemble models achieved macro F1 scores up to 0.92, showing that tone bias is systematic, measurable, and relevant to designing fair and trustworthy conversational AI.",
    "url": "https://arxiv.org/abs/2512.19950",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the presence of tone bias in large language models used in conversational systems, such as digital personal assistants. The study found that even when prompted with neutral language, these models exhibit consistent tonal skew, influencing how users perceive trust, empathy, and fairness in dialogue. By integrating controllable dialogue synthesis with tone classification models, the researchers were able to detect and measure these biases, highlighting the importance of designing fair and trustworthy conversational AI systems."
  },
  {
    "title": "Reducing Label Dependency in Human Activity Recognition with Wearables: From Supervised Learning to Novel Weakly Self-Supervised Approaches",
    "abstract": "Human activity recognition (HAR) using wearable sensors has advanced through various machine learning paradigms, each with inherent trade-offs between performance and labeling requirements. While fully supervised techniques achieve high accuracy, they demand extensive labeled datasets that are costly to obtain. Conversely, unsupervised methods eliminate labeling needs but often deliver suboptimal performance. This paper presents a comprehensive investigation across the supervision spectrum for wearable-based HAR, with particular focus on novel approaches that minimize labeling requirements while maintaining competitive accuracy. We develop and empirically compare: (1) traditional fully supervised learning, (2) basic unsupervised learning, (3) a weakly supervised learning approach with constraints, (4) a multi-task learning approach with knowledge sharing, (5) a self-supervised approach based on domain expertise, and (6) a novel weakly self-supervised learning framework that leverages domain knowledge and minimal labeled data. Experiments across benchmark datasets demonstrate that: (i) our weakly supervised methods achieve performance comparable to fully supervised approaches while significantly reducing supervision requirements; (ii) the proposed multi-task framework enhances performance through knowledge sharing between related tasks; (iii) our weakly self-supervised approach demonstrates remarkable efficiency with just 10\\% of labeled data. These results not only highlight the complementary strengths of different learning paradigms, offering insights into tailoring HAR solutions based on the availability of labeled data, but also establish that our novel weakly self-supervised framework offers a promising solution for practical HAR applications where labeled data are limited.",
    "url": "https://arxiv.org/abs/2512.19713",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores various machine learning approaches for human activity recognition using wearable sensors, aiming to reduce the labeling requirements while maintaining high accuracy. The study compares traditional supervised learning, unsupervised learning, weakly supervised learning with constraints, multi-task learning, self-supervised learning based on domain expertise, and a novel weakly self-supervised framework. The results show that the weakly supervised methods achieve comparable performance to fully supervised approaches with significantly less labeling, and the weakly self-supervised approach is particularly efficient with minimal labeled data, offering a promising solution for practical applications where labeled data is limited."
  },
  {
    "title": "The Epistemological Consequences of Large Language Models: Rethinking collective intelligence and institutional knowledge",
    "abstract": "We examine epistemological threats posed by human and LLM interaction. We develop collective epistemology as a theory of epistemic warrant distributed across human collectives, using bounded rationality and dual process theory as background. We distinguish internalist justification, defined as reflective understanding of why a proposition is true, from externalist justification, defined as reliable transmission of truths. Both are necessary for collective rationality, but only internalist justification produces reflective knowledge. We specify reflective knowledge as follows: agents understand the evaluative basis of a claim, when that basis is unavailable agents consistently assess the reliability of truth sources, and agents have a duty to apply these standards within their domains of competence. We argue that LLMs approximate externalist reliabilism because they can reliably transmit information whose justificatory basis is established elsewhere, but they do not themselves possess reflective justification. Widespread outsourcing of reflective work to reliable LLM outputs can weaken reflective standards of justification, disincentivize comprehension, and reduce agents' capacity to meet professional and civic epistemic duties. To mitigate these risks, we propose a three tier norm program that includes an epistemic interaction model for individual use, institutional and organizational frameworks that seed and enforce norms for epistemically optimal outcomes, and deontic constraints at organizational and or legislative levels that instantiate discursive norms and curb epistemic vices.",
    "url": "https://arxiv.org/abs/2512.19570",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research examines the epistemological threats posed by human interaction with large language models (LLMs). The study distinguishes between internalist and externalist justification, arguing that while LLMs can reliably transmit information, they do not possess reflective justification. The researchers propose a three-tier norm program to mitigate the risks of outsourcing reflective work to LLMs, emphasizing the importance of maintaining reflective standards of justification and meeting professional and civic epistemic duties."
  },
  {
    "title": "Towards a collaborative digital platform for railway infrastructure projects",
    "abstract": "The management of railway infrastructure projects can be supported by collaborative digital platforms. A survey was carried out to identify the needs and expectations of the various stakeholders involved in the design and construction of railway infrastructure projects regarding collaborative platforms. These needs and expectations can then be translated into functional specifications to be included in the digital platforms. A total of 21 interviews were conducted between October and December 2022, during which 35 individuals were interviewed. Key roles were represented across the different project phases: engineers from design and construction firms, project managers, infrastructure managers. And various engineering fields were represented: civil, electrical, telecommunications, tracks, systems. These interviews were carried out by CentraleSup{}lec | Universit{} Paris-Saclay and by SNCF R{}seau using a structured protocol designed to collect the specific needs of the interviewees for collaboration, as well as the guiding principles that shape both individual work practices and collaboration between professions. The resulting material was analyzed and then synthesized into a conceptual model of a collaborative digital platform for supporting the design and construction phases in a railway infrastructure project. Also, from these interviews emerged five core functionalities that the platform must offer: Providing access to existing infrastructure data; Accelerating repetitive tasks; Verifying essential project requirements; Supporting decision-making; Facilitating coordination among stakeholders.",
    "url": "https://arxiv.org/abs/2512.19169",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research aimed to identify the needs and expectations of stakeholders involved in railway infrastructure projects regarding collaborative digital platforms. Through interviews with 35 individuals from various roles and engineering fields, key functionalities for a collaborative platform were identified, including access to infrastructure data, task acceleration, project requirement verification, decision-making support, and stakeholder coordination. The findings provide insights for the development of a collaborative digital platform to support the design and construction phases of railway infrastructure projects."
  }
]