# arXiv cs.AI Summary â€“ 2025-07-07

## Measurement as Bricolage: Examining How Data Scientists Construct Target Variables for Predictive Modeling Tasks
**URL:** https://arxiv.org/abs/2507.02819

**Abstract:** Data scientists often formulate predictive modeling tasks involving fuzzy, hard-to-define concepts, such as the "authenticity" of student writing or the "healthcare need" of a patient. Yet the process by which data scientists translate fuzzy concepts into a concrete, proxy target variable remains poorly understood. We interview fifteen data scientists in education (N=8) and healthcare (N=7) to understand how they construct target variables for predictive modeling tasks. Our findings suggest that data scientists construct target variables through a bricolage process, involving iterative negotiation between high-level measurement objectives and low-level practical constraints. Data scientists attempt to satisfy five major criteria for a target variable through bricolage: validity, simplicity, predictability, portability, and resource requirements. To achieve this, data scientists adaptively use problem (re)formulation strategies, such as swapping out one candidate target variable for another when the first fails to meet certain criteria (e.g., predictability), or composing multiple outcomes into a single target variable to capture a more holistic set of modeling objectives. Based on our findings, we present opportunities for future HCI, CSCW, and ML research to better support the art and science of target variable construction.

**AI Summary:** This research explores how data scientists in education and healthcare construct target variables for predictive modeling tasks involving fuzzy concepts. The study found that data scientists use a bricolage process, combining high-level measurement objectives with practical constraints to create target variables that meet criteria such as validity, simplicity, predictability, portability, and resource requirements. The findings suggest opportunities for future research to support the art and science of target variable construction in AI.

---

## Time-Masked Transformers with Lightweight Test-Time Adaptation for Neural Speech Decoding
**URL:** https://arxiv.org/abs/2507.02800

**Abstract:** Speech neuroprostheses aim to restore communication for people with severe paralysis by decoding speech directly from neural activity. To accelerate algorithmic progress, a recent benchmark released intracranial recordings from a paralyzed participant attempting to speak, along with a baseline decoding algorithm. Prior work on the benchmark showed impressive accuracy gains. However, these gains increased computational costs and were not demonstrated in a real-time decoding setting. Here, we make three contributions that pave the way towards accurate, efficient, and real-time neural speech decoding. First, we incorporate large amounts of time masking during training. On average, over $50\%$ of each trial is masked. Second, we replace the gated recurrent unit (GRU) architecture used in the baseline algorithm with a compact Transformer. The Transformer architecture uses $77\%$ fewer parameters, cuts peak GPU memory usage by $36\%$ relative, and is significantly faster to calibrate relative to the GRU. Third, we design a lightweight variant of an existing test-time adaptation method developed for decoding handwriting from neural activity. Our variant adapts the model using multiple time masked augmentations of a single trial and requires only one gradient step per trial. Together, these contributions reduce word error rate by $19.5\%$ and effectively mitigate performance degradations across held-out days in a real-time decoding setting while substantially lowering computational costs.

**AI Summary:** This research focuses on improving neural speech decoding for individuals with severe paralysis using intracranial recordings. The study introduces time masking during training, a compact Transformer architecture, and a lightweight test-time adaptation method, resulting in a 19.5% reduction in word error rate and improved performance in real-time decoding while reducing computational costs. These findings are significant as they pave the way for more accurate, efficient, and cost-effective neural speech decoding methods for individuals with communication impairments.

---

## Who's Sorry Now: User Preferences Among Rote, Empathic, and Explanatory Apologies from LLM Chatbots
**URL:** https://arxiv.org/abs/2507.02745

**Abstract:** As chatbots driven by large language models (LLMs) are increasingly deployed in everyday contexts, their ability to recover from errors through effective apologies is critical to maintaining user trust and satisfaction. In a preregistered study with Prolific workers (N=162), we examine user preferences for three types of apologies (rote, explanatory, and empathic) issued in response to three categories of common LLM mistakes (bias, unfounded fabrication, and factual errors). We designed a pairwise experiment in which participants evaluated chatbot responses consisting of an initial error, a subsequent apology, and a resolution. Explanatory apologies were generally preferred, but this varied by context and user. In the bias scenario, empathic apologies were favored for acknowledging emotional impact, while hallucinations, though seen as serious, elicited no clear preference, reflecting user uncertainty. Our findings show the complexity of effective apology in AI systems. We discuss key insights such as personalization and calibration that future systems must navigate to meaningfully repair trust.

**AI Summary:** This research study examined user preferences for different types of apologies (rote, explanatory, and empathic) issued by chatbots in response to common mistakes made by large language models. The study found that explanatory apologies were generally preferred, but preferences varied depending on the context of the mistake and the user. The findings highlight the importance of effective apologies in AI systems to maintain user trust and satisfaction, and suggest that future systems should focus on personalization and calibration to repair trust.

---

## A wireless, inexpensive optical tracker for the CAVE
**URL:** https://arxiv.org/abs/2507.02682

**Abstract:** CAVE displays offer many advantages over other virtual reality (VR) displays, including a large, unencumbering viewing space. Unfortunately, the typical tracking subsystems used with CAVE displays tether the user and lessen this advantage. We have designed a simple, low-cost feet tracker that is wireless, leaving the user free to move. The tracker can be assembled for less than $200 US, and achieves an accuracy of 10 cm at a 20 Hz sampling rate. We have tested the prototype with two applications: a visualization supporting close visual inspection, and a walkthrough of the campus. Although the tracking was convincing, it was clear that the tracker's limitations make it less than ideal for applications requiring precise visual inspection. However, the freedom of motion allowed by the tracker was a compelling supplement to our campus walkthrough, allowing users to stroll and look around corners.

**AI Summary:** The research presents a wireless and inexpensive optical tracker for CAVE displays in virtual reality, allowing users more freedom of movement. The tracker, costing less than $200 US, achieved an accuracy of 10 cm at a 20 Hz sampling rate. While not ideal for precise visual inspection, the tracker's freedom of motion was beneficial for applications like campus walkthroughs.

---

## Are You Listening to Me? Fine-Tuning Chatbots for Empathetic Dialogue
**URL:** https://arxiv.org/abs/2507.02537

**Abstract:** Conversational agents have made significant progress since ELIZA, expanding their role across various domains, including healthcare, education, and customer service. As these agents become increasingly integrated into daily human interactions, the need for emotional intelligence, particularly empathetic listening, becomes increasingly essential. In this study, we explore how Large Language Models (LLMs) respond when tasked with generating emotionally rich interactions. Starting from a small dataset manually crafted by an expert to reflect empathic behavior, we extended the conversations using two LLMs: ChatGPT and Gemini. We analyzed the emotional progression of the dialogues using both sentiment analysis (via VADER) and expert assessments. While the generated conversations often mirrored the intended emotional structure, human evaluation revealed important differences in the perceived empathy and coherence of the responses. These findings suggest that emotion modeling in dialogues requires not only structural alignment in the expressed emotions but also qualitative depth, highlighting the importance of combining automated and humancentered methods in the development of emotionally competent agents.

**AI Summary:** This study explores the use of Large Language Models (LLMs) such as ChatGPT and Gemini in generating emotionally rich interactions for chatbots. The researchers found that while the generated conversations often reflected the intended emotional structure, there were significant differences in perceived empathy and coherence compared to human responses. This highlights the importance of combining automated and human-centered methods in developing emotionally competent conversational agents.

---

## Haptic Biofeedback for Wakeful Rest: Does Stimulation Location Make a Difference?
**URL:** https://arxiv.org/abs/2507.02453

**Abstract:** Wearable haptic interventions offer promising support for relaxation through slow, vibrotactile biofeedback. Despite their potential, current applications focus on stress-inducing procedures and fixed vibration patterns, with limited consideration of body location and dynamic biofeedback during restful states. This study investigates the effects of haptic biofeedback adjusted from real-time heart rate during eyes-closed wakeful rest, comparing four wearable body placements: the wrist, hand, forearm, and shoulder. Heart rate, alpha wave activity on the ear, subjective restfulness, and vibration experience were measured across these conditions. Results show that biofeedback reduced heart rate at the wrist, shoulder, and forearm, while alpha power measured at the ear remained unchanged. Subjective restfulness was rated highest at the shoulder and forearm, which were also the most preferred locations. In addition, participants reported greater comfort, relaxation, and further increased sleepiness at the forearm compared to the wrist, which was more easily recognizable. These findings suggest that the forearm and shoulder are ideal for unobtrusive relaxation feedback for wakeful rest, while the wrist may require design improvements for subjective experience.

**AI Summary:** This study explores the impact of haptic biofeedback on relaxation during wakeful rest, comparing different body placements for vibration stimulation. The results show that biofeedback can reduce heart rate and increase subjective restfulness, with the shoulder and forearm being the most preferred locations for this intervention. These findings suggest that wearable haptic devices on the forearm and shoulder could provide effective and comfortable support for relaxation during wakeful rest.

---

## Closed-Loop Rhythmic Haptic Biofeedback via Smartwatch for Relaxation and Sleep Onset
**URL:** https://arxiv.org/abs/2507.02432

**Abstract:** We investigate the use of musically structured, closed-loop vibration patterns as a passive biofeedback intervention for relaxation and sleep initiation. By encoding rhythmic meter structures into smartwatch vibrations and adapting their frequency to be slightly slower than the user's real-time heart rate, our system aims to reduce arousal through tactile entrainment, offering a non-invasive alternative to auditory or open-loop approaches previously used in sleep and anxiety contexts. In the first study (N=20), we compared five adaptive vibration rhythms for their effects on heart rate and subjective perceptions of relaxation in a resting context. In the second study (N=28), we evaluated the most promising pattern from Study 1 in a prolonged sleep initiation setting. Results showed increased parasympathetic activity and perceived relaxation during short-term stimulation, but no significant effects on sleep-related measures during the sleep onset phase. This work contributes to the understanding of how wearable haptic feedback can support relaxation and sleep, offering design insights and identifying methodological considerations for effectively integrating haptic interaction into self-directed interventions.

**AI Summary:** This research explores using musically structured vibrations from a smartwatch to promote relaxation and aid in sleep onset. The study found that these vibrations, slightly slower than the user's heart rate, could reduce arousal and increase feelings of relaxation in short-term use. While the vibrations did not significantly impact sleep-related measures during the onset phase, the study provides valuable insights into how wearable haptic feedback can support relaxation and sleep.

---

## From Coarse to Fine-Grained Emotion Annotation: An Immediate Recall Paradigm with Validation through Physiological Evidence and Recognition Performance
**URL:** https://arxiv.org/abs/2507.02350

**Abstract:** Traditional video-induced emotion physiological datasets often use whole-trial annotation, assigning a single emotion label to all data collected during an entire trial. This coarse-grained annotation approach misaligns with the dynamic and temporally localized nature of emotional responses as they unfold with video narratives, introducing label noise that limits emotion recognition algorithm evaluation and performance. To solve the label noise problem caused by coarse-grained annotation, we propose a fine-grained annotation method through an immediate recall paradigm. This paradigm integrates an immediate video replay phase after the initial stimulus viewing, allowing participants to precisely mark the onset timestamp, emotion label, and intensity based on their immediate recall. We validate this paradigm through physiological evidence and recognition performance. Physiological validation of multimodal signals within participant-marked windows revealed rhythm-specific EEG patterns and arousal-dependent GSR responses-with SCRs appearing in 91% of high-arousal versus 6% of low-arousal emotion windows. These objective physiological data changes strongly aligned with subjective annotations, confirming annotation precision. For recognition performance, classification experiments showed that models trained on fine-grained annotations achieved 9.7% higher accuracy than traditional whole-trial labeling, despite using less data. This work not only addresses label noise through fine-grained annotation but also demonstrates that annotation precision outweighs data scale in determining emotion recognition performance.

**AI Summary:** This research introduces a fine-grained emotion annotation method using an immediate recall paradigm to capture the dynamic and temporally localized nature of emotional responses in video narratives. The study validates this method through physiological evidence, showing that participant-marked emotion windows align with objective physiological data changes. The results indicate that models trained on fine-grained annotations achieve higher accuracy in emotion recognition compared to traditional whole-trial labeling, highlighting the importance of annotation precision over data scale in determining performance.

---

## Synthetic Heuristic Evaluation: A Comparison between AI- and Human-Powered Usability Evaluation
**URL:** https://arxiv.org/abs/2507.02306

**Abstract:** Usability evaluation is crucial in human-centered design but can be costly, requiring expert time and user compensation. In this work, we developed a method for synthetic heuristic evaluation using multimodal LLMs' ability to analyze images and provide design feedback. Comparing our synthetic evaluations to those by experienced UX practitioners across two apps, we found our evaluation identified 73% and 77% of usability issues, which exceeded the performance of 5 experienced human evaluators (57% and 63%). Compared to human evaluators, the synthetic evaluation's performance maintained consistent performance across tasks and excelled in detecting layout issues, highlighting potential attentional and perceptual strengths of synthetic evaluation. However, synthetic evaluation struggled with recognizing some UI components and design conventions, as well as identifying across screen violations. Additionally, testing synthetic evaluations over time and accounts revealed stable performance. Overall, our work highlights the performance differences between human and LLM-driven evaluations, informing the design of synthetic heuristic evaluations.

**AI Summary:** This research compared the effectiveness of synthetic heuristic evaluation using AI models with traditional human-powered usability evaluation. The study found that the synthetic evaluation method identified a higher percentage of usability issues compared to experienced human evaluators across two apps. While the synthetic evaluation excelled in detecting layout issues, it struggled with recognizing certain UI components and design conventions. Overall, the research suggests that synthetic heuristic evaluation has potential benefits in terms of consistency and performance, but also has limitations that need to be addressed for optimal usability evaluation.

---

## Human-Centered Explainability in Interactive Information Systems: A Survey
**URL:** https://arxiv.org/abs/2507.02300

**Abstract:** Human-centered explainability has become a critical foundation for the responsible development of interactive information systems, where users must be able to understand, interpret, and scrutinize AI-driven outputs to make informed decisions. This systematic survey of literature aims to characterize recent progress in user studies on explainability in interactive information systems by reviewing how explainability has been conceptualized, designed, and evaluated in practice. Following PRISMA guidelines, eight academic databases were searched, and 100 relevant articles were identified. A structural encoding approach was then utilized to extract and synthesize insights from these articles. The main contributions include 1) five dimensions that researchers have used to conceptualize explainability; 2) a classification scheme of explanation designs; 3) a categorization of explainability measurements into six user-centered dimensions. The review concludes by reflecting on ongoing challenges and providing recommendations for future exploration of related issues. The findings shed light on the theoretical foundations of human-centered explainability, informing the design of interactive information systems that better align with diverse user needs and promoting the development of systems that are transparent, trustworthy, and accountable.

**AI Summary:** This research survey examines the importance of human-centered explainability in interactive information systems, emphasizing the need for users to understand AI-driven outputs for informed decision-making. The study identifies key dimensions for conceptualizing explainability, classification schemes for explanation designs, and user-centered dimensions for measuring explainability. The findings highlight the significance of designing transparent, trustworthy, and accountable systems that meet diverse user needs.

---

## Misaligned from Within: Large Language Models Reproduce Our Double-Loop Learning Blindness
**URL:** https://arxiv.org/abs/2507.02283

**Abstract:** This paper examines a critical yet unexplored dimension of the AI alignment problem: the potential for Large Language Models (LLMs) to inherit and amplify existing misalignments between human espoused theories and theories-in-use. Drawing on action science research, we argue that LLMs trained on human-generated text likely absorb and reproduce Model 1 theories-in-use - a defensive reasoning pattern that both inhibits learning and creates ongoing anti-learning dynamics at the dyad, group, and organisational levels. Through a detailed case study of an LLM acting as an HR consultant, we show how its advice, while superficially professional, systematically reinforces unproductive problem-solving approaches and blocks pathways to deeper organisational learning. This represents a specific instance of the alignment problem where the AI system successfully mirrors human behaviour but inherits our cognitive blind spots. This poses particular risks if LLMs are integrated into organisational decision-making processes, potentially entrenching anti-learning practices while lending authority to them. The paper concludes by exploring the possibility of developing LLMs capable of facilitating Model 2 learning - a more productive theory-in-use - and suggests this effort could advance both AI alignment research and action science practice. This analysis reveals an unexpected symmetry in the alignment challenge: the process of developing AI systems properly aligned with human values could yield tools that help humans themselves better embody those same values.

**AI Summary:** This research paper explores how Large Language Models (LLMs) can inherit and amplify existing misalignments in human thinking patterns, hindering learning and creating anti-learning dynamics. Through a case study of an LLM acting as an HR consultant, the paper shows how the model's advice reinforces unproductive problem-solving approaches, highlighting the risks of integrating LLMs into organizational decision-making processes. The study suggests the potential for developing LLMs capable of promoting more productive learning patterns, which could benefit both AI alignment research and human behavior.

---

## A framework for 3D interaction techniques
**URL:** https://arxiv.org/abs/2507.02254

**Abstract:** This paper presents a software architecture for 3D interaction techniques (ITs) and an object oriented, toolkit-independent framework that implements such architecture. ITs are composed of basic filters connected in a dataflow, where virtual input devices and objects in the scene are sources of information. An execution model defines the general flow of information between filters. This framework has been designed to be extensible: new information types, new input devices, new execution models, or new interaction techniques can easily be added. Application specific code and application specific ITs are seamlessly integrated into this architecture.

**AI Summary:** This paper introduces a framework for 3D interaction techniques (ITs) that utilizes a software architecture based on basic filters connected in a dataflow. The framework allows for easy integration of new information types, input devices, execution models, and interaction techniques, making it highly extensible. This architecture enables seamless integration of application-specific code and ITs, providing a flexible and customizable solution for 3D interaction.

---

## An Exploration of Internal States in Collaborative Problem Solving
**URL:** https://arxiv.org/abs/2507.02229

**Abstract:** Collaborative problem solving (CPS) is a complex cognitive, social, and emotional process that is increasingly prevalent in educational and professional settings. This study investigates the emotional states of individuals during CPS using a mixed-methods approach. Teams of four first completed a novel CPS task. Immediately after, each individual was placed in an isolated room where they reviewed the video of their group performing the task and self-reported their internal experiences throughout the task. We performed a linguistic analysis of these internal monologues, providing insights into the range of emotions individuals experience during CPS. Our analysis showed distinct patterns in language use, including characteristic unigrams and bigrams, key words and phrases, emotion labels, and semantic similarity between emotion-related words.

**AI Summary:** This study explores the emotional states of individuals during collaborative problem solving (CPS) using a mixed-methods approach. Teams completed a CPS task and individuals then self-reported their internal experiences while reviewing a video of their group. The linguistic analysis of these internal monologues revealed distinct patterns in language use, providing insights into the range of emotions individuals experience during CPS.

---

## VergeIO: Depth-Aware Eye Interaction on Glasses
**URL:** https://arxiv.org/abs/2507.02187

**Abstract:** There is growing industry interest in creating unobtrusive designs for electrooculography (EOG) sensing of eye gestures on glasses (e.g. JINS MEME and Apple eyewear). We present VergeIO, the first EOG-based glasses that enables depth-aware eye interaction using vergence with an optimized electrode layout and novel smart glass prototype. It can distinguish between four and six depth-based eye gestures with 83-98% accuracy using personalized models in a user study across 11 users and 1,320 gesture instances. It generalizes to unseen users with an accuracy of 80-98% without any calibration. To reduce false detections, we incorporate a motion artifact detection pipeline and a preamble-based activation scheme. The system uses dry sensors without any adhesives or gel, and operates in real time with 3 mW power consumption by the sensing front-end, making it suitable for always-on sensing.

**AI Summary:** The research introduces VergeIO, a novel EOG-based glasses system that enables depth-aware eye interaction using vergence. The system can accurately distinguish between four and six depth-based eye gestures with high accuracy across multiple users, without the need for calibration. It operates in real time with low power consumption, making it suitable for always-on sensing applications.

---

## EvalAssist: A Human-Centered Tool for LLM-as-a-Judge
**URL:** https://arxiv.org/abs/2507.02186

**Abstract:** With the broad availability of large language models and their ability to generate vast outputs using varied prompts and configurations, determining the best output for a given task requires an intensive evaluation process, one where machine learning practitioners must decide how to assess the outputs and then carefully carry out the evaluation. This process is both time-consuming and costly. As practitioners work with an increasing number of models, they must now evaluate outputs to determine which model and prompt performs best for a given task. LLMs are increasingly used as evaluators to filter training data, evaluate model performance, assess harms and risks, or assist human evaluators with detailed assessments. We present EvalAssist, a framework that simplifies the LLM-as-a-judge workflow. The system provides an online criteria development environment, where users can interactively build, test, and share custom evaluation criteria in a structured and portable format. We support a set of LLM-based evaluation pipelines that leverage off-the-shelf LLMs and use a prompt-chaining approach we developed and contributed to the UNITXT open-source library. Additionally, our system also includes specially trained evaluators to detect harms and risks in LLM outputs. We have deployed the system internally in our organization with several hundreds of users.

**AI Summary:** The research introduces EvalAssist, a tool designed to simplify the process of evaluating outputs generated by large language models (LLMs) for various tasks. By providing an online criteria development environment and leveraging off-the-shelf LLMs with a prompt-chaining approach, EvalAssist aims to streamline the evaluation process, making it more efficient and cost-effective for machine learning practitioners. The system also includes specially trained evaluators to detect harms and risks in LLM outputs, showcasing its potential to assist in filtering training data and assessing model performance.

---

## The Revolution Has Arrived: What the Current State of Large Language Models in Education Implies for the Future
**URL:** https://arxiv.org/abs/2507.02180

**Abstract:** Large language Models have only been widely available since 2022 and yet in less than three years have had a significant impact on approaches to education and educational technology. Here we review the domains in which they have been used, and discuss a variety of use cases, their successes and failures. We then progress to discussing how this is changing the dynamic for learners and educators, consider the main design challenges facing LLMs if they are to become truly helpful and effective as educational systems, and reflect on the learning paradigms they support. We make clear that the new interaction paradigms they bring are significant and argue that this approach will become so ubiquitous it will become the default way in which we interact with technologies, and revolutionise what people expect from computer systems in general. This leads us to present some specific and significant considerations for the design of educational technology in the future that are likely to be needed to ensure acceptance by the changing expectations of learners and users.

**AI Summary:** Large language models have quickly become a significant force in education, with various successful and unsuccessful use cases. The impact of these models on learners and educators is changing the way we interact with technology, leading to a revolution in computer systems. The design of educational technology in the future will need to adapt to meet the changing expectations of users influenced by the prevalence of large language models.

---

## StorySpace: Technology supporting reflection, expression, and discourse in classroom narrative
**URL:** https://arxiv.org/abs/2507.02156

**Abstract:** The StorySpace project studies the role new interface technologies might play in high school education. With this approach in mind, StorySpace is specifically designed to support and enhance classroom narrative, an already well-established classroom activity. StorySpace strives to achieve this through adherence to three design goals. The first is to trigger student reflection and interpretation. The narrative medium created by StorySpace should represent the topic of classroom discussion and learning in all its complexity. In building their representation, the students will then be confronted with that same complexity. The medium should also itself be exciting and compelling, making classroom narrative interesting and fun.

**AI Summary:** The StorySpace project explores the use of new interface technologies to enhance classroom narrative in high school education. The project aims to trigger student reflection and interpretation by creating a narrative medium that represents the complexity of classroom topics. By making classroom narrative more engaging and exciting, StorySpace seeks to improve student learning and discourse in the classroom.

---

## A Theory-driven and AI-enhanced Simulation Platform for Cultivating Nutrition Literacy
**URL:** https://arxiv.org/abs/2507.02138

**Abstract:** This study introduces and evaluates Healthy Choice, an innovative theory-driven and AI-enhanced simulation platform designed to cultivate nutrition literacy through interactive scenario-based learning experiences. We collected feedback from 114 university students with diverse backgrounds who completed simulated product selection scenarios. Quantitative ratings of usefulness and ease of use demonstrated high user satisfaction.

**AI Summary:** The study introduces Healthy Choice, a simulation platform aimed at improving nutrition literacy through interactive learning experiences. Feedback from 114 university students showed high user satisfaction with the platform, indicating its potential effectiveness in promoting healthy food choices. The use of AI-enhanced technology in the platform could be a promising approach to enhancing nutrition education.

---

## PAL: Designing Conversational Agents as Scalable, Cooperative Patient Simulators for Palliative-Care Training
**URL:** https://arxiv.org/abs/2507.02122

**Abstract:** Effective communication in serious illness and palliative care is essential but often under-taught due to limited access to training resources like standardized patients. We present PAL (Palliative Assisted Learning-bot), a conversational system that simulates emotionally nuanced patient interactions and delivers structured feedback grounded in an existing empathy-based framework. PAL supports text and voice modalities and is designed to scaffold clinical skill-building through repeated, low-cost practice. Through a mixed-methods study with 17 U.S. medical trainees and clinicians, we explore user engagement with PAL, evaluate usability, and examine design tensions around modalities, emotional realism, and feedback delivery. Participants found PAL helpful for reflection and skill refinement, though some noted limitations in emotional authenticity and the adaptability of feedback. We contribute: (1) empirical evidence that large language models can support palliative communication training; (2) design insights for modality-aware, emotionally sensitive simulation tools; and (3) implications for systems that support emotional labor, cooperative learning, and AI-augmented training in high-stakes care settings.

**AI Summary:** The research presents PAL, a conversational system designed to simulate patient interactions for palliative care training. The study with medical trainees and clinicians showed that PAL was helpful for skill refinement, though some users noted limitations in emotional authenticity and feedback adaptability. The findings suggest that large language models can support palliative communication training and provide insights for designing emotionally sensitive simulation tools for cooperative learning in high-stakes care settings.

---

## Revisiting Active Learning under (Human) Label Variation
**URL:** https://arxiv.org/abs/2507.02593

**Abstract:** Access to high-quality labeled data remains a limiting factor in applied supervised learning. While label variation (LV), i.e., differing labels for the same instance, is common, especially in natural language processing, annotation frameworks often still rest on the assumption of a single ground truth. This overlooks human label variation (HLV), the occurrence of plausible differences in annotations, as an informative signal. Similarly, active learning (AL), a popular approach to optimizing the use of limited annotation budgets in training ML models, often relies on at least one of several simplifying assumptions, which rarely hold in practice when acknowledging HLV. In this paper, we examine foundational assumptions about truth and label nature, highlighting the need to decompose observed LV into signal (e.g., HLV) and noise (e.g., annotation error). We survey how the AL and (H)LV communities have addressed -- or neglected -- these distinctions and propose a conceptual framework for incorporating HLV throughout the AL loop, including instance selection, annotator choice, and label representation. We further discuss the integration of large language models (LLM) as annotators. Our work aims to lay a conceptual foundation for HLV-aware active learning, better reflecting the complexities of real-world annotation.

**AI Summary:** This research paper explores the impact of human label variation (HLV) on active learning (AL) in supervised machine learning models, particularly in natural language processing. The study highlights the need to distinguish between signal (HLV) and noise (annotation error) in labeled data and proposes a framework for incorporating HLV throughout the AL loop, including instance selection and annotator choice. The integration of large language models (LLM) as annotators is also discussed, aiming to improve the accuracy and efficiency of training ML models with limited annotation budgets.

---

## Human-Machine Collaboration and Ethical Considerations in Adaptive Cyber-Physical Systems
**URL:** https://arxiv.org/abs/2507.02578

**Abstract:** Adaptive Cyber-Physical Systems (CPS) are systems that integrate both physical and computational capabilities, which can adjust in response to changing parameters. Furthermore, they increasingly incorporate human-machine collaboration, allowing them to benefit from the individual strengths of humans and machines. Human-Machine Teaming (HMT) represents the most advanced paradigm of human-machine collaboration, envisioning seamless teamwork between humans and machines. However, achieving effective and seamless HMT in adaptive CPS is challenging. While adaptive CPS already benefit from feedback loops such as MAPE-K, there is still a gap in integrating humans into these feedback loops due to different operational cadences of humans and machines. Further, HMT requires constant monitoring of human operators, collecting potentially sensitive information about their actions and behavior. Respecting the privacy and human values of the actors of the CPS is crucial for the success of human-machine teams. This research addresses these challenges by: (1) developing novel methods and processes for integrating HMT into adaptive CPS, focusing on human-machine interaction principles and their incorporation into adaptive feedback loops found in CPS, and (2) creating frameworks for integrating, verifying, and validating ethics and human values throughout the system lifecycle, starting from requirements engineering.

**AI Summary:** This research explores the challenges and ethical considerations of integrating Human-Machine Teaming (HMT) into Adaptive Cyber-Physical Systems (CPS). The study highlights the importance of incorporating human-machine collaboration principles into adaptive feedback loops in CPS and developing frameworks for integrating ethics and human values throughout the system lifecycle. The findings emphasize the need for constant monitoring of human operators, respecting privacy, and ensuring the success of human-machine teams in adaptive CPS.

---

## TFOC-Net: A Short-time Fourier Transform-based Deep Learning Approach for Enhancing Cross-Subject Motor Imagery Classification
**URL:** https://arxiv.org/abs/2507.02510

**Abstract:** Cross-subject motor imagery (CS-MI) classification in brain-computer interfaces (BCIs) is a challenging task due to the significant variability in Electroencephalography (EEG) patterns across different individuals. This variability often results in lower classification accuracy compared to subject-specific models, presenting a major barrier to developing calibration-free BCIs suitable for real-world applications. In this paper, we introduce a novel approach that significantly enhances cross-subject MI classification performance through optimized preprocessing and deep learning techniques. Our approach involves direct classification of Short-Time Fourier Transform (STFT)-transformed EEG data, optimized STFT parameters, and a balanced batching strategy during training of a Convolutional Neural Network (CNN). This approach is uniquely validated across four different datasets, including three widely-used benchmark datasets leading to substantial improvements in cross-subject classification, achieving 67.60% on the BCI Competition IV Dataset 1 (IV-1), 65.96% on Dataset 2A (IV-2A), and 80.22% on Dataset 2B (IV-2B), outperforming state-of-the-art techniques. Additionally, we systematically investigate the classification performance using MI windows ranging from the full 4-second window to 1-second windows. These results establish a new benchmark for generalizable, calibration-free MI classification in addition to contributing a robust open-access dataset to advance research in this domain.

**AI Summary:** The research introduces a novel approach, TFOC-Net, for enhancing cross-subject motor imagery classification in brain-computer interfaces. By directly classifying Short-Time Fourier Transform-transformed EEG data with optimized parameters and using a balanced batching strategy in training a Convolutional Neural Network, the approach achieved significant improvements in classification accuracy across multiple datasets. The results establish a new benchmark for calibration-free motor imagery classification and contribute to advancing research in this field.

---

## MISC: Minimal Intervention Shared Control with Guaranteed Safety under Non-Convex Constraints
**URL:** https://arxiv.org/abs/2507.02438

**Abstract:** Shared control combines human intention with autonomous decision-making, from low-level safety overrides to high-level task guidance, enabling systems that adapt to users while ensuring safety and performance. This enhances task effectiveness and user experience across domains such as assistive robotics, teleoperation, and autonomous driving. However, existing shared control methods, based on e.g. Model Predictive Control, Control Barrier Functions, or learning-based control, struggle with feasibility, scalability, or safety guarantees, particularly since the user input is unpredictable.
To address these challenges, we propose an assistive controller framework based on Constrained Optimal Control Problem that incorporates an offline-computed Control Invariant Set, enabling online computation of control actions that ensure feasibility, strict constraint satisfaction, and minimal override of user intent. Moreover, the framework can accommodate structured class of non-convex constraints, which are common in real-world scenarios. We validate the approach through a large-scale user study with 66 participants--one of the most extensive in shared control research--using a computer game environment to assess task load, trust, and perceived control, in addition to performance. The results show consistent improvements across all these aspects without compromising safety and user intent.

**AI Summary:** This research introduces a new assistive controller framework called MISC that combines human intention with autonomous decision-making to ensure safety and performance in tasks such as assistive robotics and autonomous driving. The framework incorporates an offline-computed Control Invariant Set to enable online computation of control actions that guarantee feasibility, strict constraint satisfaction, and minimal override of user intent, even with non-convex constraints. A large-scale user study with 66 participants validates the approach, showing consistent improvements in task load, trust, perceived control, and performance without compromising safety and user intent.

---

## DigiT4TAF -- Bridging Physical and Digital Worlds for Future Transportation Systems
**URL:** https://arxiv.org/abs/2507.02400

**Abstract:** In the future, mobility will be strongly shaped by the increasing use of digitalization. Not only will individual road users be highly interconnected, but also the road and associated infrastructure. At that point, a Digital Twin becomes particularly appealing because, unlike a basic simulation, it offers a continuous, bilateral connection linking the real and virtual environments. This paper describes the digital reconstruction used to develop the Digital Twin of the Test Area Autonomous Driving-Baden-WÃ¼rttemberg (TAF-BW), Germany. The TAF-BW offers a variety of different road sections, from high-traffic urban intersections and tunnels to multilane motorways. The test area is equipped with a comprehensive Vehicle-to-Everything (V2X) communication infrastructure and multiple intelligent intersections equipped with camera sensors to facilitate real-time traffic flow monitoring. The generation of authentic data as input for the Digital Twin was achieved by extracting object lists at the intersections. This process was facilitated by the combined utilization of camera images from the intelligent infrastructure and LiDAR sensors mounted on a test vehicle. Using a unified interface, recordings from real-world detections of traffic participants can be resimulated. Additionally, the simulation framework's design and the reconstruction process is discussed. The resulting framework is made publicly available for download and utilization at: this https URL The demonstration uses two case studies to illustrate the application of the digital twin and its interfaces: the analysis of traffic signal systems to optimize traffic flow and the simulation of security-related scenarios in the communications sector.

**AI Summary:** This research paper focuses on developing a Digital Twin for the Test Area Autonomous Driving-Baden-WÃ¼rttemberg in Germany, which connects the real and virtual environments for future transportation systems. The Digital Twin utilizes data from intelligent infrastructure and LiDAR sensors to simulate real-world traffic scenarios, allowing for the optimization of traffic flow and the simulation of security-related scenarios in the communications sector. The framework developed in this study is publicly available for download and utilization, highlighting the potential impact of digitalization on shaping future mobility.

---

## Transformer-based EEG Decoding: A Survey
**URL:** https://arxiv.org/abs/2507.02320

**Abstract:** Electroencephalography (EEG) is one of the most common signals used to capture the electrical activity of the brain, and the decoding of EEG, to acquire the user intents, has been at the forefront of brain-computer/machine interfaces (BCIs/BMIs) research. Compared to traditional EEG analysis methods with machine learning, the advent of deep learning approaches have gradually revolutionized the field by providing an end-to-end long-cascaded architecture, which can learn more discriminative features automatically. Among these, Transformer is renowned for its strong handling capability of sequential data by the attention mechanism, and the application of Transformers in various EEG processing tasks is increasingly prevalent. This article delves into a relevant survey, summarizing the latest application of Transformer models in EEG decoding since it appeared. The evolution of the model architecture is followed to sort and organize the related advances, in which we first elucidate the fundamentals of the Transformer that benefits EEG decoding and its direct application. Then, the common hybrid architectures by integrating basic Transformer with other deep learning techniques (convolutional/recurrent/graph/spiking neural netwo-rks, generative adversarial networks, diffusion models, etc.) is overviewed in detail. The research advances of applying the modified intrinsic structures of customized Transformer have also been introduced. Finally, the current challenges and future development prospects in this rapidly evolving field are discussed. This paper aims to help readers gain a clear understanding of the current state of Transformer applications in EEG decoding and to provide valuable insights for future research endeavors.

**AI Summary:** This survey explores the use of Transformer models in EEG decoding for brain-computer/machine interfaces. The article discusses how Transformers have revolutionized the field by automatically learning discriminative features from EEG data. It also highlights the evolution of model architectures, common hybrid approaches, and challenges in applying Transformers to EEG decoding, providing valuable insights for future research in this rapidly evolving field.

---

## Public perspectives on the design of fusion energy facilities
**URL:** https://arxiv.org/abs/2507.02207

**Abstract:** As fusion energy technologies approach demonstration and commercial deployment, understanding public perspectives on future fusion facilities will be critical for achieving social license, especially because fusion energy facilities, unlike large fission reactors, may be sited in closer proximity to people and communities, due to distinct regulatory frameworks. In a departure from the 'decide-announce-defend' approach typically used to site energy infrastructure, we develop a participatory design methodology for collaboratively designing fusion energy facilities with prospective host communities. We present here our findings from a participatory design workshop that brought together 22 community participants and 34 engineering students. Our analysis of the textual and visual data from this workshop shows a range of design values and decision-making criteria with 'integrity' and 'respect' ranking highest among values and 'economic benefits' and 'environmental protection/safety' ranking highest among decision-making criteria. Salient design themes that emerge across facility concepts include connecting the history and legacy of the community to the design of the facility, care for workers, transparency and access to the facility, and health and safety of the host community. Participants reported predominantly positive sentiments, expressing joy and surprise as the workshop progressed from learning about fusion to designing the hypothetical facility. Our findings suggest that carrying out participatory design in the early stages of technology development can invite and make concrete public hopes and concerns, improve understanding of, and curiosity about, an emerging technology, build toward social license, and inform context-specific development of fusion energy facilities.

**AI Summary:** This research explores public perspectives on the design of future fusion energy facilities, which may be located closer to communities than traditional fission reactors. The study introduces a participatory design methodology to collaboratively design fusion facilities with prospective host communities, finding that values of 'integrity' and 'respect' are important, along with decision-making criteria such as 'economic benefits' and 'environmental protection/safety'. The findings suggest that involving the public in the design process early on can address concerns, build support, and inform the development of fusion energy facilities.

---

## Computer Science Education in the Age of Generative AI
**URL:** https://arxiv.org/abs/2507.02183

**Abstract:** Generative AI tools - most notably large language models (LLMs) like ChatGPT and Codex - are rapidly revolutionizing computer science education. These tools can generate, debug, and explain code, thereby transforming the landscape of programming instruction. This paper examines the profound opportunities that AI offers for enhancing computer science education in general, from coding assistance to fostering innovative pedagogical practices and streamlining assessments. At the same time, it highlights challenges including academic integrity concerns, the risk of over-reliance on AI, and difficulties in verifying originality. We discuss what computer science educators should teach in the AI era, how to best integrate these technologies into curricula, and the best practices for assessing student learning in an environment where AI can generate code, prototypes and user feedback. Finally, we propose a set of policy recommendations designed to harness the potential of generative AI while preserving the integrity and rigour of computer science education. Empirical data and emerging studies are used throughout to support our arguments.

**AI Summary:** Generative AI tools like ChatGPT and Codex are transforming computer science education by generating, debugging, and explaining code. While these tools offer opportunities for enhancing programming instruction, there are challenges such as academic integrity concerns and the risk of over-reliance on AI. The paper discusses how educators can best integrate AI technologies into curricula, assess student learning, and proposes policy recommendations to harness the potential of generative AI while maintaining the integrity of computer science education.

---

## Optimising task allocation to balance business goals and worker well-being for financial service workforces
**URL:** https://arxiv.org/abs/2507.01968

**Abstract:** Purpose: Financial service companies manage huge volumes of data which requires timely error identification and resolution. The associated tasks to resolve these errors frequently put financial analyst workforces under significant pressure leading to resourcing challenges and increased business risk. To address this challenge, we introduce a formal task allocation model which considers both business orientated goals and analyst well-being.
Methodology: We use a Genetic Algorithm (GA) to optimise our formal model to allocate and schedule tasks to analysts. The proposed solution is able to allocate tasks to analysts with appropriate skills and experience, while taking into account staff well-being objectives.
Findings: We demonstrate our GA model outperforms baseline heuristics, current working practice, and is applicable to a range of single and multi-objective real-world scenarios. We discuss the potential for metaheuristics (such as GAs) to efficiently find sufficiently good allocations which can provide recommendations for financial service managers in-the-loop.
Originality: A key gap in existing allocation and scheduling models, is fully considering worker well-being. This paper presents an allocation model which explicitly optimises for well-being while still improving on current working practice for efficiency.

**AI Summary:** This research introduces a formal task allocation model using a Genetic Algorithm to balance business goals and worker well-being for financial analyst workforces. The model outperformed baseline heuristics and current working practices, demonstrating its applicability to real-world scenarios. The inclusion of worker well-being as a key factor in task allocation is a novel contribution to existing models and has the potential to provide valuable recommendations for financial service managers.

---

## Spatial tangible user interfaces for cognitive assessment and training
**URL:** https://arxiv.org/abs/2507.01944

**Abstract:** This paper discusses Tangible User Interfaces (TUIs) and their potential impact on cognitive assessment and cognitive training. We believe that TUIs, and particularly a subset that we dub spatial TUIs, can extend human computer interaction beyond some of its current limitations. Spatial TUIs exploit human innate spatial and tactile ability in an intuitive and direct manner, affording interaction paradigms that are practically impossible using current interface technology. As proof-of-concept we examine implementations in the field of cognitive assessment and training. In this paper we use Cognitive Cubes, a novel TUI we developed, as an applied test bed for our beliefs, presenting promising experimental results for cognitive assessment of spatial ability, and possibly for training purposes.

**AI Summary:** This research paper explores the potential of Spatial Tangible User Interfaces (TUIs) in enhancing cognitive assessment and training. The authors introduce Cognitive Cubes, a TUI they developed, as a tool for assessing spatial ability and potentially for training purposes. The study suggests that spatial TUIs can leverage human spatial and tactile abilities in a more intuitive and direct way, offering new possibilities for interaction beyond current interface technologies.

---

## Bridging UI Design and chatbot Interactions: Applying Form-Based Principles to Conversational Agents
**URL:** https://arxiv.org/abs/2507.01862

**Abstract:** Domain specific chatbot applications often involve multi step interactions, such as refining search filters, selecting multiple items, or performing comparisons. Traditional graphical user interfaces (GUIs) handle these workflows by providing explicit "Submit" (commit data) and "Reset" (discard data) actions, allowing back-end systems to track user intent unambiguously. In contrast, conversational agents rely on subtle language cues, which can lead to confusion and incomplete context management. This paper proposes modeling these GUI inspired metaphors acknowledgment (submit like) and context switching (reset-like) as explicit tasks within large language model (LLM) prompts. By capturing user acknowledgment, reset actions, and chain of thought (CoT) reasoning as structured session data, we preserve clarity, reduce user confusion, and align domain-specific chatbot interactions with back-end logic. We demonstrate our approach in hotel booking and customer management scenarios, highlighting improvements in multi-turn task coherence, user satisfaction, and efficiency.

**AI Summary:** This research paper explores the challenges of multi-step interactions in domain-specific chatbot applications and proposes using GUI-inspired metaphors to improve user experience and back-end logic alignment. By incorporating explicit tasks for acknowledgment, reset actions, and chain of thought reasoning within large language model prompts, the study demonstrates improvements in task coherence, user satisfaction, and efficiency in scenarios such as hotel booking and customer management. This approach bridges the gap between UI design principles and chatbot interactions, enhancing the overall usability of conversational agents.

---

## Human-Machine Collaboration-Guided Space Design: Combination of Machine Learning Models and Humanistic Design Concepts
**URL:** https://arxiv.org/abs/2507.01776

**Abstract:** The integration of machine learning (ML) into spatial design holds immense potential for optimizing space utilization, enhancing functionality, and streamlining design processes. ML can automate tasks, predict performance outcomes, and tailor spaces to user preferences. However, the emotional, cultural, and aesthetic dimensions of design remain crucial for creating spaces that truly resonate with users-elements that ML alone cannot address. The key challenge lies in harmonizing data-driven efficiency with the nuanced, subjective aspects of design. This paper proposes a human-machine collaboration framework to bridge this gap. An effective framework should recognize that while ML enhances design efficiency through automation and prediction, it must be paired with human creativity to ensure spaces are emotionally engaging and culturally relevant. Human designers contribute intuition, empathy, and cultural insight, guiding ML-generated solutions to align with users' emotional and cultural needs. Additionally, we explore how various ML models can be integrated with human-centered design principles. These models can automate design generation and optimization, while human designers refine the outputs to ensure emotional resonance and aesthetic appeal. Through case studies in office and residential design, we illustrate how this framework fosters both creativity and cultural relevance. By merging ML with human creativity, spatial design can achieve a balance of efficiency and emotional impact, resulting in environments that are both functional and deeply human.

**AI Summary:** This research explores the integration of machine learning (ML) into spatial design to optimize space utilization, enhance functionality, and streamline design processes. While ML can automate tasks and predict outcomes, human creativity is essential for addressing emotional, cultural, and aesthetic dimensions of design. The proposed human-machine collaboration framework emphasizes the importance of combining ML efficiency with human intuition, empathy, and cultural insight to create spaces that are both functional and emotionally engaging. Through case studies in office and residential design, the framework demonstrates how this collaboration can achieve a balance of efficiency and emotional impact in spatial design.

---

## Towards culturally-appropriate conversational AI for health in the majority world: An exploratory study with citizens and professionals in Latin America
**URL:** https://arxiv.org/abs/2507.01719

**Abstract:** There is justifiable interest in leveraging conversational AI (CAI) for health across the majority world, but to be effective, CAI must respond appropriately within culturally and linguistically diverse contexts. Therefore, we need ways to address the fact that current LLMs exclude many lived experiences globally. Various advances are underway which focus on top-down approaches and increasing training data. In this paper, we aim to complement these with a bottom-up locally-grounded approach based on qualitative data collected during participatory workshops in Latin America. Our goal is to construct a rich and human-centred understanding of: a) potential areas of cultural misalignment in digital health; b) regional perspectives on chatbots for health and c)strategies for creating culturally-appropriate CAI; with a focus on the understudied Latin American context. Our findings show that academic boundaries on notions of culture lose meaning at the ground level and technologies will need to engage with a broader framework; one that encapsulates the way economics, politics, geography and local logistics are entangled in cultural experience. To this end, we introduce a framework for 'Pluriversal Conversational AI for Health' which allows for the possibility that more relationality and tolerance, rather than just more data, may be called for.

**AI Summary:** This research explores the need for culturally-appropriate conversational AI for health in Latin America, highlighting the importance of addressing cultural and linguistic diversity in AI development. The study emphasizes the importance of a bottom-up approach based on qualitative data collected during participatory workshops to understand potential cultural misalignments in digital health and regional perspectives on chatbots for health. The findings suggest that a framework for 'Pluriversal Conversational AI for Health' may be needed to better incorporate the complexities of cultural experience beyond just increasing training data.

---

## Designing for Community Care: Reimagining Support for Equity & Well-being in Academia
**URL:** https://arxiv.org/abs/2507.01690

**Abstract:** Academic well-being is deeply influenced by peer-support networks, yet they remain informal, inequitable, and unsustainable, often relying on personal connections and social capital rather than structured, inclusive systems. Additionally, institutional well-being responses frequently focus on student populations, neglecting the emotional labour of faculty and staff, reinforcing an exclusionary academic culture. Drawing on HCI methodologies, participatory design, and care ethics, this workshop will provide a space for rethinking how academic communities can support inclusive networks. Through pre-workshop engagement, co-design activities, and reflection, participants will examine systemic gaps in networks and explore ways to embed care, equity, and sustainability into academic peer-support frameworks -- from informal, exclusionary models to structured, inclusive care-based ecosystems. At the end of the workshop, participants will co-develop design strategies for integrating care and resilience in academic ecosystems, resources for designing equitable support systems, and a peer network invested and committed to fostering a supportive academic community.

**AI Summary:** This research explores the importance of peer-support networks in academia and the need for more structured, inclusive systems to support equity and well-being. The study highlights the lack of institutional support for faculty and staff, emphasizing the importance of embedding care, equity, and sustainability into academic peer-support frameworks. Through participatory design and care ethics, the workshop aims to develop strategies for creating a more supportive and inclusive academic community.

---

## Crafting Hanzi as Narrative Bridges: An AI Co-Creation Workshop for Elderly Migrants
**URL:** https://arxiv.org/abs/2507.01548

**Abstract:** This paper explores how older adults, particularly aging migrants in urban China, can engage AI-assisted co-creation to express personal narratives that are often fragmented, underrepresented, or difficult to verbalize. Through a pilot workshop combining oral storytelling and the symbolic reconstruction of Hanzi, participants shared memories of migration and recreated new character forms using Xiaozhuan glyphs, suggested by the Large Language Model (LLM), together with physical materials. Supported by human facilitation and a soft AI presence, participants transformed lived experience into visual and tactile expressions without requiring digital literacy. This approach offers new perspectives on human-AI collaboration and aging by repositioning AI not as a content producer but as a supportive mechanism, and by supporting narrative agency within sociotechnical systems.

**AI Summary:** This research paper explores the use of AI-assisted co-creation workshops for elderly migrants in urban China to express personal narratives through the reconstruction of Hanzi characters. The pilot workshop successfully enabled participants to share migration memories and create new character forms with the help of AI suggestions and physical materials, highlighting the potential for human-AI collaboration in supporting narrative agency without the need for digital literacy. This approach offers new insights into the role of AI in facilitating storytelling and expression among aging populations, emphasizing AI as a supportive mechanism rather than a content producer.

---

## Analysis of Drone-Assisted Building Inspection Training in VR vs 2D Monitor Display: an EEG Study
**URL:** https://arxiv.org/abs/2507.01471

**Abstract:** Researchers have been using simulation-based methods for drone-assisted inspection training. Multiple brain regions are associated with information processes and decision-making, and the connectivity of these regions may further influence inspectors' performance. However, researchers do not understand the pathways of the information flows when drone pilots process the maintenance and manipulation of information, which may affect the efficiency of tacit knowledge transfer. This study aims to reveal the causal connection between participants' brain regions using an electroencephalogram and dynamic causal modeling when processing drone-assisted building energy audit tasks using different display modalities. The results showed similar single-direction connectivity patterns for the different simulation groups. The results also showed similar patterns between brain regions related to visual inspection performance before and after training. These findings highlight the nature of brain asymmetries and may be utilized in measuring cognitive states and designing adaptive automation in the knowledge transfer of drone-based inspection.

**AI Summary:** This study investigates the impact of VR vs 2D monitor display on drone-assisted building inspection training using EEG data and dynamic causal modeling. The results show similar connectivity patterns and brain regions related to visual inspection performance across different simulation groups, suggesting potential implications for measuring cognitive states and designing adaptive automation in drone-based inspection training. These findings contribute to understanding the pathways of information processing in drone pilots and may enhance the efficiency of tacit knowledge transfer in inspection tasks.

---

## Challenges & Opportunities with LLM-Assisted Visualization Retargeting
**URL:** https://arxiv.org/abs/2507.01436

**Abstract:** Despite the ubiquity of visualization examples published on the web, retargeting existing custom chart implementations to new datasets remains difficult, time-intensive, and tedious. The adaptation process assumes author familiarity with both the implementation of the example as well as how the new dataset might need to be transformed to fit into the example code. With recent advances in Large Language Models (LLMs), automatic adaptation of code can be achieved from high-level user prompts, reducing the barrier for visualization retargeting. To better understand how LLMs can assist retargeting and its potential limitations, we characterize and evaluate the performance of LLM assistance across multiple datasets and charts of varying complexity, categorizing failures according to type and severity. In our evaluation, we compare two approaches: (1) directly instructing the LLM model to fully generate and adapt code by treating code as text inputs and (2) a more constrained program synthesis pipeline where the LLM guides the code construction process by providing structural information (e.g., visual encodings) based on properties of the example code and data. We find that both approaches struggle when new data has not been appropriately transformed, and discuss important design recommendations for future retargeting systems.

**AI Summary:** This research explores the challenges and opportunities of using Large Language Models (LLMs) to automate the process of adapting visualization code to new datasets. The study evaluates the performance of LLM assistance in retargeting visualization across various datasets and charts, highlighting limitations in cases where data transformation is needed. The findings suggest that while LLMs can facilitate code adaptation, there are important design considerations to address for more effective retargeting systems in the future.

---

## AI Meets Maritime Training: Precision Analytics for Enhanced Safety and Performance
**URL:** https://arxiv.org/abs/2507.01274

**Abstract:** Traditional simulator-based training for maritime professionals is critical for ensuring safety at sea but often depends on subjective trainer assessments of technical skills, behavioral focus, communication, and body language, posing challenges such as subjectivity, difficulty in measuring key features, and cognitive limitations. Addressing these issues, this study develops an AI-driven framework to enhance maritime training by objectively assessing trainee performance through visual focus tracking, speech recognition, and stress detection, improving readiness for high-risk scenarios. The system integrates AI techniques, including visual focus determination using eye tracking, pupil dilation analysis, and computer vision; communication analysis through a maritime-specific speech-to-text model and natural language processing; communication correctness using large language models; and mental stress detection via vocal pitch. Models were evaluated on data from simulated maritime scenarios with seafarers exposed to controlled high-stress events. The AI algorithms achieved high accuracy, with ~92% for visual detection, ~91% for maritime speech recognition, and ~90% for stress detection, surpassing existing benchmarks. The system provides insights into visual attention, adherence to communication checklists, and stress levels under demanding conditions. This study demonstrates how AI can transform maritime training by delivering objective performance analytics, enabling personalized feedback, and improving preparedness for real-world operational challenges.

**AI Summary:** This study introduces an AI-driven framework for enhancing maritime training by objectively assessing trainee performance through visual focus tracking, speech recognition, and stress detection. The AI algorithms achieved high accuracy in detecting visual focus, maritime speech, and stress levels, surpassing existing benchmarks. This research demonstrates the potential of AI in transforming maritime training by providing objective performance analytics and improving preparedness for high-risk scenarios at sea.

---

## Judgment as Coordination: A Joint Systems View of Visualization Design Practice
**URL:** https://arxiv.org/abs/2507.01209

**Abstract:** Professional visualization design has become an increasingly important area of inquiry, yet much of the field's discourse remains anchored in researcher-centered contexts. Studies of design practice often focus on individual designers' decisions and reflections, offering limited insight into the collaborative and systemic dimensions of professional work. In this paper, we propose a systems-level reframing of design judgment grounded in the coordination and adaptation that sustain progress amid uncertainty, constraint, and misalignment. Drawing on sustained engagement across multiple empirical studies--including ethnographic observation of design teams and qualitative studies of individual practitioners--we identify recurring episodes in which coherence was preserved not by selecting an optimal option, but by repairing alignment, adjusting plans, and reframing goals. We interpret these dynamics through the lens of Joint Cognitive Systems, which provide tools for analyzing how judgment emerges as a distributed capacity within sociotechnical activity. This perspective surfaces often-invisible work in visualization design and offers researchers a new conceptual vocabulary for studying how design activity is sustained in practice.

**AI Summary:** This research paper proposes a systems-level approach to understanding professional visualization design practice, focusing on the coordination and adaptation that occur in collaborative settings. The study highlights the importance of repairing alignment, adjusting plans, and reframing goals in maintaining coherence in design work. By analyzing design judgment as a distributed capacity within sociotechnical activity, the paper offers a new conceptual framework for studying how design activity is sustained in practice.

---

## A Methodological Framework for Capturing Cognitive-Affective States in Collaborative Learning
**URL:** https://arxiv.org/abs/2507.01166

**Abstract:** Identification of affective and attentional states of individuals within groups is difficult to obtain without disrupting the natural flow of collaboration. Recent work from our group used a retrospect cued recall paradigm where participants spoke about their cognitive-affective states while they viewed videos of their groups. We then collected additional participants where their reports were constrained to a subset of pre-identified cognitive-affective states. In this latter case, participants either self reported or reported in response to probes. Here, we present an initial analysis of the frequency and temporal distribution of participant reports, and how the distributions of labels changed across the two collections. Our approach has implications for the educational data mining community in tracking cognitive-affective states in collaborative learning more effectively and in developing improved adaptive learning systems that can detect and respond to cognitive-affective states.

**AI Summary:** This research presents a methodological framework for capturing cognitive-affective states in collaborative learning without disrupting the natural flow of collaboration. The study utilized a retrospect cued recall paradigm and constrained participant reports to pre-identified cognitive-affective states, finding differences in the frequency and temporal distribution of reports between the two collections. The findings have implications for the educational data mining community in better tracking cognitive-affective states in collaborative learning and developing more effective adaptive learning systems.

---

## Animated Visual Encoding and Layer Blending for Identification of Educational Game Strategies
**URL:** https://arxiv.org/abs/2507.01134

**Abstract:** Game-Based Learning has proven to be an effective method for enhancing engagement with educational material. However, gaining a deeper understanding of player strategies remains challenging. Sequential game-state and action-based tracking tools often gather extensive data that can be difficult to interpret as long-term strategy. This data presents unique problems to visualization, as it can be fairly natural, noisy data but is constrained within synthetic, controlled environments, leading to issues such as overplotting which can make interpretation complicated. We propose an animated visual encoding tool that utilizes kinetic visualization to address these issues. This tool enables researchers to construct animated data narratives through the configuration of parameter interpolation curves and blending layers. Finally, we demonstrate the usefulness of the tool while addressing specific interests as outlined by a domain expert collaborator.

**AI Summary:** The research focuses on developing an animated visual encoding tool to better understand player strategies in educational games. Traditional tracking tools can gather extensive but difficult-to-interpret data on long-term strategies. The proposed tool utilizes kinetic visualization to construct animated data narratives, addressing issues such as overplotting and allowing for a clearer interpretation of player strategies, ultimately proving to be useful in enhancing engagement with educational material.

---

## From Literature to ReWA: Discussing Reproductive Well-being in HCI
**URL:** https://arxiv.org/abs/2507.01121

**Abstract:** Reproductive well-being is shaped by intersecting cultural, religious, gendered, and political contexts, yet current technologies often reflect narrow, Western-centric assumptions. In this literature review, we synthesize findings from 147 peer-reviewed papers published between 2015 and 2025 across HCI, CSCW and social computing, ICTD, digital and public health, and AI for well-being scholarship to map the evolving reproductive well-being landscape. We identify three thematic waves that focused on early access and education, cultural sensitivity and privacy, and AI integration with policy-aware design, and highlight how technologies support or constrain diverse reproductive experiences. Our analysis reveals critical gaps in inclusivity, with persistent exclusions of men and non-binary users, migrants, and users in the Global South. Additionally, we surfaced the significant absence of literature on the role of stakeholders (e.g., husband and family members, household maids and cleaning helping hands, midwife, etc.) in the reproductive well-being space. Drawing on the findings from the literature, we propose the ReWA framework to support reproductive well-being for all agendas through six design orientations associated with: location, culture, and history; polyvocality and agency; rationality, temporality, distributive roles, and methodology.

**AI Summary:** This research review highlights the importance of considering diverse cultural, gendered, and political contexts in the development of technologies related to reproductive well-being. The study identifies three thematic waves in the literature, focusing on early access and education, cultural sensitivity and privacy, and AI integration with policy-aware design. The findings reveal gaps in inclusivity, particularly in the representation of men, non-binary users, migrants, and users in the Global South, as well as the absence of literature on the role of various stakeholders in reproductive well-being. The proposed ReWA framework aims to address these gaps and support reproductive well-being through six design orientations.

---

## AI-guided digital intervention with physiological monitoring reduces intrusive memories after experimental trauma
**URL:** https://arxiv.org/abs/2507.01081

**Abstract:** Trauma prevalence is vast globally. Evidence-based digital treatments can help, but most require human guidance. Human guides provide tailored instructions and responsiveness to internal cognitive states, but limit scalability. Can generative AI and neurotechnology provide a scalable alternative? Here we test ANTIDOTE, combining AI guidance and pupillometry to automatically deliver and monitor an evidence-based digital treatment, specifically the Imagery Competing Task Intervention (ICTI), to reduce intrusive memories after psychological trauma. One hundred healthy volunteers were exposed to videos of traumatic events and randomly assigned to an intervention or active control condition. As predicted, intervention participants reported significantly fewer intrusive memories over the following week. Post-hoc assessment against clinical rubrics confirmed the AI guide delivered the intervention successfully. Additionally, pupil size tracked intervention engagement and predicted symptom reduction, providing a candidate biomarker of intervention effectiveness. These findings open a path toward rigorous AI-guided digital interventions that can scale to trauma prevalence.

**AI Summary:** This study tested the effectiveness of an AI-guided digital intervention called ANTIDOTE, which combines AI guidance and pupillometry to automatically deliver an evidence-based treatment to reduce intrusive memories after trauma. Results showed that participants who received the intervention reported significantly fewer intrusive memories compared to those in the control group. The study suggests that AI-guided digital interventions have the potential to scale and provide effective treatment for trauma survivors.

---

## Pensieve Grader: An AI-Powered, Ready-to-Use Platform for Effortless Handwritten STEM Grading
**URL:** https://arxiv.org/abs/2507.01431

**Abstract:** Grading handwritten, open-ended responses remains a major bottleneck in large university STEM courses. We introduce Pensieve (this https URL), an AI-assisted grading platform that leverages large language models (LLMs) to transcribe and evaluate student work, providing instructors with rubric-aligned scores, transcriptions, and confidence ratings. Unlike prior tools that focus narrowly on specific tasks like transcription or rubric generation, Pensieve supports the entire grading pipeline-from scanned student submissions to final feedback-within a human-in-the-loop interface.
Pensieve has been deployed in real-world courses at over 20 institutions and has graded more than 300,000 student responses. We present system details and empirical results across four core STEM disciplines: Computer Science, Mathematics, Physics, and Chemistry. Our findings show that Pensieve reduces grading time by an average of 65%, while maintaining a 95.4% agreement rate with instructor-assigned grades for high-confidence predictions.

**AI Summary:** The study introduces Pensieve, an AI-assisted grading platform for handwritten STEM assignments that uses large language models to transcribe and evaluate student work, providing instructors with rubric-aligned scores and confidence ratings. Pensieve has been successfully deployed in real-world courses at over 20 institutions, grading over 300,000 student responses and reducing grading time by 65% while maintaining a high agreement rate with instructor-assigned grades. The platform supports the entire grading pipeline and has significant implications for improving efficiency and accuracy in STEM course grading.

---

## Beyond Black-Box AI: Interpretable Hybrid Systems for Dementia Care
**URL:** https://arxiv.org/abs/2507.01282

**Abstract:** The recent boom of large language models (LLMs) has re-ignited the hope that artificial intelligence (AI) systems could aid medical diagnosis. Yet despite dazzling benchmark scores, LLM assistants have yet to deliver measurable improvements at the bedside. This scoping review aims to highlight the areas where AI is limited to make practical contributions in the clinical setting, specifically in dementia diagnosis and care.
Standalone machine-learning models excel at pattern recognition but seldom provide actionable, interpretable guidance, eroding clinician trust. Adjacent use of LLMs by physicians did not result in better diagnostic accuracy or speed. Key limitations trace to the data-driven paradigm: black-box outputs which lack transparency, vulnerability to hallucinations, and weak causal reasoning. Hybrid approaches that combine statistical learning with expert rule-based knowledge, and involve clinicians throughout the process help bring back interpretability. They also fit better with existing clinical workflows, as seen in examples like PEIRS and ATHENA-CDS.
Future decision-support should prioritise explanatory coherence by linking predictions to clinically meaningful causes. This can be done through neuro-symbolic or hybrid AI that combines the language ability of LLMs with human causal expertise. AI researchers have addressed this direction, with explainable AI and neuro-symbolic AI being the next logical steps in further advancement in AI. However, they are still based on data-driven knowledge integration instead of human-in-the-loop approaches. Future research should measure success not only by accuracy but by improvements in clinician understanding, workflow fit, and patient outcomes. A better understanding of what helps improve human-computer interactions is greatly needed for AI systems to become part of clinical practice.

**AI Summary:** This scoping review explores the limitations of current AI systems, particularly in dementia diagnosis and care, due to their lack of interpretability and trustworthiness in clinical settings. The study suggests that hybrid approaches combining statistical learning with expert rule-based knowledge, as seen in examples like PEIRS and ATHENA-CDS, can improve interpretability and fit better with clinical workflows. Future research should focus on developing explainable AI and neuro-symbolic AI that prioritize explanatory coherence and involve clinicians in the decision-making process to enhance human-computer interactions in clinical practice.

---

## 2024 NASA SUITS Report: LLM-Driven Immersive Augmented Reality User Interface for Robotics and Space Exploration
**URL:** https://arxiv.org/abs/2507.01206

**Abstract:** As modern computing advances, new interaction paradigms have emerged, particularly in Augmented Reality (AR), which overlays virtual interfaces onto physical objects. This evolution poses challenges in machine perception, especially for tasks like 3D object pose estimation in complex, dynamic environments. Our project addresses critical issues in human-robot interaction within mobile AR, focusing on non-intrusive, spatially aware interfaces. We present URSA, an LLM-driven immersive AR system developed for NASA's 2023-2024 SUITS challenge, targeting future spaceflight needs such as the Artemis missions. URSA integrates three core technologies: a head-mounted AR device (e.g., HoloLens) for intuitive visual feedback, voice control powered by large language models for hands-free interaction, and robot tracking algorithms that enable accurate 3D localization in dynamic settings. To enhance precision, we leverage digital twin localization technologies, using datasets like DTTD-Mobile and specialized hardware such as the ZED2 camera for real-world tracking under noise and occlusion. Our system enables real-time robot control and monitoring via an AR interface, even in the absence of ground-truth sensors--vital for hazardous or remote operations. Key contributions include: (1) a non-intrusive AR interface with LLM-based voice input; (2) a ZED2-based dataset tailored for non-rigid robotic bodies; (3) a Local Mission Control Console (LMCC) for mission visualization; (4) a transformer-based 6DoF pose estimator (DTTDNet) optimized for depth fusion and real-time tracking; and (5) end-to-end integration for astronaut mission support. This work advances digital twin applications in robotics, offering scalable solutions for both aerospace and industrial domains.

**AI Summary:** The research project focuses on developing an immersive Augmented Reality (AR) system, URSA, for human-robot interaction in dynamic environments, specifically targeting space exploration needs. The system integrates a head-mounted AR device, voice control powered by large language models, and robot tracking algorithms to enable real-time control and monitoring of robots in hazardous or remote operations. Key contributions include a non-intrusive AR interface, a specialized dataset for robotic bodies, a mission visualization console, a transformer-based pose estimator, and end-to-end integration for astronaut mission support, advancing digital twin applications in robotics for aerospace and industrial domains.

---

## Are Large Brainwave Foundation Models Capable Yet? Insights from Fine-tuning
**URL:** https://arxiv.org/abs/2507.01196

**Abstract:** Foundation Models have demonstrated significant success across various domains in Artificial Intelligence (AI), yet their capabilities for brainwave modeling remain unclear. In this paper, we comprehensively evaluate current Large Brainwave Foundation Models (LBMs) through systematic fine-tuning experiments across multiple Brain-Computer Interface (BCI) benchmark tasks, including memory tasks and sleep stage classification. Our extensive analysis shows that state-of-the-art LBMs achieve only marginal improvements (0.9%-1.2%) over traditional deep architectures while requiring significantly more parameters (millions vs thousands), raising important questions about their efficiency and applicability in BCI contexts. Moreover, through detailed ablation studies and Low-Rank Adaptation (LoRA), we significantly reduce trainable parameters without performance degradation, while demonstrating that architectural and training inefficiencies limit LBMs' current capabilities. Our experiments span both full model fine-tuning and parameter-efficient adaptation techniques, providing insights into optimal training strategies for BCI applications. We pioneer the application of LoRA to LBMs, revealing that performance benefits generally emerge when adapting multiple neural network components simultaneously. These findings highlight the critical need for domain-specific development strategies to advance LBMs, suggesting that current architectures may require redesign to fully leverage the potential of foundation models in brainwave analysis.

**AI Summary:** This research paper evaluates the capabilities of Large Brainwave Foundation Models (LBMs) for brainwave modeling through fine-tuning experiments in Brain-Computer Interface (BCI) tasks. The study finds that LBMs only show marginal improvements over traditional deep architectures while requiring significantly more parameters, raising concerns about their efficiency in BCI contexts. Through ablation studies and Low-Rank Adaptation (LoRA), the researchers reduce trainable parameters without performance degradation, indicating the need for domain-specific development strategies to fully leverage the potential of LBMs in brainwave analysis.

---

## Towards a Signal Detection Based Measure for Assessing Information Quality of Explainable Recommender Systems
**URL:** https://arxiv.org/abs/2507.01168

**Abstract:** There is growing interest in explainable recommender systems that provide recommendations along with explanations for the reasoning behind them. When evaluating recommender systems, most studies focus on overall recommendation performance. Only a few assess the quality of the explanations. Explanation quality is often evaluated through user studies that subjectively gather users' opinions on representative explanatory factors that shape end-users' perspective towards the results, not about the explanation contents itself. We aim to fill this gap by developing an objective metric to evaluate Veracity: the information quality of explanations. Specifically, we decompose Veracity into two dimensions: Fidelity and Attunement. Fidelity refers to whether the explanation includes accurate information about the recommended item. Attunement evaluates whether the explanation reflects the target user's preferences. By applying signal detection theory, we first determine decision outcomes for each dimension and then combine them to calculate a sensitivity, which serves as the final Veracity value. To assess the effectiveness of the proposed metric, we set up four cases with varying levels of information quality to validate whether our metric can accurately capture differences in quality. The results provided meaningful insights into the effectiveness of our proposed metric.

**AI Summary:** This research focuses on developing an objective metric, called Veracity, to assess the information quality of explanations provided by explainable recommender systems. The metric is decomposed into two dimensions: Fidelity and Attunement, which evaluate the accuracy of information about recommended items and the alignment with user preferences, respectively. By applying signal detection theory, the researchers were able to calculate a sensitivity value for Veracity and validate the effectiveness of the metric in capturing differences in information quality.

---

## Environment-Aware and Human-Cooperative Swing Control for Lower-Limb Prostheses in Diverse Obstacle Scenarios
**URL:** https://arxiv.org/abs/2507.01111

**Abstract:** Current control strategies for powered lower limb prostheses often lack awareness of the environment and the user's intended interactions with it. This limitation becomes particularly apparent in complex terrains. Obstacle negotiation, a critical scenario exemplifying such challenges, requires both real-time perception of obstacle geometry and responsiveness to user intention about when and where to step over or onto, to dynamically adjust swing trajectories. We propose a novel control strategy that fuses environmental awareness and human cooperativeness: an on-board depth camera detects obstacles ahead of swing phase, prompting an elevated early-swing trajectory to ensure clearance, while late-swing control defers to natural biomechanical cues from the user. This approach enables intuitive stepping strategies without requiring unnatural movement patterns. Experiments with three non-amputee participants demonstrated 100 percent success across more than 150 step-overs and 30 step-ons with randomly placed obstacles of varying heights (4-16 cm) and distances (15-70 cm). By effectively addressing obstacle navigation -- a gateway challenge for complex terrain mobility -- our system demonstrates adaptability to both environmental constraints and user intentions, with promising applications across diverse locomotion scenarios.

**AI Summary:** The research proposes a novel control strategy for lower-limb prostheses that integrates environmental awareness and human cooperativeness to navigate obstacles in complex terrains. The system uses a depth camera to detect obstacles ahead of the swing phase and adjusts swing trajectories in real-time to ensure clearance, while also responding to natural biomechanical cues from the user. Experiments showed 100 percent success in negotiating obstacles of varying heights and distances, highlighting the system's adaptability to environmental constraints and user intentions in diverse locomotion scenarios.

---

## Epitome: Pioneering an Experimental Platform for AI-Social Science Integration
**URL:** https://arxiv.org/abs/2507.01061

**Abstract:** The integration of Large Language Models (LLMs) into social science experiments represents a transformative approach to understanding human-AI interactions and their societal impacts. We introduce Epitome, the world's first open experimental platform dedicated to the deep integration of artificial intelligence and social science. Rooted in theoretical foundations from management, communication studies, sociology, psychology, and ethics, Epitome focuses on the interactive impacts of AI on individuals, organizations, and society during its real-world deployment. It constructs a theoretical support system through cross-disciplinary experiments. The platform offers a one-stop comprehensive experimental solution spanning "foundation models-complex application development-user feedback" through seven core modules, while embedding the classical "control-comparison-comparative causal logic" of social science experiments into multilevel human-computer interaction environments, including dialogues, group chats, and multi-agent virtual scenarios. With its canvas-style, user-friendly interface, Epitome enables researchers to easily design and run complex experimental scenarios, facilitating systematic investigations into the social impacts of AI and exploration of integrated this http URL demonstrate its capabilities, we replicated three seminal social science experiments involving LLMs, showcasing Epitome's potential to streamline complex experimental designs and produce robust results, suitable for publishing in the top selective journals. Our findings highlight the platform's utility in enhancing the efficiency and quality of human-AI interactions, providing valuable insights into the societal implications of AI technologies. Epitome thus offers a powerful tool for advancing interdisciplinary research at the intersection of AI and social science, with potential applications in policy-making, ...

**AI Summary:** Epitome is an experimental platform that integrates artificial intelligence and social science to study human-AI interactions and societal impacts. It offers a comprehensive solution for conducting cross-disciplinary experiments and showcases its potential by replicating seminal social science experiments involving Large Language Models. The platform's user-friendly interface streamlines complex experimental designs and produces robust results, enhancing the efficiency and quality of human-AI interactions and providing valuable insights into the societal implications of AI technologies.

---

## Workflow-Based Evaluation of Music Generation Systems
**URL:** https://arxiv.org/abs/2507.01022

**Abstract:** This study presents an exploratory evaluation of Music Generation Systems (MGS) within contemporary music production workflows by examining eight open-source systems. The evaluation framework combines technical insights with practical experimentation through criteria specifically designed to investigate the practical and creative affordances of the systems within the iterative, non-linear nature of music production. Employing a single-evaluator methodology as a preliminary phase, this research adopts a mixed approach utilizing qualitative methods to form hypotheses subsequently assessed through quantitative metrics. The selected systems represent architectural diversity across both symbolic and audio-based music generation approaches, spanning composition, arrangement, and sound design tasks. The investigation addresses limitations of current MGS in music production, challenges and opportunities for workflow integration, and development potential as collaborative tools while maintaining artistic authenticity. Findings reveal these systems function primarily as complementary tools enhancing rather than replacing human expertise. They exhibit limitations in maintaining thematic and structural coherence that emphasize the indispensable role of human creativity in tasks demanding emotional depth and complex decision-making. This study contributes a structured evaluation framework that considers the iterative nature of music creation. It identifies methodological refinements necessary for subsequent comprehensive evaluations and determines viable areas for AI integration as collaborative tools in creative workflows. The research provides empirically-grounded insights to guide future development in the field.

**AI Summary:** This study evaluates eight open-source Music Generation Systems (MGS) within contemporary music production workflows, highlighting their practical and creative affordances. The findings suggest that MGS function as complementary tools rather than replacements for human expertise, with limitations in maintaining thematic and structural coherence. The research provides a structured evaluation framework for future development of MGS as collaborative tools in creative workflows, emphasizing the importance of human creativity in tasks requiring emotional depth and complex decision-making.

---

