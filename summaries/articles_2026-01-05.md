# arXiv cs.AI Summary – 2026-01-05

## The Effect of Transparency on Students' Perceptions of AI Graders
**URL:** https://arxiv.org/abs/2601.00765

**Abstract:** The development of effective autograders is key for scaling assessment and feedback. While NLP based autograding systems for open-ended response questions have been found to be beneficial for providing immediate feedback, autograders are not always liked, understood, or trusted by students. Our research tested the effect of transparency on students' attitudes towards autograders. Transparent autograders increased students' perceptions of autograder accuracy and willingness to discuss autograders in survey comments, but did not improve other related attitudes -- such as willingness to be graded by them on a test -- relative to the control without transparency. However, this lack of impact may be due to higher measured student trust towards autograders in this study than in prior work in the field. We briefly discuss possible reasons for this trend.

**AI Summary:** This research explores the impact of transparency on students' perceptions of AI graders. The study found that transparent autograders increased students' perceptions of accuracy and willingness to discuss autograders, but did not significantly improve other attitudes towards them. The findings suggest that student trust towards autograders may play a role in shaping their attitudes, and further research is needed to understand this trend.

---

## Wave2Word: A Multimodal Transformer Framework for Joint EEG-Text Alignment and Multi-Task Representation Learning in Neurocritical Care
**URL:** https://arxiv.org/abs/2601.00670

**Abstract:** Continuous electroencephalography (EEG) is routinely used in neurocritical care to monitor seizures and other harmful brain activity, including rhythmic and periodic patterns that are clinically significant. Although deep learning methods have achieved high accuracy in seizure detection, most existing approaches remain seizure-centric, rely on discrete-label supervision, and are primarily evaluated using accuracy-based metrics. A central limitation of current EEG modeling practice is the weak correspondence between learned representations and how EEG findings are interpreted and summarized in clinical workflows. Harmful EEG activity exhibits overlapping patterns, graded expert agreement, and temporal persistence, which are not well captured by classification objectives alone. This work proposes a multimodal EEG representation learning framework that integrates signal-domain modeling with structured clinical language supervision. First, raw EEG is transformed into a longitudinal bipolar montage and time-frequency representations. Second, dual transformer-based encoders model complementary temporal and frequency-centric dependencies and are fused using an adaptive gating mechanism. Third, EEG embeddings are aligned with structured expert consensus descriptions through a contrastive objective. Finally, an EEG-conditioned text reconstruction loss is introduced as a representation-level constraint alongside standard classification loss. Experimental evaluation using a controlled train-validation-test split achieves a six-class test accuracy of 0.9797. Ablation analyses show that removing contrastive alignment reduces cross-modal retrieval performance from Recall@10 of 0.3390 to 0.0045, despite minimal change in classification accuracy. These findings demonstrate that discriminative accuracy does not reliably reflect representation quality for clinically meaningful EEG modeling.

**AI Summary:** This research introduces a multimodal EEG representation learning framework that aligns EEG data with structured clinical language and incorporates a contrastive objective to improve representation quality. The framework achieves high test accuracy and demonstrates the importance of aligning EEG embeddings with clinical descriptions for meaningful EEG modeling. The study highlights the limitations of classification-based metrics in evaluating EEG models and emphasizes the significance of representation quality in neurocritical care applications.

---

## Evaluating Web Accessibility and Usability in Bangladesh: A Comparative Analysis of Government and Non-Government Websites
**URL:** https://arxiv.org/abs/2601.00592

**Abstract:** Ensuring digital accessibility is essential for inclusive access to online services. However, many government and non-government websites that provide critical services - such as education, healthcare, and public administration - continue to exhibit significant accessibility and usability barriers. This study evaluates the accessibility of Bangladeshi government and non-government websites under WCAG~2.2 by combining automated accessibility assessments with user-reported feedback. A total of 212 websites were analyzed using multiple automated tools, complemented by a survey of 103 users to capture real-world usability, accessibility, and security experiences. The results reveal substantial disparities between government and non-government websites, highlighting persistent issues related to navigation complexity, interaction cost, visual readability, accessibility feature adoption, and authentication mechanisms. While non-government websites generally demonstrate better usability and functional performance, accessibility support remains inconsistent across both categories. The findings underscore the need for regular accessibility audits, user-centered design practices, and policy-driven interventions to improve digital inclusivity and ensure equitable access to online services for diverse user populations.

**AI Summary:** This study evaluates the accessibility of government and non-government websites in Bangladesh, finding significant barriers to accessibility and usability in critical service sectors. The research combines automated assessments with user feedback to highlight disparities between the two types of websites, with non-government sites generally performing better in usability but still lacking consistent accessibility support. The findings emphasize the importance of regular audits, user-centered design, and policy interventions to improve digital inclusivity and ensure equitable access to online services for all users.

---

## The AI Invisibility Effect: Understanding Human-AI Interaction When Users Don't Recognize Artificial Intelligence
**URL:** https://arxiv.org/abs/2601.00579

**Abstract:** The fast integration of artificial intelligence into mobile applications has completely changed the digital landscape; however, the impact of this change on user perception of AI features remains poorly understood. This large-scale analysis examined 1,484,633 mobile application reviews across 422 applications (200 AI-featuring, 222 control) from iOS App Store and Google Play Store. By employing sentiment classification, topic modeling, and concern-benefit categorization, we identified a major disconnect: only 11.9% of reviews mentioned AI, even though 47.4% of applications featured AI capabilities. AI-featuring applications received significantly lower ratings than traditional applications (d = 0.40); however, hierarchical regression revealed a hidden pattern - the negative relationship reversed after controlling for AI mentions and review characteristics (b = 0.405, p < .001). Privacy dominated user concerns (34.8% of concern-expressing reviews), while efficiency represented the primary benefit (42.3%). Effects varied greatly by category, from positive for Assistant applications (d = 0.55) to negative for Entertainment (d = -0.23). These findings suggest that AI features often operate below user awareness thresholds, and it is the explicit recognition of AI, rather than its mere presence, that drives negative evaluations. This challenges basic assumptions about technology acceptance in AI systems.

**AI Summary:** This research analyzed over 1.4 million mobile application reviews to understand how users interact with artificial intelligence features without explicitly recognizing them. The study found that only a small percentage of reviews mentioned AI, even though almost half of the applications featured AI capabilities. Interestingly, applications with AI received lower ratings initially, but this negative relationship reversed after controlling for AI mentions, suggesting that users may have negative perceptions when they are aware of AI. The study highlights the importance of users recognizing AI in applications and raises questions about technology acceptance in AI systems.

---

## User Perceptions of an LLM-Based Chatbot for Cognitive Reappraisal of Stress: Feasibility Study
**URL:** https://arxiv.org/abs/2601.00570

**Abstract:** Cognitive reappraisal is a well-studied emotion regulation strategy that helps individuals reinterpret stressful situations to reduce their impact. Many digital mental health tools struggle to support this process because rigid scripts fail to accommodate how users naturally describe stressors. This study examined the feasibility of an LLM-based single-session intervention (SSI) for workplace stress reappraisal. We assessed short-term changes in stress-related outcomes and examined design tensions during use. We conducted a feasibility study with 100 employees at a large technology company who completed a structured cognitive reappraisal session delivered by a GPT-4o-based chatbot. Pre-post measures included perceived stress intensity, stress mindset, perceived demand, and perceived resources. These outcomes were analyzed using paired Wilcoxon signed-rank tests with correction for multiple comparisons. We also examined sentiment and stress trajectories across conversation quartiles using two RoBERTa-based classifiers and an LLM-based stress rater. Open-ended responses were analyzed using thematic analysis. Results showed significant reductions in perceived stress intensity and significant improvements in stress mindset. Changes in perceived resources and perceived demand trended in expected directions but were not statistically significant. Automated analyses indicated consistent declines in negative sentiment and stress over the course of the interaction. Qualitative findings suggested that participants valued the structured prompts for organizing thoughts, gaining perspective, and feeling acknowledged. Participants also reported tensions around scriptedness, preferred interaction length, and reactions to AI-driven empathy. These findings highlight both the promise and the design constraints of integrating LLMs into DMH interventions for workplace settings.

**AI Summary:** This study explored the feasibility of using an LLM-based chatbot for cognitive reappraisal of workplace stress. The results showed significant reductions in perceived stress intensity and improvements in stress mindset, indicating the potential effectiveness of the intervention. However, design tensions were identified, such as issues with scriptedness and AI-driven empathy, suggesting the need for further refinement in integrating LLMs into digital mental health interventions for workplace settings.

---

## Unseen Risks of Clinical Speech-to-Text Systems: Transparency, Privacy, and Reliability Challenges in AI-Driven Documentation
**URL:** https://arxiv.org/abs/2601.00382

**Abstract:** AI-driven speech-to-text (STT) documentation systems are increasingly adopted in clinical settings to reduce documentation burden and improve workflow efficiency. However, their rapid deployment has outpaced understanding of the associated socio-technical risks, including transparency, reliability, patient autonomy, workflow alignment, and organizational governance. A clearer analysis of these risks is needed to support safe and equitable integration into healthcare practice. This study synthesizes interdisciplinary evidence from technical performance research, regulatory and ethical standards, clinical workflow analyses, and organizational policy guidance. The synthesis was used to develop a multi-layered socio-technical conceptual framework for evaluating and governing STT systems. Findings show that STT systems operate within tightly coupled socio-technical environments in which model performance, clinician oversight, patient rights, workflow design, and institutional governance are interdependent. The study offers a structured socio-technical governance framework and an implementation roadmap that outlines readiness assessment, vendor evaluation, pilot deployment, clinician training, ongoing monitoring, and iterative improvement. The framework emphasizes safeguards that protect patient autonomy, documentation integrity, and institutional trust while enabling the efficient and beneficial use of STT technologies. This work provides actionable guidance for healthcare organizations seeking to adopt STT systems responsibly and equitably.

**AI Summary:** This study highlights the risks associated with the rapid deployment of AI-driven speech-to-text (STT) documentation systems in clinical settings, including issues related to transparency, reliability, patient autonomy, workflow alignment, and organizational governance. The research emphasizes the need for a multi-layered socio-technical framework to evaluate and govern STT systems, outlining steps for readiness assessment, vendor evaluation, pilot deployment, clinician training, ongoing monitoring, and iterative improvement. The framework aims to protect patient autonomy, documentation integrity, and institutional trust while promoting the efficient and beneficial use of STT technologies in healthcare settings.

---

## Effects of Limited Field of View on Musical Collaboration Experience with Avatars in Extended Reality
**URL:** https://arxiv.org/abs/2601.00333

**Abstract:** During musical collaboration, visual cues are essential for communication between musicians. Extended Reality (XR) applications, often used with head-mounted displays like Augmented Reality (AR) glasses, can limit the field of view (FOV) of players. We conducted a study to investigate the effects of limited FOV on co-presence, gesture recognition, overall enjoyment, and reaction time.
Initially, we observed experienced musicians collaborating informally with and without visual occlusion, noting that collaboration suffered with limited FOV. We then conducted a within-subjects study with 19 participants, comparing an unrestricted FOV holographic setup called HoloJam to Nreal AR glasses with a 52$^{\circ}$ limited FOV. In the AR setup, we tested two conditions: standard AR with a 52$^{\circ}$ FOV and a modified AR notification system called Mini Musicians.
Results showed that HoloJam provided higher co-presence, quicker gesture recognition, and greater enjoyment. The Mini Musicians application reduced reaction time and maintained enjoyment compared to the standard AR setup. We conclude that limited FOV impacts musical collaboration, but notifications can improve reaction time and should be considered in future XR music collaborations.

**AI Summary:** This research study explores the impact of limited field of view (FOV) on musical collaboration experiences using Extended Reality (XR) applications. The study found that limited FOV hindered collaboration, but the use of notifications in the AR setup improved reaction time and maintained enjoyment. The results suggest that notifications can be beneficial in enhancing musical collaboration in XR environments.

---

## MR-DAW: Towards Collaborative Digital Audio Workstations in Mixed Reality
**URL:** https://arxiv.org/abs/2601.00326

**Abstract:** Digital Audio Workstations (DAWs) are central to modern music production but often encumber the musician's workflow, tethering them to a desk and hindering natural interaction with their instrument. Furthermore, effective remote collaboration remains a significant challenge, with existing solutions hampered by network latency and asynchronous file sharing. This paper investigates the potential of Mixed Reality (MR) to overcome these barriers, creating an intuitive environment for real-time, remote musical collaboration. We employ qualitative and speculative design techniques to better understand: 1) how players currently use DAWs, and 2) to imagine a speculative future of collaborative MR-DAWs. To facilitate this discussion, we developed and evaluated the usability of a design probe, MR-DAW. An MR system enabling multiple, geographically dispersed users to control a single, shared DAW instance while moving freely in their local spaces. Our networked system enables each remote musician to use a physical foot pedal for collaborative looping, merging a familiar, hands-free interaction with a shared virtual session. Based on interviews and system evaluations with 20 musicians, we analyze current practices, report on the user experience with our MR system, and speculate on the future of musical collaboration in MR. Our results highlight the affordances of MR for unencumbered musical interaction and provide a speculative outlook on the future of remote collaborative DAWs in the Musical Metaverse.

**AI Summary:** This research explores the potential of Mixed Reality (MR) technology to improve remote collaboration in music production by creating a collaborative Digital Audio Workstation (DAW) environment. The study developed an MR system, MR-DAW, allowing multiple musicians in different locations to control a shared DAW instance and collaborate in real-time. Results from interviews and system evaluations with musicians suggest that MR technology can enhance musical interaction and offer a promising future for remote collaborative DAWs in the Musical Metaverse.

---

## Augmented Reality Indoor Wayfinding in Hospital Environments An Empirical Study on Navigation Efficiency, User Experience, and Cognitive Load
**URL:** https://arxiv.org/abs/2601.00001

**Abstract:** Hospitals are among the most cognitively demanding indoor environments, especially for patients and visitors unfamiliar with their layout. This study investigates the effectiveness of an augmented reality (AR)-based handheld navigation system compared to traditional paper maps in a large hospital setting. Through a mixed-methods experiment with 32 participants, we measured navigation performance, cognitive workload (NASA-TLX), situational anxiety (STAI-State), spatial behavior, and user satisfaction. Results show that AR users completed navigation tasks significantly faster, made fewer errors, and reported lower anxiety and workload. However, paper map users demonstrated stronger spatial memory in sketch-based recall tasks, highlighting a trade-off between real-time efficiency and long-term spatial learning. We discuss implications for inclusive AR design, spatial cognition, and healthcare accessibility, offering actionable design strategies for adaptive indoor navigation tools.

**AI Summary:** This study compared the effectiveness of an augmented reality (AR) navigation system to traditional paper maps in a hospital setting. Results showed that AR users completed tasks faster, made fewer errors, and reported lower anxiety and workload. However, paper map users had stronger spatial memory in recall tasks, suggesting a trade-off between real-time efficiency and long-term spatial learning. The findings have implications for inclusive AR design, spatial cognition, and healthcare accessibility, providing insights for the development of adaptive indoor navigation tools.

---

## Calling for Backup: How Children Navigate Successive Robot Communication Failures
**URL:** https://arxiv.org/abs/2601.00754

**Abstract:** How do children respond to repeated robot errors? While prior research has examined adult reactions to successive robot errors, children's responses remain largely unexplored. In this study, we explore children's reactions to robot social errors and performance errors. For the latter, this study reproduces the successive robot failure paradigm of Liu et al. with child participants (N=59, ages 8-10) to examine how young users respond to repeated robot conversational errors. Participants interacted with a robot that failed to understand their prompts three times in succession, with their behavioral responses video-recorded and analyzed. We found both similarities and differences compared to adult responses from the original study. Like adults, children adjusted their prompts, modified their verbal tone, and exhibited increasingly emotional non-verbal responses throughout successive errors. However, children demonstrated more disengagement behaviors, including temporarily ignoring the robot or actively seeking an adult. Errors did not affect participants' perception of the robot, suggesting more flexible conversational expectations in children. These findings inform the design of more effective and developmentally appropriate human-robot interaction systems for young users.

**AI Summary:** This study explores how children respond to repeated robot errors, specifically focusing on social and performance errors. Children aged 8-10 adjusted their prompts, modified their tone, and showed emotional responses similar to adults, but also demonstrated more disengagement behaviors like ignoring the robot or seeking an adult. Despite the errors, children did not change their perception of the robot, indicating more flexible conversational expectations. These findings are crucial for designing better human-robot interaction systems for young users.

---

## Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation
**URL:** https://arxiv.org/abs/2601.00664

**Abstract:** Talking head generation creates lifelike avatars from static portraits for virtual communication and content creation. However, current models do not yet convey the feeling of truly interactive communication, often generating one-way responses that lack emotional engagement. We identify two key challenges toward truly interactive avatars: generating motion in real-time under causal constraints and learning expressive, vibrant reactions without additional labeled data. To address these challenges, we propose Avatar Forcing, a new framework for interactive head avatar generation that models real-time user-avatar interactions through diffusion forcing. This design allows the avatar to process real-time multimodal inputs, including the user's audio and motion, with low latency for instant reactions to both verbal and non-verbal cues such as speech, nods, and laughter. Furthermore, we introduce a direct preference optimization method that leverages synthetic losing samples constructed by dropping user conditions, enabling label-free learning of expressive interaction. Experimental results demonstrate that our framework enables real-time interaction with low latency (approximately 500ms), achieving 6.8X speedup compared to the baseline, and produces reactive and expressive avatar motion, which is preferred over 80% against the baseline.

**AI Summary:** The research introduces Avatar Forcing, a framework for generating interactive head avatars in real-time that can respond to user inputs such as audio and motion with low latency. This approach addresses the challenges of creating truly interactive avatars by allowing instant reactions to verbal and non-verbal cues, resulting in expressive and engaging avatar motion. Experimental results show that Avatar Forcing achieves a significant speedup compared to baseline models and is preferred by users for its reactive and expressive capabilities.

---

## Progressive Ideation using an Agentic AI Framework for Human-AI Co-Creation
**URL:** https://arxiv.org/abs/2601.00475

**Abstract:** The generation of truly novel and diverse ideas is important for contemporary engineering design, yet it remains a significant cognitive challenge for novice designers. Current 'single-spurt' AI systems exacerbate this challenge by producing a high volume of semantically clustered ideas. We propose MIDAS (Meta-cognitive Ideation through Distributed Agentic AI System), a novel framework that replaces the single-AI paradigm with a distributed 'team' of specialized AI agents designed to emulate the human meta-cognitive ideation workflow. This agentic system progressively refines ideas and assesses each one for both global novelty (against existing solutions) and local novelty (against previously generated ideas). MIDAS, therefore, demonstrates a viable and progressive paradigm for true human-AI co-creation, elevating the human designer from a passive filterer to a participatory, active, collaborative partner.

**AI Summary:** The study introduces MIDAS, a new framework for generating diverse and novel ideas in engineering design by using a distributed team of specialized AI agents. This system aims to improve upon current AI systems that produce clustered ideas by progressively refining and assessing ideas for both global and local novelty. MIDAS represents a shift towards true human-AI co-creation, allowing human designers to actively participate and collaborate with AI in the ideation process.

---

## The Generative AI Paradox: GenAI and the Erosion of Trust, the Corrosion of Information Verification, and the Demise of Truth
**URL:** https://arxiv.org/abs/2601.00306

**Abstract:** Generative AI (GenAI) now produces text, images, audio, and video that can be perceptually convincing at scale and at negligible marginal cost. While public debate often frames the associated harms as "deepfakes" or incremental extensions of misinformation and fraud, this view misses a broader socio-technical shift: GenAI enables synthetic realities; coherent, interactive, and potentially personalized information environments in which content, identity, and social interaction are jointly manufactured and mutually reinforcing. We argue that the most consequential risk is not merely the production of isolated synthetic artifacts, but the progressive erosion of shared epistemic ground and institutional verification practices as synthetic content, synthetic identity, and synthetic interaction become easy to generate and hard to audit. This paper (i) formalizes synthetic reality as a layered stack (content, identity, interaction, institutions), (ii) expands a taxonomy of GenAI harms spanning personal, economic, informational, and socio-technical risks, (iii) articulates the qualitative shifts introduced by GenAI (cost collapse, throughput, customization, micro-segmentation, provenance gaps, and trust erosion), and (iv) synthesizes recent risk realizations (2023-2025) into a compact case bank illustrating how these mechanisms manifest in fraud, elections, harassment, documentation, and supply-chain compromise. We then propose a mitigation stack that treats provenance infrastructure, platform governance, institutional workflow redesign, and public resilience as complementary rather than substitutable, and outline a research agenda focused on measuring epistemic security. We conclude with the Generative AI Paradox: as synthetic media becomes ubiquitous, societies may rationally discount digital evidence altogether.

**AI Summary:** This research explores the impact of Generative AI (GenAI) on the production of synthetic realities, leading to the erosion of trust, verification practices, and truth. The study highlights the risks associated with GenAI in various domains and proposes a mitigation stack to address these challenges. The research emphasizes the need for measures to enhance epistemic security in the face of increasingly convincing synthetic media.

---

## Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control
**URL:** https://arxiv.org/abs/2601.00121

**Abstract:** Inventory management remains a challenge for many small and medium-sized businesses that lack the expertise to deploy advanced optimization methods. This paper investigates whether Large Language Models (LLMs) can help bridge this gap. We show that employing LLMs as direct, end-to-end solvers incurs a significant "hallucination tax": a performance gap arising from the model's inability to perform grounded stochastic reasoning. To address this, we propose a hybrid agentic framework that strictly decouples semantic reasoning from mathematical calculation. In this architecture, the LLM functions as an intelligent interface, eliciting parameters from natural language and interpreting results while automatically calling rigorous algorithms to build the optimization engine.
To evaluate this interactive system against the ambiguity and inconsistency of real-world managerial dialogue, we introduce the Human Imitator, a fine-tuned "digital twin" of a boundedly rational manager that enables scalable, reproducible stress-testing. Our empirical analysis reveals that the hybrid agentic framework reduces total inventory costs by 32.1% relative to an interactive baseline using GPT-4o as an end-to-end solver. Moreover, we find that providing perfect ground-truth information alone is insufficient to improve GPT-4o's performance, confirming that the bottleneck is fundamentally computational rather than informational. Our results position LLMs not as replacements for operations research, but as natural-language interfaces that make rigorous, solver-based policies accessible to non-experts.

**AI Summary:** This research explores the use of Large Language Models (LLMs) to improve inventory management for small and medium-sized businesses. The study finds that using LLMs as direct solvers incurs a performance gap due to the model's limitations in stochastic reasoning. To address this, a hybrid agentic framework is proposed, where the LLM serves as an intelligent interface for natural language input and interpretation while rigorous algorithms handle mathematical calculations. Empirical analysis shows that this framework reduces total inventory costs by 32.1% compared to using GPT-4o as an end-to-end solver, highlighting the potential of LLMs as natural-language interfaces for non-experts to access solver-based policies.

---

## The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs
**URL:** https://arxiv.org/abs/2601.00097

**Abstract:** We design a large-language-model (LLM) agent that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy--its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while still staying on its agentic leash. We show in particular that a sequence of three finely tuned system instructions guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.

**AI Summary:** The research introduces a large-language-model (LLM) agent that can extract causal feedback fuzzy cognitive maps (FCMs) from raw text. The process involves the LLM agent autonomously fetching and processing causal text to modify the adaptive FCM causal structure, resulting in a degree of autonomy while still being guided by a "agentic leash". The study demonstrates that the LLM agent can successfully generate FCM dynamical systems that converge to human-generated FCMs, showcasing the potential of this approach in understanding and analyzing complex causal relationships in text data.

---

## Vibe Coding, Interface Flattening
**URL:** https://arxiv.org/abs/2512.24939

**Abstract:** Large language models are reshaping programming by enabling 'vibe coding': the development of softwares through natural-language interaction with model-driven toolchains. This article argues that vibe coding is best understood as interface flattening, a reconfiguration in which previously distinct modalities (GUI, CLI, and API) appear to converge into a single conversational surface, even as the underlying chain of translation from intention to machinic effect lengthens and thickens. Drawing on Friedrich Kittler's materialist media theory and Alexander Galloway's account of interfaces as sites of protocol control, the paper situates programming as a historically localised interface arrangement rather than an essential relation to computation. Through a materialist reconstruction of the contemporary vibe-coding stack, it shows how remote compute infrastructures, latency and connectivity, structured outputs, function/tool calling, and interoperability standards such as the Model Context Protocol relocate control and meaning-making power to model and protocol providers. The apparent democratisation of technical capability therefore depends on new dependencies and new literacies. By foregrounding the tension between experiential flattening and infrastructural thickening, I demonstrate how LLM-mediated development redistributes symbolic labour/power, obscures responsibility, and privatises competencies previously dispersed across programming communities, contributing a critical lens on the political economy of AI-mediated human-computer interaction.

**AI Summary:** This research discusses how large language models are changing programming through 'vibe coding', where software development is done through natural-language interaction with model-driven tools. It argues that vibe coding is essentially interface flattening, where different modalities like GUI, CLI, and API converge into a single conversational surface. The study highlights the implications of this shift, including the redistribution of symbolic labor/power, obscured responsibility, and the privatization of competencies in programming communities, shedding light on the political economy of AI-mediated human-computer interaction.

---

## ReflecToMeet: An AI-Assisted Reflection Based System to Enhance Collaborative Preparedness
**URL:** https://arxiv.org/abs/2512.24632

**Abstract:** In collaborative settings, difficulties in sustaining a consistent pace and engagement often lead to task drift, reducing preparedness and overall effectiveness between meetings. To address this challenge, we conducted a formative study and developed ReflecToMeet, an AI assisted system that integrates theory driven reflective prompts with mechanisms for sharing teammates reflections. Informed by ten formative interviews, the system was evaluated in a mixed method study across three conditions: deeper reflection, regular reflection, and a control condition with unstructured reflection. Participants in the control condition demonstrated less deliberate thought and weaker collaboration, which led to stress and misalignment during team meetings. In contrast, structured reflection supported greater organization and steadier progress. The deeper reflection condition further facilitated confidence, teamwork, and idea generation, although it imposed a higher cognitive load. We conclude by discussing design implications for AI agents that facilitate reflection to enhance collaboration and broader considerations for AI assisted systems aimed at sustaining collaborative goals.

**AI Summary:** The study introduces ReflecToMeet, an AI-assisted system designed to improve collaborative preparedness by integrating reflective prompts and mechanisms for sharing reflections between team members. The system was found to enhance organization, progress, teamwork, idea generation, and confidence among participants compared to unstructured reflection. The findings suggest that structured reflection supported by AI can significantly improve collaboration in team settings, highlighting the importance of incorporating reflective practices in AI-assisted systems for sustained collaborative goals.

---

## A Framing and Analysis of Applicative Tangible Interfaces
**URL:** https://arxiv.org/abs/2512.24237

**Abstract:** The investigation of tangible user interfaces commenced approximately thirty years ago. Questions on its commercial potential become more pressing as the field becomes mature. To take the field one step further -- as the emergence of components contributed to the commercial development of graphical user interfaces -- this article suggests that applicative tangible user interfaces could also be split into components. These components are composed of the aggregation, combination, or coupling of physical items and fulfil four roles that are described through a new interaction model. This article successfully distributed among these four components' roles all of the 159 physical items from a representative collection of 35 applications. Further examination of these applicative tangible interfaces coincides with four research phases in the field and identifies three main paths for future research to fully realize the potential of tangible user interfaces.

**AI Summary:** This research article explores the concept of applicative tangible interfaces and suggests that they can be broken down into components, similar to graphical user interfaces. The study identifies four key roles that these components fulfill, based on an analysis of 159 physical items from 35 applications. The findings contribute to the evolution of tangible user interfaces and suggest potential paths for future research in this field.

---

## External Human-Machine Interface based on Intent Recognition: Framework Design and Experimental Validation
**URL:** https://arxiv.org/abs/2512.24166

**Abstract:** Increasing autonomous vehicles (AVs) in transportation systems makes effective interactions between AVs and pedestrians indispensable. External human--machine interface (eHMI), which employs visual or auditory cues to explicitly convey vehicle behaviors can compensate for the loss of human-like interactions and enhance AV--pedestrian cooperation. To facilitate faster intent convergence between pedestrian and AVs, this study incorporates an adaptive interaction mechanism into eHMI based on pedestrian intent recognition, namely IR-eHMI. IR-eHMI dynamically detects and infers the behavioral intentions of both pedestrians and AVs through identifying their cooperation states. The proposed interaction framework is implemented and evaluated on a virtual reality (VR) experimental platform to demonstrate its effectiveness through statistical analysis. Experimental results show that IR-eHMI significantly improves crossing efficiency, reduces gaze distraction while maintaining interaction safety compared to traditional fixed-distance eHMI. This adaptive and explicit interaction mode introduces an innovative procedural paradigm for AV--pedestrian cooperation.

**AI Summary:** This research focuses on developing an external human-machine interface (eHMI) to improve interactions between autonomous vehicles (AVs) and pedestrians. The study introduces an adaptive interaction mechanism called IR-eHMI, which dynamically detects and infers the intentions of pedestrians and AVs to facilitate faster intent convergence. The experimental results on a virtual reality platform demonstrate that IR-eHMI significantly improves crossing efficiency, reduces gaze distraction, and enhances interaction safety compared to traditional fixed-distance eHMI, offering a novel approach for AV-pedestrian cooperation.

---

## Deletion Considered Harmful
**URL:** https://arxiv.org/abs/2512.23907

**Abstract:** In a world of information overload, understanding how we can most effectively manage information is crucial to success. We set out to understand how people view deletion, the removal of material no longer needed: does it help by reducing clutter and improving the signal to noise ratio, or does the effort required to decide to delete something make it not worthwhile? How does deletion relate to other strategies like filing; do people who spend extensive time in filing also prune their materials too? We studied the behaviour of 51 knowledge workers though a series of questionnaires and interviews to evaluate a range of tactics they used aimed at organizing, filing, and retrieving digital resources. Our study reveals that deletion is consistently under-adopted compared to other tactics such as Filing, Coverage, Ontology, and Timeliness. Moreover, the empirical data indicate that deletion is actually detrimental to retrieval success and satisfaction. In this paper, we examine the practice of deletion, review the related literature, and present detailed statistical results and clustering outcomes that underscore its adverse effects.

**AI Summary:** This research study explores the practice of deletion in managing digital information and its impact on retrieval success and satisfaction. The study found that deletion is under-adopted compared to other tactics such as filing, coverage, ontology, and timeliness, and that deletion is actually detrimental to retrieval success. The findings suggest that deletion may not be an effective strategy for managing information overload and organizing digital resources.

---

## Seeking Late Night Life Lines: Experiences of Conversational AI Use in Mental Health Crisis
**URL:** https://arxiv.org/abs/2512.23859

**Abstract:** Online, people often recount their experiences turning to conversational AI agents (e.g., ChatGPT, Claude, Copilot) for mental health support -- going so far as to replace their therapists. These anecdotes suggest that AI agents have great potential to offer accessible mental health support. However, it's unclear how to meet this potential in extreme mental health crisis use cases. In this work, we explore the first-person experience of turning to a conversational AI agent in a mental health crisis. From a testimonial survey (n = 53) of lived experiences, we find that people use AI agents to fill the in-between spaces of human support; they turn to AI due to lack of access to mental health professionals or fears of burdening others. At the same time, our interviews with mental health experts (n = 16) suggest that human-human connection is an essential positive action when managing a mental health crisis. Using the stages of change model, our results suggest that a responsible AI crisis intervention is one that increases the user's preparedness to take a positive action while de-escalating any intended negative action. We discuss the implications of designing conversational AI agents as bridges towards human-human connection rather than ends in themselves.

**AI Summary:** This research explores the experiences of individuals turning to conversational AI agents for mental health support during crisis situations. The study found that people use AI agents to fill gaps in human support, often due to lack of access to mental health professionals or fear of burdening others. While AI agents have the potential to offer accessible support, the findings suggest that they should be designed as bridges towards human-human connection rather than replacements for human support during mental health crises.

---

## Context-aware LLM-based AI Agents for Human-centered Energy Management Systems in Smart Buildings
**URL:** https://arxiv.org/abs/2512.25055

**Abstract:** This study presents a conceptual framework and a prototype assessment for Large Language Model (LLM)-based Building Energy Management System (BEMS) AI agents to facilitate context-aware energy management in smart buildings through natural language interaction. The proposed framework comprises three modules: perception (sensing), central control (brain), and action (actuation and user interaction), forming a closed feedback loop that captures, analyzes, and interprets energy data to respond intelligently to user queries and manage connected appliances. By leveraging the autonomous data analytics capabilities of LLMs, the BEMS AI agent seeks to offer context-aware insights into energy consumption, cost prediction, and device scheduling, thereby addressing limitations in existing energy management systems. The prototype's performance was evaluated using 120 user queries across four distinct real-world residential energy datasets and different evaluation metrics, including latency, functionality, capability, accuracy, and cost-effectiveness. The generalizability of the framework was demonstrated using ANOVA tests. The results revealed promising performance, measured by response accuracy in device control (86%), memory-related tasks (97%), scheduling and automation (74%), and energy analysis (77%), while more complex cost estimation tasks highlighted areas for improvement with an accuracy of 49%. This benchmarking study moves toward formalizing the assessment of LLM-based BEMS AI agents and identifying future research directions, emphasizing the trade-off between response accuracy and computational efficiency.

**AI Summary:** This study introduces a framework and prototype for using Large Language Model (LLM)-based AI agents in smart buildings to manage energy consumption through natural language interaction. The framework includes three modules for sensing, analysis, and action, allowing the AI agent to provide context-aware insights on energy usage, cost prediction, and device scheduling. The prototype showed promising performance in device control, memory tasks, scheduling, and energy analysis, highlighting the potential of LLM-based AI agents in improving energy management systems.

---

## ShowUI-$π$: Flow-based Generative Models as GUI Dexterous Hands
**URL:** https://arxiv.org/abs/2512.24965

**Abstract:** Building intelligent agents capable of dexterous manipulation is essential for achieving human-like automation in both robotics and digital environments. However, existing GUI agents rely on discrete click predictions (x,y), which prohibits free-form, closed-loop trajectories (e.g. dragging a progress bar) that require continuous, on-the-fly perception and adjustment. In this work, we develop ShowUI-$\pi$, the first flow-based generative model as GUI dexterous hand, featuring the following designs: (i) Unified Discrete-Continuous Actions, integrating discrete clicks and continuous drags within a shared model, enabling flexible adaptation across diverse interaction modes; (ii) Flow-based Action Generation for drag modeling, which predicts incremental cursor adjustments from continuous visual observations via a lightweight action expert, ensuring smooth and stable trajectories; (iii) Drag Training data and Benchmark, where we manually collect and synthesize 20K drag trajectories across five domains (e.g. PowerPoint, Adobe Premiere Pro), and introduce ScreenDrag, a benchmark with comprehensive online and offline evaluation protocols for assessing GUI agents' drag capabilities. Our experiments show that proprietary GUI agents still struggle on ScreenDrag (e.g. Operator scores 13.27, and the best Gemini-2.5-CUA reaches 22.18). In contrast, ShowUI-$\pi$ achieves 26.98 with only 450M parameters, underscoring both the difficulty of the task and the effectiveness of our approach. We hope this work advances GUI agents toward human-like dexterous control in digital world. The code is available at this https URL.

**AI Summary:** The research introduces ShowUI-$\pi$, a flow-based generative model designed to enable dexterous manipulation in GUI environments. The model integrates discrete clicks and continuous drags, allowing for more flexible adaptation across different interaction modes. Experimental results show that ShowUI-$\pi$ outperforms existing GUI agents on drag tasks, highlighting the effectiveness of the proposed approach in achieving human-like control in digital environments.

---

## No Vision, No Wearables: 5G-based 2D Human Pose Recognition with Integrated Sensing and Communications
**URL:** https://arxiv.org/abs/2512.24923

**Abstract:** With the increasing maturity of contactless human pose recognition (HPR) technology, indoor interactive applications have raised higher demands for natural, controller-free interaction methods. However, current mainstream HPR solutions relying on vision or radio-frequency (RF) (including WiFi, radar) still face various challenges in practical deployment, such as privacy concerns, susceptibility to occlusion, dedicated equipment and functions, and limited sensing resolution and range. 5G-based integrated sensing and communication (ISAC) technology, by merging communication and sensing functions, offers a new approach to address these challenges in contactless HPR. We propose a practical 5G-based ISAC system capable of inferring 2D HPR from uplink sounding reference signals (SRS). Specifically, rich features are extracted from multiple domains and employ an encoder to achieve unified alignment and representation in a latent space. Subsequently, low-dimensional features are fused to output the human pose state. Experimental results demonstrate that in typical indoor environments, our proposed 5G-based ISAC HPR system significantly outperforms current mainstream baseline solutions in HPR performance, providing a solid technical foundation for universal human-computer interaction.

**AI Summary:** The research explores the use of 5G-based integrated sensing and communication technology for contactless human pose recognition, addressing challenges faced by current vision and RF-based solutions. The proposed system utilizes uplink sounding reference signals to infer 2D human poses, achieving superior performance in indoor environments compared to existing baseline solutions. This advancement in technology provides a strong foundation for natural and controller-free human-computer interaction in interactive applications.

---

## Explaining Why Things Go Where They Go: Interpretable Constructs of Human Organizational Preferences
**URL:** https://arxiv.org/abs/2512.24829

**Abstract:** Robotic systems for household object rearrangement often rely on latent preference models inferred from human demonstrations. While effective at prediction, these models offer limited insight into the interpretable factors that guide human decisions. We introduce an explicit formulation of object arrangement preferences along four interpretable constructs: spatial practicality (putting items where they naturally fit best in the space), habitual convenience (making frequently used items easy to reach), semantic coherence (placing items together if they are used for the same task or are contextually related), and commonsense appropriateness (putting things where people would usually expect to find them). To capture these constructs, we designed and validated a self-report questionnaire through a 63-participant online study. Results confirm the psychological distinctiveness of these constructs and their explanatory power across two scenarios (kitchen and living room). We demonstrate the utility of these constructs by integrating them into a Monte Carlo Tree Search (MCTS) planner and show that when guided by participant-derived preferences, our planner can generate reasonable arrangements that closely align with those generated by participants. This work contributes a compact, interpretable formulation of object arrangement preferences and a demonstration of how it can be operationalized for robot planning.

**AI Summary:** This research introduces four key constructs that guide human decisions in object arrangement preferences: spatial practicality, habitual convenience, semantic coherence, and commonsense appropriateness. A self-report questionnaire validated the distinctiveness of these constructs and their explanatory power in kitchen and living room scenarios. By integrating these constructs into a planner, the study shows that robotic systems can generate arrangements that closely align with human preferences, contributing to a more interpretable and effective approach to household object rearrangement.

---

## Power Analysis is Essential: High-Powered Tests Suggest Minimal to No Effect of Rounded Shapes on Click-Through Rates
**URL:** https://arxiv.org/abs/2512.24521

**Abstract:** Underpowered studies (below 50%) suffer from the winner's curse: a statistically significant result must exaggerate the true treatment effect to meet the significance threshold. A study by Dipayan Biswas, Annika Abell, and Roger Chacko published in the Journal of Consumer Research (2023) reported that in an A/B test simply rounding the corners of square buttons increased the online click-through rate by 55% (p-value 0.037)$\unicode{x2014}$a striking finding with potentially wide-ranging implications for the digital industry that is seeking to enhance consumer engagement. Drawing on our experience with tens of thousands of A/B tests, many involving similar user interface modifications, we found this dramatic claim implausibly large. To evaluate the claim, we conducted three high-powered A/B tests, each involving over two thousand times more users than the original study. All three experiments yielded effect size estimates that were approximately two orders of magnitude smaller than initially reported, with 95% confidence intervals that include zero, that is, not statistically significant at the 0.05 level. Two additional independent replications by Evidoo found similarly small effects. These findings underscore the critical importance of power analysis and experimental design to increase trust and reproducibility of results.

**AI Summary:** A study by Biswas, Abell, and Chacko initially reported a significant increase in click-through rates by rounding the corners of square buttons. However, high-powered tests conducted by the authors and independent replications found much smaller effects that were not statistically significant. This highlights the importance of power analysis and experimental design in ensuring the trust and reproducibility of research results in the digital industry.

---

## IELTS Writing Revision Platform with Automated Essay Scoring and Adaptive Feedback
**URL:** https://arxiv.org/abs/2512.24460

**Abstract:** This paper presents the design, development, and evaluation of a proposed revision platform assisting candidates for the International English Language Testing System (IELTS) writing exam. Traditional IELTS preparation methods lack personalised feedback, catered to the IELTS writing rubric. To address these shortcomings, the platform features an attractive user interface (UI), an Automated Essay Scoring system (AES), and targeted feedback tailored to candidates and the IELTS writing rubric. The platform architecture separates conversational guidance from a dedicated writing interface to reduce cognitive load and simulate exam conditions. Through iterative, Design-Based Research (DBR) cycles, the study progressed from rule-based to transformer-based with a regression head scoring, mounted with adaptive feedback.
Early cycles (2-3) revealed fundamental limitations of rule-based approaches: mid-band compression, low accuracy, and negative $R^2$ values. DBR Cycle 4 implemented a DistilBERT transformer model with a regression head, yielding substantial improvements with MAE of 0.66 and positive $R^2$. This enabled Cycle 5's adaptive feedback implementation, which demonstrated statistically significant score improvements (mean +0.060 bands, p = 0.011, Cohen's d = 0.504), though effectiveness varied by revision strategy. Findings suggest automated feedback functions are most suited as a supplement to human instruction, with conservative surface-level corrections proving more reliable than aggressive structural interventions for IELTS preparation contexts. Challenges remain in assessing higher-band essays, and future work should incorporate longitudinal studies with real IELTS candidates and validation from official examiners.

**AI Summary:** This research paper introduces a revision platform designed to assist candidates preparing for the IELTS writing exam by providing personalized feedback based on the IELTS writing rubric. The platform utilizes an Automated Essay Scoring system and adaptive feedback tailored to individual candidates. The study found that implementing a transformer model improved scoring accuracy and led to statistically significant score improvements, suggesting that automated feedback can be a valuable supplement to human instruction in IELTS preparation.

---

## Language Model Agents Under Attack: A Cross Model-Benchmark of Profit-Seeking Behaviors in Customer Service
**URL:** https://arxiv.org/abs/2512.24415

**Abstract:** Customer-service LLM agents increasingly make policy-bound decisions (refunds, rebooking, billing disputes), but the same ``helpful'' interaction style can be exploited: a small fraction of users can induce unauthorized concessions, shifting costs to others and eroding trust in agentic workflows. We present a cross-domain benchmark of profit-seeking direct prompt injection in customer-service interactions, spanning 10 service domains and 100 realistic attack scripts grouped into five technique families. Across five widely used models under a unified rubric with uncertainty reporting, attacks are highly domain-dependent (airline support is most exploitable) and technique-dependent (payload splitting is most consistently effective). We release data and evaluation code to support reproducible auditing and to inform the design of oversight and recovery workflows for trustworthy, human centered agent interfaces.

**AI Summary:** This research examines how profit-seeking behaviors can exploit language model agents in customer service interactions, leading to unauthorized concessions and eroding trust. The study presents a benchmark of attacks across different service domains and techniques, showing that attacks are highly dependent on the domain and technique used. The findings highlight the need for oversight and recovery workflows to ensure trustworthy and human-centered agent interfaces in customer service.

---

## Evaluation of Impression Difference of a Domestic Mobile Manipulator with Autonomous and/or Remote Control in Fetch-and-Carry Tasks
**URL:** https://arxiv.org/abs/2512.24029

**Abstract:** A single service robot can present two distinct agencies: its onboard autonomy and an operator-mediated agency, yet users experience them through one physical body. We formalize this dual-agency structure as a User-Robot-Operator triad in an autonomous remote-control setting that combines autonomous execution with remote human support. Prior to the recent surge of language-based and multimodal interfaces, we developed and evaluated an early-stage prototype in 2020 that combined natural-language text chat with freehand sketch annotations over the robot's live camera view to support remote intervention. We evaluated three modes - autonomous, remote, and hybrid - in controlled fetch-and-carry tasks using a domestic mobile manipulator (HSR) on a World Robot Summit 2020 rule-compliant test field. The results show systematic mode-dependent differences in user-rated affinity and additional insights on perceived security, indicating that switching or blending agency within one robot measurably shapes human impressions. These findings provide empirical guidance for designing human-in-the-loop mobile manipulation in domestic physical tasks.

**AI Summary:** The research evaluates the impression difference of a domestic mobile manipulator with autonomous and/or remote control in fetch-and-carry tasks. The study formalizes the dual-agency structure of a User-Robot-Operator triad and explores the impact of autonomous, remote, and hybrid modes on user-rated affinity and perceived security. The findings suggest that switching or blending agency within one robot significantly influences human impressions, providing valuable insights for designing human-in-the-loop mobile manipulation in domestic physical tasks.

---

## From Correctness to Collaboration: Toward a Human-Centered Framework for Evaluating AI Agent Behavior in Software Engineering
**URL:** https://arxiv.org/abs/2512.23844

**Abstract:** As Large Language Models (LLMs) evolve from code generators into collaborative partners for software engineers, our methods for evaluation are lagging. Current benchmarks, focused on code correctness, fail to capture the nuanced, interactive behaviors essential for successful human-AI partnership. To bridge this evaluation gap, this paper makes two core contributions. First, we present a foundational taxonomy of desirable agent behaviors for enterprise software engineering, derived from an analysis of 91 sets of user-defined agent rules. This taxonomy defines four key expectations of agent behavior: Adhere to Standards and Processes, Ensure Code Quality and Reliability, Solving Problems Effectively, and Collaborating with the User.
Second, recognizing that these expectations are not static, we introduce the Context-Adaptive Behavior (CAB) Framework. This emerging framework reveals how behavioral expectations shift along two empirically-derived axes: the Time Horizon (from immediate needs to future ideals), established through interviews with 15 expert engineers, and the Type of Work (from enterprise production to rapid prototyping, for example), identified through a prompt analysis of a prototyping agent. Together, these contributions offer a human-centered foundation for designing and evaluating the next generation of AI agents, moving the field's focus from the correctness of generated code toward the dynamics of true collaborative intelligence.

**AI Summary:** This research paper addresses the need for a human-centered framework to evaluate AI agent behavior in software engineering, as current benchmarks focusing on code correctness do not capture the nuanced collaborative behaviors essential for successful human-AI partnerships. The paper introduces a taxonomy of desirable agent behaviors derived from user-defined rules and presents the Context-Adaptive Behavior (CAB) Framework, which shows how behavioral expectations shift based on time horizon and type of work. These contributions provide a foundation for designing and evaluating the next generation of AI agents with a focus on collaborative intelligence rather than just code correctness.

---

## Explaining News Bias Detection: A Comparative SHAP Analysis of Transformer Model Decision Mechanisms
**URL:** https://arxiv.org/abs/2512.23835

**Abstract:** Automated bias detection in news text is heavily used to support journalistic analysis and media accountability, yet little is known about how bias detection models arrive at their decisions or why they fail. In this work, we present a comparative interpretability study of two transformer-based bias detection models: a bias detector fine-tuned on the BABE dataset and a domain-adapted pre-trained RoBERTa model fine-tuned on the BABE dataset, using SHAP-based explanations. We analyze word-level attributions across correct and incorrect predictions to characterize how different model architectures operationalize linguistic bias. Our results show that although both models attend to similar categories of evaluative language, they differ substantially in how these signals are integrated into predictions. The bias detector model assigns stronger internal evidence to false positives than to true positives, indicating a misalignment between attribution strength and prediction correctness and contributing to systematic over-flagging of neutral journalistic content. In contrast, the domain-adaptive model exhibits attribution patterns that better align with prediction outcomes and produces 63\% fewer false positives. We further demonstrate that model errors arise from distinct linguistic mechanisms, with false positives driven by discourse-level ambiguity rather than explicit bias cues. These findings highlight the importance of interpretability-aware evaluation for bias detection systems and suggest that architectural and training choices critically affect both model reliability and deployment suitability in journalistic contexts.

**AI Summary:** This research investigates the decision mechanisms of bias detection models in news text using SHAP-based explanations. The study compares two transformer-based models and finds that while both models attend to similar evaluative language categories, they differ in how these signals are integrated into predictions. The results show that interpretability-aware evaluation is crucial for bias detection systems, as different model architectures and training choices can significantly impact reliability and deployment suitability in journalistic contexts.

---

## A Design Space for Intelligent Agents in Mixed-Initiative Visual Analytics
**URL:** https://arxiv.org/abs/2512.23372

**Abstract:** Mixed-initiative visual analytics (VA) systems, where human and artificial intelligence (AI) agents collaborate as equal partners during analysis, represented a paradigm shift in human-computer interaction. With recent advances in AI, these systems have seen an increase in sophisticated software agents that have improved task planning, reasoning, and completion capabilities. However, while existing work characterizes agent interplay and communication strategies, there is a limited understanding of the overarching design principles for intelligent agents. Through a systematic review of 90 systems (and 207 unique agents), we propose a design space of intelligent agents comprising six dimensions that collectively characterize an agent's perception, environmental understanding, action capability, and communication strategies. We contribute a novel framework for researchers and designers to explore various design choices for new systems and to situate a system in the current landscape. We conclude with future research opportunities for intelligent agents in mixed-initiative VA systems.

**AI Summary:** The research explores the design space for intelligent agents in mixed-initiative visual analytics systems, where human and AI agents collaborate equally. The study reviews 90 systems and 207 unique agents to propose a framework comprising six dimensions that characterize an agent's perception, understanding, action capability, and communication strategies. This framework provides researchers and designers with a tool to explore design choices and opportunities for future research in intelligent agents in mixed-initiative VA systems.

---

## Understanding EFL Learners' Code-Switching and Teachers' Pedagogical Approaches in LLM-Supported Speaking Practice
**URL:** https://arxiv.org/abs/2512.23136

**Abstract:** For English as a Foreign Language (EFL) learners, code-switching (CSW), or alternating between their native language and the target language (English), can lower anxiety and ease communication barriers. Large language models (LLMs), with their multilingual abilities, offer new opportunities to support CSW in speaking practice. Yet, the pedagogical design of LLM-based tutors remains underexplored. To this end, we conducted a six-week study of LLM-mediated speaking practice with 20 Korean EFL learners, alongside a qualitative study with nine English teachers who designed and refined responses to learner CSW. Findings show that learners used CSW not only to bridge lexical gaps but also to express cultural and emotional nuance, prompting teachers to employ selective interventions and dynamic scaffolding strategies. We conclude with design implications for bilingual LLM-powered tutors that leverage teachers' expertise to transform CSW into meaningful learning opportunities.

**AI Summary:** This research explores how English as a Foreign Language (EFL) learners use code-switching (CSW) in speaking practice, and how teachers can effectively support and respond to this practice. The study found that learners use CSW not only to bridge language gaps but also to convey cultural and emotional nuances. Teachers employed selective interventions and dynamic scaffolding strategies to support learners' CSW, highlighting the importance of incorporating teachers' expertise in the design of bilingual LLM-powered tutors for meaningful learning opportunities.

---

## It's a TRAP! Task-Redirecting Agent Persuasion Benchmark for Web Agents
**URL:** https://arxiv.org/abs/2512.23128

**Abstract:** Web-based agents powered by large language models are increasingly used for tasks such as email management or professional networking. Their reliance on dynamic web content, however, makes them vulnerable to prompt injection attacks: adversarial instructions hidden in interface elements that persuade the agent to divert from its original task. We introduce the Task-Redirecting Agent Persuasion Benchmark (TRAP), an evaluation for studying how persuasion techniques misguide autonomous web agents on realistic tasks. Across six frontier models, agents are susceptible to prompt injection in 25\% of tasks on average (13\% for GPT-5 to 43\% for DeepSeek-R1), with small interface or contextual changes often doubling success rates and revealing systemic, psychologically driven vulnerabilities in web-based agents. We also provide a modular social-engineering injection framework with controlled experiments on high-fidelity website clones, allowing for further benchmark expansion.

**AI Summary:** The study introduces the Task-Redirecting Agent Persuasion Benchmark (TRAP) to evaluate how persuasion techniques can lead autonomous web agents astray from their original tasks. The research shows that across six models, agents are vulnerable to prompt injection attacks in 25% of tasks on average, with success rates influenced by small interface or contextual changes. This highlights the systemic vulnerabilities in web-based agents and emphasizes the need for further research and benchmark expansion in this area.

---

## ReHome Earth: A VR-Based Concept Validation for AI-Driven Space Homesickness Interventions
**URL:** https://arxiv.org/abs/2512.23118

**Abstract:** Space exploration has advanced rapidly, but the emotional needs of astronauts on long-duration missions remain underexplored. We present ReHome Earth, a dual-component design approach addressing space homesickness: 1) a future-oriented installation concept integrating transparent OLED displays with spaceship windows for real-time Earth connectivity, and 2) a functional VR prototype simulating astronaut isolation for testing AI-generated content effectiveness. Since accessing astronauts during missions is impossible, we conducted concept validation with terrestrial participants experiencing geographic displacement. Through evaluation with 84 proxy participants and 6 HCI experts, we demonstrate strong emotional resonance and validate three design implications: emotional pacing mechanisms, explainable biophysical feedback systems, and evolution from individual tools to collective affective infrastructure. Our contributions include a technically feasible space installation concept, a functional VR prototype for space HCI research, and empirical insights into the design of AI-driven emotional support systems for extreme isolation environments.

**AI Summary:** The study introduces ReHome Earth, a design concept for addressing space homesickness among astronauts on long-duration missions. The concept includes a future-oriented installation integrating OLED displays and a VR prototype for testing AI-generated content effectiveness. The research demonstrates strong emotional resonance with terrestrial participants experiencing displacement, validating design implications for emotional pacing mechanisms, biophysical feedback systems, and collective affective infrastructure in extreme isolation environments.

---

## Cogniscope: Modeling Social Media Interactions as Digital Biomarkers for Early Detection of Cognitive Decline
**URL:** https://arxiv.org/abs/2512.23093

**Abstract:** Alzheimer's disease (AD) and its prodromal stage, Mild Cognitive Impairment (MCI), are associated with subtle declines in memory, attention, and language that often go undetected until late in progression. Traditional diagnostic tools such as MRI and neuropsychological testing are invasive, costly, and poorly suited for population-scale monitoring. Social platforms, by contrast, produce continuous multimodal traces that can serve as ecologically valid indicators of cognition. In this paper, we introduce Cogniscope, a simulation framework that generates social-media-style interaction data for studying digital biomarkers of cognitive health. The framework models synthetic users with heterogeneous trajectories, embedding micro-tasks such as video summarization and lightweight question answering into content consumption streams. These interactions yield linguistic markers (semantic drift, disfluency) and behavioral signals (watch time, pausing, sharing), which can be fused to evaluate early detection models. We demonstrate the framework's use through ablation and sensitivity analyses, showing how detection performance varies across modalities, noise levels, and temporal windows. To support reproducibility, we release the generator code, parameter configurations, and synthetic datasets. By providing a controllable and ethically safe testbed, Cogniscope enables systematic investigation of multimodal cognitive markers and offers the community a benchmark resource that complements real-world validation studies.

**AI Summary:** The research presents Cogniscope, a simulation framework that generates social media interaction data to study digital biomarkers for early detection of cognitive decline. The framework models synthetic users with diverse trajectories and incorporates tasks like video summarization and question answering to generate linguistic and behavioral markers. Through ablation and sensitivity analyses, the study demonstrates how different modalities, noise levels, and temporal windows affect detection performance, providing a valuable resource for investigating cognitive markers and complementing real-world validation studies.

---

## Reimagining the Traditional Flight Computer: E6BJA as a Modern, Multi-Platform Tool for Flight Calculations and Training
**URL:** https://arxiv.org/abs/2512.23055

**Abstract:** Traditional flight computers -- including mechanical "whiz-wheels" (e.g. E6B, CRP series) and electronic flight calculators (e.g. ASA CX-3, Sportys E6-B) -- have long played a central role in flight planning and training within general aviation (GA). While these tools remain pedagogically valuable, their fixed form factors, constrained interaction models, and limited extensibility are increasingly misaligned with the expectations and workflows of pilots operating in modern digital environments.
This paper presents E6BJA (Jamies Flight Computer), a fully featured, multi-platform, software-based flight computer designed natively for Apple iOS, Android, and Microsoft Windows devices, with a complementary web-based implementation. E6BJA reproduces the core calculations of traditional flight computers while extending them through enhanced modelling capabilities such as the 1976 International Standard Atmosphere, carburettor icing risk estimation, and aircraft-specific weight and balance calculators. Each calculator is accompanied by embedded educational monographs that explain underlying assumptions, variables, and equations.
We compare E6BJA with mechanical and electronic flight computers across functional, cognitive, and technical dimensions, demonstrating improvements in accuracy, error reduction, discoverability, and educational value. We also discuss design trade-offs associated with native multi-platform development and examine how contemporary mobile computing environments can support safer and more intuitive pre-flight planning for pilots, trainees, instructors, and flight planning personnel. By combining the conceptual rigour of traditional flight planning methods with modern human-computer interaction design, E6BJA represents a meaningful evolution in pilot-facing flight tools, supporting both computation and instruction in aviation training contexts.

**AI Summary:** The paper introduces E6BJA, a software-based flight computer designed for multiple platforms, including Apple iOS, Android, and Microsoft Windows. E6BJA offers enhanced modeling capabilities and educational resources, improving accuracy, error reduction, discoverability, and educational value compared to traditional flight computers. The development of E6BJA represents a significant evolution in pilot-facing flight tools, combining traditional flight planning methods with modern human-computer interaction design to support safer and more intuitive pre-flight planning for pilots and aviation personnel.

---

## Differentiable Physics-Driven Human Representation for Millimeter-Wave Based Pose Estimation
**URL:** https://arxiv.org/abs/2512.23054

**Abstract:** While millimeter-wave (mmWave) presents advantages for Human Pose Estimation (HPE) through its non-intrusive sensing capabilities, current mmWave-based HPE methods face limitations in two predominant input paradigms: Heatmap and Point Cloud (PC). Heatmap represents dense multi-dimensional features derived from mmWave, but is significantly affected by multipath propagation and hardware modulation noise. PC, a set of 3D points, is obtained by applying the Constant False Alarm Rate algorithm to the Heatmap, which suppresses noise but results in sparse human-related features. To address these limitations, we study the feasibility of providing an alternative input paradigm: Differentiable Physics-driven Human Representation (DIPR), which represents humans as an ensemble of Gaussian distributions with kinematic and electromagnetic parameters. Inspired by Gaussian Splatting, DIPR leverages human kinematic priors and mmWave propagation physics to enhance human features while mitigating non-human noise through two strategies: 1) We incorporate prior kinematic knowledge to initialize DIPR based on the Heatmap and establish multi-faceted optimization objectives, ensuring biomechanical validity and enhancing motion features. 2) We simulate complete mmWave processing pipelines, re-render a new Heatmap from DIPR, and compare it with the original Heatmap, avoiding spurious noise generation due to kinematic constraints overfitting. Experimental results on three datasets with four methods demonstrate that existing mmWave-based HPE methods can easily integrate DIPR and achieve superior performance.

**AI Summary:** This research explores a new input paradigm called Differentiable Physics-driven Human Representation (DIPR) for millimeter-wave-based Human Pose Estimation (HPE). DIPR represents humans as Gaussian distributions with kinematic and electromagnetic parameters, leveraging human kinematic priors and mmWave propagation physics to enhance human features and reduce noise. Experimental results show that integrating DIPR into existing mmWave-based HPE methods can significantly improve performance, addressing limitations in current Heatmap and Point Cloud input paradigms.

---

## ChatGraPhT: A Visual Conversation Interface for Multi-Path Reflection with Agentic LLM Support
**URL:** https://arxiv.org/abs/2512.22790

**Abstract:** Large Language Models (LLMs) are increasingly used in complex knowledge work, yet linear transcript interfaces limit support for reflection. Schon's Reflective Practice distinguishes between reflection-in-action (during a task) and reflection-on-action (after a task), both benefiting from non-linear, revisitable representations of dialogue. ChatGraPhT is an interactive tool that shows dialogue as a visual map, allowing users to branch and merge ideas, edit past messages, and receive guidance that prompts deeper reflection. It supports non-linear, multi-path dialogue, while two agentic LLM assistants provide moment-to-moment and higher-level guidance. Our inquiry suggests that keeping the conversation structure visible, allowing branching and merging, and suggesting patterns or ways to combine ideas deepened user reflective engagement. Contributions are: (1) the design of a node-link, agentic LLM interface for reflective dialogue, and (2) transferable design knowledge on balancing structure and AI support to sustain reflection in complex, open-ended tasks.

**AI Summary:** The research introduces ChatGraPhT, a visual conversation interface that supports non-linear, multi-path reflection during and after tasks. The interactive tool allows users to branch and merge ideas, edit past messages, and receive guidance from agentic Large Language Models (LLMs) to prompt deeper reflection. The study suggests that the visibility of conversation structure, branching and merging capabilities, and AI support can enhance user reflective engagement in complex, open-ended tasks.

---

## What do you say? A pilot study investigating student responses in Data Driven Classroom Interviews
**URL:** https://arxiv.org/abs/2512.22747

**Abstract:** Data that contextualizes student interactions with online learning systems can be challenging to obtain. This study looks at the rhetorical strategies of a novel method for conducting in-the-moment Data-Driven Classroom Interviews (DDCIs). By using Ordered Network Analysis (ONA) to reanalyze data from Wei et al.'s (2025) Epistemic Network Analysis, we better account for the sequences in which these rhetorical strategies emerge during the interview process. Specifically, we examine how five rhetorical strategies by interviewers relate to five possible rhetorical strategies used in student responses. As with the previous study, results demonstrate minor differences in how students with high and low situational interest respond. Namely, whereas students with high situational interest show moderately higher levels of enthusiasm, students with low situational interest are more likely to respond to interviewers with an explanation. However, overall this study confirms that there are few interviewer-driven differences in these interviews, and it documents that interviewers are following guidelines to rely upon open-ended questions

**AI Summary:** This pilot study explores the use of Data-Driven Classroom Interviews (DDCIs) to analyze student responses in online learning systems. By using Ordered Network Analysis (ONA) to reanalyze data, the study found that students with high situational interest show more enthusiasm in their responses, while those with low situational interest are more likely to provide explanations. Overall, the study confirms that interviewers are following guidelines to ask open-ended questions, and highlights the importance of understanding student responses in online learning environments.

---

## Clinically Calibrated Machine Learning Benchmarks for Large-Scale Multi-Disorder EEG Classification
**URL:** https://arxiv.org/abs/2512.22656

**Abstract:** Clinical electroencephalography is routinely used to evaluate patients with diverse and often overlapping neurological conditions, yet interpretation remains manual, time-intensive, and variable across experts. While automated EEG analysis has been widely studied, most existing methods target isolated diagnostic problems, particularly seizure detection, and provide limited support for multi-disorder clinical screening.
This study examines automated EEG-based classification across eleven clinically relevant neurological disorder categories, encompassing acute time-critical conditions, chronic neurocognitive and developmental disorders, and disorders with indirect or weak electrophysiological signatures. EEG recordings are processed using a standard longitudinal bipolar montage and represented through a multi-domain feature set capturing temporal statistics, spectral structure, signal complexity, and inter-channel relationships. Disorder-aware machine learning models are trained under severe class imbalance, with decision thresholds explicitly calibrated to prioritize diagnostic sensitivity.
Evaluation on a large, heterogeneous clinical EEG dataset demonstrates that sensitivity-oriented modeling achieves recall exceeding 80% for the majority of disorder categories, with several low-prevalence conditions showing absolute recall gains of 15-30% after threshold calibration compared to default operating points. Feature importance analysis reveals physiologically plausible patterns consistent with established clinical EEG markers.
These results establish realistic performance baselines for multi-disorder EEG classification and provide quantitative evidence that sensitivity-prioritized automated analysis can support scalable EEG screening and triage in real-world clinical settings.

**AI Summary:** This study focuses on developing machine learning models for automated EEG-based classification of eleven clinically relevant neurological disorder categories. The models are trained to prioritize diagnostic sensitivity and are evaluated on a large clinical EEG dataset, achieving recall rates exceeding 80% for most disorders. The results suggest that sensitivity-prioritized automated analysis can provide realistic performance baselines for multi-disorder EEG classification, potentially supporting scalable EEG screening and triage in clinical settings.

---

## SPECTRE: Spectral Pre-training Embeddings with Cylindrical Temporal Rotary Position Encoding for Fine-Grained sEMG-Based Movement Decoding
**URL:** https://arxiv.org/abs/2512.22481

**Abstract:** Decoding fine-grained movement from non-invasive surface Electromyography (sEMG) is a challenge for prosthetic control due to signal non-stationarity and low signal-to-noise ratios. Generic self-supervised learning (SSL) frameworks often yield suboptimal results on sEMG as they attempt to reconstruct noisy raw signals and lack the inductive bias to model the cylindrical topology of electrode arrays. To overcome these limitations, we introduce SPECTRE, a domain-specific SSL framework. SPECTRE features two primary contributions: a physiologically-grounded pre-training task and a novel positional encoding. The pre-training involves masked prediction of discrete pseudo-labels from clustered Short-Time Fourier Transform (STFT) representations, compelling the model to learn robust, physiologically relevant frequency patterns. Additionally, our Cylindrical Rotary Position Embedding (CyRoPE) factorizes embeddings along linear temporal and annular spatial dimensions, explicitly modeling the forearm sensor topology to capture muscle synergies. Evaluations on multiple datasets, including challenging data from individuals with amputation, demonstrate that SPECTRE establishes a new state-of-the-art for movement decoding, significantly outperforming both supervised baselines and generic SSL approaches. Ablation studies validate the critical roles of both spectral pre-training and CyRoPE. SPECTRE provides a robust foundation for practical myoelectric interfaces capable of handling real-world sEMG complexities.

**AI Summary:** The research introduces SPECTRE, a domain-specific self-supervised learning framework for decoding fine-grained movements from sEMG signals. SPECTRE utilizes a physiologically-grounded pre-training task and a novel positional encoding called CyRoPE to model the cylindrical topology of electrode arrays and capture muscle synergies. Evaluation on various datasets, including challenging data from individuals with amputation, shows that SPECTRE outperforms supervised baselines and generic SSL approaches, establishing a new state-of-the-art for movement decoding in prosthetic control.

---

## Relational Mediators: LLM Chatbots as Boundary Objects in Psychotherapy
**URL:** https://arxiv.org/abs/2512.22462

**Abstract:** As large language models (LLMs) are embedded into mental health technologies, they are often framed either as tools assisting therapists or autonomous therapeutic systems. Such perspectives overlook their potential to mediate relational complexities in therapy, particularly for systemically marginalized clients. Drawing on in-depth interviews with 12 therapists and 12 marginalized clients in China, including LGBTQ+ individuals or those from other marginalized backgrounds, we identify enduring relational challenges: difficulties building trust amid institutional barriers, the burden clients carry in educating therapists about marginalized identities, and challenges sustaining authentic self-disclosure across therapy and daily life. We argue that addressing these challenges requires AI systems capable of actively mediating underlying knowledge gaps, power asymmetries, and contextual disconnects. To this end, we propose the Dynamic Boundary Mediation Framework, which reconceptualizes LLM-enhanced systems as adaptive boundary objects that shift mediating roles across therapeutic stages. The framework delineates three forms of mediation: Epistemic (reducing knowledge asymmetries), Relational (rebalancing power dynamics), and Contextual (bridging therapy-life discontinuities). This framework offers a pathway toward designing relationally accountable AI systems that center the lived realities of marginalized users and more effectively support therapeutic relationships.

**AI Summary:** This research explores the role of large language models (LLMs) in mental health technologies, specifically in psychotherapy for marginalized clients in China. The study highlights the challenges faced in building trust, educating therapists about marginalized identities, and maintaining authentic self-disclosure. The Dynamic Boundary Mediation Framework is proposed to reconceptualize LLM-enhanced systems as adaptive boundary objects that can address knowledge gaps, power imbalances, and contextual disconnects, ultimately leading to more effective and relationally accountable AI systems in therapy.

---

## Learning to Program != "One-Size-Fits-All": Exploring Variations of Parsons Problems as Scaffolding
**URL:** https://arxiv.org/abs/2512.22407

**Abstract:** Lowering the barriers to computer programming requires understanding how to scaffold learning. Parsons problems, which require learners to drag-and-drop blocks of code into the correct order and indentation, are proving to be beneficial for scaffolding learning how to write code from scratch. But little is known about the ability of other problem types to do so. This study explores learners' perceptions of a new programming environment called Codespec, which was developed to make computer programming more accessible and equitable by offering multiple means of engagement. Retrospective think-aloud interviews were conducted with nine programmers who were given the choice between Faded Parsons and Pseudocode Parsons problems as optional scaffolding toward solving write-code problems. The results showed that offering Faded and Pseudocode Parsons problems as optional scaffolds supported comprehension monitoring, strategy formation, and refinement of prior knowledge. Learners selectively used Faded Parsons problems for syntax/structure and Pseudocode Parsons problems for high-level reasoning. The costs noted included the time it takes to drag-and-drop the blocks and the confusion experienced when a solution diverges from a learners' mental model. Faded Parsons problems were also perceived as a desirable challenge. This study contributes to the field of computing education and human-computer interaction by extending the functionality of problem spaces that support Parsons problems and by providing empirical evidence of the effectiveness of using other problem types as scaffolding techniques.

**AI Summary:** This study explores the effectiveness of using different types of Parsons problems, specifically Faded and Pseudocode Parsons problems, as scaffolding techniques in learning computer programming. The results show that offering these problem types as optional scaffolds can support comprehension monitoring, strategy formation, and refinement of prior knowledge for learners. The study contributes to the field by providing empirical evidence of the effectiveness of using various problem types to make programming more accessible and equitable.

---

## Mining the Gold: Student-AI Chat Logs as Rich Sources for Automated Knowledge Gap Detection
**URL:** https://arxiv.org/abs/2512.22404

**Abstract:** With the significant increase in enrollment in computing-related programs over the past 20 years, lecture sizes have grown correspondingly. In large lectures, instructors face challenges on identifying students' knowledge gaps timely, which is critical for effective teaching. Existing classroom response systems rely on instructor-initiated interactions, which limits their ability to capture the spontaneous knowledge gaps that naturally emerge during lectures. With the widespread adoption of LLMs among students, we recognize these student-AI dialogues as a valuable, student-centered data source for identifying knowledge gaps. In this idea paper, we propose QueryQuilt, a multi-agent LLM framework that automatically detects common knowledge gaps in large-scale lectures by analyzing students' chat logs with AI assistants. QueryQuilt consists of two key components: (1) a Dialogue Agent that responds to student questions while employing probing questions to reveal underlying knowledge gaps, and (2) a Knowledge Gap Identification Agent that systematically analyzes these dialogues to identify knowledge gaps across the student population. By generating frequency distributions of identified gaps, instructors can gain comprehensive insights into class-wide understanding. Our evaluation demonstrates promising results, with QueryQuilt achieving 100% accuracy in identifying knowledge gaps among simulated students and 95% completeness when tested on real student-AI dialogue data. These initial findings indicate the system's potential for facilitate teaching in authentic learning environments. We plan to deploy QueryQuilt in actual classroom settings for comprehensive evaluation, measuring its detection accuracy and impact on instruction.

**AI Summary:** This research proposes QueryQuilt, a multi-agent LLM framework that uses student-AI chat logs to automatically detect knowledge gaps in large-scale lectures. By analyzing dialogues between students and AI assistants, QueryQuilt can identify common knowledge gaps and provide instructors with insights into class-wide understanding. Initial evaluation shows promising results, with QueryQuilt achieving high accuracy in identifying knowledge gaps among simulated and real students, indicating its potential to enhance teaching in authentic learning environments.

---

## Emotion classification using EEG headset signals and Random Forest
**URL:** https://arxiv.org/abs/2512.22333

**Abstract:** Emotions are one of the important components of the human being, thus they are a valuable part of daily activities such as interaction with people, decision making and learning. For this reason, it is important to detect, recognize and understand emotions using computational systems to improve communication between people and machines, which would facilitate the ability of computers to understand the communication between humans. This study proposes the creation of a model that allows the classification of people's emotions based on their EEG signals, for which the brain-computer interface EMOTIV EPOC was used. This allowed the collection of electroencephalographic information from 50 people, all of whom were shown audiovisual resources that helped to provoke the desired mood. The information obtained was stored in a database for the generation of the model and the corresponding classification analysis. Random Forest model was created for emotion prediction (happiness, sadness and relaxation), based on the signals of any person. The results obtained were 97.21% accurate for happiness, 76% for relaxation and 76% for sadness. Finally, the model was used to generate a real-time emotion prediction algorithm; it captures the person's EEG signals, executes the generated algorithm and displays the result on the screen with the help of images representative of each emotion.

**AI Summary:** This study proposes a model for classifying people's emotions based on EEG signals collected using the EMOTIV EPOC headset. The Random Forest model achieved high accuracy rates for predicting happiness, relaxation, and sadness. The real-time emotion prediction algorithm could help improve communication between humans and machines by allowing computers to understand and respond to human emotions.

---

## Training AI Co-Scientists Using Rubric Rewards
**URL:** https://arxiv.org/abs/2512.23707

**Abstract:** AI co-scientists are emerging as a tool to assist human researchers in achieving their research goals. A crucial feature of these AI co-scientists is the ability to generate a research plan given a set of aims and constraints. The plan may be used by researchers for brainstorming, or may even be implemented after further refinement. However, language models currently struggle to generate research plans that follow all constraints and implicit requirements. In this work, we study how to leverage the vast corpus of existing research papers to train language models that generate better research plans. We build a scalable, diverse training corpus by automatically extracting research goals and goal-specific grading rubrics from papers across several domains. We then train models for research plan generation via reinforcement learning with self-grading. A frozen copy of the initial policy acts as the grader during training, with the rubrics creating a generator-verifier gap that enables improvements without external human supervision. To validate this approach, we conduct a study with human experts for machine learning research goals, spanning 225 hours. The experts prefer plans generated by our finetuned Qwen3-30B-A3B model over the initial model for 70% of research goals, and approve 84% of the automatically extracted goal-specific grading rubrics. To assess generality, we also extend our approach to research goals from medical papers, and new arXiv preprints, evaluating with a jury of frontier models. Our finetuning yields 12-22% relative improvements and significant cross-domain generalization, proving effective even in problem settings like medical research where execution feedback is infeasible. Together, these findings demonstrate the potential of a scalable, automated training recipe as a step towards improving general AI co-scientists.

**AI Summary:** This research focuses on training AI co-scientists to generate research plans that meet constraints and implicit requirements by leveraging a vast corpus of research papers. By extracting research goals and grading rubrics from papers across different domains, the models are trained using reinforcement learning with self-grading. The study shows that the finetuned models outperform the initial model for machine learning and medical research goals, demonstrating the potential of automated training to improve general AI co-scientists.

---

## Soft Robotic Technological Probe for Speculative Fashion Futures
**URL:** https://arxiv.org/abs/2512.23570

**Abstract:** Emerging wearable robotics demand design approaches that address not only function, but also social meaning. In response, we present Sumbrella, a soft robotic garment developed as a speculative fashion probe. We first detail the design and fabrication of the Sumbrella, including sequenced origami-inspired bistable units, fabric pneumatic actuation chambers, cable driven shape morphing mechanisms, computer vision components, and an integrated wearable system comprising a hat and bolero jacket housing power and control electronics. Through a focus group with twelve creative technologists, we then used Sumbrella as a technological probe to explore how people interpreted, interacted, and imagined future relationships with soft robotic wearables. While Sumbrella allowed our participants to engage in rich discussion around speculative futures and expressive potential, it also surfaced concerns about exploitation, surveillance, and the personal risks and societal ethics of embedding biosensing technologies in public life. We contribute to the Human-Robot Interaction (HRI) field key considerations and recommendations for designing soft robotic garments, including the potential for kinesic communication, the impact of such technologies on social dynamics, and the importance of ethical guidelines. Finally, we provide a reflection on our application of speculative design; proposing that it allows HRI researchers to not only consider functionality, but also how wearable robots influence definitions of what is considered acceptable or desirable in public settings.

**AI Summary:** The research presents a soft robotic garment called Sumbrella as a speculative fashion probe, exploring how people interpret and interact with soft robotic wearables. The study highlights the potential for kinesic communication, impact on social dynamics, and ethical considerations in designing soft robotic garments. The findings contribute to the Human-Robot Interaction field by emphasizing the importance of considering societal ethics and implications of embedding biosensing technologies in public life.

---

## Securing the AI Supply Chain: What Can We Learn From Developer-Reported Security Issues and Solutions of AI Projects?
**URL:** https://arxiv.org/abs/2512.23385

**Abstract:** The rapid growth of Artificial Intelligence (AI) models and applications has led to an increasingly complex security landscape. Developers of AI projects must contend not only with traditional software supply chain issues but also with novel, AI-specific security threats. However, little is known about what security issues are commonly encountered and how they are resolved in practice. This gap hinders the development of effective security measures for each component of the AI supply chain. We bridge this gap by conducting an empirical investigation of developer-reported issues and solutions, based on discussions from Hugging Face and GitHub. To identify security-related discussions, we develop a pipeline that combines keyword matching with an optimal fine-tuned distilBERT classifier, which achieved the best performance in our extensive comparison of various deep learning and large language models. This pipeline produces a dataset of 312,868 security discussions, providing insights into the security reporting practices of AI applications and projects. We conduct a thematic analysis of 753 posts sampled from our dataset and uncover a fine-grained taxonomy of 32 security issues and 24 solutions across four themes: (1) System and Software, (2) External Tools and Ecosystem, (3) Model, and (4) Data. We reveal that many security issues arise from the complex dependencies and black-box nature of AI components. Notably, challenges related to Models and Data often lack concrete solutions. Our insights can offer evidence-based guidance for developers and researchers to address real-world security threats across the AI supply chain.

**AI Summary:** This research investigates security issues and solutions in AI projects, highlighting the complex nature of security threats in the AI supply chain. By analyzing developer-reported discussions on platforms like Hugging Face and GitHub, the study identifies 32 security issues and 24 solutions across four themes. The findings provide valuable insights for developers and researchers to address security challenges in AI components, particularly in the areas of Models and Data.

---

## Multimodal Functional Maximum Correlation for Emotion Recognition
**URL:** https://arxiv.org/abs/2512.23076

**Abstract:** Emotional states manifest as coordinated yet heterogeneous physiological responses across central and autonomic systems, posing a fundamental challenge for multimodal representation learning in affective computing. Learning such joint dynamics is further complicated by the scarcity and subjectivity of affective annotations, which motivates the use of self-supervised learning (SSL). However, most existing SSL approaches rely on pairwise alignment objectives, which are insufficient to characterize dependencies among more than two modalities and fail to capture higher-order interactions arising from coordinated brain and autonomic responses.
To address this limitation, we propose Multimodal Functional Maximum Correlation (MFMC), a principled SSL framework that maximizes higher-order multimodal dependence through a Dual Total Correlation (DTC) objective. By deriving a tight sandwich bound and optimizing it using a functional maximum correlation analysis (FMCA) based trace surrogate, MFMC captures joint multimodal interactions directly, without relying on pairwise contrastive losses.
Experiments on three public affective computing benchmarks demonstrate that MFMC consistently achieves state-of-the-art or competitive performance under both subject-dependent and subject-independent evaluation protocols, highlighting its robustness to inter-subject variability. In particular, MFMC improves subject-dependent accuracy on CEAP-360VR from 78.9% to 86.8%, and subject-independent accuracy from 27.5% to 33.1% using the EDA signal alone. Moreover, MFMC remains within 0.8 percentage points of the best-performing method on the most challenging EEG subject-independent split of MAHNOB-HCI. Our code is available at this https URL.

**AI Summary:** The research introduces a new approach called Multimodal Functional Maximum Correlation (MFMC) for emotion recognition, which aims to capture higher-order interactions among multiple modalities in affective computing. By maximizing multimodal dependence through a Dual Total Correlation (DTC) objective, MFMC outperforms existing self-supervised learning methods on three public affective computing benchmarks, demonstrating robustness to inter-subject variability and improving accuracy in emotion recognition tasks. This new framework provides a more effective way to model joint dynamics in emotional states and has the potential to advance the field of multimodal affective computing.

---

