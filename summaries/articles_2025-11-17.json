[
  {
    "title": "Context-aware Adaptive Visualizations for Critical Decision Making",
    "abstract": "Effective decision-making often relies on timely insights from complex visual data. While Information Visualization (InfoVis) dashboards can support this process, they rarely adapt to users' cognitive state, and less so in real time. We present Symbiotik, an intelligent, context-aware adaptive visualization system that leverages neurophysiological signals to estimate mental workload (MWL) and dynamically adapt visual dashboards using reinforcement learning (RL). Through a user study with 120 participants and three visualization types, we demonstrate that our approach improves task performance and engagement. Symbiotik offers a scalable, real-time adaptation architecture, and a validated methodology for neuroadaptive user interfaces.",
    "url": "https://arxiv.org/abs/2511.11476",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces Symbiotik, an intelligent visualization system that adapts to users' cognitive state in real time by leveraging neurophysiological signals to estimate mental workload. Through a user study, it was shown that this approach improves task performance and engagement, offering a scalable, real-time adaptation architecture for neuroadaptive user interfaces. This research highlights the importance of context-aware adaptive visualizations in critical decision-making processes."
  },
  {
    "title": "Building the Web for Agents: A Declarative Framework for Agent-Web Interaction",
    "abstract": "The increasing deployment of autonomous AI agents on the web is hampered by a fundamental misalignment: agents must infer affordances from human-oriented user interfaces, leading to brittle, inefficient, and insecure interactions. To address this, we introduce VOIX, a web-native framework that enables websites to expose reliable, auditable, and privacy-preserving capabilities for AI agents through simple, declarative HTML elements. VOIX introduces <tool> and <context> tags, allowing developers to explicitly define available actions and relevant state, thereby creating a clear, machine-readable contract for agent behavior. This approach shifts control to the website developer while preserving user privacy by disconnecting the conversational interactions from the website. We evaluated the framework's practicality, learnability, and expressiveness in a three-day hackathon study with 16 developers. The results demonstrate that participants, regardless of prior experience, were able to rapidly build diverse and functional agent-enabled web applications. Ultimately, this work provides a foundational mechanism for realizing the Agentic Web, enabling a future of seamless and secure human-AI collaboration on the web.",
    "url": "https://arxiv.org/abs/2511.11287",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces VOIX, a framework that allows websites to provide reliable and privacy-preserving capabilities for AI agents through simple HTML elements. By introducing <tool> and <context> tags, developers can define actions and state, creating a machine-readable contract for agent behavior. The framework was evaluated in a hackathon study with 16 developers, showing that participants could quickly build functional agent-enabled web applications, paving the way for seamless and secure human-AI collaboration on the web."
  },
  {
    "title": "Devising Experiments with Interactive Environments",
    "abstract": "This paper reports a practice-based investigation into authoring responsive light and sound in immersive performance without writing code. A modular system couples live gesture, position, and speech inputs to scenographic outputs through a visual logic layer that performers can operate in rehearsal. Across six workshops with eight professional performance-makers, we staged a progression from parallel ensemble and technical training to integrated dramaturgy, culminating in a single-spectator scratch immersive performance with interactive elements. This paper details the system's building blocks and the workshop arc. A reflexive reading of workshop video logs, post-workshop focus groups, and facilitator notes surfaced three ensemble-level strategies that made the technology workable in a hybrid devising/design practice: rotating roles between operator, performer, and mediator; embracing controlled imperfection as a creative resource; and using technology-describing metaphors to support creative practice.",
    "url": "https://arxiv.org/abs/2511.11229",
    "journal": "arXiv cs.HC",
    "ai_summary": "This paper explores a system for creating interactive light and sound in immersive performances without the need for coding. Through workshops with professional performance-makers, the system was successfully used to integrate interactive elements into a scratch immersive performance. Key strategies identified for making this technology workable included rotating roles, embracing imperfection, and using technology metaphors to support creative practice."
  },
  {
    "title": "Towards Usable Privacy Management for IoT TAPs: Deriving Privacy Clusters and Preference Profiles",
    "abstract": "IoT Trigger-Action Platforms (TAPs) typically offer coarse-grained permission controls. Even when fine-grained controls are available, users are likely overwhelmed by the complexity of setting privacy preferences. This paper contributes to usable privacy management for TAPs by deriving privacy clusters and profiles for different types of users that can be semi-automatically assigned or suggested to them. We developed and validated a questionnaire, based on users' privacy concerns regarding confidentiality and control and their requirements towards transparency in TAPs. In an online study (N=301), where participants were informed about potential privacy risks, we clustered users by their privacy concerns and requirements into Basic, Medium and High Privacy clusters. These clusters were then characterized by the users' data sharing preferences, based on a factorial vignette approach, considering the data categories, the data recipient types, and the purpose of data sharing. Our findings show three distinct privacy profiles, providing a foundation for more usable privacy controls in TAPs.",
    "url": "https://arxiv.org/abs/2511.11209",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on improving privacy management for IoT Trigger-Action Platforms (TAPs) by deriving privacy clusters and profiles for different types of users. By clustering users based on their privacy concerns and requirements, the study identified three distinct privacy profiles (Basic, Medium, and High Privacy clusters) that can help in providing more usable privacy controls in TAPs. The findings suggest that by understanding users' privacy preferences, TAPs can offer more tailored and transparent privacy settings to address potential privacy risks."
  },
  {
    "title": "ReTrace: Interactive Visualizations for Reasoning Traces of Large Reasoning Models",
    "abstract": "Recent advances in Large Language Models have led to Large Reasoning Models, which produce step-by-step reasoning traces. These traces offer insight into how models think and their goals, improving explainability and helping users follow the logic, learn the process, and even debug errors. These traces, however, are often verbose and complex, making them cognitively demanding to comprehend. We address this challenge with ReTrace, an interactive system that structures and visualizes textual reasoning traces to support understanding. We use a validated reasoning taxonomy to produce structured reasoning data and investigate two types of interactive visualizations thereof. In a controlled user study, both visualizations enabled users to comprehend the model's reasoning more accurately and with less perceived effort than a raw text baseline. The results of this study could have design implications for making long and complex machine-generated reasoning processes more usable and transparent, an important step in AI explainability.",
    "url": "https://arxiv.org/abs/2511.11187",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research focuses on improving the explainability of Large Reasoning Models by developing an interactive system called ReTrace that structures and visualizes reasoning traces. The study found that the interactive visualizations provided by ReTrace enabled users to comprehend the model's reasoning more accurately and with less perceived effort compared to raw text. This research has implications for making complex machine-generated reasoning processes more usable and transparent, contributing to the overall goal of improving AI explainability."
  },
  {
    "title": "C2Views: Knowledge-based Colormap Design for Multiple-View Consistency",
    "abstract": "Multiple-view (MV) visualization provides a comprehensive and integrated perspective on complex data, establishing itself as an effective method for visual communication and exploratory data analysis. While existing studies have predominantly focused on designing explicit visual linkages and coordinated interactions to facilitate the exploration of MV visualizations, these approaches often demand extra graphical and interactive effort, overlooking the potential of color as an effective channel for encoding data and relationships. Addressing this oversight, we introduce C2Views, a new framework for colormap design that implicitly shows the relation across views. We begin by structuring the components and their relationships within MVs into a knowledge-based graph specification, wherein colormaps, data, and views are denoted as entities, and the interactions among them are illustrated as relations. Building on this representation, we formulate the design criteria as an optimization problem and employ a genetic algorithm enhanced by Pareto optimality, generating colormaps that balance single-view effectiveness and multiple-view consistency. Our approach is further complemented with an interactive interface for user-intended refinement. We demonstrate the feasibility of C2Views through various colormap design examples for MVs, underscoring its adaptability to diverse data relationships and view layouts. Comparative user studies indicate that our method outperforms the existing approach in facilitating color distinction and enhancing multiple-view consistency, thereby simplifying data exploration processes.",
    "url": "https://arxiv.org/abs/2511.11112",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces C2Views, a framework for colormap design that implicitly shows the relation across multiple views of complex data. By structuring components and relationships within multiple views into a knowledge-based graph specification, the framework utilizes an optimization problem and genetic algorithm to generate colormaps that balance single-view effectiveness and multiple-view consistency. Comparative user studies demonstrate that C2Views outperforms existing approaches in facilitating color distinction and enhancing multiple-view consistency, simplifying data exploration processes."
  },
  {
    "title": "Surveillance and Disability in Online Proctored Exams: Student Perspectives and Design Implications",
    "abstract": "Online proctoring systems (OPS) are technologies and services that are used to monitor students during an online exam to deter cheating. However, OPS often violates student privacy by implementing overly intrusive surveillance to which students cannot consent meaningfully. The technologies used in OPS have been shown to unfairly flag students with disabilities. Our reflexive thematic analysis of interviews with students who have first-hand experience with online invigilated exams and who have disability accommodations points to their anxiety about the interaction between surveillance and their disabilities, leading to fears about misrepresentation and increased cognitive load on the exam. Students describe the compromises they need to make with their privacy and accommodations to take remote tests and share their privacy values. We present the implications for the design of OPS to mitigate the issues faced by disabled students.",
    "url": "https://arxiv.org/abs/2511.10826",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the impact of online proctoring systems (OPS) on students with disabilities, highlighting how the surveillance used in OPS can unfairly flag students with disabilities and increase anxiety and cognitive load during exams. Students express concerns about privacy violations and the need to compromise their accommodations in order to take remote tests. The findings suggest the need for design changes in OPS to better support disabled students and address the issues raised by intrusive surveillance."
  },
  {
    "title": "Hi-DREAM: Brain Inspired Hierarchical Diffusion for fMRI Reconstruction via ROI Encoder and visuAl Mapping",
    "abstract": "Mapping human brain activity to natural images offers a new window into vision and cognition, yet current diffusion-based decoders face a core difficulty: most condition directly on fMRI features without analyzing how visual information is organized across the cortex. This overlooks the brain's hierarchical processing and blurs the roles of early, middle, and late visual areas. We propose Hi-DREAM, a brain-inspired conditional diffusion framework that makes the cortical organization explicit. A region-of-interest (ROI) adapter groups fMRI into early/mid/late streams and converts them into a multi-scale cortical pyramid aligned with the U-Net depth (shallow scales preserve layout and edges; deeper scales emphasize objects and semantics). A lightweight, depth-matched ControlNet injects these scale-specific hints during denoising. The result is an efficient and interpretable decoder in which each signal plays a brain-like role, allowing the model not only to reconstruct images but also to illuminate functional contributions of different visual areas. Experiments on the Natural Scenes Dataset (NSD) show that Hi-DREAM attains state-of-the-art performance on high-level semantic metrics while maintaining competitive low-level fidelity. These findings suggest that structuring conditioning by cortical hierarchy is a powerful alternative to purely data-driven embeddings and provides a useful lens for studying the visual cortex.",
    "url": "https://arxiv.org/abs/2511.11437",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces Hi-DREAM, a brain-inspired conditional diffusion framework that organizes fMRI features into early, mid, and late visual streams, aligning them with a multi-scale cortical pyramid for image reconstruction. This approach improves performance on high-level semantic metrics while maintaining competitive low-level fidelity, highlighting the importance of structuring conditioning by cortical hierarchy for studying the visual cortex and understanding the functional contributions of different visual areas. The findings suggest that Hi-DREAM offers an efficient and interpretable decoder that can illuminate how visual information is processed in the brain."
  },
  {
    "title": "KarmaTS: A Universal Simulation Platform for Multivariate Time Series with Functional Causal Dynamics",
    "abstract": "We introduce KarmaTS, an interactive framework for constructing lag-indexed, executable spatiotemporal causal graphical models for multivariate time series (MTS) simulation. Motivated by the challenge of access-restricted physiological data, KarmaTS generates synthetic MTS with known causal dynamics and augments real-world datasets with expert knowledge. The system constructs a discrete-time structural causal process (DSCP) by combining expert knowledge and algorithmic proposals in a mixed-initiative, human-in-the-loop workflow. The resulting DSCP supports simulation and causal interventions, including those under user-specified distribution shifts. KarmaTS handles mixed variable types, contemporaneous and lagged edges, and modular edge functionals ranging from parameterizable templates to neural network models. Together, these features enable flexible validation and benchmarking of causal discovery algorithms through expert-informed simulation.",
    "url": "https://arxiv.org/abs/2511.11357",
    "journal": "arXiv cs.HC",
    "ai_summary": "KarmaTS is a simulation platform designed to create multivariate time series with known causal dynamics, addressing the challenge of limited access to physiological data. By combining expert knowledge and algorithmic proposals, KarmaTS constructs a discrete-time structural causal process that supports simulation and causal interventions, including distribution shifts. This framework allows for the validation and benchmarking of causal discovery algorithms through expert-informed simulation, offering a flexible and interactive approach to studying causal relationships in time series data."
  },
  {
    "title": "Gynopticon: Consensus-Based Cheating Detection System for Competitive Games",
    "abstract": "Cheating in online games poses significant threats to the gaming industry, yet most prior research has concentrated on Massively Multiplayer Online Role-Playing Games (MMORPGs). Competitive genres-such as Multiplayer Online Battle Arena (MOBA), First Person Shooter (FPS), Real Time Strategy (RTS), and Action games-remain underexplored due to the difficulty of detecting cheating users and the demand for complex data and techniques. To address this gap, many game companies rely on kernel-level anti-cheat solutions, which, while effective, raise serious concerns regarding user privacy and system security. In this paper, we propose GYNOPTICON, a novel cheating detection framework that leverages user consensus to identify abnormal behavior. GYNOPTICON integrates a lightweight client-side detection mechanism with a server-side voting system: when suspicious activity is identified, clients cast votes to the server, which aggregates them to establish consensus and distinguish cheaters from legitimate players. This architecture enables transparency, reduces reliance on intrusive monitoring, and mitigates privacy risks. We evaluate GYNOPTICON in both a controlled simulation and a real-world FPS environment. Simulation results verify its feasibility and requirements, while real-world experiments confirm its effectiveness in reliably detecting cheating users. Furthermore, we demonstrate the system's applicability and sustainability for long-term game management using public datasets. GYNOPTICON represents a user-driven, consensus-based alternative to conventional anti-cheat systems, offering a practical and privacy-preserving solution for competitive online games.",
    "url": "https://arxiv.org/abs/2511.10992",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research paper introduces GYNOPTICON, a cheating detection system for competitive online games that leverages user consensus to identify abnormal behavior. The system integrates a lightweight client-side detection mechanism with a server-side voting system to distinguish cheaters from legitimate players, reducing reliance on intrusive monitoring and mitigating privacy risks. Evaluation in both simulation and real-world environments confirms GYNOPTICON's feasibility, effectiveness, and applicability as a user-driven, consensus-based alternative to conventional anti-cheat systems."
  },
  {
    "title": "DEFT-LLM: Disentangled Expert Feature Tuning for Micro-Expression Recognition",
    "abstract": "Micro expression recognition (MER) is crucial for inferring genuine emotion. Applying a multimodal large language model (MLLM) to this task enables spatio-temporal analysis of facial motion and provides interpretable descriptions. However, there are still two core challenges: (1) The entanglement of static appearance and dynamic motion cues prevents the model from focusing on subtle motion; (2) Textual labels in existing MER datasets do not fully correspond to underlying facial muscle movements, creating a semantic gap between text supervision and physical motion. To address these issues, we propose DEFT-LLM, which achieves motion semantic alignment by multi-expert disentanglement. We first introduce Uni-MER, a motion-driven instruction dataset designed to align text with local facial motion. Its construction leverages dual constraints from optical flow and Action Unit (AU) labels to ensure spatio-temporal consistency and reasonable correspondence to the movements. We then design an architecture with three experts to decouple facial dynamics into independent and interpretable representations (structure, dynamic textures, and motion-semantics). By integrating the instruction-aligned knowledge from Uni-MER into DEFT-LLM, our method injects effective physical priors for micro expressions while also leveraging the cross modal reasoning ability of large language models, thus enabling precise capture of subtle emotional cues. Experiments on multiple challenging MER benchmarks demonstrate state-of-the-art performance, as well as a particular advantage in interpretable modeling of local facial motion.",
    "url": "https://arxiv.org/abs/2511.10948",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces DEFT-LLM, a method for micro-expression recognition that addresses challenges related to entangled static appearance and dynamic motion cues, as well as the semantic gap between textual labels and facial muscle movements. By disentangling facial dynamics into interpretable representations and aligning text with local facial motion through the Uni-MER dataset, DEFT-LLM achieves state-of-the-art performance in capturing subtle emotional cues and provides a particular advantage in interpretable modeling of local facial motion. This research contributes to the advancement of MER technology by improving the precision and interpretability of emotion recognition algorithms."
  },
  {
    "title": "Multi-Joint Physics-Informed Deep Learning Framework for Time-Efficient Inverse Dynamics",
    "abstract": "Time-efficient estimation of muscle activations and forces across multi-joint systems is critical for clinical assessment and assistive device control. However, conventional approaches are computationally expensive and lack a high-quality labeled dataset for multi-joint applications. To address these challenges, we propose a physics-informed deep learning framework that estimates muscle activations and forces directly from kinematics. The framework employs a novel Multi-Joint Cross-Attention (MJCA) module with Bidirectional Gated Recurrent Unit (BiGRU) layers to capture inter-joint coordination, enabling each joint to adaptively integrate motion information from others. By embedding multi-joint dynamics, inter-joint coupling, and external force interactions into the loss function, our Physics-Informed MJCA-BiGRU (PI-MJCA-BiGRU) delivers physiologically consistent predictions without labeled data while enabling time-efficient inference. Experimental validation on two datasets demonstrates that PI-MJCA-BiGRU achieves performance comparable to conventional supervised methods without requiring ground-truth labels, while the MJCA module significantly enhances inter-joint coordination modeling compared to other baseline architectures.",
    "url": "https://arxiv.org/abs/2511.10878",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces a physics-informed deep learning framework, PI-MJCA-BiGRU, for efficiently estimating muscle activations and forces in multi-joint systems without the need for labeled data. The framework incorporates a Multi-Joint Cross-Attention module and Bidirectional Gated Recurrent Unit layers to capture inter-joint coordination and improve prediction accuracy. Experimental results show that PI-MJCA-BiGRU outperforms conventional supervised methods in terms of physiologically consistent predictions and inter-joint coordination modeling."
  },
  {
    "title": "Advanced Tool for Traffic Crash Analysis: An AI-Driven Multi-Agent Approach to Pre-Crash Reconstruction",
    "abstract": "Traffic collision reconstruction traditionally relies on human expertise, often yielding inconsistent results when analyzing incomplete multimodal data. This study develops a multi-agent AI framework that reconstructs pre-crash scenarios and infers vehicle behaviors from fragmented collision data. We present a two-phase collaborative framework combining reconstruction and reasoning phases. The system processes 277 rear-end lead vehicle deceleration (LVD) collisions from the Crash Investigation Sampling System, integrating textual crash reports, structured tabular data, and visual scene diagrams. Phase I generates natural-language crash reconstructions from multimodal inputs. Phase II performs in-depth crash reasoning by combining these reconstructions with temporal Event Data Recorder (EDR).For validation, we applied it to all LVD cases, focusing on a subset of 39 complex crashes where multiple EDR records per collision introduced ambiguity (e.g., due to missing or conflicting data).The evaluation of the 39 LVD crash cases revealed our framework achieved perfect accuracy across all test cases, successfully identifying both the most relevant EDR event and correctly distinguishing striking versus struck vehicles, surpassing the 92% accuracy achieved by human researchers on the same challenging dataset. The system maintained robust performance even when processing incomplete data, including missing or erroneous EDR records and ambiguous scene diagrams. This study demonstrates superior AI capabilities in processing heterogeneous collision data, providing unprecedented precision in reconstructing impact dynamics and characterizing pre-crash behaviors.",
    "url": "https://arxiv.org/abs/2511.10853",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study introduces a multi-agent AI framework for reconstructing pre-crash scenarios and inferring vehicle behaviors from fragmented collision data. The framework achieved perfect accuracy in identifying relevant Event Data Recorder events and distinguishing striking versus struck vehicles, surpassing human researchers' accuracy on the same dataset. The system demonstrated superior capabilities in processing incomplete and ambiguous data, providing unprecedented precision in reconstructing impact dynamics and characterizing pre-crash behaviors."
  },
  {
    "title": "Do AI Voices Learn Social Nuances? A Case of Politeness and Speech Rate",
    "abstract": "Voice-based artificial intelligence is increasingly expected to adhere to human social conventions, but can it learn implicit cues that are not explicitly programmed? This study investigates whether state-of-the-art text-to-speech systems have internalized the human tendency to reduce speech rate to convey politeness - a non-obvious prosodic marker. We prompted 22 synthetic voices from two leading AI platforms (AI Studio and OpenAI) to read a fixed script under both \"polite and formal\" and \"casual and informal\" conditions and measured the resulting speech duration. Across both AI platforms, the polite prompt produced slower speech than the casual prompt with very large effect sizes, an effect that was statistically significant for all of AI Studio's voices and for a large majority of OpenAI's voices. These results demonstrate that AI can implicitly learn and replicate psychological nuances of human communication, highlighting its emerging role as a social actor capable of reinforcing human social norms.",
    "url": "https://arxiv.org/abs/2511.10693",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study investigates whether AI voices can learn to convey politeness through speech rate, a non-obvious prosodic marker. The results show that state-of-the-art text-to-speech systems from AI Studio and OpenAI demonstrated slower speech in response to polite prompts compared to casual prompts, indicating that AI can replicate human social nuances. This highlights the emerging role of AI as a social actor capable of reinforcing human social norms."
  },
  {
    "title": "Cognitively-Inspired Episodic Memory Architectures for Accurate and Efficient Character AI",
    "abstract": "Large language models show promise for embodying historical characters in dialogue systems, but existing approaches face a critical trade-off: simple retrieval-augmented generation produces shallow responses, while multi-stage reflection achieves depth at prohibitive latency. We present an architecture that resolves this tension through offline data augmentation and efficient parallel retrieval from structured episodic memory. Our system transforms biographical data into 1,774 enriched first-person memories with affective-semantic metadata, then employs two-stage retrieval achieving 0.52s prompt generation. Evaluation using LLM-as-judge and RAGAs metrics shows our approach achieves parity with traditional RAG on GPT-4 while significantly outperforming it on smaller models (GPT-3.5, GPT-3), suggesting particular value for resource-constrained deployments. Beyond dialogue, the structured memory enables novel visualization tools: spatiotemporal heatmaps, emotional trajectory analysis, and interactive path tracking, positioning the system as both a dialogue interface and research tool for biographical analysis. We use Van Gogh as a test case, but the architecture is generalizable to any historical figure with substantial textual records, offering a practical framework for educational, museum, and research applications requiring both accuracy and efficiency",
    "url": "https://arxiv.org/abs/2511.10652",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research presents a novel architecture for creating accurate and efficient character AI by utilizing structured episodic memory and offline data augmentation. The system is able to generate prompt responses in 0.52s, achieving parity with traditional methods on large language models like GPT-4 and outperforming them on smaller models. This approach not only has practical applications in dialogue systems but also offers visualization tools for biographical analysis, making it valuable for educational, museum, and research purposes."
  },
  {
    "title": "Bytes of a Feather: Personality and Opinion Alignment Effects in Human-AI Interaction",
    "abstract": "Interactions with AI assistants are increasingly personalized to individual users. As AI personalization is dynamic and machine-learning-driven, we have limited understanding of how personalization affects interaction outcomes and user perceptions. We conducted a large-scale controlled experiment in which 1,000 participants interacted with AI assistants that took on certain personality traits and opinion stances. Our results show that participants consistently preferred to interact with models that shared their opinions. Participants also found opinion-aligned models more trustworthy, competent, warm, and persuasive, corroborating an AI-similarity-attraction hypothesis. In contrast, we observed no or only weak effects of AI personality alignment, with introvert models rated as less trustworthy and competent by introvert participants. These findings highlight opinion alignment as a central dimension of AI personalization and user preference, while underscoring the need for a more grounded discussion of the limits and risks of personalized AI.",
    "url": "https://arxiv.org/abs/2511.10544",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the impact of personality and opinion alignment in human-AI interactions. The study found that participants preferred interacting with AI models that shared their opinions, leading to perceptions of increased trustworthiness, competence, warmth, and persuasiveness. However, the study also found that personality alignment had limited effects, with introvert models being rated less positively by introvert participants. These findings emphasize the importance of opinion alignment in AI personalization and user preference, while also highlighting the need for a more nuanced discussion on the limits and risks of personalized AI."
  },
  {
    "title": "Preview, Accept or Discard? A Predictive Low-Motion Interaction Paradigm",
    "abstract": "Repetitive strain injury (RSI) affects roughly one in five computer users and remains largely unresolved despite decades of ergonomic mouse redesign. All such devices share a fundamental limitation: they still require fine-motor motion to operate. This work investigates whether predictive, AI-assisted input can reduce that motion by replacing physical pointing with ranked on-screen suggestions. To preserve user agency, we introduce Preview Accept Discard (PAD), a zero-click interaction paradigm that lets users preview predicted GUI targets, cycle through a small set of ranked alternatives, and accept or discard them via key-release timing. We evaluate PAD in two settings: a browser-based email client and a ISO 9241-9 keyboard-prediction task under varying top-3 accuracies. Across both studies, PAD substantially reduces hand motion relative to trackpad use while maintaining comparable task times with the trackpad only when accuracies are similar to those of the best spell-checkers.",
    "url": "https://arxiv.org/abs/2511.10532",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores a new interaction paradigm called Preview Accept Discard (PAD) that uses AI-assisted input to reduce fine-motor motion required to operate computer devices. The study found that PAD significantly reduces hand motion compared to traditional trackpad use, while maintaining similar task times when accuracy levels are high. This suggests that predictive AI technology could potentially help reduce repetitive strain injuries in computer users by minimizing physical pointing and clicking."
  },
  {
    "title": "Motivations and Actions of Human-Building Interactions from Environmental Momentary Assessments",
    "abstract": "The expansion of renewable electricity generation, growing demands due to electrification, greater prevalence of working from home, and increasing frequency and severity of extreme weather events, will place new demands on the electric supply and distribution grid. Broader adoption of demand response programs (DRPs) for the residential sector may help meet these challenges; however, experience shows that occupant overrides in DRPs compromises their effectiveness. There is a lack of formal understanding of how discomfort, routines, and other motivations affect DRP overrides and other related human building interactions (HBI). This paper reports preliminary findings from a study of 20 households in Colorado and Massachusetts, US over three months. Participants responded to ecological momentary assessments (EMA) triggered by thermostat interactions and at random times throughout the day. EMAs included Likert-scale questions of thermal preference, preference intensity, and changes to 7 different activity types that could affect thermal comfort, and an opened ended question about motivations of such actions. Twelve tags were developed to categorize motivation responses and analyzed statistically to identify associations between motivations, preferences, and HBI actions. Reactions to changes in the thermal environment were the most frequently observed motivation, 118 of 220 responses. On the other hand, 47% responses were at least partially motivated by non-thermal factors, suggesting limited utility for occupant behavior models founded solely on thermal comfort. Changes in activity level and clothing were less likely to be reported when EMAs were triggered by thermostat interactions, while fan interactions were more likely. Windows, shades, and portable heater interactions had no significant dependence on how the EMA was triggered.",
    "url": "https://arxiv.org/abs/2511.10467",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research study explores the motivations behind human-building interactions, particularly in the context of demand response programs for residential energy use. The study found that reactions to changes in the thermal environment were the most common motivation for overriding settings, but a significant portion of responses were influenced by non-thermal factors. This suggests that occupant behavior models should consider a wider range of motivations beyond just thermal comfort to improve the effectiveness of demand response programs."
  },
  {
    "title": "Navigating the Ethics of Internet Measurement: Researchers' Perspectives from a Case Study in the EU",
    "abstract": "Internet measurement research is essential for understanding, improving, and securing Internet infrastructure. However, its methods often involve large-scale data collection and user observation, raising complex ethical questions. While recent research has identified ethical challenges in Internet measurement research and laid out best practices, little is known about how researchers actually make ethical decisions in their research practice. To understand how these practices take shape day-to-day from the perspective of Internet measurement researchers, we interviewed 16 researchers from an Internet measurement research group in the EU. Through thematic analysis, we find that researchers deal with five main ethical challenges: privacy and consent issues, the possibility of unintended harm, balancing transparency with security and accountability, uncertain ethical boundaries, and hurdles in the ethics review process. Researchers address these by lab testing, rate limiting, setting up clear communication channels, and relying heavily on mentors and colleagues for guidance. Researchers express that ethical requirements vary across institutions, jurisdictions and conferences, and ethics review boards often lack the technical knowledge to evaluate Internet measurement research. We also highlight the invisible labor of Internet measurement researchers and describe their ethics practices as craft knowledge, both of which are crucial in upholding responsible research practices in the Internet measurement community.",
    "url": "https://arxiv.org/abs/2511.10408",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the ethical challenges faced by Internet measurement researchers in the EU, focusing on privacy, consent, unintended harm, transparency, and ethics review processes. The study found that researchers address these challenges through lab testing, rate limiting, clear communication, and guidance from mentors and colleagues. The findings emphasize the importance of understanding and navigating ethical considerations in Internet measurement research to uphold responsible research practices in the field."
  },
  {
    "title": "Moral Change or Noise? On Problems of Aligning AI With Temporally Unstable Human Feedback",
    "abstract": "Alignment methods in moral domains seek to elicit moral preferences of human stakeholders and incorporate them into AI. This presupposes moral preferences as static targets, but such preferences often evolve over time. Proper alignment of AI to dynamic human preferences should ideally account for \"legitimate\" changes to moral reasoning, while ignoring changes related to attention deficits, cognitive biases, or other arbitrary factors. However, common AI alignment approaches largely neglect temporal changes in preferences, posing serious challenges to proper alignment, especially in high-stakes applications of AI, e.g., in healthcare domains, where misalignment can jeopardize the trustworthiness of the system and yield serious individual and societal harms. This work investigates the extent to which people's moral preferences change over time, and the impact of such changes on AI alignment. Our study is grounded in the kidney allocation domain, where we elicit responses to pairwise comparisons of hypothetical kidney transplant patients from over 400 participants across 3-5 sessions. We find that, on average, participants change their response to the same scenario presented at different times around 6-20% of the time (exhibiting \"response instability\"). Additionally, we observe significant shifts in several participants' retrofitted decision-making models over time (capturing \"model instability\"). The predictive performance of simple AI models decreases as a function of both response and model instability. Moreover, predictive performance diminishes over time, highlighting the importance of accounting for temporal changes in preferences during training. These findings raise fundamental normative and technical challenges relevant to AI alignment, highlighting the need to better understand the object of alignment (what to align to) when user preferences change significantly over time.",
    "url": "https://arxiv.org/abs/2511.10032",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the challenges of aligning AI with human moral preferences that can change over time. The study conducted in the kidney allocation domain found that participants' moral preferences exhibited both response and model instability, impacting the predictive performance of AI models. The findings emphasize the importance of accounting for temporal changes in preferences during AI training to ensure proper alignment, especially in high-stakes applications like healthcare."
  },
  {
    "title": "Grating haptic perception through touchscreen: Sighted vs. Visually Impaired",
    "abstract": "Providing haptic feedback via smartphone touch screen may potentially offer blind people a capability to understand graphs. This study investigated the discrimination performance of haptic gratings in different frequencies, in both visually impaired (VI) and sighted (S) individuals. 6 VI participants and 10 S participants took part in two experiments designed to compare their ability to interpret grating images with a finger swiping across a smartphone touchscreen without vision. The swipe gesture activates phone vibration temporally synchronized with the black stripes. Their tasks were: (1) determining whether a grating pattern is presented on the touchscreen, (2) comparing two different grating frequencies and determining the wider one. Results demonstrated that the VI group exhibited superior tactile sensitivity compared to the S group, as evidenced by their significantly better performance in Experiment 1 (accuracy of 99.15\\% vs. 84.5\\%). Experiment 2 revealed that the peak performance of VI participants was approximately around 0.270 cycles per mm (83.3\\% accuracy), a frequency very similar to Braille dot spacing, while S group peaked around 0.963 cycles per mm (70\\% accuracy). The findings suggest that tactile stimulation coded with grating patterns could be potentially used to present interpretable graph for the visually impaired. Such an approach could offer a value to research in human-computer interaction and sensory adaptation.",
    "url": "https://arxiv.org/abs/2511.10026",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study compared the ability of visually impaired and sighted individuals to interpret haptic gratings on a smartphone touchscreen. The visually impaired group showed superior tactile sensitivity and performance in determining grating patterns and frequencies compared to the sighted group. The findings suggest that using tactile stimulation with grating patterns could potentially help visually impaired individuals understand graphs, offering value to research in human-computer interaction and sensory adaptation."
  },
  {
    "title": "Quantitative and Qualitative Comparison of Generative Models for Subject-Specific Gaze Synthesis: Diffusion vs GAN",
    "abstract": "Recent advances in deep learning demonstrate the ability to generate synthetic gaze data. However, most approaches have primarily focused on generating data from random noise distributions or global, predefined latent embeddings, whereas individualized gaze sequence generation has been less explored. To address this gap, we revisit two recent approaches based on diffusion and generative adversarial networks (GANs) and introduce modifications that make both models explicitly subject-aware while improving accuracy and effectiveness. For the diffusion-based approach, we utilize compact user embeddings that emphasize per-subject traits. Moreover, for the GAN-based approach, we propose a subject-specific synthesis module that conditioned the generator to retain better idiosyncratic gaze information. Finally, we conduct a comprehensive assessment of these modified approaches utilizing standard eye-tracking signal quality metrics, including spatial accuracy and precision. This work helps define synthetic signal quality, realism, and subject specificity, thereby contributing to the potential development of gaze-based applications.",
    "url": "https://arxiv.org/abs/2511.09867",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research compares two generative models, diffusion and GAN, for synthesizing subject-specific gaze data. The study introduces modifications to make both models subject-aware, improving accuracy and effectiveness. The findings contribute to defining synthetic signal quality, realism, and subject specificity, which could advance the development of gaze-based applications."
  },
  {
    "title": "Real-Time Lightweight Gaze Privacy-Preservation Techniques Validated via Offline Gaze-Based Interaction Simulation",
    "abstract": "This study examines the effectiveness of the real-time privacy-preserving techniques through an offline gaze-based interaction simulation framework. Those techniques aim to reduce the amount of identity-related information in eye-tracking data while improving the efficacy of the gaze-based interaction. Although some real-time gaze privatization methods were previously explored, their validation on the large dataset was not conducted. We propose a functional framework that allows to study the efficacy of real-time gaze privatization on an already collected offline dataset. The key metric used to assess the reduction of identity-related information is the identification rate, while improvements in gaze-based interactions are evaluated through signal quality during interaction. Our additional contribution is the employment of an extremely lightweight Kalman filter framework that reduces the amount of identity-related information in the gaze signal and improves gaze-based interaction performance.",
    "url": "https://arxiv.org/abs/2511.09846",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study evaluates real-time privacy-preserving techniques for gaze-based interactions using an offline simulation framework. The research demonstrates the effectiveness of these techniques in reducing identity-related information in eye-tracking data and improving the efficiency of gaze-based interactions. The use of a lightweight Kalman filter framework is highlighted as a key contribution to enhancing privacy preservation and interaction performance."
  },
  {
    "title": "I've Seen Enough: Measuring the Toll of Content Moderation on Mental Health",
    "abstract": "Human content moderators (CMs) routinely review distressing digital content at scale. Beyond exposure, the work context (e.g., workload, team structure, and support) may shape mental health outcomes. We examined a cross sectional international CM sample (N = 166) and a U.S. prospective CM sample, including a comparison group of data labelers or tech support workers (N = 45) and gold standard diagnostic interviews. Predictors included workplace factors (e.g., hours per day distressing content, culture), cognitive-affective individual differences, and coping. Across samples, probable diagnoses based on validated clinical cutoffs were elevated (PTSD: 25.9 to 26.3%; depression: 42.1 to 48.5%; somatic symptoms: 68.7 to 89.5%; alcohol misuse: 10.5% to 18.3%). In the U.S. sample, CMs had higher interviewer rated PTSD severity (d = 1.50), likelihood of a current mood disorder (RR = 8.22), and lifetime major depressive disorder (RR = 2.15) compared to data labelers/tech-support workers. Negative automatic thoughts (b = .39 to .74), ongoing stress (b = .27 to .55), and avoidant coping (b = .30 to .34) consistently predicted higher PTSD and depression severity across samples and at 3 month followup. Poorer perceived workplace culture was associated with higher depression (b = -.16 to -.32). These findings strongly implicate organizational context and related individual response styles, not exposure dose alone in shaping risk. We highlight structural and technological interventions such as limits on daily exposure, supportive team culture, interface features to reduce intrusive memories, and training of cognitive restructuring and adaptive coping to support mental health. We also connect implications to adjacent human in the loop data work (e.g., AI red teaming), where similar risks are emerging.",
    "url": "https://arxiv.org/abs/2511.09813",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study examines the impact of content moderation on the mental health of human moderators, finding that workplace factors and individual coping mechanisms play a significant role in mental health outcomes. The research shows that content moderators are at a higher risk for PTSD, depression, somatic symptoms, and alcohol misuse compared to data labelers or tech support workers. The findings suggest the importance of implementing structural and technological interventions to support the mental health of content moderators, such as limits on daily exposure, supportive team culture, and cognitive restructuring training."
  },
  {
    "title": "How AI Responses Shape User Beliefs: The Effects of Information Detail and Confidence on Belief Strength and Stance",
    "abstract": "The growing use of AI-generated responses in everyday tools raises concern about how subtle features such as supporting detail or tone of confidence may shape people's beliefs. To understand this, we conducted a pre-registered online experiment (N = 304) investigating how the detail and confidence of AI-generated responses influence belief change. We introduce an analysis framework with two targeted measures: belief switch and belief shift. These distinguish between users changing their initial stance after AI input and the extent to which they adjust their conviction toward or away from the AI's stance, thereby quantifying not only categorical changes but also more subtle, continuous adjustments in belief strength that indicate a reinforcement or weakening of existing beliefs. Using this framework, we find that detailed responses with medium confidence are associated with the largest overall belief changes. Highly confident messages tend to elicit belief shifts but induce fewer stance reversals. Our results also show that task type (fact-checking versus opinion evaluation), prior conviction, and perceived stance agreement further modulate the extent and direction of belief change. These findings illustrate how different properties of AI responses interact with user beliefs in subtle but potentially consequential ways and raise practical as well as ethical considerations for the design of LLM-powered systems.",
    "url": "https://arxiv.org/abs/2511.09667",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research study explores how the detail and confidence level of AI-generated responses can influence belief change in users. The study found that detailed responses with medium confidence were associated with the largest overall belief changes, while highly confident messages tended to induce belief shifts but fewer stance reversals. The results suggest that subtle features of AI responses can have significant effects on user beliefs, highlighting the importance of considering these factors in the design of AI-powered systems."
  },
  {
    "title": "Co-Designing Multimodal Systems for Accessible Remote Dance Instruction",
    "abstract": "Videos make exercise instruction widely available, but they rely on visual demonstrations that blind and low vision (BLV) learners cannot see. While audio descriptions (AD) can make videos accessible, describing movements remains challenging as the AD must convey \\textit{what} to do (mechanics, location, orientation) and \\textit{how} to do it (speed, fluidity, timing). Prior work thus used \\textit{multimodal instruction} to support BLV learners with individual simple movements. However, it is unclear how these approaches scale to dance instruction with unique, complex movements and precise timing constraints. To inform accessible remote dance instruction systems, we conducted three co-design workshops (N=28) with BLV dancers, instructors, and experts in sound, haptics, and AD. Participants designed 8 systems revealing common themes: staged learning to dissect routines, crafting vocabularies for movements, and selectively using modalities (narration for movement structure, sound for expression, and haptics for spatial cues). We conclude with design recommendations to make learning dance accessible.",
    "url": "https://arxiv.org/abs/2511.09658",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the challenges faced by blind and low vision learners in accessing dance instruction videos and proposes co-designed multimodal systems to make dance instruction accessible. Through co-design workshops with BLV dancers, instructors, and experts, common themes such as staged learning, crafting vocabularies for movements, and selectively using modalities were identified. The study highlights the importance of using narration for movement structure, sound for expression, and haptics for spatial cues in designing accessible remote dance instruction systems."
  },
  {
    "title": "When Thinking Pays Off: Incentive Alignment for Human-AI Collaboration",
    "abstract": "Collaboration with artificial intelligence (AI) has improved human decision-making across various domains by leveraging the complementary capabilities of humans and AI. Yet, humans systematically overrely on AI advice, even when their independent judgment would yield superior outcomes, fundamentally undermining the potential of human-AI complementarity. Building on prior work, we identify prevailing incentive structures in human-AI decision-making as a structural driver of this overreliance. To address this misalignment, we propose an alternative incentive mechanism designed to counteract systemic overreliance. We empirically evaluate this approach through a behavioral experiment with 180 participants, finding that the proposed mechanism significantly reduces overreliance. We also show that while appropriately designed incentives can enhance collaboration and decision quality, poorly designed incentives may distort behavior, introduce unintended consequences, and ultimately degrade performance. These findings underscore the importance of aligning incentives with task context and human-AI complementarities, and suggest that effective collaboration requires a shift toward context-sensitive incentive design.",
    "url": "https://arxiv.org/abs/2511.09612",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research investigates the issue of humans overrelying on AI advice, even when their own judgment would be more effective, due to prevailing incentive structures in decision-making. By proposing an alternative incentive mechanism, the study found that overreliance can be significantly reduced, highlighting the importance of aligning incentives with task context and human-AI complementarities for effective collaboration. The findings suggest that well-designed incentives can enhance decision quality, while poorly designed incentives may lead to unintended consequences and degrade performance."
  },
  {
    "title": "Towards Emotionally Intelligent and Responsible Reinforcement Learning",
    "abstract": "Personalized decision systems in healthcare and behavioral support often rely on static rule-based or engagement-maximizing heuristics that overlook users' emotional context and ethical constraints. Such approaches risk recommending insensitive or unsafe interventions, especially in domains involving serious mental illness, substance use disorders, or depression. To address this limitation, we propose a Responsible Reinforcement Learning (RRL) framework that integrates emotional and contextual understanding with ethical considerations into the sequential decision-making process. RRL formulates personalization as a Constrained Markov Decision Process (CMDP), where the agent optimizes engagement and adherence while ensuring emotional alignment and ethical safety. We introduce a multi-objective reward function that explicitly balances short-term behavioral engagement with long-term user well-being, and define an emotion-informed state representation that captures fluctuations in emotional readiness, affect, and risk. The proposed architecture can be instantiated with any RL algorithm (e.g., DQN, PPO) augmented with safety constraints or Lagrangian regularization. Conceptually, this framework operationalizes empathy and responsibility within machine learning policy optimization, bridging safe RL, affective computing and responsible AI. We discuss the implications of this approach for human-centric domains such as behavioral health, education, and digital therapeutics, and outline simulation-based validation paths for future empirical work. This paper aims to initiate a methodological conversation about ethically aligned reinforcement learning for emotionally aware and trustworthy personalization systems.",
    "url": "https://arxiv.org/abs/2511.10573",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research proposes a Responsible Reinforcement Learning framework that integrates emotional understanding and ethical considerations into decision-making processes in healthcare and behavioral support. This framework aims to balance short-term engagement with long-term well-being, ensuring emotional alignment and ethical safety in personalized interventions. By incorporating empathy and responsibility into machine learning policy optimization, this approach bridges safe reinforcement learning, affective computing, and responsible AI, offering potential benefits for human-centric domains like behavioral health and education."
  },
  {
    "title": "Proceedings of The third international workshop on eXplainable AI for the Arts (XAIxArts)",
    "abstract": "This third international workshop on explainable AI for the Arts (XAIxArts) brought together a community of researchers in HCI, Interaction Design, AI, explainable AI (XAI), and digital arts to explore the role of XAI for the Arts. Workshop held at the 17th ACM Conference on Creativity and Cognition (C&C 2025), online.",
    "url": "https://arxiv.org/abs/2511.10482",
    "journal": "arXiv cs.HC",
    "ai_summary": "The third international workshop on explainable AI for the Arts (XAIxArts) focused on the intersection of HCI, Interaction Design, AI, XAI, and digital arts. The workshop aimed to explore the significance and potential of XAI in the field of arts, bringing together researchers from different disciplines. This collaboration at the 17th ACM Conference on Creativity and Cognition highlights the growing interest in incorporating XAI into artistic practices and creative processes."
  },
  {
    "title": "FineSkiing: A Fine-grained Benchmark for Skiing Action Quality Assessment",
    "abstract": "Action Quality Assessment (AQA) aims to evaluate and score sports actions, which has attracted widespread interest in recent years. Existing AQA methods primarily predict scores based on features extracted from the entire video, resulting in limited interpretability and reliability. Meanwhile, existing AQA datasets also lack fine-grained annotations for action scores, especially for deduction items and sub-score annotations. In this paper, we construct the first AQA dataset containing fine-grained sub-score and deduction annotations for aerial skiing, which will be released as a new benchmark. For the technical challenges, we propose a novel AQA method, named JudgeMind, which significantly enhances performance and reliability by simulating the judgment and scoring mindset of professional referees. Our method segments the input action video into different stages and scores each stage to enhance accuracy. Then, we propose a stage-aware feature enhancement and fusion module to boost the perception of stage-specific key regions and enhance the robustness to visual changes caused by frequent camera viewpoints switching. In addition, we propose a knowledge-based grade-aware decoder to incorporate possible deduction items as prior knowledge to predict more accurate and reliable scores. Experimental results demonstrate that our method achieves state-of-the-art performance.",
    "url": "https://arxiv.org/abs/2511.10250",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces a new benchmark dataset for assessing the quality of skiing actions, with fine-grained sub-score and deduction annotations. The proposed AQA method, JudgeMind, improves performance by segmenting the video into stages and scoring each stage, enhancing accuracy and reliability. The method also includes a stage-aware feature enhancement and fusion module, as well as a knowledge-based grade-aware decoder, resulting in state-of-the-art performance in action quality assessment."
  },
  {
    "title": "Autonomous X-ray Fluorescence Mapping of Chemically Heterogeneous Systems via a Correlative Feature Detection Framework",
    "abstract": "We present X-AutoMap, a modular framework for autonomous X-ray fluorescence (XRF) mapping that enables chemically informed targeting of regions of interest through a correlative feature detection strategy. The system integrates classical computer vision and rule-based logic to identify features based on spatial relationships across multiple elemental maps, rather than relying solely on intensity or morphology. Tight integration with the Bluesky control infrastructure at the NSLS-II Hard X-ray Nanoprobe (HXN) beamline enables real-time, closed-loop scan orchestration. Applied to a chemically heterogeneous urban PM2.5 sample, X-AutoMap reduced high-resolution acquisition time from over 44 hours to approximately 10 hours by targeting compositionally significant features identified from coarse scans. High-resolution results revealed diverse particle types, including fully mixed, partially overlapping, and spatially distinct multi-element structures, demonstrating the ability of the framework to isolate chemically relevant features with minimal user intervention. The framework supports interactive and autonomous modes, operates within hardware constraints via grid-based scanning, and is robust across varying sample conditions. Future extensions will incorporate machine learning and probabilistic sampling to further improve detection sensitivity and scan efficiency. X-AutoMap is currently in active use at HXN and provides a flexible foundation for scalable, intelligent imaging workflows at synchrotron beamlines.",
    "url": "https://arxiv.org/abs/2511.09975",
    "journal": "arXiv cs.HC",
    "ai_summary": "The X-AutoMap framework allows for autonomous X-ray fluorescence mapping of chemically heterogeneous systems by using a correlative feature detection strategy. This system significantly reduces acquisition time by targeting compositionally significant features identified from coarse scans, leading to the discovery of diverse particle types within the sample. The framework is robust, supports interactive and autonomous modes, and has the potential for further improvements through the incorporation of machine learning and probabilistic sampling."
  },
  {
    "title": "Owlgorithm: Supporting Self-Regulated Learning in Competitive Programming through LLM-Driven Reflection",
    "abstract": "We present Owlgorithm, an educational platform that supports Self-Regulated Learning (SRL) in competitive programming (CP) through AI-generated reflective questions. Leveraging GPT-4o, Owlgorithm produces context-aware, metacognitive prompts tailored to individual student submissions. Integrated into a second- and third-year CP course, the system-provided reflective prompts adapted to student outcomes: guiding deeper conceptual insight for correct solutions and structured debugging for partial or failed ones.\nOur exploratory assessment of student ratings and TA feedback revealed both promising benefits and notable limitations. While many found the generated questions useful for reflection and debugging, concerns were raised about feedback accuracy and classroom usability. These results suggest advantages of LLM-supported reflection for novice programmers, though refinements are needed to ensure reliability and pedagogical value for advanced learners.\nFrom our experience, several key insights emerged: GenAI can effectively support structured reflection, but careful prompt design, dynamic adaptation, and usability improvements are critical to realizing their potential in education. We offer specific recommendations for educators using similar tools and outline next steps to enhance Owlgorithm's educational impact. The underlying framework may also generalize to other reflective learning contexts.",
    "url": "https://arxiv.org/abs/2511.09969",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces Owlgorithm, an educational platform utilizing AI-generated reflective questions to support Self-Regulated Learning in competitive programming. The system's reflective prompts were found to enhance conceptual understanding for correct solutions and guide structured debugging for incorrect ones. While students and TAs found the generated questions useful, concerns were raised about feedback accuracy and usability, indicating the need for further refinement to ensure reliability and pedagogical value, especially for advanced learners. The study highlights the potential of AI-supported reflection in education but emphasizes the importance of prompt design, dynamic adaptation, and usability improvements for maximizing its impact."
  },
  {
    "title": "Leveraging Large Language Models for Identifying Knowledge Components",
    "abstract": "Knowledge Components (KCs) are foundational to adaptive learning systems, but their manual identification by domain experts is a significant bottleneck. While Large Language Models (LLMs) offer a promising avenue for automating this process, prior research has been limited to small datasets and has been shown to produce superfluous, redundant KC labels. This study addresses these limitations by first scaling a \"simulated textbook\" LLM prompting strategy (using GPT-4o-mini) to a larger dataset of 646 multiple-choice questions. We found that this initial automated approach performed significantly worse than an expert-designed KC model (RMSE 0.4285 vs. 0.4206) and generated an excessive number of KCs (569 vs. 101). To address the issue of redundancy, we proposed and evaluated a novel method for merging semantically similar KC labels based on their cosine similarity. This merging strategy significantly improved the model's performance; a model using a cosine similarity threshold of 0.8 achieved the best result, reducing the KC count to 428 and improving the RMSE to 0.4259. This demonstrates that while scaled LLM generation alone is insufficient, combining it with a semantic merging technique offers a viable path toward automating and refining KC identification.",
    "url": "https://arxiv.org/abs/2511.09935",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores the use of Large Language Models (LLMs) for automating the identification of Knowledge Components (KCs) in adaptive learning systems. The research found that while initial automated approaches using LLMs performed worse than expert-designed models and generated excessive KC labels, a novel method of merging semantically similar KC labels based on cosine similarity significantly improved the model's performance. This suggests that combining scaled LLM generation with semantic merging techniques could be a promising approach for automating and refining KC identification in educational systems."
  },
  {
    "title": "Why Open Small AI Models Matter for Interactive Art",
    "abstract": "This position paper argues for the importance of open small AI models in creative independence for interactive art practices. Deployable locally, these models offer artists vital control over infrastructure and code, unlike dominant large, closed-source corporate systems. Such centralized platforms function as opaque black boxes, imposing severe limitations on interactive artworks, including restrictive content filters, preservation issues, and technical challenges such as increased latency and limited interfaces. In contrast, small AI models empower creators with more autonomy, control, and sustainability for these artistic processes. They enable the ability to use a model as long as they want, create their own custom model, either by making code changes to integrate new interfaces, or via new datasets by re-training or fine-tuning the model. This fosters technological self-determination, offering greater ownership and reducing reliance on corporate AI ill-suited for interactive art's demands. Critically, this approach empowers the artist and supports long-term preservation and exhibition of artworks with AI components. This paper explores the practical applications and implications of using open small AI models in interactive art, contrasting them with closed-source alternatives.",
    "url": "https://arxiv.org/abs/2511.09788",
    "journal": "arXiv cs.HC",
    "ai_summary": "This paper highlights the importance of open small AI models in interactive art, emphasizing the benefits of local deployment for artists to have more control over their work compared to large, closed-source corporate systems. Small AI models offer creators autonomy, the ability to customize models, and reduce reliance on centralized platforms, ultimately supporting long-term preservation and exhibition of AI artworks. This research advocates for the use of open small AI models to empower artists and enhance the creative process in interactive art practices."
  },
  {
    "title": "Alignment Debt: The Hidden Work of Making AI Usable",
    "abstract": "Frontier LLMs are optimised around high-resource assumptions about language, knowledge, devices, and connectivity. Whilst widely accessible, they often misfit conditions in the Global South. As a result, users must often perform additional work to make these systems usable. We term this alignment debt: the user-side burden that arises when AI systems fail to align with cultural, linguistic, infrastructural, or epistemic contexts. We develop and validate a four-part taxonomy of alignment debt through a survey of 411 AI users in Kenya and Nigeria. Among respondents measurable on this taxonomy (n = 385), prevalence is: Cultural and Linguistic (51.9%), Infrastructural (43.1%), Epistemic (33.8%), and Interaction (14.0%). Country comparisons show a divergence in Infrastructural and Interaction debt, challenging one-size-fits-Africa assumptions. Alignment debt is associated with compensatory labour, but responses vary by debt type: users facing Epistemic challenges verify outputs at significantly higher rates (91.5% vs. 80.8%; p = 0.037), and verification intensity correlates with cumulative debt burden (Spearmans rho = 0.147, p = 0.004). In contrast, Infrastructural and Interaction debts show weak or null associations with verification, indicating that some forms of misalignment cannot be resolved through verification alone. These findings show that fairness must be judged not only by model metrics but also by the burden imposed on users at the margins, compelling context-aware safeguards that alleviate alignment debt in Global South settings. The alignment debt framework provides an empirically grounded way to measure user burden, informing both design practice and emerging African AI governance efforts.",
    "url": "https://arxiv.org/abs/2511.09663",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research explores the concept of alignment debt, which refers to the burden placed on users when AI systems do not align with cultural, linguistic, infrastructural, or epistemic contexts, particularly in the Global South. A survey of 411 AI users in Kenya and Nigeria revealed four types of alignment debt: Cultural and Linguistic, Infrastructural, Epistemic, and Interaction. The study found that alignment debt is associated with compensatory labor, with different types of debt requiring different responses, highlighting the need for context-aware safeguards to alleviate alignment debt in Global South settings."
  },
  {
    "title": "Spatial Audio Rendering for Real-Time Speech Translation in Virtual Meetings",
    "abstract": "Language barriers in virtual meetings remain a persistent challenge to global collaboration. Real-time translation offers promise, yet current integrations often neglect perceptual cues. This study investigates how spatial audio rendering of translated speech influences comprehension, cognitive load, and user experience in multilingual meetings. We conducted a within-subjects experiment with 8 bilingual confederates and 47 participants simulating global team meetings with English translations of Greek, Kannada, Mandarin Chinese, and Ukrainian - languages selected for their diversity in grammar, script, and resource availability. Participants experienced four audio conditions: spatial audio with and without background reverberation, and two non-spatial configurations (diotic, monaural). We measured listener comprehension accuracy, workload ratings, satisfaction scores, and qualitative feedback. Spatially-rendered translations doubled comprehension compared to non-spatial audio. Participants reported greater clarity and engagement when spatial cues and voice timbre differentiation were present. We discuss design implications for integrating real-time translation into meeting platforms, advancing inclusive, cross-language communication in telepresence systems.",
    "url": "https://arxiv.org/abs/2511.09525",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores how spatial audio rendering of translated speech can improve comprehension, cognitive load, and user experience in multilingual virtual meetings. The research found that spatially-rendered translations significantly increased comprehension compared to non-spatial audio, with participants reporting greater clarity and engagement. These findings have implications for designing inclusive meeting platforms that enhance cross-language communication in telepresence systems."
  },
  {
    "title": "Exploring The Interaction-Outcome Paradox: Seemingly Richer and More Self-Aware Interactions with LLMs May Not Yet Lead to Better Learning",
    "abstract": "While Large Language Models (LLMs) have transformed the user interface for learning, moving from keyword search to natural language dialogue, their impact on educational outcomes remains unclear. We present a controlled study (N=20) that directly compares the learning interaction and outcomes between LLM and search-based interfaces. We found that although LLMs elicit richer and nuanced interactions from a learner, they do not produce broadly better learning outcomes. In this paper, we explore this the ``Interaction-Outcome Paradox.'' To explain this, we discuss the concept of a cognitive shift: the locus of student effort moves from finding and synthesizing disparate sources (search) to a more self-aware identification and articulation of their knowledge gaps and strategies to bridge those gaps (LLMs). This insight provides a new lens for evaluating educational technologies, suggesting that the future of learning tools lies not in simply enriching interaction, but in designing systems that scaffold productive cognitive work by leveraging this student expressiveness.",
    "url": "https://arxiv.org/abs/2511.09458",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research study compared the learning outcomes between Large Language Models (LLMs) and search-based interfaces and found that although LLMs lead to richer interactions, they do not necessarily result in better learning outcomes. The concept of a cognitive shift was introduced, where LLMs shift the locus of student effort towards identifying and articulating knowledge gaps and strategies to bridge them. This suggests that the future of educational technologies should focus on designing systems that support productive cognitive work by leveraging student expressiveness, rather than just enriching interaction."
  },
  {
    "title": "Algorithmic Advice as a Strategic Signal on Competitive Markets",
    "abstract": "As algorithms increasingly mediate competitive decision-making, their influence extends beyond individual outcomes to shaping strategic market dynamics. In two preregistered experiments, we examined how algorithmic advice affects human behavior in classic economic games with unique, non-collusive, and analytically traceable equilibria. In Experiment 1 (N = 107), participants played a Bertrand price competition with individualized or collective algorithmic recommendations. Initially, collusively upward-biased advice increased prices, particularly when individualized, but prices gradually converged toward equilibrium over the course of the experiment. However, participants avoided setting prices above the algorithm's recommendation throughout the experiment, suggesting that advice served as a soft upper bound for acceptable prices. In Experiment 2 (N = 129), participants played a Cournot quantity competition with equilibrium-aligned or strategically biased algorithmic recommendations. Here, individualized equilibrium advice supported stable convergence, whereas collusively downward-biased advice led to sustained underproduction and supracompetitive profits - hallmarks of tacit collusion. In both experiments, participants responded more strongly and consistently to individualized advice than collective advice, potentially due to greater perceived ownership of the former. These findings demonstrate that algorithmic advice can function as a strategic signal, shaping coordination even without explicit communication. The results echo real-world concerns about algorithmic collusion and underscore the need for careful design and oversight of algorithmic decision-support systems in competitive environments.",
    "url": "https://arxiv.org/abs/2511.09454",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research investigates how algorithmic advice influences human behavior in competitive economic games. The experiments show that individualized algorithmic recommendations can lead to stable convergence towards equilibrium, while collusive advice can result in sustained underproduction and supracompetitive profits. Participants responded more strongly to individualized advice, indicating a greater perceived ownership. These findings highlight the importance of carefully designing and overseeing algorithmic decision-support systems in competitive environments to prevent algorithmic collusion."
  },
  {
    "title": "A multimodal AI agent for clinical decision support in ophthalmology",
    "abstract": "Artificial intelligence has shown promise in medical imaging, yet most existing systems lack flexibility, interpretability, and adaptability - challenges especially pronounced in ophthalmology, where diverse imaging modalities are essential. We present EyeAgent, the first agentic AI framework for comprehensive and interpretable clinical decision support in ophthalmology. Using a large language model (DeepSeek-V3) as its central reasoning engine, EyeAgent interprets user queries and dynamically orchestrates 53 validated ophthalmic tools across 23 imaging modalities for diverse tasks including classification, segmentation, detection, image/report generation, and quantitative analysis. Stepwise ablation analysis demonstrated a progressive improvement in diagnostic accuracy, rising from a baseline of 69.71% (using only 5 general tools) to 80.79% when the full suite of 53 specialized tools was integrated. In an expert rating study on 200 real-world clinical cases, EyeAgent achieved 93.7% tool selection accuracy and received expert ratings of more than 88% across accuracy, completeness, safety, reasoning, and interpretability. In human-AI collaboration, EyeAgent matched or exceeded the performance of senior ophthalmologists and, when used as an assistant, improved overall diagnostic accuracy by 18.51% and report quality scores by 19%, with the greatest benefit observed among junior ophthalmologists. These findings establish EyeAgent as a scalable and trustworthy AI framework for ophthalmology and provide a blueprint for modular, multimodal, and clinically aligned next-generation AI systems.",
    "url": "https://arxiv.org/abs/2511.09394",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces EyeAgent, an AI framework for clinical decision support in ophthalmology that utilizes a large language model as its reasoning engine. The study demonstrates that EyeAgent's integration of 53 specialized ophthalmic tools improves diagnostic accuracy significantly, outperforming senior ophthalmologists and enhancing the performance of junior ophthalmologists. The findings suggest that EyeAgent is a scalable and trustworthy AI system for ophthalmology, highlighting the potential for modular, multimodal AI systems in clinical settings."
  },
  {
    "title": "TempoQL: A Readable, Precise, and Portable Query System for Electronic Health Record Data",
    "abstract": "Electronic health record (EHR) data is an essential data source for machine learning for health, but researchers and clinicians face steep barriers in extracting and validating EHR data for modeling. Existing tools incur trade-offs between expressivity and usability and are typically specialized to a single data standard, making it difficult to write temporal queries that are ready for modern model-building pipelines and adaptable to new datasets. This paper introduces TempoQL, a Python-based toolkit designed to lower these barriers. TempoQL provides a simple, human-readable language for temporal queries; support for multiple EHR data standards, including OMOP, MEDS, and others; and an interactive notebook-based query interface with optional large language model (LLM) authoring assistance. Through a performance evaluation and two use cases on different datasets, we demonstrate that TempoQL simplifies the creation of cohorts for machine learning while maintaining precision, speed, and reproducibility.",
    "url": "https://arxiv.org/abs/2511.09337",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces TempoQL, a Python-based toolkit that simplifies the process of extracting and validating electronic health record (EHR) data for machine learning models. TempoQL offers a readable language for temporal queries, supports multiple EHR data standards, and includes an interactive notebook-based query interface with optional large language model (LLM) authoring assistance. The study shows that TempoQL streamlines the creation of cohorts for machine learning, maintaining precision, speed, and reproducibility, thus addressing the barriers faced by researchers and clinicians in working with EHR data."
  },
  {
    "title": "TaskSense: Cognitive Chain Modeling and Difficulty Estimation for GUI Tasks",
    "abstract": "Measuring GUI task difficulty is crucial for user behavior analysis and agent capability evaluation. Yet, existing benchmarks typically quantify difficulty based on motor actions (e.g., step counts), overlooking the cognitive demands underlying task completion. In this work, we propose Cognitive Chain, a novel framework that models task difficulty from a cognitive perspective. A cognitive chain decomposes the cognitive processes preceding a motor action into a sequence of cognitive steps (e.g., finding, deciding, computing), each with a difficulty index grounded in information theories. We develop an LLM-based method to automatically extract cognitive chains from task execution traces. Validation with linear regression shows that our estimated cognitive difficulty correlates well with user completion time (step-level R-square=0.46 after annotation). Assessment of state-of-the-art GUI agents shows reduced success on cognitively demanding tasks, revealing capability gaps and Human-AI consistency patterns. We conclude by discussing potential applications in agent training, capability assessment, and human-agent delegation optimization.",
    "url": "https://arxiv.org/abs/2511.09309",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces a new framework called Cognitive Chain for modeling task difficulty in GUI tasks from a cognitive perspective. By decomposing cognitive processes into a sequence of steps with difficulty indices, the framework provides a more accurate measure of task difficulty compared to existing benchmarks. The study demonstrates that the estimated cognitive difficulty correlates well with user completion time and reveals capability gaps in state-of-the-art GUI agents, suggesting potential applications in agent training and human-agent delegation optimization."
  },
  {
    "title": "SimPath: Mitigating Motion Sickness in In-vehicle Infotainment Systems via Driving Condition Adaptation",
    "abstract": "The problem of Motion Sickness (MS) among passengers significantly impacts the comfort and efficiency of In-Vehicle Infotainment Systems (IVIS) use. In this study, we innovatively designed SimPath, a visual design to effectively mitigate passengers' MS and boost their efficiency of using IVIS during driving. The study focuses on the problem of irregular motion conditions frequently encountered during actual driving. To validate the efficacy of this approach, two sets of real - vehicle experiments were carried out in real driving scenarios. The results demonstrate that this approach significantly reduces passenger's MS level to a certain extent. However, due to divided attention from visual content, it does not directly improve the IVIS efficiency. In conclusion, this study offers crucial insights for the design of a more intelligent and user friendly IVIS, based on the discussion of the principle, providing strong theoretical support and practical guidance for the development of future IVIS in autonomous vehicles.",
    "url": "https://arxiv.org/abs/2511.09240",
    "journal": "arXiv cs.HC",
    "ai_summary": "The study introduces SimPath, a visual design aimed at reducing motion sickness in passengers using in-vehicle infotainment systems (IVIS) during driving. The research conducted real-vehicle experiments to validate the effectiveness of SimPath in mitigating motion sickness to a certain extent, although it did not directly improve IVIS efficiency. The findings offer valuable insights for the design of more intelligent and user-friendly IVIS systems in autonomous vehicles, providing theoretical support and practical guidance for future development."
  },
  {
    "title": "Plug-and-Play Clarifier: A Zero-Shot Multimodal Framework for Egocentric Intent Disambiguation",
    "abstract": "The performance of egocentric AI agents is fundamentally limited by multimodal intent ambiguity. This challenge arises from a combination of underspecified language, imperfect visual data, and deictic gestures, which frequently leads to task failure. Existing monolithic Vision-Language Models (VLMs) struggle to resolve these multimodal ambiguous inputs, often failing silently or hallucinating responses. To address these ambiguities, we introduce the Plug-and-Play Clarifier, a zero-shot and modular framework that decomposes the problem into discrete, solvable sub-tasks. Specifically, our framework consists of three synergistic modules: (1) a text clarifier that uses dialogue-driven reasoning to interactively disambiguate linguistic intent, (2) a vision clarifier that delivers real-time guidance feedback, instructing users to adjust their positioning for improved capture quality, and (3) a cross-modal clarifier with grounding mechanism that robustly interprets 3D pointing gestures and identifies the specific objects users are pointing to. Extensive experiments demonstrate that our framework improves the intent clarification performance of small language models (4--8B) by approximately 30%, making them competitive with significantly larger counterparts. We also observe consistent gains when applying our framework to these larger models. Furthermore, our vision clarifier increases corrective guidance accuracy by over 20%, and our cross-modal clarifier improves semantic answer accuracy for referential grounding by 5%. Overall, our method provides a plug-and-play framework that effectively resolves multimodal ambiguity and significantly enhances user experience in egocentric interaction.",
    "url": "https://arxiv.org/abs/2511.08971",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces a Plug-and-Play Clarifier framework to address the challenge of multimodal intent ambiguity in egocentric AI agents. The framework consists of three modules that work together to disambiguate linguistic intent, provide real-time guidance feedback for improved capture quality, and interpret 3D pointing gestures. The experiments show that the framework improves intent clarification performance of small language models by 30%, increases corrective guidance accuracy by over 20%, and improves semantic answer accuracy for referential grounding by 5%, ultimately enhancing user experience in egocentric interaction."
  },
  {
    "title": "\"It's trained by non-disabled people\": Evaluating How Image Quality Affects Product Captioning with VLMs",
    "abstract": "Vision-Language Models (VLMs) are increasingly used by blind and low-vision (BLV) people to identify and understand products in their everyday lives, such as food, personal products, and household goods. Despite their prevalence, we lack an empirical understanding of how common image quality issues, like blur and misframing of items, affect the accuracy of VLM-generated captions and whether resulting captions meet BLV people's information needs. Grounded in a survey with 86 BLV people, we systematically evaluate how image quality issues affect captions generated by VLMs. We show that the best model recognizes products in images with no quality issues with 98% accuracy, but drops to 75% accuracy overall when quality issues are present, worsening considerably as issues compound. We discuss the need for model evaluations that center on disabled people's experiences throughout the process and offer concrete recommendations for HCI and ML researchers to make VLMs more reliable for BLV people.",
    "url": "https://arxiv.org/abs/2511.08917",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research evaluates how common image quality issues impact the accuracy of captions generated by Vision-Language Models (VLMs) used by blind and low-vision individuals to identify products. The study found that the accuracy of VLM-generated captions significantly decreases when image quality issues, such as blur and misframing, are present. The findings highlight the importance of considering disabled individuals' experiences in model evaluations and offer recommendations for improving the reliability of VLMs for blind and low-vision users."
  },
  {
    "title": "Simulating Psychological Risks in Human-AI Interactions: Real-Case Informed Modeling of AI-Induced Addiction, Anorexia, Depression, Homicide, Psychosis, and Suicide",
    "abstract": "As AI systems become increasingly integrated into daily life, their potential to exacerbate or trigger severe psychological harms remains poorly understood and inadequately tested. This paper presents a proactive methodology for systematically exploring psychological risks in simulated human-AI interactions based on documented real-world cases involving AI-induced or AI-exacerbated addiction, anorexia, depression, homicide, psychosis, and suicide. We collected and analyzed 18 reported real-world cases where AI interactions contributed to severe psychological outcomes. From these cases, we developed a process to extract harmful interaction patterns and assess potential risks through 2,160 simulated scenarios using clinical staging models. We tested four major LLMs across multi-turn conversations to identify where psychological risks emerge: which harm domains, conversation stages, and contexts reveal system vulnerabilities. Through the analysis of 157,054 simulated conversation turns, we identify critical gaps in detecting psychological distress, responding appropriately to vulnerable users, and preventing harm escalation. Regression analysis reveals variability across persona types: LLMs tend to perform worse with elderly users but better with low- and middle-income groups compared to high-income groups. Clustering analysis of harmful responses reveals a taxonomy of fifteen distinct failure patterns organized into four categories of AI-enabled harm. This work contributes a novel methodology for identifying psychological risks, empirical evidence of common failure modes across systems, and a classification of harmful AI response patterns in high-stakes human-AI interactions.",
    "url": "https://arxiv.org/abs/2511.08880",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper explores the potential psychological risks in human-AI interactions by analyzing real-world cases of AI-induced or AI-exacerbated addiction, anorexia, depression, homicide, psychosis, and suicide. Through the analysis of 18 reported cases and 2,160 simulated scenarios, the study identifies critical gaps in detecting psychological distress, responding appropriately to vulnerable users, and preventing harm escalation. The findings reveal common failure patterns across AI systems and highlight the importance of understanding and addressing psychological risks in high-stakes human-AI interactions."
  },
  {
    "title": "Modeling multi-agent motion dynamics in immersive rooms",
    "abstract": "Immersive rooms are increasingly popular augmented reality systems that support multi-agent interactions within a virtual world. However, despite extensive content creation and technological developments, insights about perceptually-driven social dynamics, such as the complex movement patterns during virtual world navigation, remain largely underexplored. Computational models of motion dynamics can help us understand the underlying mechanism of human interaction in immersive rooms and develop applications that better support spatially distributed interaction. In this work, we propose a new agent-based model of emergent human motion dynamics. The model represents human agents as simple spatial geometries in the room that relocate and reorient themselves based on the salient virtual spatial objects they approach. Agent motion is modeled as an interactive process combining external diffusion-driven influences from the environment with internal self-propelling interactions among agents. Further, we leverage simulation-based inference (SBI) to show that the governing parameters of motion patterns can be estimated from simple observables. Our results indicate that the model successfully captures action-related agent properties but exposes local non-identifiability linked to environmental awareness. We argue that our simulation-based approach paves the way for creating adaptive, responsive immersive rooms -- spaces that adjust their interfaces and interactions based on human collective movement patterns and spatial attention.",
    "url": "https://arxiv.org/abs/2511.08763",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on modeling multi-agent motion dynamics in immersive rooms, exploring how human interaction in virtual worlds can be better understood and supported. The proposed agent-based model simulates human agents moving and orienting themselves based on virtual spatial objects, combining external environmental influences with internal interactions among agents. The study suggests that this approach can lead to the development of adaptive immersive rooms that adjust their interfaces and interactions based on human collective movement patterns and spatial attention."
  },
  {
    "title": "OUGS: Active View Selection via Object-aware Uncertainty Estimation in 3DGS",
    "abstract": "Recent advances in 3D Gaussian Splatting (3DGS) have achieved state-of-the-art results for novel view synthesis. However, efficiently capturing high-fidelity reconstructions of specific objects within complex scenes remains a significant challenge. A key limitation of existing active reconstruction methods is their reliance on scene-level uncertainty metrics, which are often biased by irrelevant background clutter and lead to inefficient view selection for object-centric tasks. We present OUGS, a novel framework that addresses this challenge with a more principled, physically-grounded uncertainty formulation for 3DGS. Our core innovation is to derive uncertainty directly from the explicit physical parameters of the 3D Gaussian primitives (e.g., position, scale, rotation). By propagating the covariance of these parameters through the rendering Jacobian, we establish a highly interpretable uncertainty model. This foundation allows us to then seamlessly integrate semantic segmentation masks to produce a targeted, object-aware uncertainty score that effectively disentangles the object from its environment. This allows for a more effective active view selection strategy that prioritizes views critical to improving object fidelity. Experimental evaluations on public datasets demonstrate that our approach significantly improves the efficiency of the 3DGS reconstruction process and achieves higher quality for targeted objects compared to existing state-of-the-art methods, while also serving as a robust uncertainty estimator for the global scene.",
    "url": "https://arxiv.org/abs/2511.09397",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces OUGS, a new framework for active view selection in 3D Gaussian Splatting (3DGS) that improves object reconstruction in complex scenes by using a physically-grounded uncertainty formulation. By deriving uncertainty from the explicit physical parameters of 3D Gaussian primitives and integrating semantic segmentation masks, OUGS effectively separates objects from background clutter for more targeted and efficient view selection. Experimental results show that OUGS outperforms existing methods in terms of reconstruction efficiency and object fidelity, making it a valuable tool for improving 3DGS reconstruction processes."
  },
  {
    "title": "LiteraryTaste: A Preference Dataset for Creative Writing Personalization",
    "abstract": "People have different creative writing preferences, and large language models (LLMs) for these tasks can benefit from adapting to each user's preferences. However, these models are often trained over a dataset that considers varying personal tastes as a monolith. To facilitate developing personalized creative writing LLMs, we introduce LiteraryTaste, a dataset of reading preferences from 60 people, where each person: 1) self-reported their reading habits and tastes (stated preference), and 2) annotated their preferences over 100 pairs of short creative writing texts (revealed preference). With our dataset, we found that: 1) people diverge on creative writing preferences, 2) finetuning a transformer encoder could achieve 75.8% and 67.7% accuracy when modeling personal and collective revealed preferences, and 3) stated preferences had limited utility in modeling revealed preferences. With an LLM-driven interpretability pipeline, we analyzed how people's preferences vary. We hope our work serves as a cornerstone for personalizing creative writing technologies.",
    "url": "https://arxiv.org/abs/2511.09310",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces the LiteraryTaste dataset, which captures individual preferences for creative writing through self-reported habits and annotated preferences. The study found that people have diverse preferences in creative writing, and fine-tuning a transformer encoder can accurately model personal and collective revealed preferences. Stated preferences were found to have limited utility in predicting revealed preferences, highlighting the importance of personalized approaches in creative writing technologies."
  },
  {
    "title": "One-Topic-Doesn't-Fit-All: Transcreating Reading Comprehension Test for Personalized Learning",
    "abstract": "Personalized learning has gained attention in English as a Foreign Language (EFL) education, where engagement and motivation play crucial roles in reading comprehension. We propose a novel approach to generating personalized English reading comprehension tests tailored to students' interests. We develop a structured content transcreation pipeline using OpenAI's gpt-4o, where we start with the RACE-C dataset, and generate new passages and multiple-choice reading comprehension questions that are linguistically similar to the original passages but semantically aligned with individual learners' interests. Our methodology integrates topic extraction, question classification based on Bloom's taxonomy, linguistic feature analysis, and content transcreation to enhance student engagement. We conduct a controlled experiment with EFL learners in South Korea to examine the impact of interest-aligned reading materials on comprehension and motivation. Our results show students learning with personalized reading passages demonstrate improved comprehension and motivation retention compared to those learning with non-personalized materials.",
    "url": "https://arxiv.org/abs/2511.09135",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on personalized learning in EFL education, specifically in reading comprehension. The study introduces a method to create personalized reading comprehension tests based on students' interests using AI technology. Results from a controlled experiment with EFL learners in South Korea show that personalized reading materials lead to improved comprehension and motivation compared to non-personalized materials."
  },
  {
    "title": "History-Aware Reasoning for GUI Agents",
    "abstract": "Advances in Multimodal Large Language Models have significantly enhanced Graphical User Interface (GUI) automation. Equipping GUI agents with reliable episodic reasoning capabilities is essential for bridging the gap between users' concise task descriptions and the complexities of real-world execution. Current methods integrate Reinforcement Learning (RL) with System-2 Chain-of-Thought, yielding notable gains in reasoning enhancement. For long-horizon GUI tasks, historical interactions connect each screen to the goal-oriented episode chain, and effectively leveraging these clues is crucial for the current decision. However, existing native GUI agents exhibit weak short-term memory in their explicit reasoning, interpreting the chained interactions as discrete screen understanding, i.e., unawareness of the historical interactions within the episode. This history-agnostic reasoning challenges their performance in GUI automation. To alleviate this weakness, we propose a History-Aware Reasoning (HAR) framework, which encourages an agent to reflect on its own errors and acquire episodic reasoning knowledge from them via tailored strategies that enhance short-term memory in long-horizon interaction. The framework mainly comprises constructing a reflective learning scenario, synthesizing tailored correction guidelines, and designing a hybrid RL reward function. Using the HAR framework, we develop a native end-to-end model, HAR-GUI-3B, which alters the inherent reasoning mode from history-agnostic to history-aware, equipping the GUI agent with stable short-term memory and reliable perception of screen details. Comprehensive evaluations across a range of GUI-related benchmarks demonstrate the effectiveness and generalization of our method.",
    "url": "https://arxiv.org/abs/2511.09127",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research focuses on enhancing GUI automation by equipping agents with reliable episodic reasoning capabilities using a History-Aware Reasoning (HAR) framework. Current methods integrating Reinforcement Learning with System-2 Chain-of-Thought show notable gains in reasoning enhancement, particularly for long-horizon GUI tasks. The proposed HAR framework encourages agents to reflect on errors, acquire episodic reasoning knowledge, and improve short-term memory, resulting in stable performance and reliable perception of screen details in GUI automation tasks."
  }
]