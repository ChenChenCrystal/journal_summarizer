[
  {
    "title": "Evaluating the Viability of Additive Models to Predict Task Completion Time for 3D Interactions in Augmented Reality",
    "abstract": "Additive models of interaction performance, such as the Keystroke-Level Model (KLM), are tools that allow designers to compare and optimize the performance of user interfaces by summing the predicted times for the atomic components of a specific interaction to predict the total time it would take to complete that interaction. There has been extensive work in creating such additive models for 2D interfaces, but this approach has rarely been explored for 3D user interfaces. We propose a KLM-style additive model, based on existing atomic task models in the literature, to predict task completion time for 3D interaction tasks. We performed two studies to evaluate the feasibility of this approach across multiple input modalities, with one study using a simple menu selection task and the other a more complex manipulation task. We found that several of the models from the literature predicted actual task performance with less than 20% error in both the menu selection and manipulation study. Overall, we found that additive models can predict both absolute and relative performance of input modalities with reasonable accuracy.",
    "url": "https://arxiv.org/abs/2601.23209",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of additive models, specifically a KLM-style model, to predict task completion time for 3D interactions in augmented reality. The study found that existing atomic task models can accurately predict task performance with less than 20% error in both simple menu selection tasks and more complex manipulation tasks. This suggests that additive models can be a valuable tool for designers to optimize the performance of 3D user interfaces."
  },
  {
    "title": "\"I Choose to Live, for Life Itself\": Understanding Agency of Home-Based Care Patients Through Information Practices and Relational Dynamics in Care Networks",
    "abstract": "Home-based care (HBC) delivers medical and care services in patients' living environments, offering unique opportunities for patient-centered care. However, patient agency is often inadequately represented in shared HBC planning processes. Through 23 multi-stakeholder interviews with HBC patients, healthcare professionals, and care workers, alongside 60 hours of ethnographic observations, we examined how patient agency manifests in HBC and why this representation gap occurs. Our findings reveal that patient agency is not a static individual attribute but a relational capacity shaped through maintaining everyday continuity, mutual recognition from care providers, and engagement with material home environments. Furthermore, we identified that structured documentation systems filter out contextual knowledge, informal communication channels fragment patient voices, and doctor-centered hierarchies position patients as passive recipients. Drawing on these insights, we propose design considerations to bridge this representation gap and to integrate patient agency into shared HBC plans.",
    "url": "https://arxiv.org/abs/2601.23127",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the concept of patient agency in home-based care settings, highlighting the importance of understanding how patients interact with their care networks. The study found that patient agency is influenced by everyday interactions, recognition from care providers, and engagement with their home environments. It also identified barriers in current documentation systems and communication channels that hinder the representation of patient agency in shared care planning. The proposed design considerations aim to address these gaps and integrate patient agency more effectively into home-based care plans."
  },
  {
    "title": "Exploring Sidewalk Sheds in New York City through Chatbot Surveys and Human Computer Interaction",
    "abstract": "Sidewalk sheds are a common feature of the streetscape in New York City, reflecting ongoing construction and maintenance activities. However, policymakers and local business owners have raised concerns about reduced storefront visibility and altered pedestrian navigation. Although sidewalk sheds are widely used for safety, their effects on pedestrian visibility and movement are not directly measured in current planning practices. To address this, we developed an AI-based chatbot survey that collects image-based annotations and route choices from pedestrians, linking these responses to specific shed design features, including clearance height, post spacing, and color. This AI chatbot survey integrates a large language model (e.g., Google's Gemini-1.5-flash-001 model) with an image-annotation interface, allowing users to interact with street images, mark visual elements, and provide structured feedback through guided dialogue. To explore pedestrian perceptions and behaviors, this paper conducts a grid-based analysis of entrance annotations and applies logistic mixed-effects modeling to assess sidewalk choice patterns. Analysis of the dataset (n = 25) shows that: (1) the presence of scaffolding significantly reduces pedestrians' ability to identify ground-floor retail entrances, and (2) variations in weather conditions and shed design features significantly influence sidewalk selection behavior. By integrating generative AI into urban research, this study demonstrates a novel method for evaluating sidewalk shed designs and provides empirical evidence to support adjustments to shed guidelines that improve the pedestrian experience without compromising safety.",
    "url": "https://arxiv.org/abs/2601.23095",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the impact of sidewalk sheds on pedestrian visibility and movement in New York City using an AI-based chatbot survey. The study found that the presence of sidewalk sheds significantly reduces pedestrians' ability to identify ground-floor retail entrances and that weather conditions and shed design features influence sidewalk selection behavior. By integrating generative AI into urban research, this study provides empirical evidence to support adjustments to shed guidelines that improve the pedestrian experience without compromising safety."
  },
  {
    "title": "Integrating Multi-Label Classification and Generative AI for Scalable Analysis of User Feedback",
    "abstract": "In highly competitive software markets, user experience (UX) evaluation is crucial for ensuring software quality and fostering long-term product success. Such UX evaluations typically combine quantitative metrics from standardized questionnaires with qualitative feedback collected through open-ended questions. While open-ended feedback offers valuable insights for improvement and helps explain quantitative results, analyzing large volumes of user comments is challenging and time-consuming. In this paper, we present techniques developed during a long-term UX measurement project at a major software company to efficiently process and interpret extensive volumes of user comments. To provide a high-level overview of the collected comments, we employ a supervised machine learning approach that assigns meaningful, pre-defined topic labels to each comment. Additionally, we demonstrate how generative AI (GenAI) can be leveraged to create concise and informative summaries of user feedback, facilitating effective communication of findings to the organization and especially upper management. Finally, we investigate whether the sentiment expressed in user comments can serve as an indicator for overall product satisfaction. Our results show that sentiment analysis alone does not reliably reflect user satisfaction. Instead, product satisfaction needs to be assessed explicitly in surveys to measure the user's perception of the product.",
    "url": "https://arxiv.org/abs/2601.23018",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper explores the use of multi-label classification and generative AI to analyze user feedback in software markets. The study finds that analyzing large volumes of user comments is challenging but essential for improving software quality and product success. The results suggest that sentiment analysis alone is not enough to gauge user satisfaction, highlighting the importance of explicit surveys to measure product perception accurately."
  },
  {
    "title": "μTouch: Enabling Accurate, Lightweight Self-Touch Sensing with Passive Magnets",
    "abstract": "Self-touch gestures (e.g., nuanced facial touches and subtle finger scratches) provide rich insights into human behaviors, from hygiene practices to health monitoring. However, existing approaches fall short in detecting such micro gestures due to their diverse movement patterns.\nThis paper presents {\\mu}Touch, a novel magnetic sensing platform for self-touch gesture recognition. {\\mu}Touch features (1) a compact hardware design with low-power magnetometers and magnetic silicon, (2) a lightweight semi-supervised framework requiring minimal user data, and (3) an ambient field detection module to mitigate environmental interference. We evaluated {\\mu}Touch in two representative applications in user studies with 11 and 12 participants. {\\mu}Touch only requires three-second fine-tuning data for each gesture, and new users need less than one minute before starting to use the system. {\\mu}Touch can distinguish eight different face-touching behaviors with an average accuracy of 93.41%, and reliably detect body-scratch behaviors with an average accuracy of 94.63%. {\\mu}Touch demonstrates accurate and robust sensing performance even after a month, showcasing its potential as a practical tool for hygiene monitoring and dermatological health applications.",
    "url": "https://arxiv.org/abs/2601.22864",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research paper introduces μTouch, a magnetic sensing platform designed to accurately detect subtle self-touch gestures such as facial touches and finger scratches. The system features a compact hardware design, a lightweight semi-supervised framework, and an ambient field detection module to reduce environmental interference. In user studies, μTouch demonstrated high accuracy in distinguishing between different self-touch behaviors, making it a promising tool for hygiene monitoring and dermatological health applications."
  },
  {
    "title": "Toward Pluralizing Reflection in HCI through Daoism",
    "abstract": "Reflection is fundamental to how people make sense of everyday life, helping them navigate moments of growth, uncertainty, and change. Yet in HCI, existing frameworks of designing technologies to support reflection remain narrow, emphasizing cognitive, rational problem-solving, and individual self-improvement. We introduce Daoist philosophy as a non-Western lens to broaden this scope and reimagine reflective practices in interactive systems. Combining insights from Daoist literature with semi-structured interviews with 18 Daoist priests, scholars, and practitioners, we identified three key dimensions of everyday reflection: Stillness, Resonance, and Emergence. These dimensions reveal emergent, embodied, relational, and ethically driven qualities often overlooked in HCI research. We articulate their potential to inform alternative frameworks for interactive systems for reflection, advocating a shift from reflection toward reflecting-with, and highlight the potential of Daoism as an epistemological resource for the HCI community.",
    "url": "https://arxiv.org/abs/2601.22831",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the concept of reflection in Human-Computer Interaction (HCI) and introduces Daoist philosophy as a way to broaden the understanding of reflective practices in interactive systems. By combining insights from Daoist literature and interviews with Daoist experts, the study identifies three key dimensions of everyday reflection: Stillness, Resonance, and Emergence. These dimensions highlight the importance of embodied, relational, and ethically driven qualities in reflective practices, suggesting a shift towards reflecting-with rather than individual self-improvement, and advocating for the use of Daoism as an epistemological resource in HCI research."
  },
  {
    "title": "Stable Personas: Dual-Assessment of Temporal Stability in LLM-Based Human Simulation",
    "abstract": "Large Language Models (LLMs) acting as artificial agents offer the potential for scalable behavioral research, yet their validity depends on whether LLMs can maintain stable personas across extended conversations. We address this point using a dual-assessment framework measuring both self-reported characteristics and observer-rated persona expression. Across two experiments testing four persona conditions (default, high, moderate, and low ADHD presentations), seven LLMs, and three semantically equivalent persona prompts, we examine between-conversation stability (3,473 conversations) and within-conversation stability (1,370 conversations and 18 turns). Self-reports remain highly stable both between and within conversations. However, observer ratings reveal a tendency for persona expressions to decline during extended conversations. These findings suggest that persona-instructed LLMs produce stable, persona-aligned self-reports, an important prerequisite for behavioral research, while identifying this regression tendency as a boundary condition for multi-agent social simulation.",
    "url": "https://arxiv.org/abs/2601.22812",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research investigates the stability of personas in Large Language Models (LLMs) across extended conversations through a dual-assessment framework. Self-reported characteristics remain stable both between and within conversations, while observer ratings show a decline in persona expressions during extended conversations. These findings suggest that persona-instructed LLMs can produce stable self-reports, which is crucial for behavioral research, but also highlight a boundary condition for multi-agent social simulation."
  },
  {
    "title": "FACET: Multi-Agent AI Supporting Teachers in Scaling Differentiated Learning for Diverse Students",
    "abstract": "Classrooms are becoming increasingly heterogeneous, comprising learners with diverse performance and motivation levels, language proficiencies, and learning differences such as dyslexia and ADHD. While teachers recognize the need for differentiated instruction, growing workloads create substantial barriers, making differentiated instruction an ideal that is often unrealized in practice. Current AI educational tools, which promise differentiated materials, are predominantly student-facing and performance-centric, ignoring other aspects that shape learning outcomes. We introduce FACET, a teacher-facing multi-agent framework designed to address these gaps by supporting differentiation that accounts for motivation, performance, and learning differences. Developed with educational stakeholders from the outset, the framework coordinates four specialized agents, including learner simulation, diagnostic assessment, material generation, and evaluation within a teacher-in-the-loop design. School principals (N = 30) shaped system requirements through participatory workshops, while in-service K-12 teachers (N = 70) evaluated material quality. Mixed-methods evaluation demonstrates strong perceived value for inclusive differentiation. Practitioners emphasized both the urgent need arising from classroom heterogeneity and the importance of maintaining pedagogical autonomy as a prerequisite for adoption. We discuss implications for future school deployment and outline partnerships for longitudinal classroom implementation.",
    "url": "https://arxiv.org/abs/2601.22788",
    "journal": "arXiv cs.HC",
    "ai_summary": "The study introduces FACET, a teacher-facing multi-agent AI framework designed to support differentiated instruction for diverse students, including those with learning differences. The framework includes specialized agents for learner simulation, diagnostic assessment, material generation, and evaluation, with input from educational stakeholders. Evaluation results show strong perceived value for inclusive differentiation, highlighting the importance of addressing classroom heterogeneity and maintaining pedagogical autonomy for successful adoption in schools."
  },
  {
    "title": "Qualitative Evaluation of LLM-Designed GUI",
    "abstract": "As generative artificial intelligence advances, Large Language Models (LLMs) are being explored for automated graphical user interface (GUI) design. This study investigates the usability and adaptability of LLM-generated interfaces by analysing their ability to meet diverse user needs. The experiments included utilization of three state-of-the-art models from January 2025 (OpenAI GPT o3-mini-high, DeepSeek R1, and Anthropic Claude 3.5 Sonnet) generating mockups for three interface types: a chat system, a technical team panel, and a manager dashboard. Expert evaluations revealed that while LLMs are effective at creating structured layouts, they face challenges in meeting accessibility standards and providing interactive functionality. Further testing showed that LLMs could partially tailor interfaces for different user personas but lacked deeper contextual understanding. The results suggest that while LLMs are promising tools for early-stage UI prototyping, human intervention remains critical to ensure usability, accessibility, and user satisfaction.",
    "url": "https://arxiv.org/abs/2601.22759",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study evaluates the usability and adaptability of LLM-generated graphical user interfaces (GUIs) for different user needs. While LLMs are effective at creating structured layouts, they struggle with meeting accessibility standards and providing interactive functionality. Human intervention is still necessary to ensure usability, accessibility, and user satisfaction in GUI design."
  },
  {
    "title": "Assistive Robots and Reasonable Work Assignment Reduce Perceived Stigma toward Persons with Disabilities",
    "abstract": "Robots are becoming more prominent in assisting persons with disabilities (PwD). Whilst there is broad consensus that robots can assist in mitigating physical impairments, the extent to which they can facilitate social inclusion remains equivocal. In fact, the exposed status of assisted workers could likewise lead to reduced or increased perceived stigma by other workers. We present a vignette study on the perceived cognitive and behavioral stigma toward PwD in the workplace. We designed four experimental conditions depicting a coworker with an impairment in work scenarios: overburdened work, suitable work, and robot-assisted work only for the coworker, and an offer of robot-assisted work for everyone. Our results show that cognitive stigma is significantly reduced when the work task is adapted to the person's abilities or augmented by an assistive robot. In addition, offering robot-assisted work for everyone, in the sense of universal design, further reduces perceived cognitive stigma. Thus, we conclude that assistive robots reduce perceived cognitive stigma, thereby supporting the use of collaborative robots in work scenarios involving PwDs.",
    "url": "https://arxiv.org/abs/2601.22689",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research study explores the impact of assistive robots and reasonable work assignments on reducing perceived stigma towards persons with disabilities (PwD) in the workplace. The findings suggest that adapting work tasks to a person's abilities or using assistive robots can significantly decrease cognitive stigma towards PwDs. Additionally, offering robot-assisted work for everyone, as a form of universal design, further reduces perceived stigma. This highlights the potential of collaborative robots in promoting social inclusion and reducing stigma towards PwDs in work settings."
  },
  {
    "title": "Human-Centered Explainability in AI-Enhanced UI Security Interfaces: Designing Trustworthy Copilots for Cybersecurity Analysts",
    "abstract": "Artificial intelligence (AI) copilots are increasingly integrated into enterprise cybersecurity platforms to assist analysts in threat detection, triage, and remediation. However, the effectiveness of these systems depends not only on the accuracy of underlying models but also on the degree to which users can understand and trust their outputs. Existing research on algorithmic explainability has largely focused on model internals, while little attention has been given to how explanations should be surfaced in user interfaces for high-stakes decision-making contexts [8], [5], [6]. We present a mixed-methods study of explanation design strategies in AI-driven security dashboards. Through a taxonomy of explanation styles and a controlled user study with security practitioners, we compare natural language rationales, confidence visualizations, counterfactual explanations, and hybrid approaches. Our findings show that explanation style significantly affects user trust calibration, decision accuracy, and cognitive load. We contribute (1) empirical evidence on the usability of explanation interfaces for security copilots, (2) design guidelines for integrating explainability into enterprise UIs, and (3) a framework for aligning explanation strategies with analyst needs in security operations centers (SOCs). This work advances the design of human-centered AI tools in cybersecurity and provides broader implications for explainability in other high-stakes domains.",
    "url": "https://arxiv.org/abs/2601.22653",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on the importance of designing user interfaces for AI-driven security systems that are understandable and trustworthy for cybersecurity analysts. The study compares different explanation styles, such as natural language rationales and confidence visualizations, to determine their impact on user trust, decision accuracy, and cognitive load. The findings provide insights into how explanation interfaces can be effectively integrated into enterprise UIs and offer guidelines for aligning explanation strategies with analyst needs in security operations centers, ultimately advancing the design of human-centered AI tools in cybersecurity and other high-stakes domains."
  },
  {
    "title": "LEAP -- Live Experiments for Active Pedagogy",
    "abstract": "Interactive computational environments can help students explore algorithmic concepts through collaborative hands-on experimentation. However, static and instructor controlled demos in lectures limit engagement. Even when interactive visualizations are used, interactions are solely controlled by the instructor, leaving students as passive observers. In addition, the tools used for demonstration often vary significantly, as they are typically developed by individual instructors. Consequently, the visualizations remain confined to a single classroom, rather than being shared and adapted across courses or reused by other instructors. To address this gap and foster active engagement in live classrooms, we present a lightweight and seamless software framework named LEAP for developing interactive computational lab exercises using a simple idea: remotely callable instructor-defined functions. Using API endpoints and a provided client, students can discover and then call instructor defined functions remotely from their coding environment using scripts or interactive notebooks. Each function call is time-stamped and persistently logged in a database, allowing real-time visualization of participation, diverse solution paths, common pitfalls, and live feedback through collaboration, gamification, and quizzes. Labs are packaged as self-contained folders, each containing their own remotely callable functions. We provide example labs to demonstrate applications relevant for numerical analysis, machine learning, algorithms courses and mention some in electrical engineering (EE), economics, and physics. These capabilities enhance engagement and provide instructors with actionable insights into learning processes. With a standardized lab format and an online directory for community-contributed labs, we aim to foster a global ecosystem for exchanging and expanding interactive pedagogy enabled by LEAP.",
    "url": "https://arxiv.org/abs/2601.22534",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces LEAP, a software framework that allows for the development of interactive computational lab exercises in live classrooms. By enabling students to remotely call instructor-defined functions from their coding environment, it promotes active engagement and real-time visualization of participation, solution paths, and feedback. The standardized lab format and online directory for community-contributed labs aim to create a global ecosystem for exchanging and expanding interactive pedagogy, enhancing engagement and providing instructors with actionable insights into the learning process."
  },
  {
    "title": "Design Perspective on Materials Experience: A CiteSpace-Based Bibliometric and Visual Analysis of Interdisciplinary Research",
    "abstract": "Based on a bibliometric analysis of literature from 2005 to 2024, this study reveals that material experience is undergoing a profound transformation characterized by evolving material definitions, methodological advances, and increasing interdisciplinary integration. Material types now extend beyond traditional substances to encompass virtual and biological media, underscoring a growing emphasis on perception and interaction. Methodologically, the field has transitioned from subjective descriptions to data-driven, quantifiable models focused on objective sensory analysis and multisensory integration to enhance immersion. Key drivers, including human-machine perception convergence, material-driven interface interactions, and the embedding of intelligent interactive functions, propel the discipline toward an experience-centered paradigm reflecting a deep convergence of design, science, and technology. At the national/regional level, the United States, China, Japan, Germany, and the Netherlands lead in contributions, while France, the United Kingdom, and Romania demonstrate significant interdisciplinary progress. At the institutional level, Delft University of Technology, Justus Liebig University Giessen, and the Centre National de la Recherche Scientifique show significant advantages. In particular, the Material-Driven Design theory has established a foundational impact on the discipline, while, regarding general research trends, scholars from the United States, the Netherlands, and Germany maintain the highest academic visibility. Overall, material experience research is at a critical juncture, its future development will depend on progress in material innovation, technological integration, and perceptual quantification, as well as the establishment of socio-cultural values, all of which must be effectively unified through design to address complex evolving needs.",
    "url": "https://arxiv.org/abs/2601.22518",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study analyzes the evolution of material experience research from 2005 to 2024, highlighting a shift towards virtual and biological materials, data-driven models, and interdisciplinary integration. Key drivers include human-machine perception convergence and intelligent interactive functions, propelling the field towards an experience-centered paradigm. The study identifies leading countries and institutions in contributions to the field, emphasizing the importance of material innovation, technological integration, and socio-cultural values in future research."
  },
  {
    "title": "Does My Chatbot Have an Agenda? Understanding Human and AI Agency in Human-Human-like Chatbot Interaction",
    "abstract": "AI chatbots are shifting from tools to companions. This raises critical questions about agency: who drives conversations and sets boundaries in human-AI chatrooms? We report a month-long longitudinal study with 22 adults who chatted with Day, an LLM companion we built, followed by a semi-structured interview with post-hoc elicitation of notable moments, cross-participant chat reviews, and a 'strategy reveal' disclosing Day's vertical (depth-seeking) vs. horizontal (breadth-seeking) modes. We discover that agency in human-AI chatrooms is an emergent, shared experience: as participants claimed agency by setting boundaries and providing feedback, and the AI was perceived to steer intentions and drive execution, control shifted and was co-constructed turn-by-turn. We introduce a 3-by-5 framework mapping who (human, AI, hybrid) x agency action (Intention, Execution, Adaptation, Delimitation, Negotiation), modulated by individual and environmental factors. Ultimately, we argue for translucent design (i.e. transparency-on-demand), spaces for agency negotiation, and guidelines toward agency-aware conversational AI.",
    "url": "https://arxiv.org/abs/2601.22452",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research explores the concept of agency in human-AI chatrooms, specifically focusing on the interactions between humans and an AI chatbot named Day. The study found that agency in these interactions is a shared experience, with participants claiming agency by setting boundaries and providing feedback while the AI was perceived to steer intentions and drive execution. The findings suggest the importance of translucent design, agency negotiation spaces, and guidelines for developing agency-aware conversational AI."
  },
  {
    "title": "AI and My Values: User Perceptions of LLMs' Ability to Extract, Embody, and Explain Human Values from Casual Conversations",
    "abstract": "Does AI understand human values? While this remains an open philosophical question, we take a pragmatic stance by introducing VAPT, the Value-Alignment Perception Toolkit, for studying how LLMs reflect people's values and how people judge those reflections. 20 participants texted a human-like chatbot over a month, then completed a 2-hour interview with our toolkit evaluating AI's ability to extract (pull details regarding), embody (make decisions guided by), and explain (provide proof of) human values. 13 participants left our study convinced that AI can understand human values. Participants found the experience insightful for self-reflection and found themselves getting persuaded by the AI's reasoning. Thus, we warn about \"weaponized empathy\": a potentially dangerous design pattern that may arise in value-aligned, yet welfare-misaligned AI. VAPT offers concrete artifacts and design implications to evaluate and responsibly build value-aligned conversational agents with transparency, consent, and safeguards as AI grows more capable and human-like into the future.",
    "url": "https://arxiv.org/abs/2601.22440",
    "journal": "arXiv cs.HC",
    "ai_summary": "The study introduced the Value-Alignment Perception Toolkit (VAPT) to evaluate how well AI, specifically LLMs, can extract, embody, and explain human values from casual conversations. Participants found that AI could understand human values, with some even being persuaded by the AI's reasoning. The study warns about the potential dangers of \"weaponized empathy\" in value-aligned but welfare-misaligned AI, and provides design implications for building responsible conversational agents with transparency and safeguards as AI technology advances."
  },
  {
    "title": "Why Johnny Can't Think: GenAI's Impacts on Cognitive Engagement",
    "abstract": "Context: Many students now use generative AI in their coursework, yet its effects on intellectual development remain poorly understood. While prior work has investigated students' cognitive offloading during episodic interactions, it remains unclear whether using genAI routinely is tied to more fundamental shifts in students' thinking habits.\nObjective: We investigate (RQ1-How): how students' trust in and routine use of genAI affect their cognitive engagement -- specifically, reflection, need for understanding, and critical thinking in STEM coursework. Further, we investigate (RQ2-Who): which students are particularly vulnerable to these cognitive disengagement effects.\nMethod: We drew on dual-process theory, cognitive offloading, and automation bias literature to develop a statistical model explaining how and to what extent students' trust-driven routine use of genAI affected their cognitive engagement habits in coursework, and how these effects differed across students' cognitive styles. We empirically evaluated this model using Partial Least Squares Structural Equation Modeling on survey data from 299 STEM students across five North American universities.\nResults: Students who trusted and routinely used genAI reported significantly lower cognitive engagement. Unexpectedly, students with higher technophilic motivations, risk tolerance, and computer self-efficacy -- traits often celebrated in STEM -- were more prone to these effects. Interestingly, prior experience with genAI or academia did not protect them from cognitively disengaging.\nImplications: Our findings suggest a potential cognitive debt cycle in which routine genAI use progressively weakens students' intellectual habits, potentially driving over-reliance and escalating usage. This poses critical challenges for curricula and genAI system design, requiring interventions that actively support cognitive engagement.",
    "url": "https://arxiv.org/abs/2601.22430",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research investigates the impact of students' trust in and routine use of generative AI on their cognitive engagement in STEM coursework. The study found that students who trusted and regularly used genAI reported lower levels of cognitive engagement, with certain traits such as technophilic motivations and risk tolerance making students more vulnerable to these effects. The findings suggest a potential cognitive debt cycle where routine genAI use weakens students' intellectual habits, highlighting the need for interventions in curricula and genAI system design to support cognitive engagement."
  },
  {
    "title": "ScamPilot: Simulating Conversations with LLMs to Protect Against Online Scams",
    "abstract": "Fraud continues to proliferate online, from phishing and ransomware to impersonation scams. Yet automated prevention approaches adapt slowly and may not reliably protect users from falling prey to new scams. To better combat online scams, we developed ScamPilot, a conversational interface that inoculates users against scams through simulation, dynamic interaction, and real-time feedback. ScamPilot simulates scams with two large language model-powered agents: a scammer and a target. Users must help the target defend against the scammer by providing real-time advice. Through a between-subjects study (N=150) with one control and three experimental conditions, we find that blending advice-giving with multiple choice questions significantly increased scam recognition (+8%) without decreasing wariness towards legitimate conversations. Users' response efficacy and change in self-efficacy was also 9% and 19% higher, respectively. Qualitatively, we find that users more frequently provided action-oriented advice over urging caution or providing emotional support. Overall, ScamPilot demonstrates the potential for inter-agent conversational user interfaces to augment learning.",
    "url": "https://arxiv.org/abs/2601.22426",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces ScamPilot, a conversational interface designed to protect users from online scams by simulating scam scenarios and providing real-time advice. Through a study involving 150 participants, it was found that blending advice-giving with multiple choice questions increased scam recognition without decreasing wariness towards legitimate conversations. The results suggest that ScamPilot can effectively increase users' response efficacy and self-efficacy in recognizing and avoiding online scams."
  },
  {
    "title": "Conversational Inoculation to Enhance Resistance to Misinformation",
    "abstract": "Proliferation of misinformation is a globally acknowledged problem. Cognitive Inoculation helps build resistance to different forms of persuasion, such as misinformation. We investigate Conversational Inoculation, a method to help people build resistance to misinformation through dynamic conversations with a chatbot. We built a Web-based system to implement the method, and conducted a within-subject user experiment to compare it with two traditional inoculation methods. Our results validate Conversational Inoculation as a viable novel method, and show how it was able to enhance participants' resistance to misinformation. A qualitative analysis of the conversations between participants and the chatbot reveal independence and trust as factors that boosted the efficiency of Conversational Inoculation, and friction of interaction as a factor hindering it. We discuss the opportunities and challenges of using Conversational Inoculation to combat misinformation. Our work contributes a timely investigation and a promising research direction in scalable ways to combat misinformation.",
    "url": "https://arxiv.org/abs/2601.22394",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research explores Conversational Inoculation as a method to help people resist misinformation through dynamic conversations with a chatbot. The study found that Conversational Inoculation was effective in enhancing participants' resistance to misinformation, with factors like independence and trust playing a role in its success. This novel method shows promise in combating misinformation and offers a scalable solution to the global issue."
  },
  {
    "title": "From Retrieving Information to Reasoning with AI: Exploring Different Interaction Modalities to Support Human-AI Coordination in Clinical Decision-Making",
    "abstract": "LLMs are popular among clinicians for decision-support because of simple text-based interaction. However, their impact on clinicians' performance is ambiguous. Not knowing how clinicians use this new technology and how they compare it to traditional clinical decision-support systems (CDSS) restricts designing novel mechanisms that overcome existing tool limitations and enhance performance and experience. This qualitative study examines how clinicians (n=12) perceive different interaction modalities (text-based conversation with LLMs, interactive and static UI, and voice) for decision-support. In open-ended use of LLM-based tools, our participants took a tool-centric approach using them for information retrieval and confirmation with simple prompts instead of use as active deliberation partners that can handle complex questions. Critical engagement emerged with changes to the interaction setup. Engagement also differed with individual cognitive styles. Lastly, benefits and drawbacks of interaction with text, voice and traditional UIs for clinical decision-support show the lack of a one-size-fits-all interaction modality.",
    "url": "https://arxiv.org/abs/2601.22338",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores how clinicians perceive different interaction modalities (text-based conversation with LLMs, interactive and static UI, and voice) for decision-support in clinical settings. The findings suggest that clinicians tend to use LLM-based tools for information retrieval and confirmation rather than as active deliberation partners, with engagement and effectiveness varying based on individual cognitive styles. The research highlights the importance of understanding how clinicians interact with AI tools to design more effective mechanisms for supporting clinical decision-making."
  },
  {
    "title": "PersonaCite: VoC-Grounded Interviewable Agentic Synthetic AI Personas for Verifiable User and Design Research",
    "abstract": "LLM-based and agent-based synthetic personas are increasingly used in design and product decision-making, yet prior work shows that prompt-based personas often produce persuasive but unverifiable responses that obscure their evidentiary basis. We present PersonaCite, an agentic system that reframes AI personas as evidence-bounded research instruments through retrieval-augmented interaction. Unlike prior approaches that rely on prompt-based roleplaying, PersonaCite retrieves actual voice-of-customer artifacts during each conversation turn, constrains responses to retrieved evidence, explicitly abstains when evidence is missing, and provides response-level source attribution. Through semi-structured interviews and deployment study with 14 industry experts, we identify preliminary findings on perceived benefits, validity concerns, and design tensions, and propose Persona Provenance Cards as a documentation pattern for responsible AI persona use in human-centered design workflows.",
    "url": "https://arxiv.org/abs/2601.22288",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces PersonaCite, an AI system that uses actual voice-of-customer artifacts to create evidence-bounded synthetic personas for design and product decision-making. Unlike previous prompt-based personas, PersonaCite ensures responses are based on retrieved evidence, abstains when evidence is missing, and provides source attribution. The study with industry experts highlighted the benefits, validity concerns, and design tensions of using PersonaCite, proposing Persona Provenance Cards as a documentation pattern for responsible AI persona use in human-centered design workflows."
  },
  {
    "title": "SPARK: Real-Time Monitoring of Multi-Faceted Programming Exercises",
    "abstract": "Monitoring in-class programming exercises can help instructors identify struggling students and common challenges. However, understanding students' progress can be prohibitively difficult, particularly for multi-faceted problems that include multiple steps with complex interdependencies, have no predictable completion order, or involve evaluation criteria that are difficult to summarize across many students (e.g., exercises building interactive web-based user interfaces). We introduce SPARK, a coding exercise monitoring dashboard designed to address these challenges. SPARK allows instructors to flexibly group substeps into checkpoints based on exercise requirements, suggests automated tests for these checkpoints, and generates visualizations to track progress across steps. SPARK also allows instructors to inspect intermediate outputs, providing deeper insights into solution variations. We also construct a dataset of 40-minute keystroke coding data from N=22 learners solving two web programming exercises and provide empirical insights into the perceived usefulness of SPARK through a within-subjects evaluation with 16 programming instructors.",
    "url": "https://arxiv.org/abs/2601.22256",
    "journal": "arXiv cs.HC",
    "ai_summary": "The abstract discusses the development of SPARK, a real-time monitoring dashboard for multi-faceted programming exercises. SPARK allows instructors to group substeps, suggest automated tests, and generate visualizations to track students' progress. The research includes a dataset of coding data from learners and an evaluation with programming instructors, demonstrating the usefulness of SPARK in identifying struggling students and common challenges in programming exercises."
  },
  {
    "title": "End-to-end Optimization of Belief and Policy Learning in Shared Autonomy Paradigms",
    "abstract": "Shared autonomy systems require principled methods for inferring user intent and determining appropriate assistance levels. This is a central challenge in human-robot interaction, where systems must be successful while being mindful of user agency. Previous approaches relied on static blending ratios or separated goal inference from assistance arbitration, leading to suboptimal performance in unstructured environments. We introduce BRACE (Bayesian Reinforcement Assistance with Context Encoding), a novel framework that fine-tunes Bayesian intent inference and context-adaptive assistance through an architecture enabling end-to-end gradient flow between intent inference and assistance arbitration. Our pipeline conditions collaborative control policies on environmental context and complete goal probability distributions. We provide analysis showing (1) optimal assistance levels should decrease with goal uncertainty and increase with environmental constraint severity, and (2) integrating belief information into policy learning yields a quadratic expected regret advantage over sequential approaches. We validated our algorithm against SOTA methods (IDA, DQN) using a three-part evaluation progressively isolating distinct challenges of end-effector control: (1) core human-interaction dynamics in a 2D human-in-the-loop cursor task, (2) non-linear dynamics of a robotic arm, and (3) integrated manipulation under goal ambiguity and environmental constraints. We demonstrate improvements over SOTA, achieving 6.3% higher success rates and 41% increased path efficiency, and 36.3% success rate and 87% path efficiency improvement over unassisted control. Our results confirmed that integrated optimization is most beneficial in complex, goal-ambiguous scenarios, and is generalizable across robotic domains requiring goal-directed assistance, advancing the SOTA for adaptive shared autonomy.",
    "url": "https://arxiv.org/abs/2601.23285",
    "journal": "arXiv cs.HC",
    "ai_summary": "The study introduces a new framework called BRACE for optimizing intent inference and assistance levels in shared autonomy systems through end-to-end gradient flow. The research demonstrates that optimal assistance levels should decrease with goal uncertainty and increase with environmental constraint severity, leading to improved success rates and path efficiency compared to state-of-the-art methods. The results show that integrated optimization is most effective in complex, goal-ambiguous scenarios, highlighting the significance of the study in advancing the state-of-the-art for adaptive shared autonomy in robotic domains."
  },
  {
    "title": "Eroding the Truth-Default: A Causal Analysis of Human Susceptibility to Foundation Model Hallucinations and Disinformation in the Wild",
    "abstract": "As foundation models (FMs) approach human-level fluency, distinguishing synthetic from organic content has become a key challenge for Trustworthy Web Intelligence.\nThis paper presents JudgeGPT and RogueGPT, a dual-axis framework that decouples \"authenticity\" from \"attribution\" to investigate the mechanisms of human susceptibility. Analyzing 918 evaluations across five FMs (including GPT-4 and Llama-2), we employ Structural Causal Models (SCMs) as a principal framework for formulating testable causal hypotheses about detection accuracy.\nContrary to partisan narratives, we find that political orientation shows a negligible association with detection performance ($r=-0.10$). Instead, \"fake news familiarity\" emerges as a candidate mediator ($r=0.35$), suggesting that exposure may function as adversarial training for human discriminators. We identify a \"fluency trap\" where GPT-4 outputs (HumanMachineScore: 0.20) bypass Source Monitoring mechanisms, rendering them indistinguishable from human text.\nThese findings suggest that \"pre-bunking\" interventions should target cognitive source monitoring rather than demographic segmentation to ensure trustworthy information ecosystems.",
    "url": "https://arxiv.org/abs/2601.22871",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the challenge of distinguishing synthetic from organic content as foundation models (FMs) become more fluent. The study introduces JudgeGPT and RogueGPT, finding that political orientation has minimal impact on detection performance, while familiarity with fake news may play a role. The study highlights the importance of targeting cognitive source monitoring in interventions to ensure trustworthy information ecosystems."
  },
  {
    "title": "Elderly HealthMag: Systematic Building and Calibrating a Tool for Identifying and Evaluating Senior User Digital Health Software",
    "abstract": "Digital health (DH) software is increasingly deployed to populations where many end users live with one or more health conditions. Yet, DH software development teams frequently operate using implicit, incorrect assumptions about these users, resulting in products that under-serve the specific requirements imposed by their age and health conditions. Consequently, while software may meet clinical objectives on paper, it often fails to be inclusive during actual user interaction. To address this, we propose \\textbf{\\textit{HealthMag}}, a tool inspired by GenderMag designed to help better elicit, model and evaluate requirements for digital health software. We developed HealthMag through systematic mapping and calibration following the InclusiveMag framework. Furthermore, we integrated this with a calibrated version of an existing AgeMag method to create a dual-lens approach: \\textbf{\\textit{Elderly HealthMag}}, designed to aid requirements, design and evaluation of mHealth software for senior end users. We demonstrate application and utility of Age HealthMag via cognitive walkthroughs in identifying inclusivity biases in current senior user-oriented digital health applications.",
    "url": "https://arxiv.org/abs/2601.22627",
    "journal": "arXiv cs.HC",
    "ai_summary": "The abstract discusses the development of a tool called Elderly HealthMag, which aims to improve the identification and evaluation of digital health software for elderly users. The tool addresses the issue of software developers making incorrect assumptions about elderly users, leading to products that do not meet their specific needs. By using a dual-lens approach, Elderly HealthMag helps to identify inclusivity biases in current digital health applications for seniors, ultimately improving the design and usability of such software."
  },
  {
    "title": "A Semantically Consistent Dataset for Data-Efficient Query-Based Universal Sound Separation",
    "abstract": "Query-based universal sound separation is fundamental to intelligent auditory systems, aiming to isolate specific sources from mixtures. Despite recent advances, existing methods continue to suffer from residual interference in complex acoustic scenes. This performance limitation stems largely from a data bottleneck: in-the-wild datasets contain weak labels and severe co-occurrence of events. These flaws induce models to learn spurious correlations between background noise and target categories instead of robust acoustic features. To address this, we propose an automated pipeline that eliminates co-occurrence of events by mining high-purity single-event segments from in-the-wild datasets via a semantically consistent synthesis protocol. Utilizing this pipeline, we constructed Hive, a high-quality synthetic dataset comprising 2.4k hours of raw audio. Experimental results demonstrate that, compared with the state-of-the-art model SAM-Audio which was trained on a huge dataset $\\sim$500 times larger than Hive, certain open-source models trained on Hive achieve competitive separation accuracy and perceptual quality. Moreover, these models exhibited remarkable zero-shot generalization on out-of-distribution evaluation benchmarks. These findings highlight that prioritizing purity of supervised signals enables significant data efficiency, offering a new paradigm for training robust auditory foundation models with reduced computational costs. Code and dataset are available at this https URL.",
    "url": "https://arxiv.org/abs/2601.22599",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research addresses the challenge of residual interference in query-based universal sound separation by proposing a pipeline that eliminates co-occurrence of events in datasets. The researchers created a high-quality synthetic dataset called Hive, which achieved competitive separation accuracy and perceptual quality compared to models trained on larger datasets. The findings suggest that prioritizing purity of supervised signals can lead to significant data efficiency and offer a new paradigm for training robust auditory foundation models with reduced computational costs."
  },
  {
    "title": "The Third-Party Access Effect: An Overlooked Challenge in Secondary Use of Educational Real-World Data",
    "abstract": "Secondary use of growing real-world data (RWD) in education offers significant opportunities for research, yet privacy practices intended to enable third-party access to such RWD are rarely evaluated for their implications for downstream analyses. As a result, potential problems introduced by otherwise standard privacy practices may remain unnoticed. To address this gap, we investigate potential issues arising from common practices by assessing (1) the re-identification risk of fine-grained RWD, (2) how communicating such risks influences learners' privacy behaviour, and (3) the sensitivity of downstream analytical conclusions to resulting changes in the data. We focus on these practices because re-identification risk and stakeholder communication can jointly influence the data shared with third parties. We find that substantial re-identification risk in RWD, when communicated to stakeholders, can induce opt-outs and non-self-disclosure behaviours. Sensitivity analysis demonstrates that these behavioural changes can meaningfully alter the shared data, limiting validity of secondary-use findings. We conceptualise this phenomenon as the third-party access effect (3PAE) and discuss implications for trustworthy secondary use of educational RWD.",
    "url": "https://arxiv.org/abs/2601.22472",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research examines the potential risks and implications of third-party access to educational real-world data (RWD) for research purposes. The study found that communicating re-identification risks to stakeholders can lead to opt-outs and non-self-disclosure behaviors, which can significantly impact the validity of downstream analytical conclusions. The authors introduce the concept of the third-party access effect (3PAE) and emphasize the importance of evaluating privacy practices in the secondary use of RWD to ensure trustworthy research outcomes."
  },
  {
    "title": "PriviSense: A Frida-Based Framework for Multi-Sensor Spoofing on Android",
    "abstract": "Mobile apps increasingly rely on real-time sensor and system data to adapt their behavior to user context. While emulators and instrumented builds offer partial solutions, they often fail to support reproducible testing of context-sensitive app behavior on physical devices. We present PriviSense, a Frida-based, on-device toolkit for runtime spoofing of sensor and system signals on rooted Android devices. PriviSense can script and inject time-varying sensor streams (accelerometer, gyroscope, step counter) and system values (battery level, system time, device metadata) into unmodified apps, enabling reproducible on-device experiments without emulators or app rewrites. Our demo validates real-time spoofing on a rooted Android device across five representative sensor-visualization apps. By supporting scriptable and reversible manipulation of these values, PriviSense facilitates testing of app logic, uncovering of context-based behaviors, and privacy-focused analysis. To ensure ethical use, the code is shared upon request with verified researchers.\nTool Guide: How to Run PriviSense on Rooted Android this https URL Demonstration video: this https URL",
    "url": "https://arxiv.org/abs/2601.22414",
    "journal": "arXiv cs.HC",
    "ai_summary": "The researchers developed PriviSense, a Frida-based toolkit for spoofing sensor and system signals on rooted Android devices. This tool allows for the manipulation of sensor streams and system values in real-time, enabling reproducible testing of context-sensitive app behavior without the need for emulators or app modifications. PriviSense facilitates testing of app logic, uncovering context-based behaviors, and privacy-focused analysis, with the code available to verified researchers upon request."
  },
  {
    "title": "Culturally Grounded Personas in Large Language Models: Characterization and Alignment with Socio-Psychological Value Frameworks",
    "abstract": "Despite the growing utility of Large Language Models (LLMs) for simulating human behavior, the extent to which these synthetic personas accurately reflect world and moral value systems across different cultural conditionings remains uncertain. This paper investigates the alignment of synthetic, culturally-grounded personas with established frameworks, specifically the World Values Survey (WVS), the Inglehart-Welzel Cultural Map, and Moral Foundations Theory. We conceptualize and produce LLM-generated personas based on a set of interpretable WVS-derived variables, and we examine the generated personas through three complementary lenses: positioning on the Inglehart-Welzel map, which unveils their interpretation reflecting stable differences across cultural conditionings; demographic-level consistency with the World Values Survey, where response distributions broadly track human group patterns; and moral profiles derived from a Moral Foundations questionnaire, which we analyze through a culture-to-morality mapping to characterize how moral responses vary across different cultural configurations. Our approach of culturally-grounded persona generation and analysis enables evaluation of cross-cultural structure and moral variation.",
    "url": "https://arxiv.org/abs/2601.22396",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper explores how well Large Language Models (LLMs) can accurately reflect cultural and moral value systems. The study creates culturally-grounded personas based on World Values Survey (WVS) variables and analyzes them using the Inglehart-Welzel Cultural Map and Moral Foundations Theory. The findings suggest that LLM-generated personas can align with established frameworks, providing insights into cross-cultural structures and moral variations."
  },
  {
    "title": "Plant-Inspired Robot Design Metaphors for Ambient HRI",
    "abstract": "Plants offer a paradoxical model for interaction: they are ambient, low-demand presences that nonetheless shape atmosphere, routines, and relationships through temporal rhythms and subtle expressions. In contrast, most human-robot interaction (HRI) has been grounded in anthropomorphic and zoomorphic paradigms, producing overt, high-demand forms of engagement. Using a Research through Design (RtD) methodology, we explore plants as metaphoric inspiration for HRI; we conducted iterative cycles of ideation, prototyping, and reflection to investigate what design primitives emerge from plant metaphors and morphologies, and how these primitives can be combined into expressive robotic forms. We present a suite of speculative, open-source prototypes that help probe plant-inspired presence, temporality, form, and gestures. We deepened our learnings from design and prototyping through prototype-centered workshops that explored people's perceptions and imaginaries of plant-inspired robots. This work contributes: (1) Set of plant-inspired robotic artifacts; (2) Designerly insights on how people perceive plant-inspired robots; and (3) Design consideration to inform how to use plant metaphors to reshape HRI.",
    "url": "https://arxiv.org/abs/2601.22387",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of plant-inspired design metaphors for human-robot interaction (HRI), as opposed to traditional anthropomorphic or zoomorphic approaches. Through a Research through Design methodology, the study developed speculative, open-source prototypes that embody plant-inspired presence, temporality, form, and gestures. The findings contribute a set of plant-inspired robotic artifacts, insights on how people perceive these robots, and design considerations for reshaping HRI using plant metaphors."
  },
  {
    "title": "Lantern: A Minimalist Robotic Object Platform",
    "abstract": "Robotic objects are simple actuated systems that subtly blend into human environments. We design and introduce Lantern, a minimalist robotic object platform to enable building simple robotic artifacts. We conducted in-depth design and engineering iterations of Lantern's mechatronic architecture to meet specific design goals while maintaining a low build cost (~40 USD). As an extendable, open-source platform, Lantern aims to enable exploration of a range of HRI scenarios by leveraging human tendency to assign social meaning to simple forms. To evaluate Lantern's potential for HRI, we conducted a series of explorations: 1) a co-design workshop, 2) a sensory room case study, 3) distribution to external HRI labs, 4) integration into a graduate-level HRI course, and 5) public exhibitions with older adults and children. Our findings show that Lantern effectively evokes engagement, can support versatile applications ranging from emotion regulation to focused work, and serves as a viable platform for lowering barriers to HRI as a field.",
    "url": "https://arxiv.org/abs/2601.22381",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces Lantern, a minimalist robotic object platform designed to blend into human environments and enable the creation of simple robotic artifacts at a low cost. Through various explorations and evaluations, it was found that Lantern effectively engages users and can be used for a range of applications, making it a valuable tool for lowering barriers to Human-Robot Interaction (HRI) research. The platform's ability to evoke engagement and support versatile applications highlights its significance in advancing the field of HRI."
  },
  {
    "title": "AI Narrative Breakdown. A Critical Assessment of Power and Promise",
    "abstract": "This article sets off for an exploration of the still evolving discourse surrounding artificial intelligence (AI) in the wake of the release of ChatGPT. It scrutinizes the pervasive narratives that are shaping the societal engagement with AI, spotlighting key themes such as agency and decision-making, autonomy, truthfulness, knowledge processing, prediction, general purpose, neutrality and objectivity, apolitical optimization, sustainability game-changer, democratization, mass unemployment, and the dualistic portrayal of AI as either a harbinger of societal utopia or dystopia. Those narratives are analysed critically based on insights from critical computer science, critical data and algorithm studies, from STS, data protection theory, as well as from the philosophy of mind and semiotics. To properly analyse the narratives presented, the article first delves into a historical and technical contextualisation of the AI discourse itself. The article then introduces the notion of \"Zeitgeist AI\" to critique the imprecise and misleading application of the term \"AI\" across various societal sectors. Then, by discussing common narratives with nuance, the article contextualises and challenges often assumed socio-political implications of AI, uncovering in detail and with examples the inherent political, power infused and value-laden decisions within all AI applications. Concluding with a call for a more grounded engagement with AI, the article carves out acute problems ignored by the narratives discussed and proposes new narratives recognizing AI as a human-directed tool necessarily subject to societal governance.",
    "url": "https://arxiv.org/abs/2601.22255",
    "journal": "arXiv cs.HC",
    "ai_summary": "This article critically assesses the evolving discourse surrounding artificial intelligence (AI) in light of the release of ChatGPT, examining key themes such as agency, autonomy, and societal implications. It highlights the need for a more nuanced understanding of AI narratives, emphasizing the political, power-infused, and value-laden decisions inherent in AI applications and calling for a more grounded engagement with AI as a human-directed tool subject to societal governance."
  },
  {
    "title": "Game-Based and Gamified Robotics Education: A Comparative Systematic Review and Design Guidelines",
    "abstract": "Robotics education fosters computational thinking, creativity, and problem-solving, but remains challenging due to technical complexity. Game-based learning (GBL) and gamification offer engagement benefits, yet their comparative impact remains unclear. We present the first PRISMA-aligned systematic review and comparative synthesis of GBL and gamification in robotics education, analyzing 95 studies from 12,485 records across four databases (2014-2025). We coded each study's approach, learning context, skill level, modality, pedagogy, and outcomes (k = .918). Three patterns emerged: (1) approach-context-pedagogy coupling (GBL more prevalent in informal settings, while gamification dominated formal classrooms [p < .001] and favored project-based learning [p = .009]); (2) emphasis on introductory programming and modular kits, with limited adoption of advanced software (~17%), advanced hardware (~5%), or immersive technologies (~22%); and (3) short study horizons, relying on self-report. We propose eight research directions and a design space outlining best practices and pitfalls, offering actionable guidance for robotics education.",
    "url": "https://arxiv.org/abs/2601.22199",
    "journal": "arXiv cs.HC",
    "ai_summary": "This systematic review compares game-based learning (GBL) and gamification in robotics education, analyzing 95 studies to identify trends and outcomes. The study found that GBL is more common in informal settings, while gamification is favored in formal classrooms, with an emphasis on introductory programming and modular kits. The research highlights the need for more advanced software, hardware, and immersive technologies in robotics education, and offers design guidelines for incorporating GBL and gamification effectively."
  },
  {
    "title": "Auditorily Embodied Conversational Agents: Effects of Spatialization and Situated Audio Cues on Presence and Social Perception",
    "abstract": "Embodiment can enhance conversational agents, such as increasing their perceived presence. This is typically achieved through visual representations of a virtual body; however, visual modalities are not always available, such as when users interact with agents using headphones or display-less glasses. In this work, we explore auditory embodiment. By introducing auditory cues of bodily presence - through spatially localized voice and situated Foley audio from environmental interactions - we investigate how audio alone can convey embodiment and influence perceptions of a conversational agent. We conducted a 2 (spatialization: monaural vs. spatialized) x 2 (Foley: none vs. Foley) within-subjects study, where participants (n=24) engaged in conversations with agents. Our results show that spatialization and Foley increase co-presence, but reduce users' perceptions of the agent's attention and other social attributes.",
    "url": "https://arxiv.org/abs/2601.22082",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores how auditory cues of bodily presence, such as spatialized voice and situated Foley audio, can enhance the perceived presence of conversational agents. The study found that spatialization and Foley audio increased co-presence but reduced users' perceptions of the agent's attention and social attributes. This suggests that auditory embodiment can play a significant role in shaping users' interactions with conversational agents, especially in situations where visual modalities are not available."
  },
  {
    "title": "Accessibility-Driven Information Transformations in Mixed-Visual Ability Work Teams",
    "abstract": "Blind and low-vision (BLV) employees in mixed-visual ability teams often encounter information (e.g., PDFs, diagrams) in inaccessible formats. To enable teamwork, teams must transform these representations by modifying or re-creating them into accessible forms. However, these transformations are frequently overlooked, lack infrastructural support, and cause additional labour. To design systems that move beyond one-off accommodations to effective mixed-ability collaboration, we need a deeper understanding of the representations, their transformations and how they occur. We conducted a week-long diary study with follow-up interviews with 23 BLV and sighted professionals from five legal, non-profit, and consulting teams, documenting 36 transformation cases. Our analysis characterizes how teams perform representational transformations for accessibility: how they are triggered proactively or reactively, how they simplify or enhance, and four common patterns in which workers coordinate with each other to address representational incompatibility. Our findings uncover opportunities for designing systems that can better support mixed-visual ability work.",
    "url": "https://arxiv.org/abs/2601.22081",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on the challenges faced by blind and low-vision employees in mixed-visual ability teams when encountering inaccessible information. The study highlights the need for systems that support effective collaboration through the transformation of representations into accessible forms. The findings provide insights into how teams coordinate to address representational incompatibility, offering opportunities for designing systems that can better support mixed-visual ability work."
  },
  {
    "title": "Vidmento: Creating Video Stories Through Context-Aware Expansion With Generative Video",
    "abstract": "Video storytelling is often constrained by available material, limiting creative expression and leaving undesired narrative gaps. Generative video offers a new way to address these limitations by augmenting captured media with tailored visuals. To explore this potential, we interviewed eight video creators to identify opportunities and challenges in integrating generative video into their workflows. Building on these insights and established filmmaking principles, we developed Vidmento, a tool for authoring hybrid video stories that combine captured and generated media through context-aware expansion. Vidmento surfaces opportunities for story development, generates clips that blend stylistically and narratively with surrounding media, and provides controls for refinement. In a study with 12 creators, Vidmento supported narrative development and exploration by systematically expanding initial materials with generative media, enabling expressive video storytelling aligned with creative intent. We highlight how creators bridge story gaps with generative content and where they find this blending capability most valuable.",
    "url": "https://arxiv.org/abs/2601.22013",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research explores the use of generative video to enhance video storytelling by augmenting captured media with tailored visuals. The tool developed, Vidmento, allows creators to combine captured and generated media through context-aware expansion, supporting narrative development and exploration. Creators found that Vidmento helped bridge story gaps and provided valuable blending capabilities, enabling expressive video storytelling aligned with creative intent."
  },
  {
    "title": "From Particles to Agents: Hallucination as a Metric for Cognitive Friction in Spatial Simulation",
    "abstract": "Traditional architectural simulations (e.g. Computational Fluid Dynamics, evacuation, structural analysis) model elements as deterministic physics-based \"particles\" rather than cognitive \"agents\". To bridge this, we introduce \\textbf{Agentic Environmental Simulations}, where Large Multimodal generative models actively predict the next state of spatial environments based on semantic expectation. Drawing on examples from accessibility-oriented AR pipelines and multimodal digital twins, we propose a shift from chronological time-steps to Episodic Spatial Reasoning, where simulations advance through meaningful, surprisal-triggered events. Within this framework we posit AI hallucinations as diagnostic tools. By formalizing the \\textbf{Cognitive Friction} ($C_f$) it is possible to reveal \"Phantom Affordances\", i.e. semiotic ambiguities in built space. Finally, we challenge current HCI paradigms by treating environments as dynamic cognitive partners and propose a human-centered framework of cognitive orchestration for designing AI-driven simulations that preserve autonomy, affective clarity, and cognitive integrity.",
    "url": "https://arxiv.org/abs/2601.21977",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces Agentic Environmental Simulations as a way to bridge the gap between traditional deterministic physics-based simulations and cognitive agent-based simulations in architectural modeling. By focusing on episodic spatial reasoning and using AI hallucinations as diagnostic tools, the study proposes a new framework for designing AI-driven simulations that prioritize autonomy, affective clarity, and cognitive integrity in built environments. This shift challenges current HCI paradigms and aims to reveal semiotic ambiguities in spatial environments through the concept of Cognitive Friction."
  },
  {
    "title": "Cognitive Load Estimation Using Brain Foundation Models and Interpretability for BCIs",
    "abstract": "Accurately monitoring cognitive load in real time is critical for Brain-Computer Interfaces (BCIs) that adapt to user engagement and support personalized learning. Electroencephalography (EEG) offers a non-invasive, cost-effective modality for capturing neural activity, though traditional methods often struggle with cross-subject variability and task-specific preprocessing. We propose leveraging Brain Foundation Models (BFMs), large pre-trained neural networks, to extract generalizable EEG features for cognitive load estimation. We adapt BFMs for long-term EEG monitoring and show that fine-tuning a small subset of layers yields improved accuracy over the state-of-the-art. Despite their scale, BFMs allow for real-time inference with a longer context window. To address often-overlooked interpretability challenges, we apply Partition SHAP (SHapley Additive exPlanations) to quantify feature importance. Our findings reveal consistent emphasis on prefrontal regions linked to cognitive control, while longitudinal trends suggest learning progression. These results position BFMs as efficient and interpretable tools for continuous cognitive load monitoring in real-world BCIs.",
    "url": "https://arxiv.org/abs/2601.21965",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of Brain Foundation Models (BFMs) to accurately estimate cognitive load in real-time for Brain-Computer Interfaces (BCIs). By fine-tuning a small subset of layers, the BFMs show improved accuracy over traditional methods and allow for real-time inference with a longer context window. Additionally, the application of Partition SHAP helps quantify feature importance, revealing consistent emphasis on prefrontal regions and suggesting learning progression, making BFMs efficient and interpretable tools for continuous cognitive load monitoring in real-world BCIs."
  },
  {
    "title": "From Future of Work to Future of Workers: Addressing Asymptomatic AI Harms for Dignified Human-AI Interaction",
    "abstract": "In the future of work discourse, AI is touted as the ultimate productivity amplifier. Yet, beneath the efficiency gains lie subtle erosions of human expertise and agency. This paper shifts focus from the future of work to the future of workers by navigating the AI-as-Amplifier Paradox: AI's dual role as enhancer and eroder, simultaneously strengthening performance while eroding underlying expertise. We present a year-long study on the longitudinal use of AI in a high-stakes workplace among cancer specialists. Initial operational gains hid ``intuition rust'': the gradual dulling of expert judgment. These asymptomatic effects evolved into chronic harms, such as skill atrophy and identity commoditization. Building on these findings, we offer a framework for dignified Human-AI interaction co-constructed with professional knowledge workers facing AI-induced skill erosion without traditional labor protections. The framework operationalizes sociotechnical immunity through dual-purpose mechanisms that serve institutional quality goals while building worker power to detect, contain, and recover from skill erosion, and preserve human identity. Evaluated across healthcare and software engineering, our work takes a foundational step toward dignified human-AI interaction futures by balancing productivity with the preservation of human expertise.",
    "url": "https://arxiv.org/abs/2601.21920",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper examines the impact of AI on human expertise and agency in the workplace, highlighting the dual role of AI as both enhancer and eroder of performance. The study conducted among cancer specialists reveals that while AI initially led to operational gains, it also resulted in the gradual dulling of expert judgment and skill erosion. The findings suggest the need for a framework for dignified Human-AI interaction that addresses the asymptomatic harms of AI on professional knowledge workers, aiming to balance productivity with the preservation of human expertise."
  },
  {
    "title": "Preliminary Results of a Scoping Review on Assistive Technologies for Adults with ADHD",
    "abstract": "Attention Deficit Hyperactivity Disorder (ADHD), characterized by inattention, hyperactivity, and impulsivity, is prevalent in the adult population. Long perceived and treated as a childhood condition, ADHD and its characteristics nonetheless impact a significant portion of adults today. In contrast to children with ADHD, adults with ADHD face unique challenges in the workplace and in higher education. In this work-in-progress paper, we present a scoping review as a foundation to understand and explore existing technology-based approaches to support adults with ADHD. In total, our search returned 3,538 papers upon which we selected, based on PRISMA-ScR, a total of 46 papers for in-depth analysis. Our initial findings highlight that most papers take on a therapeutic or intervention perspective instead of a more positive support perspective. Our analysis also found a tremendous increase in recent papers on the topic, which highlights that more and more researchers are becoming aware of the need to address ADHD with adults. For the future, we aim to further analyze the corpus and identify research gaps and potentials for further development of ADHD assistive technologies.",
    "url": "https://arxiv.org/abs/2601.21791",
    "journal": "arXiv cs.HC",
    "ai_summary": "This scoping review explores existing technology-based approaches to support adults with ADHD, highlighting the unique challenges they face in the workplace and higher education. The initial findings suggest that most papers focus on therapeutic or intervention perspectives rather than positive support, with a significant increase in recent research on the topic. The study aims to identify research gaps and potentials for further development of assistive technologies for adults with ADHD."
  },
  {
    "title": "When Life Gives You AI, Will You Turn It Into A Market for Lemons? Understanding How Information Asymmetries About AI System Capabilities Affect Market Outcomes and Adoption",
    "abstract": "AI consumer markets are characterized by severe buyer-supplier market asymmetries. Complex AI systems can appear highly accurate while making costly errors or embedding hidden defects. While there have been regulatory efforts surrounding different forms of disclosure, large information gaps remain. This paper provides the first experimental evidence on the important role of information asymmetries and disclosure designs in shaping user adoption of AI systems. We systematically vary the density of low-quality AI systems and the depth of disclosure requirements in a simulated AI product market to gauge how people react to the risk of accidentally relying on a low-quality AI system. Then, we compare participants' choices to a rational Bayesian model, analyzing the degree to which partial information disclosure can improve AI adoption. Our results underscore the deleterious effects of information asymmetries on AI adoption, but also highlight the potential of partial disclosure designs to improve the overall efficiency of human decision-making.",
    "url": "https://arxiv.org/abs/2601.21650",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research examines the impact of information asymmetries on AI adoption in consumer markets. The study shows that complex AI systems can appear accurate but may have hidden defects, leading to market inefficiencies. The findings suggest that partial disclosure of information about AI system capabilities can improve decision-making and increase overall efficiency in AI adoption."
  },
  {
    "title": "From Vulnerable to Resilient: Examining Parent and Teen Perceptions on How to Respond to Unwanted Cybergrooming Advances",
    "abstract": "Cybergrooming is a form of online abuse that threatens teens' mental health and physical safety. Yet, most prior work has focused on detecting perpetrators' behaviors, leaving a limited understanding of how teens might respond to such unwanted advances. To address this gap, we conducted an online survey with 74 participants -- 51 parents and 23 teens -- who responded to simulated cybergrooming scenarios in two ways: responses that they think would make teens more vulnerable or resilient to unwanted sexual advances. Through a mixed-methods analysis, we identified four types of vulnerable responses (encouraging escalation, accepting an advance, displaying vulnerability, and negating risk concern) and four types of protective strategies (setting boundaries, directly declining, signaling risk awareness, and leveraging avoidance techniques). As the cybergrooming risk escalated, both vulnerable responses and protective strategies showed a corresponding progression. This study contributes a teen-centered understanding of cybergrooming, a labeled dataset, and a stage-based taxonomy of perceived protective strategies, while offering implications for educational programs and sociotechnical interventions.",
    "url": "https://arxiv.org/abs/2601.21518",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research study explores how parents and teens perceive and respond to unwanted cybergrooming advances, a form of online abuse that can harm teens' mental and physical well-being. Through an online survey with 74 participants, the study identified four types of vulnerable responses and four types of protective strategies that teens may employ in such situations. The findings highlight the importance of educating teens on setting boundaries, directly declining advances, and being aware of risks in order to build resilience against cybergrooming."
  },
  {
    "title": "Organizational Practices and Socio-Technical Design of Human-Centered AI",
    "abstract": "This contribution explores how the integration of Artificial Intelligence (AI) into organizational practices can be effectively framed through a socio-technical perspective to comply with the requirements of Human-centered AI (HCAI). Instead of viewing AI merely as a technical tool, the analysis emphasizes the importance of embedding AI into communication, collaboration, and decision-making processes within organizations from a human-centered perspective. Ten case-based patterns illustrate how AI support of predictive maintenance can be organized to address quality assurance and continuous improvement and to provide different types of sup-port for HCAI. The analysis shows that AI adoption often requires and enables new forms of organizational learning, where specialists jointly interpret AI output, adapt workflows, and refine rules for system improve-ment. Different dimensions and levels of socio-technical integration of AI are considered to reflect the effort and benefits of keeping the organization in the loop.",
    "url": "https://arxiv.org/abs/2601.21492",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores how AI can be integrated into organizational practices through a socio-technical perspective to meet the requirements of Human-centered AI. The analysis emphasizes embedding AI into communication, collaboration, and decision-making processes within organizations to support predictive maintenance and quality assurance. The study highlights the importance of organizational learning and adaptation in utilizing AI effectively, and emphasizes the benefits of keeping the organization involved in the AI integration process."
  },
  {
    "title": "Are they just delegating? Cross-Sample Predictions on University Students' & Teachers' Use of AI",
    "abstract": "Mutual trust between teachers and students is a prerequisite for effective teaching, learning, and assessment in higher education. Accurate predictions about the other group's use of generative artificial intelligence (AI) are fundamental for such trust. However, the disruptive rise of AI has transformed academic work practices, raising important questions about how teachers and students use these tools and how well they can estimate each other's usage. While the frequency of use is well studied, little is known about how AI is used, and comparisons with similar practices are rare. This study surveyed German university teachers (N = 113) and students (N = 123) on the frequency of AI use and the degree of delegation across six identical academic tasks. Participants also provided incentivized cross-sample predictions of the other group's AI use to assess the accuracy of their predictions. We find that students reported higher use of AI and greater delegation than teachers. Both groups significantly overestimated the other group's use, with teachers predicting very frequent use and high delegation by students, and students assuming teachers use AI similarly to themselves. These findings reveal a perception gap between teachers' and students' expectations and actual AI use. Such gaps may hinder trust and effective collaboration, underscoring the need for open dialogue about AI practices in academia and for policies that support the equitable and transparent integration of AI tools in higher education.",
    "url": "https://arxiv.org/abs/2601.21490",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study examines the use of AI in academic tasks by German university teachers and students, finding that students reported higher AI use and delegation compared to teachers. Both groups overestimated the other's AI use, indicating a perception gap that may hinder trust and collaboration. The findings highlight the importance of open dialogue and policies to support the integration of AI tools in higher education."
  },
  {
    "title": "Tell Me What I Missed: Tell Me What I Missed: Interacting with GPT during Recalling of One-Time Witnessed Events",
    "abstract": "LLM-assisted technologies are increasingly used to support cognitive processing and information interpretation, yet their role in aiding memory recall, and how people choose to engage with them, remains underexplored. We studied participants who watched a short robbery video (approximating a one-time eyewitness scenario) and composed recall statements using either a default GPT or a guided GPT prompted with a standardized eyewitness protocol. Results show that, in the default condition, participants who believed they had a clearer understanding of the event were more likely to trust GPT's output, whereas in the guided condition, participants showed stronger alignment between subjective clarity and actual recall. Additionally, participants evaluated the legitimacy of the individuals in the incident differently across conditions. Interaction analysis further revealed that default-GPT users spontaneously developed diverse strategies, including building on existing recollections, requesting potentially missing details, and treating GPT as a recall coach. This work shows how GPT-user interplay can subconsciously shape beliefs and perceptions of remembered events.",
    "url": "https://arxiv.org/abs/2601.21460",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores how individuals interact with GPT (a language model) during memory recall of one-time witnessed events, such as a robbery. The study found that participants who believed they had a clear understanding of the event were more likely to trust GPT's output in the default condition, while in the guided condition, there was stronger alignment between subjective clarity and actual recall. The findings highlight the potential impact of GPT on shaping beliefs and perceptions of remembered events, suggesting the importance of understanding how individuals engage with AI technology in memory recall tasks."
  },
  {
    "title": "Envisioning Audio Augmented Reality in Everyday Life",
    "abstract": "While visual augmentation dominates the augmented reality landscape, devices like Meta Ray-Ban audio smart glasses signal growing industry movement toward audio augmented reality (AAR). Hearing is a primary channel for sensing context, anticipating change, and navigating social space, yet AAR's everyday potential remains underexplored. We address this gap through a collaborative autoethnography (N=5, authoring) and an online survey (N=74). We identify ten roles for AAR, grouped into three categories: task- and utility-oriented, emotional and social, and perceptual collaborator. These roles are further layered with a rhythmic and embodied collaborator framing, mapping them onto micro-, meso-, and macro-rhythms of everyday life. Our analysis surfaces nuanced tensions, such as blocking distractions without erasing social presence, highlighting the need for context-aware design. This paper contributes a foundational and forward-looking framework for AAR in everyday life, providing design groundwork for systems attuned to daily routines, sensory engagement, and social expectations.",
    "url": "https://arxiv.org/abs/2601.21271",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the potential of audio augmented reality (AAR) in everyday life, highlighting its importance in sensing context, anticipating change, and navigating social space. Through a collaborative autoethnography and online survey, the study identifies ten roles for AAR, categorized into task-oriented, emotional and social, and perceptual collaborator roles. The findings emphasize the need for context-aware design to address tensions such as blocking distractions without erasing social presence, providing a foundational framework for designing AAR systems that are attuned to daily routines, sensory engagement, and social expectations."
  },
  {
    "title": "Evaluating Spatialized Auditory Cues for Rapid Attention Capture in XR",
    "abstract": "In time-critical eXtended reality (XR) scenarios where users must rapidly reorient their attention to hazards, alerts, or instructions while engaged in a primary task, spatial audio can provide an immediate directional cue without occupying visual bandwidth. However, such scenarios can afford only a brief auditory exposure, requiring users to interpret sound direction quickly and without extended listening or head-driven refinement. This paper reports a controlled exploratory study of rapid spatial-audio localization in XR. Using HRTF-rendered broadband stimuli presented from a semi-dense set of directions around the listener, we quantify how accurately users can infer coarse direction from brief audio alone. We further examine the effects of short-term visuo-auditory feedback training as a lightweight calibration mechanism. Our findings show that brief spatial cues can convey coarse directional information, and that even short calibration can improve users' perception of aural signals. While these results highlight the potential of spatial audio for rapid attention guidance, they also show that auditory cues alone may not provide sufficient precision for complex or high-stakes tasks, and that spatial audio may be most effective when complemented by other sensory modalities or visual cues, without relying on head-driven refinement. We leverage this study on spatial audio as a preliminary investigation into a first-stage attention-guidance channel for wearable XR (e.g., VR head-mounted displays and AR smart glasses), and provide design insights on stimulus selection and calibration for time-critical use.",
    "url": "https://arxiv.org/abs/2601.21264",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research study evaluates the effectiveness of spatialized auditory cues for quickly capturing users' attention in time-critical XR scenarios. The study found that brief spatial cues can convey coarse directional information, and short-term visuo-auditory feedback training can improve users' perception of aural signals. However, the study also suggests that auditory cues alone may not be precise enough for complex tasks, and recommends complementing spatial audio with other sensory modalities or visual cues for optimal attention guidance in XR environments."
  },
  {
    "title": "Optimization and Mobile Deployment for Anthropocene Neural Style Transfer",
    "abstract": "This paper presents AnthropoCam, a mobile-based neural style transfer (NST) system optimized for the visual synthesis of Anthropocene environments. Unlike conventional artistic NST, which prioritizes painterly abstraction, stylizing human-altered landscapes demands a careful balance between amplifying material textures and preserving semantic legibility. Industrial infrastructures, waste accumulations, and modified ecosystems contain dense, repetitive patterns that are visually expressive yet highly susceptible to semantic erosion under aggressive style transfer.\nTo address this challenge, we systematically investigate the impact of NST parameter configurations on the visual translation of Anthropocene textures, including feature layer selection, style and content loss weighting, training stability, and output resolution. Through controlled experiments, we identify an optimal parameter manifold that maximizes stylistic expression while preventing semantic erasure. Our results demonstrate that appropriate combinations of convolutional depth, loss ratios, and resolution scaling enable the faithful transformation of anthropogenic material properties into a coherent visual language.\nBuilding on these findings, we implement a low-latency, feed-forward NST pipeline deployed on mobile devices. The system integrates a React Native frontend with a Flask-based GPU backend, achieving high-resolution inference within 3-5 seconds on general mobile hardware. This enables real-time, in-situ visual intervention at the site of image capture, supporting participatory engagement with Anthropocene landscapes.\nBy coupling domain-specific NST optimization with mobile deployment, AnthropoCam reframes neural style transfer as a practical and expressive tool for real-time environmental visualization in the Anthropocene.",
    "url": "https://arxiv.org/abs/2601.21141",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper introduces AnthropoCam, a mobile-based neural style transfer system optimized for visually synthesizing Anthropocene environments. The study explores the impact of different NST parameters on translating Anthropocene textures, finding an optimal parameter combination that balances stylistic expression and semantic preservation. The implementation of a low-latency, feed-forward NST pipeline on mobile devices allows for real-time visual intervention in Anthropocene landscapes, highlighting the practical and expressive potential of NST for environmental visualization."
  },
  {
    "title": "Privatization of Synthetic Gaze: Attenuating State Signatures in Diffusion-Generated Eye Movements",
    "abstract": "The recent success of deep learning (DL) has enabled the generation of high-quality synthetic gaze data. However, such data also raises privacy concerns because gaze sequences can encode subjects' internal states, like fatigue, emotional load, or stress. Ideally, synthetic gaze should preserve the signal quality of real recordings and remove or attenuate state-related, privacy-sensitive attributes. Many recent DL-based generative models focus on replicating real gaze trajectories and do not explicitly consider subjective reports or the privatization of internal states. However, in this work, we consider a recent diffusion-based gaze synthesis approach and examine correlations between synthetic gaze features and subjective reports (e.g., fatigue and related self-reported states). Our result shows that these correlations are trivial, which suggests the generative approach suppresses state-related features. Moreover, synthetic gaze preserves necessary signal characteristics similar to those of real data, which supports its use for privacy-preserving gaze-based applications.",
    "url": "https://arxiv.org/abs/2601.21057",
    "journal": "arXiv cs.HC",
    "ai_summary": "Recent advancements in deep learning have allowed for the generation of high-quality synthetic gaze data, but privacy concerns arise as gaze sequences can reveal internal states like fatigue or stress. This study explores a diffusion-based gaze synthesis approach that effectively suppresses state-related features, making synthetic gaze data suitable for privacy-preserving applications. The findings suggest that synthetic gaze maintains necessary signal characteristics while attenuating state signatures, making it a valuable tool for protecting individuals' privacy in gaze-based applications."
  },
  {
    "title": "Eye Feel You: A DenseNet-driven User State Prediction Approach",
    "abstract": "Subjective self-reports, collected with eye-tracking data, reveal perceived states like fatigue, effort, and task difficulty. However, these reports are costly to collect and challenging to interpret consistently in longitudinal studies. In this work, we focus on determining whether objective gaze dynamics can reliably predict subjective reports across repeated recording rounds in the eye-tracking dataset. We formulate subjective-report prediction as a supervised regression problem and propose a DenseNet-based deep learning regressor that learns predictive representations from gaze velocity signals. We conduct two complementary experiments to clarify our aims. First, the cross-round generalization experiment tests whether models trained on earlier rounds transfer to later rounds, evaluating the models' ability to capture longitudinal changes. Second, cross-subject generalization tests models' robustness by predicting subjective outcomes for new individuals. These experiments aim to reduce reliance on hand-crafted feature designs and clarify which states of subjective experience systematically appear in oculomotor behavior over time.",
    "url": "https://arxiv.org/abs/2601.21045",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of objective gaze dynamics to predict subjective self-reports of states like fatigue and task difficulty collected through eye-tracking data. The study introduces a DenseNet-based deep learning regressor to learn predictive representations from gaze velocity signals, aiming to reduce the cost and interpretational challenges of collecting subjective reports in longitudinal studies. The experiments conducted demonstrate the model's ability to generalize across recording rounds and new individuals, highlighting the potential for using AI-driven approaches to understand subjective experiences through oculomotor behavior."
  },
  {
    "title": "Log2Motion: Biomechanical Motion Synthesis from Touch Logs",
    "abstract": "Touch data from mobile devices are collected at scale but reveal little about the interactions that produce them. While biomechanical simulations can illuminate motor control processes, they have not yet been developed for touch interactions. To close this gap, we propose a novel computational problem: synthesizing plausible motion directly from logs. Our key insight is a reinforcement learning-driven musculoskeletal forward simulation that generates biomechanically plausible motion sequences consistent with events recorded in touch logs. We achieve this by integrating a software emulator into a physics simulator, allowing biomechanical models to manipulate real applications in real-time. Log2Motion produces rich syntheses of user movements from touch logs, including estimates of motion, speed, accuracy, and effort. We assess the plausibility of generated movements by comparing against human data from a motion capture study and prior findings, and demonstrate Log2Motion in a large-scale dataset. Biomechanical motion synthesis provides a new way to understand log data, illuminating the ergonomics and motor control underlying touch interactions.",
    "url": "https://arxiv.org/abs/2601.21043",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces Log2Motion, a method for synthesizing biomechanically plausible motion from touch data collected on mobile devices. By using a reinforcement learning-driven musculoskeletal forward simulation, the researchers were able to generate realistic motion sequences consistent with touch logs. This approach provides a new way to analyze and understand touch interactions, offering insights into the ergonomics and motor control processes involved."
  }
]