# arXiv cs.AI Summary â€“ 2026-02-16

## The Fuzzy Front Ends: Reflections on the Never-Ending Story of Visualization Co-Design
**URL:** https://arxiv.org/abs/2602.13182

**Abstract:** Co-design is an increasingly popular approach in HCI and visualization, yet there is little guidance on how to effectively apply this method in visualization contexts. In this paper, we visually present our experience of a two-and-a-half-year co-design project with the local arts community. Focusing on facilitating community exploration and sense-making around arts funding distribution, the project involved a series of co-design sessions between visualization researchers and members of the arts community. Through these iterative sessions, we built shared understanding and developed visualization prototypes tailored to community needs. However, the practice is far from complete, and we found ourselves continually returning to the "fuzzy front end" of the co-design process. We share this ongoing story through comic-style visuals and reflect on three fuzzy front ends that we encountered during the project. By sharing these experiences with the visualization community, we hope to offer insights that others can draw on in their own community-engaged co-design work.

**AI Summary:** This paper discusses the challenges and benefits of using co-design in visualization projects, specifically in collaboration with the local arts community. The researchers share their experiences of a two-and-a-half-year project, highlighting the importance of iterative co-design sessions in building shared understanding and developing tailored visualization prototypes. The paper emphasizes the ongoing nature of co-design work and the need for continued reflection and adaptation to address the "fuzzy front ends" of the process, offering insights for others engaging in community-engaged co-design projects.

---

## Preference-Guided Prompt Optimization for Text-to-Image Generation
**URL:** https://arxiv.org/abs/2602.13131

**Abstract:** Generative models are increasingly powerful, yet users struggle to guide them through prompts. The generative process is difficult to control and unpredictable, and user instructions may be ambiguous or under-specified. Prior prompt refinement tools heavily rely on human effort, while prompt optimization methods focus on numerical functions and are not designed for human-centered generative tasks, where feedback is better expressed as binary preferences and demands convergence within few iterations. We present APPO, a preference-guided prompt optimization algorithm. Instead of iterating prompts, users only provide binary preferential feedback. APPO adaptively balances its strategies between exploiting user feedback and exploring new directions, yielding effective and efficient optimization. We evaluate APPO on image generation, and the results show APPO enables achieving satisfactory outcomes in fewer iterations with lower cognitive load than manual prompt editing. We anticipate APPO will advance human-AI collaboration in generative tasks by leveraging user preferences to guide complex content creation.

**AI Summary:** The research introduces APPO, a preference-guided prompt optimization algorithm for text-to-image generation. Unlike previous methods that rely heavily on human effort or numerical functions, APPO allows users to provide binary preferential feedback to guide the generative process. Results show that APPO is effective and efficient, enabling satisfactory outcomes in fewer iterations with lower cognitive load, which could advance human-AI collaboration in complex content creation tasks.

---

## Automating UI Optimization through Multi-Agentic Reasoning
**URL:** https://arxiv.org/abs/2602.13126

**Abstract:** We present AutoOptimization, a novel multi-objective optimization framework for adapting user interfaces. From a user's verbal preferences for changing a UI, our framework guides a prioritization-based Pareto frontier search over candidate layouts. It selects suitable objective functions for UI placement while simultaneously parameterizing them according to the user's instructions to define the optimization problem. A solver then generates a series of optimal UI layouts, which our framework validates against the user's instructions to adapt the UI with the final solution. Our approach thus overcomes the previous need for manual inspection of layouts and the use of population averages for objective parameters. We integrate multiple agents sequentially within our framework, enabling the system to leverage their reasoning capabilities to interpret user preferences, configure the optimization problem, and validate optimization outcomes.

**AI Summary:** The research introduces AutoOptimization, a framework that automates the process of adapting user interfaces based on verbal preferences. By utilizing a multi-objective optimization approach and integrating multiple agents, the framework can generate optimal UI layouts that align with user instructions without the need for manual inspection or population averages. This approach streamlines the UI optimization process and improves the accuracy of adapting UIs to user preferences.

---

## "It's More of a Lifestyle'': Design Considerations for Supporting Everyday Practices in Community-Based Farming
**URL:** https://arxiv.org/abs/2602.13119

**Abstract:** Farming plays a significant role in the economy by supporting related industries such as food, retail, and local services. Community-based small farms, while offering unique social and cultural benefits, face persistent challenges, including limited access to formal education and underdeveloped infrastructure, which have been discussed in prior research. This study focuses on community-driven factors, such as workarounds for recording critical information and practices for passing down farming knowledge across generations. Through 11 semi-structured interviews with farmers from a small ethnic community, the Hmong, we explore how bonding social capital, rooted in close family and community ties, supports informal knowledge exchange and creates pathways to bridging and linking capital. These relationships help farmers connect to broader networks, resources, and institutions. Our findings highlight opportunities for designing technologies that support and strengthen existing support systems. We discuss how technologies should be designed to reflect the cultural values, unique practices, and intergenerational relationships embedded in community-based farms.

**AI Summary:** This study explores the challenges faced by community-based small farms, particularly the Hmong ethnic community, and how informal knowledge exchange and close family ties play a crucial role in supporting farming practices. The findings suggest that technology can be designed to support and strengthen existing support systems within these communities by reflecting their cultural values and unique practices. By understanding and incorporating these factors, technology can help farmers connect to broader networks, resources, and institutions, ultimately improving their farming practices and sustainability.

---

## GroundLink: Exploring How Contextual Meeting Snippets Can Close Common Ground Gaps in Editing 3D Scenes for Virtual Production
**URL:** https://arxiv.org/abs/2602.12987

**Abstract:** Virtual Production (VP) professionals often face challenges accessing tacit knowledge and creative intent, which are important in forming common ground with collaborators and in contributing more effectively and efficiently to the team. From our formative study (N=23) with a follow-up interview (N=6), we identified the significance and prevalence of this challenge. To help professionals access knowledge, we present GroundLink, a Unity add-on that surfaces meeting-derived knowledge directly in the editor to support establishing common ground. It features a meeting knowledge dashboard for capturing and reviewing decisions and comments, constraint-aware feedforward that proactively informs the editor environment, and cross-modal synchronization that provides referential links between the dashboard and the editor. A comparative study (N=12) suggested that GroundLink help users build common ground with their team while improving perceived confidence and ease of editing the 3D scene. An expert evaluation with VP professionals (N=5) indicated strong potential for GroundLink in real-world workflows.

**AI Summary:** The research explores the challenges faced by Virtual Production (VP) professionals in accessing tacit knowledge and creative intent when editing 3D scenes. The study identified the prevalence of this challenge and developed GroundLink, a Unity add-on that surfaces meeting-derived knowledge directly in the editor to help establish common ground with collaborators. Comparative studies and expert evaluations suggest that GroundLink can improve confidence and ease of editing while facilitating better communication and collaboration within VP teams.

---

## Human Tool: An MCP-Style Framework for Human-Agent Collaboration
**URL:** https://arxiv.org/abs/2602.12953

**Abstract:** Human-AI collaboration faces growing challenges as AI systems increasingly outperform humans on complex tasks, while humans remain responsible for orchestration, validation, and decision oversight. To address this imbalance, we introduce Human Tool, an MCP-style interface abstraction, building on recent Model Context Protocol designs, that exposes humans as callable tools within AI-led, proactive workflows. Here, "tool" denotes a coordination abstraction, not a reduction of human authority or responsibility. Building on LLM-based agent architectures, we operationalize Human Tool by modeling human contributions through structured tool schemas of capabilities, information, and authority. These schemas enable agents to dynamically invoke human input based on relative strengths and reintegrate it through efficient, natural interaction protocols. We validate the framework through controlled studies in both decision-making and creative tasks, demonstrating improved task performance, reduced human workload, and more balanced collaboration dynamics compared to baseline systems. Finally, we discuss implications for human-centered AI design, highlighting how MCP-style human tools enable strong AI leadership while amplifying uniquely human strengths.

**AI Summary:** The research introduces Human Tool, a framework for human-agent collaboration that addresses the imbalance between AI systems and human decision-making. By modeling human contributions through structured tool schemas, agents can dynamically invoke human input and reintegrate it efficiently. Controlled studies show improved task performance, reduced human workload, and more balanced collaboration dynamics compared to baseline systems, highlighting the potential for Human Tool to enhance human-centered AI design.

---

## Never say never: Exploring the effects of available knowledge on agent persuasiveness in controlled physiotherapy motivation dialogues
**URL:** https://arxiv.org/abs/2602.12924

**Abstract:** Generative Social Agents (GSAs) are increasingly impacting human users through persuasive means. On the one hand, they might motivate users to pursue personal goals, such as healthier lifestyles. On the other hand, they are associated with potential risks like manipulation and deception, which are induced by limited control over probabilistic agent outputs. However, as GSAs manifest communicative patterns based on available knowledge, their behavior may be regulated through their access to such knowledge. Following this approach, we explored persuasive ChatGPT-generated messages in the context of human-robot physiotherapy motivation. We did so by comparing ChatGPT-generated responses to predefined inputs from a hypothetical physiotherapy patient. In Study 1, we qualitatively analyzed 13 ChatGPT-generated dialogue scripts with varying knowledge configurations regarding persuasive message characteristics. In Study 2, third-party observers (N = 27) rated a selection of these dialogues in terms of the agent's expressiveness, assertiveness, and persuasiveness. Our findings indicate that LLM-based GSAs can adapt assertive and expressive personality traits -- significantly enhancing perceived persuasiveness. Moreover, persuasiveness significantly benefited from the availability of information about the patients' age and past profession, mediated by perceived assertiveness and expressiveness. Contextual knowledge about physiotherapy benefits did not significantly impact persuasiveness, possibly because the LLM had inherent knowledge about such benefits even without explicit prompting. Overall, the study highlights the importance of empirically studying behavioral patterns of GSAs, specifically in terms of what information generative AI systems require for consistent and responsible communication.

**AI Summary:** This research explores the impact of available knowledge on the persuasiveness of Generative Social Agents (GSAs) in physiotherapy motivation dialogues. The study found that GSAs with access to information about patients' age and past profession exhibited more assertive and expressive personality traits, leading to increased persuasiveness. Interestingly, contextual knowledge about physiotherapy benefits did not significantly impact persuasiveness, suggesting that GSAs may already possess inherent knowledge in this area. This study emphasizes the importance of understanding how AI systems utilize information for effective and responsible communication.

---

## Comparative Study of Ultrasound Shape Completion and CBCT-Based AR Workflows for Spinal Needle Interventions
**URL:** https://arxiv.org/abs/2602.12920

**Abstract:** Purpose: This study compares two augmented reality (AR)-guided imaging workflows, one based on ultrasound shape completion and the other on cone-beam computed tomography (CBCT), for planning and executing lumbar needle interventions. The aim is to assess how imaging modality influences user performance, usability, and trust during AR-assisted spinal procedures.
Methods: Both imaging systems were integrated into an AR framework, enabling in situ visualization and trajectory guidance. The ultrasound-based workflow combined AR-guided robotic scanning, probabilistic shape completion, and AR visualization. The CBCT-based workflow used AR-assisted scan volume planning, CBCT acquisition, and AR visualization. A between-subject user study was conducted and evaluated in two phases: (1) planning and image acquisition, and (2) needle insertion.
Results: Planning time was significantly shorter with the CBCT-based workflow, while SUS, SEQ, and NASA-TLX were comparable between modalities. In the needle insertion phase, the CBCT-based workflow yielded marginally faster insertion times, lower placement error, and better subjective ratings with higher Trust. The ultrasound-based workflow achieved adequate accuracy for facet joint insertion, but showed larger errors for lumbar puncture, where reconstructions depended more heavily on shape completion.
Conclusion: The findings indicate that both AR-guided imaging pipelines are viable for spinal intervention support. CBCT-based AR offers advantages in efficiency, precision, usability, and user confidence during insertion, whereas ultrasound-based AR provides adaptive, radiation-free imaging but is limited by shape completion in deeper spinal regions. These complementary characteristics motivate hybrid AR guidance that uses CBCT for global anatomical context and planning, augmented by ultrasound for adaptive intraoperative updates.

**AI Summary:** This study compared two augmented reality (AR)-guided imaging workflows for spinal needle interventions, one based on ultrasound shape completion and the other on cone-beam computed tomography (CBCT). The results showed that the CBCT-based workflow was more efficient, precise, and instilled higher user confidence during needle insertion, while the ultrasound-based workflow provided adaptive, radiation-free imaging but had limitations in deeper spinal regions. The findings suggest that a hybrid AR guidance system combining both modalities could offer the best of both worlds for spinal interventions.

---

## Reflection at Design Actualization (RDA) : A Tool and Process For Research Through Game Design
**URL:** https://arxiv.org/abs/2602.12887

**Abstract:** There is a growing interest in researching game design processes, artifacts and culture through active game design. Tools and processes to support these attempts are limited, especially in terms of a) capturing smaller design decisions where rich tacit information is often situated, and b) visually tracking the project's growth and evolution. To address this gap, we present Reflection at Design Actualization (RDA), an open source tool and process for collecting granular reflections at playtesting moments and automatically recording the playtests, bringing reflection and data collection closer to the point where design decisions concretize. Three researchers engaged with and evaluated RDA in three varied game development projects, adhering to the principles of autobiographical design. We illustrate the designer experience with RDA through three themes, namely, designer-routine compromise, designer-researcher persona consolidation, and mirror effect of RDA. We further discuss the tool's challenges and share each designer's personal experience as case studies.

**AI Summary:** The abstract discusses the development of Reflection at Design Actualization (RDA), a tool and process for collecting granular reflections during playtesting moments in game design projects. The tool aims to capture smaller design decisions and visually track the project's growth and evolution. Three researchers evaluated RDA in different game development projects, highlighting themes such as designer-routine compromise and the mirror effect of RDA. The tool's challenges and personal experiences of the designers are also discussed.

---

## Knowledge-Based Design Requirements for Generative Social Robots in Higher Education
**URL:** https://arxiv.org/abs/2602.12873

**Abstract:** Generative social robots (GSRs) powered by large language models enable adaptive, conversational tutoring but also introduce risks such as hallucina-tions, overreliance, and privacy violations. Existing frameworks for educa-tional technologies and responsible AI primarily define desired behaviors, yet they rarely specify the knowledge prerequisites that enable generative systems to express these behaviors reliably. To address this gap, we adopt a knowledge-based design perspective and investigate what information tutor-ing-oriented GSRs require to function responsibly and effectively in higher education. Based on twelve semi-structured interviews with university stu-dents and lecturers, we identify twelve design requirements across three knowledge types: self-knowledge (assertive, conscientious and friendly per-sonality with customizable role), user-knowledge (personalized information about student learning goals, learning progress, motivation type, emotional state and background), and context-knowledge (learning materials, educa-tional strategies, course-related information, and physical learning environ-ment). By identifying these knowledge requirements, this work provides a structured foundation for the design of tutoring GSRs and future evaluations, aligning generative system capabilities with pedagogical and ethical expecta-tions.

**AI Summary:** This research explores the knowledge requirements for generative social robots (GSRs) in higher education, focusing on self-knowledge, user-knowledge, and context-knowledge. Through interviews with university students and lecturers, twelve design requirements were identified to enable responsible and effective functioning of GSRs in educational settings. By addressing this gap in existing frameworks, this work provides a structured foundation for the design and evaluation of tutoring GSRs, aligning their capabilities with pedagogical and ethical expectations.

---

## Media Framing Moderates Risk-Benefit Perceptions and Value Tradeoffs in Human-Robot Collaboration
**URL:** https://arxiv.org/abs/2602.12785

**Abstract:** Public acceptance of industrial human-robot collaboration (HRC) is shaped by how risks and benefits are perceived by affected employees. Positive or negative media framing may shape and shift how individuals evaluate HRC. This study examines how message framing moderates the effects of perceived risks and perceived benefits on overall attributed value. In a pre-registered study, participants (N = 1150) were randomly assigned to read either a positively or negatively framed newspaper article in one of three industrial contexts (autonomy, employment, safety) about HRC in production. Subsequently, perceived risks, benefits, and value were measured using reliable and publicly available psychometric scales. Two multiple regressions (one per framing condition) tested for main and interaction effects. Framing influenced absolute evaluations of risk, benefits, and value. In both frames, risks and benefits significantly predicted attributed value. Under positive framing, only main effects were observed (risks: beta = -0.52; benefits: beta = 0.45). Under negative framing, both predictors had stronger main effects (risks: beta = -0.69; benefits: beta = 0.63) along with a significant negative interaction (beta = -0.32), indicating that higher perceived risk diminishes the positive effect of perceived benefits. Model fit was higher for the positive frame (R^2 = 0.715) than for the negative frame (R^2 = 0.583), indicating greater explained variance in value attributions. Framing shapes the absolute evaluation of HRC and how risks and benefits are cognitively integrated in trade-offs. Negative framing produces stronger but interdependent effects, whereas positive framing supports additive evaluations. These findings highlight the role of strategic communication in fostering acceptance of HRC and underscore the need to consider framing in future HRC research.

**AI Summary:** This research study explores how media framing affects perceptions of risks and benefits in human-robot collaboration (HRC) in industrial settings. The study found that positive framing led to more positive evaluations of HRC, while negative framing resulted in stronger but interdependent effects on perceived risks and benefits. These findings emphasize the importance of strategic communication in shaping public acceptance of HRC and suggest that framing should be considered in future research on the topic.

---

## iRULER: Intelligible Rubric-Based User-Defined LLM Evaluation for Revision
**URL:** https://arxiv.org/abs/2602.12779

**Abstract:** Large Language Models (LLMs) have become indispensable for evaluating writing. However, text feedback they provide is often unintelligible, generic, and not specific to user criteria. Inspired by structured rubrics in education and intelligible AI explanations, we propose iRULER following identified design guidelines to \textit{scaffold} the review process by \textit{specific} criteria, providing \textit{justification} for score selection, and offering \textit{actionable} revisions to target different quality levels. To \textit{qualify} user-defined criteria, we recursively used iRULER with a rubric-of-rubrics to iteratively \textit{refine} rubrics. In controlled experiments on writing revision and rubric creation, iRULER most improved validated LLM-judged review scores and was perceived as most helpful and aligned compared to read-only rubric and text-based LLM feedback. Qualitative findings further support how iRULER satisfies the design guidelines for user-defined feedback. This work contributes interactive rubric tools for intelligible LLM-based review and revision of writing, and user-defined rubric creation.

**AI Summary:** The research introduces iRULER, a system designed to improve the evaluation of writing by Large Language Models (LLMs) by providing specific criteria, justifications for scores, and actionable revisions. Through controlled experiments, iRULER was shown to improve LLM-judged review scores and was perceived as more helpful and aligned with user needs compared to traditional rubrics and text-based LLM feedback. This work contributes to the development of interactive rubric tools for intelligible LLM-based review and revision of writing, as well as user-defined rubric creation.

---

## Usage Matters: The Role of Frequency, Duration, and Experience in Presence Formation in Social Virtual Reality
**URL:** https://arxiv.org/abs/2602.12775

**Abstract:** The sense of presence is central to immersive experiences in Virtual Reality (VR), and particularly salient in socially rich platforms like social VR. While prior studies have explored various aspects related to presence, less is known about how ongoing usage behaviors shape presence in everyday engagement. To address this gap, we examine whether usage intensity, captured through frequency of use, session duration, and years of VR experience, predicts presence in social VR. A survey of 295 users assessed overall, social, spatial, and self-presence using validated scales. Results show that both frequency and duration consistently predict higher presence across all dimensions, with interaction effects indicating that frequent and extended sessions synergistically amplify the experience of "being there." These effects were stable across age and gender. Our findings extend presence research beyond the laboratory by identifying behavioral predictors in social VR and offer insights for building inclusive environments that reliably foster presence.

**AI Summary:** This research examines how usage behaviors, such as frequency of use, session duration, and years of VR experience, impact the sense of presence in social Virtual Reality (VR). The study found that both frequency and duration of usage predict higher presence in social VR, with frequent and extended sessions enhancing the feeling of "being there." These findings highlight the importance of ongoing usage in shaping immersive experiences in social VR and provide insights for creating inclusive environments that promote presence.

---

## The Configuration of Space: Probing the Way Social Interaction and Perception are Affected by Task-Specific Spatial Representations in Online Video Communication
**URL:** https://arxiv.org/abs/2602.12771

**Abstract:** Humans live and act in 3D space, but often work and communicate on 2D surfaces. The prevalence of online communication on 2D screens raises the issue of whether human spatial configuration affects our capabilities, social perception, and behaviors when interacting with others in 2D video chat. How do factors like location, setting, and context subtly shape our online communication, particularly in scenarios such as social support and topic-based discussions? Using this http URL as a platform, we compared a normal gallery interface with a scene-based Room-type interface where participants are located in circular arrangement on screen in a social support task, and found that participants allocated attention to the group as a whole, and had pronounced self-awareness in the Room format. We then chose a two-sided topic for discussion in the Gallery interface and the Room interface where participants on each team face-off against each other, and found that they utilized spatial references to orient their allegiances, expressing greater engagement with those farther away in digital space and greater empathy with those closer, in the Room over the Gallery format. We found spatial effects in the way participants hide from the spotlight, in perspective-taking, and in their use of expressive gestures in time on the screen. This work highlights the need for considering spatial configuration in 2D in the design of collaborative communication systems to optimize for psychological needs for particular tasks.

**AI Summary:** This research explores how the spatial configuration of online video communication affects social interaction and perception. The study found that participants in a Room-type interface exhibited increased attention to the group as a whole and greater self-awareness, while those in a Gallery interface showed spatial effects in their engagement and empathy with others. The findings suggest that designing collaborative communication systems with consideration for spatial configuration can optimize psychological needs for specific tasks.

---

## Social, Spatial, and Self-Presence as Predictors of Basic Psychological Need Satisfaction in Social Virtual Reality
**URL:** https://arxiv.org/abs/2602.12764

**Abstract:** Extensive research has examined presence and basic psychological needs (drawing on Self-Determination Theory) in digital media. While prior work offers hints of potential connections, we lack a systematic account of whether and how distinct presence dimensions map onto the basic needs of autonomy, competence, and relatedness. We surveyed 301 social VR users and analyzed using Structural Equation Modeling. Results show that social presence predicts all three needs, while self-presence predicts competence and relatedness, and spatial presence shows no direct or moderating effects. Gender and age moderated these relationships: women benefited more from social presence for autonomy and relatedness, men from self- and spatial presence for competence and autonomy, and younger users showed stronger associations between social presence and relatedness, and between self-presence and autonomy. These findings position presence as a motivational mechanism shaped by demographic factors. The results offer theoretical insights and practical implications for designing inclusive, need-supportive multiuser VR environments.

**AI Summary:** This study explores the relationship between different dimensions of presence in social virtual reality and basic psychological needs satisfaction. The results show that social presence predicts all three basic needs (autonomy, competence, and relatedness), while self-presence predicts competence and relatedness. Gender and age also play a role in how these relationships manifest, with women benefiting more from social presence for autonomy and relatedness, and men benefiting more from self- and spatial presence for competence and autonomy. These findings have implications for designing inclusive and need-supportive multiuser VR environments.

---

## "Not Human, Funnier": How Machine Identity Shapes Humor Perception in Online AI Stand-up Comedy
**URL:** https://arxiv.org/abs/2602.12763

**Abstract:** Chatbots are increasingly applied to domains previously reserved for human actors. One such domain is comedy, whereby both the general public working with ChatGPT and research-based LLM-systems have tried their hands on making humor. In formative interviews with professional comedians and video analyses of stand-up comedy in humans, we found that human performers often use their ethnic, gender, community, and demographic-based identity to enable joke-making. This suggests whether the identity of AI itself can empower AI humor generation for human audiences. We designed a machine-identity-based agent that uses its own status as AI to tell jokes in online performance format. Studies with human audiences (N=32) showed that machine-identity-based agents were seen as funnier than baseline-GPT agent. This work suggests the design of human-AI integrated systems that explicitly utilize AI as its own unique identity apart from humans.

**AI Summary:** This research explores how the identity of AI influences humor perception in online stand-up comedy. By analyzing the use of identity in human comedians and creating a machine-identity-based agent, the study found that AI with its own unique identity can be perceived as funnier by human audiences compared to a baseline AI agent. This suggests the potential for designing human-AI integrated systems that leverage AI's distinct identity to enhance humor generation for human audiences.

---

## SoK: Understanding the Pedagogical, Health, Ethical, and Privacy Challenges of Extended Reality in Early Childhood Education
**URL:** https://arxiv.org/abs/2602.12749

**Abstract:** Extended Reality (XR) combines dense sensing, real-time rendering, and close-range interaction, making its use in early childhood education both promising and high risk. To investigate this, we conduct a Systematization of Knowledge (SoK) of 111 peer-reviewed studies with children aged 3-8, quantifying how technical, pedagogical, health, privacy, and equity challenges arise in practice. We found that AR dominates the landscape (73%), focusing primarily on tablets or phones, while VR remains uncommon and typically relies on head mounted displays (HMDs). We integrate these quantitative patterns into a joint risk and attention matrix and an Augmented Human Development (AHD) model that link XR pipeline properties to cognitive load, sensory conflict, and access inequity. Finally, implementing a seven dimension coding scheme on a 0 - 2 scale, we obtain mean scholarly attention scores of 1.56 for pedagogy, 1.04 for privacy (primarily procedural consent), 0.96 for technical reliability, 0.92 for accessibility in low resource contexts, 0.81 for medical and health issues, 0.52 for accessibility for disabilities, and 0.14 for data security practices. This indicates that pedagogy receives the most systematic scrutiny, while data access practices is largely overlooked. We conclude by offering a roadmap for Child-Centered XR that helps HCI researchers and educators move beyond novelty to design systems that are developmentally aligned, secure by default, and accessible to diverse learners.

**AI Summary:** The research examines the challenges and opportunities of using Extended Reality (XR) in early childhood education, focusing on children aged 3-8. The study found that Augmented Reality (AR) is more commonly used than Virtual Reality (VR) in this context, with a focus on tablets or phones. The research highlights the importance of addressing pedagogical, health, ethical, and privacy concerns in the design of XR systems for young children, and offers a roadmap for creating Child-Centered XR that is developmentally appropriate, secure, and accessible.

---

## From Guidelines to Practice: Evaluating the Reproducibility of Methods in Computational Social Science
**URL:** https://arxiv.org/abs/2602.12747

**Abstract:** Reproducibility remains a central challenge in computational social science, where complex workflows, evolving software ecosystems, and inconsistent documentation hinder researchers ability to re-execute published methods. This study presents a systematic evaluation of reproducibility across three conditions: uncurated documentation, curated documentation, and curated documentation paired with a preset execution environment. Using 47 usability test sessions, we combine behavioral performance indicators (success rates, task time, and error profiles) with questionnaire data and thematic analysis to identify technical and conceptual barriers to reproducibility.
Curated documentation substantially reduced repository-level errors and improved users ability to interpret method outputs. Standardizing the execution environment further improved reproducibility, yielding the highest success rate and shortest task completion times. Across conditions, participants frequently relied on AI tools for troubleshooting, often enabling independent resolution of issues without facilitator intervention.
Our findings demonstrate that reproducibility barriers are multi-layered and require coordinated improvements in documentation quality, environment stability, and conceptual clarity. We discuss implications for the design of reproducibility platforms and infrastructure in computational social science.

**AI Summary:** This study evaluates the reproducibility of methods in computational social science under different conditions, finding that curated documentation and standardized execution environments significantly improve reproducibility. Participants frequently relied on AI tools for troubleshooting, highlighting the importance of improving documentation quality, environment stability, and conceptual clarity in order to address reproducibility barriers in the field. The findings suggest the need for improved reproducibility platforms and infrastructure in computational social science research.

---

## Bonik Somiti: A Social-market Tool for Safe, Accountable, and Harmonious Informal E-Market Ecosystem in Bangladesh
**URL:** https://arxiv.org/abs/2602.12650

**Abstract:** People in informal e-markets often try to deal with fraud and financial harm by sharing posts, screenshots, and warnings in social media groups. However, buyers and sellers frequently face further problems because these reports are scattered, hard to verify, and rarely lead to resolution. We studied these issues through a survey with 124 participants and interviews with 36 buyers, sellers, and related stakeholders from Bangladesh and designed Bonik Somiti, a socio-technical system that supports structured reporting, admin-led mediation, and accountability in informal e-markets. Our evaluation with 32 participants revealed several challenges in managing fraud, resolving disputes, and building trust within existing informal practices and the assumptions behind them. Based on these findings, we further discuss how community-centered technologies can be designed to support safer and more accountable informal e-markets in the Global South.

**AI Summary:** The research explores the challenges faced by buyers and sellers in informal e-markets in Bangladesh, where reports of fraud and financial harm are scattered and difficult to verify. The study led to the development of Bonik Somiti, a system that facilitates structured reporting, admin-led mediation, and accountability in these markets. The findings highlight the need for community-centered technologies to support safer and more accountable informal e-markets in the Global South.

---

## Editable XAI: Toward Bidirectional Human-AI Alignment with Co-Editable Explanations of Interpretable Attributes
**URL:** https://arxiv.org/abs/2602.12569

**Abstract:** While Explainable AI (XAI) helps users understand AI decisions, misalignment in domain knowledge can lead to disagreement. This inconsistency hinders understanding, and because explanations are often read-only, users lack the control to improve alignment. We propose making XAI editable, allowing users to write rules to improve control and gain deeper understanding through the generation effect of active learning. We developed CoExplain, leveraging a neural network for universal representation and symbolic rules for intuitive reasoning on interpretable attributes. CoExplain explains the neural network with a faithful proxy decision tree, parses user-written rules as an equivalent neural network graph, and collaboratively optimizes the decision tree. In a user study (N=43), CoExplain and manually editable XAI improved user understanding and model alignment compared to read-only XAI. CoExplain was easier to use with fewer edits and less time. This work contributes Editable XAI for bidirectional AI alignment, improving understanding and control.

**AI Summary:** The research introduces Editable XAI, a system that allows users to edit explanations of AI decisions to improve alignment and understanding. By enabling users to write rules and actively participate in the explanation process, Editable XAI enhances control and facilitates deeper comprehension through active learning. The study demonstrates that CoExplain, a system developed based on this concept, outperformed traditional read-only XAI in terms of user understanding and model alignment, highlighting the importance of bidirectional AI alignment for improving user control and comprehension.

---

## GatheringSense: AI-Generated Imagery and Embodied Experiences for Understanding Literati Gatherings
**URL:** https://arxiv.org/abs/2602.12565

**Abstract:** Chinese literati gatherings (Wenren Yaji), as a situated form of Chinese traditional culture, remain underexplored in depth. Although generative AI supports powerful multimodal generation, current cultural applications largely emphasize aesthetic reproduction and struggle to convey the deeper meanings of cultural rituals and social frameworks. Based on embodied cognition, we propose an AI-driven dual-path framework for cultural understanding, which we instantiate through GatheringSense, a literati-gathering experience. We conduct a mixed-methods study (N=48) to compare how AI-generated multimodal content and embodied participation complement each other in supporting the understanding of literati gatherings and fostering cultural resonance. Our results show that AI-generated content effectively improves the readability of cultural symbols and initial emotional attraction, yet limitations in physical coherence and micro-level credibility may affect users' satisfaction. In contrast, embodied experience significantly deepens participants' understanding of ritual rules and social roles, and increases their psychological closeness and presence. Based on these findings, we offer empirical evidence and five transferable design implications for generative experience in cultural heritage.

**AI Summary:** This research explores the use of AI-generated imagery and embodied experiences to understand Chinese literati gatherings. The study finds that AI-generated content improves the readability of cultural symbols and initial emotional attraction, while embodied experiences deepen understanding of ritual rules and social roles. The findings suggest that a combination of AI-generated content and embodied participation can enhance cultural resonance and provide valuable insights for designing generative experiences in cultural heritage.

---

## KeySense: LLM-Powered Hands-Down, Ten-Finger Typing on Commodity Touchscreens
**URL:** https://arxiv.org/abs/2602.12432

**Abstract:** Existing touchscreen software keyboards prevent users from resting their hands, forcing slow and fatiguing index-finger tapping ("chicken typing") instead of familiar hands-down ten-finger typing. We present KeySense, a purely software solution that preserves physical keyboard motor skills. KeySense isolates intentional taps from resting-finger noise using cognitive-motor timing patterns, and then uses a fine-tuned LLM decoder to convert the resulting noisy letter sequence into the intended word. In controlled component tests, the decoder substantially outperforms two statistical baselines (top-1 accuracy 84.8% vs 75.7% and 79.3%). A 12-participant study shows clear ergonomic and performance benefits: compared with the conventional hover-style keyboard, users rated KeySense as markedly less physically demanding (NASA-TLX median 1.5 vs 4.0), and after brief practice typed significantly faster (WPM 28.3 vs 26.2, p < 0.01). These results indicate that KeySense enables accurate, efficient, and comfortable ten-finger text entry on commodity touchscreens without any extra hardware.

**AI Summary:** The research introduces KeySense, a software solution that allows users to type with all ten fingers on touchscreen devices without having to hover their hands. KeySense uses cognitive-motor timing patterns and a fine-tuned LLM decoder to isolate intentional taps from resting-finger noise, resulting in improved typing accuracy and speed. A study with 12 participants showed that KeySense is less physically demanding and enables faster typing compared to conventional touchscreen keyboards, indicating its potential for accurate, efficient, and comfortable text entry on commodity touchscreens without the need for additional hardware.

---

## Eyes on Many: Evaluating Gaze, Hand, and Voice for Multi-Object Selection in Extended Reality
**URL:** https://arxiv.org/abs/2602.12406

**Abstract:** Interacting with multiple objects simultaneously makes us fast. A pre-step to this interaction is to select the objects, i.e., multi-object selection, which is enabled through two steps: (1) toggling multi-selection mode -- mode-switching -- and then (2) selecting all the intended objects -- subselection. In extended reality (XR), each step can be performed with the eyes, hands, and voice. To examine how design choices affect user performance, we evaluated four mode-switching (SemiPinch, FullPinch, DoublePinch, and Voice) and three subselection techniques (Gaze+Dwell, Gaze+Pinch, and Gaze+Voice) in a user study. Results revealed that while DoublePinch paired with Gaze+Pinch yielded the highest overall performance, SemiPinch achieved the lowest performance. Although Voice-based mode-switching showed benefits, Gaze+Voice subselection was less favored, as the required repetitive vocal commands were perceived as tedious. Overall, these findings provide empirical insights and inform design recommendations for multi-selection techniques in XR.

**AI Summary:** This research evaluates different techniques for multi-object selection in extended reality, focusing on mode-switching and subselection using the eyes, hands, and voice. The study found that DoublePinch paired with Gaze+Pinch resulted in the highest performance, while Voice-based mode-switching showed benefits but Gaze+Voice subselection was less favored due to perceived tediousness. These findings offer valuable insights and design recommendations for improving multi-selection techniques in XR applications.

---

## Resource-Efficient Gesture Recognition through Convexified Attention
**URL:** https://arxiv.org/abs/2602.13030

**Abstract:** Wearable e-textile interfaces require gesture recognition capabilities but face severe constraints in power consumption, computational capacity, and form factor that make traditional deep learning impractical. While lightweight architectures like MobileNet improve efficiency, they still demand thousands of parameters, limiting deployment on textile-integrated platforms. We introduce a convexified attention mechanism for wearable applications that dynamically weights features while preserving convexity through nonexpansive simplex projection and convex loss functions. Unlike conventional attention mechanisms using non-convex softmax operations, our approach employs Euclidean projection onto the probability simplex combined with multi-class hinge loss, ensuring global convergence guarantees. Implemented on a textile-based capacitive sensor with four connection points, our approach achieves 100.00\% accuracy on tap gestures and 100.00\% on swipe gestures -- consistent across 10-fold cross-validation and held-out test evaluation -- while requiring only 120--360 parameters, a 97\% reduction compared to conventional approaches. With sub-millisecond inference times (290--296$\mu$s) and minimal storage requirements ($<$7KB), our method enables gesture interfaces directly within e-textiles without external processing. Our evaluation, conducted in controlled laboratory conditions with a single-user dataset, demonstrates feasibility for basic gesture interactions. Real-world deployment would require validation across multiple users, environmental conditions, and more complex gesture vocabularies. These results demonstrate how convex optimization can enable efficient on-device machine learning for textile interfaces.

**AI Summary:** This research introduces a convexified attention mechanism for gesture recognition on wearable e-textile interfaces, addressing constraints in power consumption and computational capacity. The approach achieves high accuracy on tap and swipe gestures with minimal parameters and inference times, enabling on-device machine learning directly within e-textiles. While promising for basic gesture interactions, further validation across multiple users and complex gesture vocabularies is needed for real-world deployment.

---

## X-SYS: A Reference Architecture for Interactive Explanation Systems
**URL:** https://arxiv.org/abs/2602.12748

**Abstract:** The explainable AI (XAI) research community has proposed numerous technical methods, yet deploying explainability as systems remains challenging: Interactive explanation systems require both suitable algorithms and system capabilities that maintain explanation usability across repeated queries, evolving models and data, and governance constraints. We argue that operationalizing XAI requires treating explainability as an information systems problem where user interaction demands induce specific system requirements. We introduce X-SYS, a reference architecture for interactive explanation systems, that guides (X)AI researchers, developers and practitioners in connecting interactive explanation user interfaces (XUI) with system capabilities. X-SYS organizes around four quality attributes named STAR (scalability, traceability, responsiveness, and adaptability), and specifies a five-component decomposition (XUI Services, Explanation Services, Model Services, Data Services, Orchestration and Governance). It maps interaction patterns to system capabilities to decouple user interface evolution from backend computation. We implement X-SYS through SemanticLens, a system for semantic search and activation steering in vision-language models. SemanticLens demonstrates how contract-based service boundaries enable independent evolution, offline/online separation ensures responsiveness, and persistent state management supports traceability. Together, this work provides a reusable blueprint and concrete instantiation for interactive explanation systems supporting end-to-end design under operational constraints.

**AI Summary:** The research introduces X-SYS, a reference architecture for interactive explanation systems, to address the challenges of deploying explainability in AI systems. X-SYS focuses on scalability, traceability, responsiveness, and adaptability, and provides a five-component decomposition to guide researchers, developers, and practitioners in connecting interactive explanation user interfaces with system capabilities. The implementation of X-SYS through SemanticLens demonstrates how contract-based service boundaries, offline/online separation, and persistent state management support end-to-end design of interactive explanation systems under operational constraints.

---

## Artic: AI-oriented Real-time Communication for MLLM Video Assistant
**URL:** https://arxiv.org/abs/2602.12641

**Abstract:** AI Video Assistant emerges as a new paradigm for Real-time Communication (RTC), where one peer is a Multimodal Large Language Model (MLLM) deployed in the cloud. This makes interaction between humans and AI more intuitive, akin to chatting with a real person. However, a fundamental mismatch exists between current RTC frameworks and AI Video Assistants, stemming from the drastic shift in Quality of Experience (QoE) and more challenging networks. Measurements on our production prototype also confirm that current RTC fails, causing latency spikes and accuracy drops.
To address these challenges, we propose Artic, an AI-oriented RTC framework for MLLM Video Assistants, exploring the shift from "humans watching video" to "AI understanding video." Specifically, Artic proposes: (1) Response Capability-aware Adaptive Bitrate, which utilizes MLLM accuracy saturation to proactively cap bitrate, reserving bandwidth headroom to absorb future fluctuations for latency reduction; (2) Zero-overhead Context-aware Streaming, which allocates limited bitrate to regions most important for the response, maintaining accuracy even under ultra-low bitrates; and (3) Degraded Video Understanding Benchmark, the first benchmark evaluating how RTC-induced video degradation affects MLLM accuracy. Prototype experiments using real-world uplink traces show that compared with existing methods, Artic significantly improves accuracy by 15.12% and reduces latency by 135.31 ms. We will release the benchmark and codes at this https URL.

**AI Summary:** The research introduces Artic, an AI-oriented Real-time Communication (RTC) framework designed for Multimodal Large Language Model (MLLM) Video Assistants. The study highlights the challenges faced in current RTC frameworks when interacting with AI Video Assistants, such as latency spikes and accuracy drops. Through experiments and prototype testing, Artic is shown to significantly improve accuracy by 15.12% and reduce latency by 135.31 ms compared to existing methods, offering a more efficient and effective communication platform for humans interacting with AI.

---

## AI Agents for Inventory Control: Human-LLM-OR Complementarity
**URL:** https://arxiv.org/abs/2602.12631

**Abstract:** Inventory control is a fundamental operations problem in which ordering decisions are traditionally guided by theoretically grounded operations research (OR) algorithms. However, such algorithms often rely on rigid modeling assumptions and can perform poorly when demand distributions shift or relevant contextual information is unavailable. Recent advances in large language models (LLMs) have generated interest in AI agents that can reason flexibly and incorporate rich contextual signals, but it remains unclear how best to incorporate LLM-based methods into traditional decision-making pipelines.
We study how OR algorithms, LLMs, and humans can interact and complement each other in a multi-period inventory control setting. We construct InventoryBench, a benchmark of over 1,000 inventory instances spanning both synthetic and real-world demand data, designed to stress-test decision rules under demand shifts, seasonality, and uncertain lead times. Through this benchmark, we find that OR-augmented LLM methods outperform either method in isolation, suggesting that these methods are complementary rather than substitutes.
We further investigate the role of humans through a controlled classroom experiment that embeds LLM recommendations into a human-in-the-loop decision pipeline. Contrary to prior findings that human-AI collaboration can degrade performance, we show that, on average, human-AI teams achieve higher profits than either humans or AI agents operating alone. Beyond this population-level finding, we formalize an individual-level complementarity effect and derive a distribution-free lower bound on the fraction of individuals who benefit from AI collaboration; empirically, we find this fraction to be substantial.

**AI Summary:** This research explores the use of AI agents in inventory control, specifically examining how traditional OR algorithms, large language models (LLMs), and human decision-makers can complement each other in making ordering decisions. The study finds that combining OR algorithms with LLM methods leads to better performance than using either method alone, indicating their complementary nature. Additionally, a controlled experiment shows that human-AI teams achieve higher profits than humans or AI agents working alone, highlighting the potential benefits of collaboration between humans and AI in inventory control.

---

## PISHYAR: A Socially Intelligent Smart Cane for Indoor Social Navigation and Multimodal Human-Robot Interaction for Visually Impaired People
**URL:** https://arxiv.org/abs/2602.12597

**Abstract:** This paper presents PISHYAR, a socially intelligent smart cane designed by our group to combine socially aware navigation with multimodal human-AI interaction to support both physical mobility and interactive assistance. The system consists of two components: (1) a social navigation framework implemented on a Raspberry Pi 5 that integrates real-time RGB-D perception using an OAK-D Lite camera, YOLOv8-based object detection, COMPOSER-based collective activity recognition, D* Lite dynamic path planning, and haptic feedback via vibration motors for tasks such as locating a vacant seat; and (2) an agentic multimodal LLM-VLM interaction framework that integrates speech recognition, vision language models, large language models, and text-to-speech, with dynamic routing between voice-only and vision-only modes to enable natural voice-based communication, scene description, and object localization from visual input. The system is evaluated through a combination of simulation-based tests, real-world field experiments, and user-centered studies. Results from simulated and real indoor environments demonstrate reliable obstacle avoidance and socially compliant navigation, achieving an overall system accuracy of approximately 80% under different social conditions. Group activity recognition further shows robust performance across diverse crowd scenarios. In addition, a preliminary exploratory user study with eight visually impaired and low-vision participants evaluates the agentic interaction framework through structured tasks and a UTAUT-based questionnaire reveals high acceptance and positive perceptions of usability, trust, and perceived sociability during our experiments. The results highlight the potential of PISHYAR as a multimodal assistive mobility aid that extends beyond navigation to provide socially interactive support for such users.

**AI Summary:** The research presents PISHYAR, a socially intelligent smart cane that combines social navigation and multimodal human-robot interaction to assist visually impaired individuals. The system utilizes advanced technologies such as object detection, path planning, and speech recognition to provide reliable obstacle avoidance and socially compliant navigation. Evaluation through simulations, field experiments, and user studies demonstrates the system's effectiveness and high acceptance among visually impaired users, showcasing its potential as a comprehensive assistive mobility aid with interactive capabilities.

---

## Not a Silver Bullet for Loneliness: How Attachment and Age Shape Intimacy with AI Companions
**URL:** https://arxiv.org/abs/2602.12476

**Abstract:** Artificial intelligence (AI) companions are increasingly promoted as solutions for loneliness, often overlooking how personal dispositions and life-stage conditions shape artificial intimacy. Because intimacy is a primary coping mechanism for loneliness that varies by attachment style and age, we examine how different types of users form intimate relationships with AI companions in response to loneliness. Drawing on a hermeneutic literature review and a survey of 277 active AI companion users, we develop and test a model in which loneliness predicts intimacy, moderated by attachment insecurity and conditioned by age. Although the cross-sectional data limits causal inference, the results reveal a differentiated pattern. Loneliness is paradoxically associated with reduced intimacy for securely attached users but with increased intimacy for avoidant and ambivalent users, while anxious users show mixed effects. Older adults report higher intimacy even at lower loneliness levels. These findings challenge portrayals of AI companions as universal remedies for loneliness. Instead, artificial intimacy emerges as a sociotechnical process shaped by psychological dispositions and demographic conditions. The study clarifies who is most likely to form intimate relationships with AI companions and highlights ethical risks in commercial models that may capitalise on user vulnerability.

**AI Summary:** This research examines how attachment style and age influence the formation of intimate relationships with AI companions in response to loneliness. The study found that loneliness predicts intimacy with AI companions, with different effects based on attachment insecurity and age. Securely attached users showed reduced intimacy, while avoidant and ambivalent users showed increased intimacy in response to loneliness. Older adults reported higher intimacy levels even at lower levels of loneliness. These findings challenge the idea that AI companions are universal remedies for loneliness and highlight the importance of considering individual psychological dispositions and demographic factors in the development of artificial intimacy.

---

## SHAPR: A Solo Human-Centred and AI-Assisted Practice Framework for Research Software Development
**URL:** https://arxiv.org/abs/2602.12443

**Abstract:** Research software has become a central vehicle for inquiry and learning in many Higher Degree Research (HDR) contexts, where solo researchers increasingly develop software-based artefacts as part of their research methodology. At the same time, generative artificial intelligence is reshaping development practice, offering powerful forms of assistance while introducing new challenges for accountability, reflection, and methodological rigour. Although Action Design Research (ADR) provides a well-established foundation for studying and constructing socio-technical artefacts, it offers limited guidance on how its principles can be operationalised in the day-to-day practice of solo, AI-assisted research software development. This paper proposes the SHAPR framework (Solo, Human-centred, AI-assisted PRactice) as a practice-level operational framework that complements ADR by translating its high-level principles into actionable guidance for contemporary research contexts. SHAPR supports the enactment of ADR Building-Intervention-Evaluation cycles by making explicit the roles, artefacts, reflective practices, and lightweight governance mechanisms required to sustain human accountability and learning in AI-assisted development. The contribution of the paper is conceptual: SHAPR itself is treated as the primary design artefact and unit of analysis and is evaluated formatively through reflective analysis of its internal coherence, alignment with ADR principles, and applicability to solo research practice. By explicitly linking research software development, Human-AI collaboration, and reflective learning, this study contributes to broader discussions on how SHAPR can support both knowledge production and HDR researcher training.

**AI Summary:** The abstract discusses the development of the SHAPR framework, which aims to provide guidance for solo researchers using AI in research software development. The framework complements Action Design Research (ADR) principles by translating them into actionable steps for contemporary research contexts. By emphasizing human accountability, AI collaboration, and reflective learning, SHAPR aims to support knowledge production and training for Higher Degree Research (HDR) researchers.

---

## A Lightweight Cubature Kalman Filter for Attitude and Heading Reference Systems Using Simplified Prediction Equations
**URL:** https://arxiv.org/abs/2602.12283

**Abstract:** Attitude and Heading Reference Systems (AHRSs) are broadly applied wherever reliable orientation and motion sensing is required. In this paper, we present an improved Cubature Kalman Filter (CKF) with lower computational cost while maintaining estimation accuracy, which is named "Kaisoku Cubature Kalman Filter (KCKF)". The computationally efficient equations of the KCKF are derived by simplifying those of the CKF, while preserving equivalent mathematical relations. The lightweight prediction equations in the KCKF are derived by expanding the summation terms in the CKF and simplifying the result. This paper shows that the KCKF requires fewer floating-point operations (FLOPs) than the CKF. The controlled experimental results show that the KCKF reduces the computation time by approximately 19% compared to the CKF on a high-performance computer, whereas the KCKF reduces the computation time by approximately 15% compared to the CKF on a low-cost single-board computer. In addition, the KCKF maintains the attitude estimation accuracy of the CKF.

**AI Summary:** This research paper introduces the Kaisoku Cubature Kalman Filter (KCKF) as a lightweight alternative to the traditional Cubature Kalman Filter (CKF) for Attitude and Heading Reference Systems (AHRS). The KCKF reduces computational cost while maintaining estimation accuracy by simplifying prediction equations and requiring fewer floating-point operations. Experimental results demonstrate that the KCKF reduces computation time by approximately 19% on high-performance computers and 15% on low-cost single-board computers compared to the CKF, making it a more efficient option for AHRS applications.

---

## VIRENA: Virtual Arena for Research, Education, and Democratic Innovation
**URL:** https://arxiv.org/abs/2602.12207

**Abstract:** Digital platforms shape how people communicate, deliberate, and form opinions. Studying these dynamics has become increasingly difficult due to restricted data access, ethical constraints on real-world experiments, and limitations of existing research tools. VIRENA (Virtual Arena) is a platform that enables controlled experimentation in realistic social media environments. Multiple participants interact simultaneously in realistic replicas of feed-based platforms (Instagram, Facebook, Reddit) and messaging apps (WhatsApp, Messenger). Large language model-powered AI agents participate alongside humans with configurable personas and realistic behavior. Researchers can manipulate content moderation approaches, pre-schedule stimulus content, and run experiments across conditions through a visual interface requiring no programming skills. VIRENA makes possible research designs that were previously impractical: studying human--AI interaction in realistic social contexts, experimentally comparing moderation interventions, and observing group deliberation as it unfolds. Built on open-source technologies that ensure data remain under institutional control and comply with data protection requirements, VIRENA is currently in use at the University of Zurich and available for pilot collaborations. Designed for researchers, educators, and public organizations alike, VIRENA's no-code interface makes controlled social media simulation accessible across disciplines and sectors. This paper documents its design, architecture, and capabilities.

**AI Summary:** The VIRENA platform allows researchers to conduct controlled experiments in realistic social media environments, including platforms like Instagram, Facebook, and Reddit, as well as messaging apps like WhatsApp and Messenger. The platform features large language model-powered AI agents that interact alongside human participants with configurable personas. VIRENA enables the study of human-AI interaction, comparison of moderation interventions, and observation of group deliberation in a way that was previously impractical, making it a valuable tool for researchers, educators, and public organizations.

---

## Embodied AI Agents for Team Collaboration in Co-located Blue-Collar Work
**URL:** https://arxiv.org/abs/2602.12136

**Abstract:** Blue-collar work is often highly collaborative, embodied, and situated in shared physical environments, yet most research on collaborative AI has focused on white-collar work. This position paper explores how the embodied nature of AI agents can support team collaboration and communication in co-located blue-collar workplaces. From the context of our newly started CAI-BLUE research project, we present two speculative scenarios from industrial and maintenance contexts that illustrate how embodied AI agents can support shared situational awareness and facilitate inclusive communication across experience levels. We outline open questions related to embodied AI agent design around worker inclusion, agency, transformation of blue-collar collaboration practices over time, and forms of acceptable AI embodiments. We argue that embodiment is not just an aesthetic choice but should become a socio-material design strategy of AI systems in blue-collar workplaces.

**AI Summary:** This research paper highlights the importance of incorporating embodied AI agents in blue-collar workplaces to support team collaboration and communication. The study presents speculative scenarios from industrial and maintenance contexts to demonstrate how embodied AI agents can enhance shared situational awareness and inclusive communication across different experience levels. The findings suggest that designing AI systems with embodiment as a key strategy can improve collaboration practices and worker inclusion in blue-collar work environments.

---

## Wisdom of the LLM Crowd: A Large Scale Benchmark of Multi-Label U.S. Election-Related Harmful Social Media Content
**URL:** https://arxiv.org/abs/2602.11962

**Abstract:** The spread of election misinformation and harmful political content conveys misleading narratives and poses a serious threat to democratic integrity. Detecting harmful content at early stages is essential for understanding and potentially mitigating its downstream spread. In this study, we introduce USE24-XD, a large-scale dataset of nearly 100k posts collected from X (formerly Twitter) during the 2024 U.S. presidential election cycle, enriched with spatio-temporal metadata. To substantially reduce the cost of manual annotation while enabling scalable categorization, we employ six large language models (LLMs) to systematically annotate posts across five nuanced categories: Conspiracy, Sensationalism, Hate Speech, Speculation, and Satire. We validate LLM annotations with crowdsourcing (n = 34) and benchmark them against human annotators. Inter-rater reliability analyses show comparable agreement patterns between LLMs and humans, with LLMs exhibiting higher internal consistency and achieving up to 0.90 recall on Speculation. We apply a wisdom-of-the-crowd approach across LLMs to aggregate annotations and curate a robust multi-label dataset. 60% of posts receive at least one label. We further analyze how human annotator demographics, including political ideology and affiliation, shape labeling behavior, highlighting systematic sources of subjectivity in judgments of harmful content. The USE24-XD dataset is publicly released to support future research.

**AI Summary:** This study introduces the USE24-XD dataset, which consists of nearly 100k social media posts from the 2024 U.S. presidential election cycle, annotated by large language models (LLMs) across five categories of harmful content. The research shows that LLM annotations exhibit high agreement with human annotators, with LLMs achieving up to 0.90 recall on Speculation. The dataset, which is publicly available, can help in detecting and understanding harmful social media content related to elections, ultimately contributing to efforts to preserve democratic integrity.

---

## Who Does What? Archetypes of Roles Assigned to LLMs During Human-AI Decision-Making
**URL:** https://arxiv.org/abs/2602.11924

**Abstract:** LLMs are increasingly supporting decision-making across high-stakes domains, requiring critical reflection on the socio-technical factors that shape how humans and LLMs are assigned roles and interact during human-in-the-loop decision-making. This paper introduces the concept of human-LLM archetypes -- defined as re-curring socio-technical interaction patterns that structure the roles of humans and LLMs in collaborative decision-making. We describe 17 human-LLM archetypes derived from a scoping literature review and thematic analysis of 113 LLM-supported decision-making papers. Then, we evaluate these diverse archetypes across real-world clinical diagnostic cases to examine the potential effects of adopting distinct human-LLM archetypes on LLM outputs and decision outcomes. Finally, we present relevant tradeoffs and design choices across human-LLM archetypes, including decision control, social hierarchies, cognitive forcing strategies, and information requirements. Through our analysis, we show that selection of human-LLM interaction archetype can influence LLM outputs and decisions, bringing important risks and considerations for the designers of human-AI decision-making systems

**AI Summary:** This research paper explores the concept of human-LLM archetypes, which are recurring patterns that shape the roles of humans and LLMs in decision-making. The study identifies 17 archetypes through a literature review and analysis of LLM-supported decision-making papers, and evaluates their impact on decision outcomes in clinical diagnostic cases. The findings highlight the importance of considering the selection of human-LLM interaction archetypes in designing AI decision-making systems, as they can significantly influence LLM outputs and decisions.

---

## Decision Support System for Technology Opportunity Discovery: An Application of the Schwartz Theory of Basic Values
**URL:** https://arxiv.org/abs/2602.11855

**Abstract:** Discovering technology opportunities (TOD) remains a critical challenge for innovation management, especially in early-stage development where consumer needs are often unclear. Existing methods frequently fail to systematically incorporate end-user perspectives, resulting in a misalignment between technological potentials and market relevance. This study proposes a novel decision support framework that bridges this gap by linking technological feasibility with fundamental human values. The framework integrates two distinct lenses: the engineering-based Technology Readiness Levels (TRL) and Schwartz's theory of basic human values. By combining these, the approach enables a structured exploration of how emerging technologies may satisfy diverse user motivations. To illustrate the framework's feasibility and insight potential, we conducted exploratory workshops with general consumers and internal experts at Sony Computer Science Laboratories, Inc., analyzing four real-world technologies (two commercial successes and two failures). Two consistent patterns emerged: (1) internal experts identified a wider value landscape than consumers (vision gap), and (2) successful technologies exhibited a broader range of associated human values (value breadth), suggesting strategic foresight may underpin market success. This study contributes both a practical tool for early-stage R\&D decision-making and a theoretical link between value theory and innovation outcomes. While exploratory in scope, the findings highlight the promise of value-centric evaluation as a foundation for more human-centered technology opportunity discovery.

**AI Summary:** This research proposes a decision support framework that combines Technology Readiness Levels with Schwartz's theory of basic human values to help discover technology opportunities that align with consumer needs. The study conducted workshops with consumers and experts at Sony Computer Science Laboratories, Inc. to analyze real-world technologies and found that successful technologies aligned with a broader range of human values. This framework offers a practical tool for early-stage R&D decision-making and emphasizes the importance of value-centric evaluation in innovation outcomes.

---

## V-SHiNE: A Virtual Smart Home Framework for Explainability Evaluation
**URL:** https://arxiv.org/abs/2602.11775

**Abstract:** Explanations are essential for helping users interpret and trust autonomous smart-home decisions, yet evaluating their quality and impact remains methodologically difficult in this domain. V-SHiNE addresses this gap: a browser-based smarthome simulation framework for scalable and realistic assessment of explanations. It allows researchers to configure environments, simulate behaviors, and plug in custom explanation engines, with flexible delivery modes and rich interaction logging. A study with 159 participants demonstrates its feasibility. V-SHiNE provides a lightweight, reproducible platform for advancing user-centered evaluation of explainable intelligent systems

**AI Summary:** The research introduces V-SHiNE, a virtual smart home framework designed to evaluate the quality and impact of explanations in autonomous smart home decisions. The framework allows researchers to configure environments, simulate behaviors, and customize explanation engines, making it easier to assess explanations in a scalable and realistic manner. A study with 159 participants showed the feasibility of V-SHiNE, offering a lightweight and reproducible platform for advancing the evaluation of explainable intelligent systems in user-centered contexts.

---

## Building Intelligent User Interfaces for Human-AI Alignment
**URL:** https://arxiv.org/abs/2602.11753

**Abstract:** Aligning AI systems with human values fundamentally relies on effective human feedback. While significant research has addressed training algorithms, the role of user interface is often overlooked and only treated as an implementation detail rather than a critical factor of alignment. This paper addresses this gap by introducing a reference model that offers a systematic framework for analyzing where and how user interface contributions can improve human-AI alignment. The structured taxonomy of the reference model is demonstrated through two case studies and a preliminary investigation featuring six user interfaces. This work highlights opportunities to advance alignment through human-computer interaction.

**AI Summary:** This research paper emphasizes the importance of user interfaces in aligning AI systems with human values. It introduces a reference model that systematically analyzes how user interface design can improve human-AI alignment, showcasing this through case studies and user interface evaluations. The findings suggest that focusing on human-computer interaction can significantly enhance the alignment between AI systems and human values.

---

## Mapping the Landscape of Affective Extended Reality: A Scoping Review of Biodata-Driven Systems for Understanding and Sharing Emotions
**URL:** https://arxiv.org/abs/2602.11710

**Abstract:** This paper introduces the notion of affective extended reality (XR) to characterise XR systems that use biodata to enable understanding of emotions. The HCI literature contains many such systems, but they have not yet been mapped into a coherent whole. To address this, we conducted a scoping review of 82 papers that explore the nexus of biodata, emotions, and XR. We analyse the technologies used in these systems, the interaction techniques employed, and the methods used to evaluate their effectiveness. Through our analysis, we contribute a mapping of the current landscape of affective XR, revealing diversity in the goals for enabling emotion sharing. We demonstrate how HCI researchers have explored the design of the interaction flows in XR biofeedback systems, highlighting key design dimensions and challenges in understanding emotions. We discuss underused approaches for emotion sharing and highlight opportunities for future research on affective XR.

**AI Summary:** This research paper introduces the concept of affective extended reality (XR) systems that utilize biodata to understand emotions. Through a scoping review of 82 papers, the authors analyze the technologies, interaction techniques, and evaluation methods used in these systems. The study reveals a diverse landscape of affective XR systems and highlights design dimensions, challenges, and opportunities for future research in this area.

---

## "I Was Told to Come Back and Share This": Social Media-Based Near-Death Experience Disclosures as Expressions of Spiritual Beliefs
**URL:** https://arxiv.org/abs/2602.11663

**Abstract:** People who experienced near-death events often turn to personal expression as a way of processing trauma and articulating beliefs. While scholars have examined how individuals share near-death experiences (NDEs), limited research has explored how these narratives are communicated collaboratively on today's social media platforms. We analyzed 200 randomly sampled TikTok videos tagged with #nde and related hashtags. Content analysis revealed that individuals often use NDE narratives to articulate personal meaning, with spiritual and religious themes appearing in the majority of posts and serving as a means of exploring and making sense of personal spiritual perspectives. Consistent with this, analyses of comment sections reveal that videos containing spiritual themes tend to attract more engagement and foster deeper conversations around faith and meaning. Our findings offer insights into how online platforms facilitate community-level engagement with spirituality, and suggest implications for design of spaces that support shared expression and connection in specialized communities.

**AI Summary:** This research explores how individuals share near-death experiences (NDEs) on social media platforms, specifically TikTok. The study found that NDE narratives are often used to articulate personal meaning, with spiritual and religious themes being prevalent in these posts. Videos with spiritual themes tended to attract more engagement and foster deeper conversations around faith and meaning, highlighting the significance of online platforms in facilitating community-level engagement with spirituality.

---

## Behavioral Indicators of Overreliance During Interaction with Conversational Language Models
**URL:** https://arxiv.org/abs/2602.11567

**Abstract:** LLMs are now embedded in a wide range of everyday scenarios. However, their inherent hallucinations risk hiding misinformation in fluent responses, raising concerns about overreliance on AI. Detecting overreliance is challenging, as it often arises in complex, dynamic contexts and cannot be easily captured by post-hoc task outcomes. In this work, we aim to investigate how users' behavioral patterns correlate with overreliance. We collected interaction logs from 77 participants working with an LLM injected plausible misinformation across three real-world tasks and we assessed overreliance by whether participants detected and corrected these errors. By semantically encoding and clustering segments of user interactions, we identified five behavioral patterns linked to overreliance: users with low overreliance show careful task comprehension and fine-grained navigation; users with high overreliance show frequent copy-paste, skipping initial comprehension, repeated LLM references, coarse locating, and accepting misinformation despite hesitation. We discuss design implications for mitigation.

**AI Summary:** This research investigates behavioral indicators of overreliance on conversational language models (LLMs) by analyzing user interactions with LLMs injected with misinformation. The study found that users with low overreliance exhibited careful task comprehension and navigation, while those with high overreliance displayed behaviors such as frequent copy-pasting, skipping initial comprehension, and accepting misinformation despite hesitation. These findings have implications for designing AI systems to mitigate overreliance and improve user interactions with LLMs.

---

## Implications of AI Involvement for Trust in Expert Advisory Workflows Under Epistemic Dependence
**URL:** https://arxiv.org/abs/2602.11522

**Abstract:** The increasing integration of AI-powered tools into expert workflows, such as medicine, law, and finance, raises a critical question: how does AI involvement influence a user's trust in the human expert, the AI system, and their combination? To investigate this, we conducted a user study (N=77) featuring a simulated course-planning task. We compared various conditions that differed in both the presence of AI and the specific mode of human-AI collaboration. Our results indicate that while the advisor's ability to create a correct schedule is important, the user's perception of expertise and trust is also influenced by how the expert utilized the AI assistant. These findings raise important considerations for the design of human-AI hybrid teams, particularly when the adoption of recommendations depends on the end-user's perception of the recommender's expertise.

**AI Summary:** This research explores how the integration of AI tools into expert workflows affects trust in human experts and AI systems. The study found that users' perception of expertise and trust is influenced by how the expert utilizes the AI assistant, not just the accuracy of the recommendations. These findings have implications for designing effective human-AI hybrid teams, especially when user trust in the recommender's expertise is crucial for adoption of recommendations.

---

## An Educational Human Machine Interface Providing Request-to-Intervene Trigger and Reason Explanation for Enhancing the Driver's Comprehension of ADS's System Limitations
**URL:** https://arxiv.org/abs/2602.11507

**Abstract:** Level 3 automated driving systems (ADS) have attracted significant attention and are being commercialized. A level 3 ADS prompts the driver to take control by issuing a request to intervene (RtI) when its operational design domains (ODD) are exceeded. However, complex traffic situations can cause drivers to perceive multiple potential triggers of RtI simultaneously, causing hesitation or confusion during take-over. Therefore, drivers need to clearly understand the ADS's system limitations to ensure safe take-over. This study proposes a voice-based educational human machine interface~(HMI) for providing RtI trigger cues and reason to help drivers understand ADS's system limitations. The results of a between-group experiment using a driving simulator showed that incorporating effective trigger cues and reason into the RtI was related to improved driver comprehension of the ADS's system limitations. Moreover, most participants, instructed via the proposed method, could proactively take over control of the ADS in cases where RtI fails; meanwhile, their number of collisions was lower compared with the other RtI HMI conditions. Therefore, using the proposed method to continually enhance the driver's understanding of the system limitations of ADS through the proposed method is associated with safer and more effective real-time interactions with ADS.

**AI Summary:** This research study focuses on enhancing driver comprehension of level 3 automated driving systems (ADS) by providing clear trigger cues and reasons for intervention. The study found that incorporating effective trigger cues and reasons into the request-to-intervene (RtI) process improved driver understanding of the ADS system limitations. Drivers who were educated through the proposed voice-based educational human machine interface were able to proactively take control of the ADS in cases of failure, resulting in fewer collisions and safer interactions with the system.

---

## Data-driven modelling of low-dimensional dynamical structures underlying complex full-body human movement
**URL:** https://arxiv.org/abs/2602.11492

**Abstract:** One of the central challenges in the study of human motor control and learning is the degrees-of-freedom problem. Although the dynamical systems approach (DSA) has provided valuable insights into addressing this issue, its application has largely been confined to cyclic or simplified motor movements. To overcome this limitation, the present study employs neural ordinary differential equations (NODEs) to model the time evolution of non-cyclic full-body movements as a low-dimensional latent dynamical system. Given the temporal complexity full-body kinematic chains, baseball pitching was selected as a representative target movement to examine whether DSA could be extended to more complex, ecologically valid human movements. Results of the verification experiment demonstrated that the time evolution of a complex pitching motion could be accurately predicted (R^2 > 0.45) using the NODE-based dynamical model. Notably, approximately 50% of the variance in the latter half of the pitching motion was explained using only the initial ~8% of the temporal sequence, underscoring how subsequent movement evolves from initial conditions according to ODE-defined dynamics in latent space. These findings indicate the potential to extend the DSA to more complex and ecologically valid forms of human movement.

**AI Summary:** This research explores using neural ordinary differential equations (NODEs) to model the time evolution of non-cyclic full-body movements, such as baseball pitching, as a low-dimensional latent dynamical system. The study demonstrates that the time evolution of complex pitching motions can be accurately predicted using this approach, with approximately 50% of the variance in the latter half of the motion explained by the initial 8% of the temporal sequence. These findings suggest the potential to extend the dynamical systems approach to more complex and ecologically valid forms of human movement.

---

## Understanding Persuasive Interactions between Generative Social Agents and Humans: The Knowledge-based Persuasion Model (KPM)
**URL:** https://arxiv.org/abs/2602.11483

**Abstract:** Generative social agents (GSAs) use artificial intelligence to autonomously communicate with human users in a natural and adaptive manner. Currently, there is a lack of theorizing regarding interactions with GSAs, and likewise, few guidelines exist for studying how they influence user attitudes and behaviors. Consequently, we propose the Knowledge-based Persuasion Model (KPM) as a novel theoretical framework. According to the KPM, a GSA's self, user, and context-related knowledge drives its persuasive behavior, which in turn shapes the attitudes and behaviors of a responding human user. By synthesizing existing research, the model offers a structured approach to studying interactions with GSAs, supporting the development of agents that motivate rather than manipulate humans. Accordingly, the KPM encourages the integration of responsible GSAs that adhere to social norms and ethical standards with the goal of increasing user wellbeing. Implications of the KPM for research and application domains such as healthcare and education are discussed.

**AI Summary:** The research abstract introduces the Knowledge-based Persuasion Model (KPM), which aims to provide a theoretical framework for understanding interactions between generative social agents (GSAs) and humans. The KPM suggests that a GSA's knowledge influences its persuasive behavior, which in turn impacts human attitudes and behaviors. The model emphasizes the importance of developing responsible GSAs that adhere to ethical standards and social norms to promote user wellbeing in areas such as healthcare and education.

---

## Interpretive Cultures: Resonance, randomness, and negotiated meaning for AI-assisted tarot divination
**URL:** https://arxiv.org/abs/2602.11367

**Abstract:** While generative AI tools are increasingly adopted for creative and analytical tasks, their role in interpretive practices, where meaning is subjective, plural, and non-causal, remains poorly understood. This paper examines AI-assisted tarot reading, a divinatory practice in which users pose a query, draw cards through a randomized process, and ask AI systems to interpret the resulting symbols. Drawing on interviews with tarot practitioners and Hartmut Rosa's Theory of Resonance, we investigate how users seek, negotiate, and evaluate resonant interpretations in a context where no causal relationship exists between the query and the data being interpreted. We identify distinct ways practitioners incorporate AI into their interpretive workflows, including using AI to navigate uncertainty and self-doubt, explore alternative perspectives, and streamline or extend existing divinatory practices. Based on these findings, we offer design recommendations for AI systems that support interpretive meaning-making without collapsing ambiguity or foreclosing user agency.

**AI Summary:** This research explores the use of AI in tarot reading, a practice where subjective and non-causal meanings are important. The study shows how users incorporate AI into their interpretive processes to navigate uncertainty, explore different perspectives, and enhance existing practices. The findings suggest design recommendations for AI systems that can support interpretive meaning-making without removing ambiguity or user agency.

---

## Situated, Dynamic, and Subjective: Envisioning the Design of Theory-of-Mind-Enabled Everyday AI with Industry Practitioners
**URL:** https://arxiv.org/abs/2602.11342

**Abstract:** Theory of Mind (ToM) -- the ability to infer what others are thinking (e.g., intentions) from observable cues -- is traditionally considered fundamental to human social interactions. This has sparked growing efforts in building and benchmarking AI's ToM capability, yet little is known about how such capability could translate into the design and experience of everyday user-facing AI products and services. We conducted 13 co-design sessions with 26 U.S.-based AI practitioners to envision, reflect, and distill design recommendations for ToM-enabled everyday AI products and services that are both future-looking and grounded in the realities of AI design and development practices. Analysis revealed three interrelated design recommendations: ToM-enabled AI should 1) be situated in the social context that shape users' mental states, 2) be responsive to the dynamic nature of mental states, and 3) be attuned to subjective individual differences. We surface design tensions within each recommendation that reveal a broader gap between practitioners' envisioned futures of ToM-enabled AI and the realities of current AI design and development practices. These findings point toward the need to move beyond static, inference-driven approach to ToM and toward designing ToM as a pervasive capability that supports continuous human-AI interaction loops.

**AI Summary:** This research explores the design implications of Theory of Mind (ToM) in everyday AI products and services, based on insights from 26 AI practitioners. The study highlights the importance of situating ToM in social contexts, being responsive to dynamic mental states, and recognizing subjective individual differences. The findings suggest a need to move towards designing ToM as a pervasive capability that supports continuous human-AI interaction loops, bridging the gap between practitioners' envisioned futures and current AI design practices.

---

## Same Feedback, Different Source: How AI vs. Human Feedback Shapes Learner Engagement
**URL:** https://arxiv.org/abs/2602.11311

**Abstract:** When learners receive feedback, what they believe about its source may shape how they engage with it. As AI is used alongside human instructors, understanding these attribution effects is essential for designing effective hybrid AI-human educational systems. We designed a creative coding interface that isolates source attribution while controlling for content: all participants receive identical LLM-generated feedback, but half see it attributed to AI and half to a human teaching assistant (TA). We found two key results. First, perceived feedback source affected engagement: learners in the TA condition spent significantly more time and effort (d = 0.88-1.56) despite receiving identical feedback. Second, perceptions differed: AI-attributed feedback ratings were predicted by prior trust in AI (r = 0.85), while TA-attributed ratings were predicted by perceived genuineness (r = 0.65). These findings suggest that feedback source shapes both engagement and evaluation, with implications for hybrid educational system design.

**AI Summary:** This study examines how learners engage with feedback based on their perception of the source (AI vs. human). The research found that learners were more engaged when feedback was attributed to a human teaching assistant, even when the feedback itself was identical. Additionally, perceptions of feedback varied based on the source, with trust in AI influencing ratings for AI-attributed feedback and perceived genuineness influencing ratings for TA-attributed feedback. These findings have implications for designing effective hybrid AI-human educational systems.

---

## DiSCoKit: An Open-Source Toolkit for Deploying Live LLM Experiences in Survey Research
**URL:** https://arxiv.org/abs/2602.11230

**Abstract:** Advancing social-scientific research of human-AI interaction dynamics and outcomes often requires researchers to deliver experiences with live large-language models (LLMs) to participants through online survey platforms. However, technical and practical challenges (from logging chat data to manipulating AI behaviors for experimental designs) often inhibit survey-based deployment of AI stimuli. We developed DiSCoKit--an open-source toolkit for deploying live LLM experiences (e.g., ones based on models delivered through Microsoft Azure portal) through JavaScript-enabled survey platforms (e.g., Qualtrics). This paper introduces that toolkit, explaining its scientific impetus, describes its architecture and operation, as well as its deployment possibilities and limitations.

**AI Summary:** The research paper introduces DiSCoKit, an open-source toolkit designed to facilitate the deployment of live large-language models (LLMs) in survey research. The toolkit addresses technical and practical challenges researchers face when delivering AI experiences to participants, such as logging chat data and manipulating AI behaviors for experimental designs. DiSCoKit allows for the deployment of LLM experiences through JavaScript-enabled survey platforms like Qualtrics, providing researchers with a valuable tool for studying human-AI interaction dynamics and outcomes in social-scientific research.

---

## Althea: Human-AI Collaboration for Fact-Checking and Critical Reasoning
**URL:** https://arxiv.org/abs/2602.11161

**Abstract:** The web's information ecosystem demands fact-checking systems that are both scalable and epistemically trustworthy. Automated approaches offer efficiency but often lack transparency, while human verification remains slow and inconsistent. We introduce Althea, a retrieval-augmented system that integrates question generation, evidence retrieval, and structured reasoning to support user-driven evaluation of online claims. On the AVeriTeC benchmark, Althea achieves a Macro-F1 of 0.44, outperforming standard verification pipelines and improving discrimination between supported and refuted claims. We further evaluate Althea through a controlled user study and a longitudinal survey experiment (N = 642), comparing three interaction modes that vary in the degree of scaffolding: an Exploratory mode with guided reasoning, a Summary mode providing synthesized verdicts, and a Self-search mode that offers procedural guidance without algorithmic intervention. Results show that guided interaction produces the strongest immediate gains in accuracy and confidence, while self-directed search yields the most persistent improvements over time. This pattern suggests that performance gains are not driven solely by effort or exposure, but by how cognitive work is structured and internalized.

**AI Summary:** The research introduces Althea, a system that combines human and AI collaboration for fact-checking online claims. Althea outperforms standard verification pipelines in discriminating between supported and refuted claims, achieving a Macro-F1 of 0.44 on the AVeriTeC benchmark. The study shows that guided interaction with Althea leads to immediate gains in accuracy and confidence, while self-directed search results in persistent improvements over time, indicating that the structure of cognitive work plays a significant role in performance gains.

---

