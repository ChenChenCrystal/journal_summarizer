# arXiv cs.AI Summary â€“ 2026-01-12

## A Framework for Optimizing Human-Machine Interaction in Classification Systems
**URL:** https://arxiv.org/abs/2601.05974

**Abstract:** Automated decision systems increasingly rely on human oversight to ensure accuracy in uncertain cases. This paper presents a practical framework for optimizing such human-in-the-loop classification systems using a double-threshold policy. Instead of relying on a single decision cutoff, the system defines two thresholds (a lower and an upper) to automatically accept or reject confident cases while routing ambiguous ones for human review. We formalize this problem as an optimization task that balances system accuracy against human review workload and demonstrate its behavior through extensive Monte Carlo simulations. Our results quantify how different probability score distributions affect the efficiency of human intervention and identify the regions of diminishing returns where additional review yields minimal benefit. The framework provides a general, reproducible method for improving reliability in any decision pipeline requiring selective human validation, including applications in entity resolution, fraud detection, medical triage, and content moderation.

**AI Summary:** This paper introduces a framework for optimizing human-machine interaction in classification systems by implementing a double-threshold policy to determine which cases require human review. By balancing system accuracy with human review workload, the framework aims to improve efficiency in decision pipelines requiring selective human validation. The results from Monte Carlo simulations demonstrate how different probability score distributions impact the effectiveness of human intervention, offering a reproducible method for enhancing reliability in various applications such as entity resolution, fraud detection, medical triage, and content moderation.

---

## How to Analyse Interviews: A Documentary Method of Interpretation
**URL:** https://arxiv.org/abs/2601.05871

**Abstract:** Interviews are commonplace in HCI. This paper presents a novel documentary method of interpretation that supports analysis of the topics contained within a collection of transcripts, topics that are endogenous to it and which elaborate participants collective reasoning about issues of relevance to research. We contrast endogenous topic analysis with established qualitative approaches, including content analysis, grounded theory, interpretative phenomenological analysis, and thematic analysis, to draw out the distinctive character of the documentary method of interpretation. Unlike established methods, the DMI does not require that the analyst be proficient in qualitative analysis, or have sound knowledge of underlying theories and methods. The DMI is a members method, not a social science method, that relies on mastery of natural language; a competence most people possess.

**AI Summary:** This paper introduces a new documentary method of interpretation (DMI) for analyzing interview transcripts in the field of HCI. The DMI focuses on identifying topics that are inherent to the transcripts and reflect participants' collective reasoning on relevant issues. Unlike traditional qualitative analysis methods, the DMI does not require specialized knowledge or training, making it accessible to a wider range of researchers. The DMI is based on natural language mastery, making it a user-friendly approach for analyzing interviews.

---

## Decoding Workload and Agreement From EEG During Spoken Dialogue With Conversational AI
**URL:** https://arxiv.org/abs/2601.05825

**Abstract:** Passive brain-computer interfaces offer a potential source of implicit feedback for alignment of large language models, but most mental state decoding has been done in controlled tasks. This paper investigates whether established EEG classifiers for mental workload and implicit agreement can be transferred to spoken human-AI dialogue. We introduce two conversational paradigms - a Spelling Bee task and a sentence completion task- and an end-to-end pipeline for transcribing, annotating, and aligning word-level conversational events with continuous EEG classifier output. In a pilot study, workload decoding showed interpretable trends during spoken interaction, supporting cross-paradigm transfer. For implicit agreement, we demonstrate continuous application and precise temporal alignment to conversational events, while identifying limitations related to construct transfer and asynchronous application of event-based classifiers. Overall, the results establish feasibility and constraints for integrating passive BCI signals into conversational AI systems.

**AI Summary:** This research explores the potential of using EEG signals to decode mental workload and implicit agreement during human-AI dialogue. The study introduces two conversational paradigms and an end-to-end pipeline for aligning EEG classifier output with conversational events. The results show the feasibility of integrating passive BCI signals into conversational AI systems, with interpretable trends in workload decoding and precise temporal alignment for implicit agreement, while also highlighting limitations related to construct transfer and asynchronous application of event-based classifiers.

---

## Improving Clinical Data Accessibility Through Automated FHIR Data Transformation Tools
**URL:** https://arxiv.org/abs/2601.05822

**Abstract:** The Fast Healthcare Interoperability Resources (FHIR) standard has emerged as a widely adopted specification for exchanging structured clinical data across healthcare systems. However, raw FHIR resources are often complex, verbose, and difficult for clinicians and analysts to interpret without specialized tooling. This paper presents a lightweight, browser-based system that improves the accessibility of FHIR data by automatically transforming raw JSON resources into human-readable PDF and Excel reports, along with interactive data visualizations. The system supports both remote retrieval of FHIR resources from server endpoints and the upload of local FHIR JSON files, enabling both online and offline analysis. Using a modular React architecture with jsPDF, xlsx, and Recharts, the tool parses, normalizes, visualizes, and exports FHIR data in an intuitive format. Evaluation results demonstrate that the system enhances interpretability and usability while preserving the semantic integrity of FHIR structures. Limitations and future extensions, including expanded FHIR profile support and clinical validation, are discussed.

**AI Summary:** This research paper introduces a browser-based system that automatically transforms complex FHIR data into easy-to-read PDF and Excel reports, as well as interactive data visualizations. The system improves the accessibility and interpretability of clinical data for clinicians and analysts, both online and offline. Evaluation results show that the tool enhances usability without compromising the semantic integrity of FHIR structures, suggesting potential for further development in supporting expanded FHIR profiles and clinical validation.

---

## SAFE: Secure and Accurate Federated Learning for Privacy-Preserving Brain-Computer Interfaces
**URL:** https://arxiv.org/abs/2601.05789

**Abstract:** Electroencephalogram (EEG)-based brain-computer interfaces (BCIs) are widely adopted due to their efficiency and portability; however, their decoding algorithms still face multiple challenges, including inadequate generalization, adversarial vulnerability, and privacy leakage. This paper proposes Secure and Accurate FEderated learning (SAFE), a federated learning-based approach that protects user privacy by keeping data local during model training. SAFE employs local batch-specific normalization to mitigate cross-subject feature distribution shifts and hence improves model generalization. It further enhances adversarial robustness by introducing perturbations in both the input space and the parameter space through federated adversarial training and adversarial weight perturbation. Experiments on five EEG datasets from motor imagery (MI) and event-related potential (ERP) BCI paradigms demonstrated that SAFE consistently outperformed 14 state-of-the-art approaches in both decoding accuracy and adversarial robustness, while ensuring privacy protection. Notably, it even outperformed centralized training approaches that do not consider privacy protection at all. To our knowledge, SAFE is the first algorithm to simultaneously achieve high decoding accuracy, strong adversarial robustness, and reliable privacy protection without using any calibration data from the target subject, making it highly desirable for real-world BCIs.

**AI Summary:** The research paper introduces SAFE, a federated learning-based approach for EEG-based brain-computer interfaces that addresses challenges such as inadequate generalization, adversarial vulnerability, and privacy leakage. SAFE utilizes local batch-specific normalization to improve model generalization, while also enhancing adversarial robustness through federated adversarial training and adversarial weight perturbation. Experimental results show that SAFE outperforms 14 state-of-the-art approaches in decoding accuracy and adversarial robustness, even surpassing centralized training methods without compromising privacy protection. This makes SAFE a desirable algorithm for real-world BCIs, as it achieves high decoding accuracy, strong adversarial robustness, and reliable privacy protection without requiring calibration data from the target subject.

---

## Advancing credit mobility through stakeholder-informed AI design and adoption
**URL:** https://arxiv.org/abs/2601.05666

**Abstract:** Transferring from a 2-year to a 4-year college is crucial for socioeconomic mobility, yet students often face challenges ensuring their credits are fully recognized, leading to delays in their academic progress and unexpected costs. Determining whether courses at different institutions are equivalent (i.e., articulation) is essential for successful credit transfer, as it minimizes unused credits and increases the likelihood of bachelor's degree completion. However, establishing articulation agreements remains time- and resource-intensive, as all candidate articulations are reviewed manually. Although recent efforts have explored the use of artificial intelligence to support this work, its use in articulation practice remains limited. Given these challenges and the need for scalable support, this study applies artificial intelligence to suggest articulations between institutions in collaboration with the State University of New York system, one of the largest systems of higher education in the US. To develop our methodology, we first surveyed articulation staff and faculty to assess adoption rates of baseline algorithmic recommendations and gather feedback on perceptions and concerns about these recommendations. Building on these insights, we developed a supervised alignment method that addresses superficial matching and institutional biases in catalog descriptions, achieving a 5.5-fold improvement in accuracy over previous methods. Based on articulation predictions of this method and a 61% average surveyed adoption rate among faculty and staff, these findings project a 12-fold increase in valid credit mobility opportunities that would otherwise remain unrealized. This study suggests that stakeholder-informed design of AI in higher education administration can expand student credit mobility and help reshape current institutional decision-making in course articulation.

**AI Summary:** This study focuses on the use of artificial intelligence to improve credit transfer between 2-year and 4-year colleges, addressing challenges in articulation agreements. By surveying stakeholders and developing a supervised alignment method, the study achieved significant improvements in accuracy and projected a 12-fold increase in valid credit mobility opportunities. The findings highlight the potential for AI to support higher education administration and improve student outcomes in credit transfer.

---

## Productive Discussion Moves in Groups Addressing Controversial Issues
**URL:** https://arxiv.org/abs/2601.05651

**Abstract:** Engaging learners in dialogue around controversial issues is essential for examining diverse values and perspectives in pluralistic societies. While prior research has identified productive discussion moves mainly in STEM-oriented contexts, less is known about what constitutes productive discussion in ethical and value-laden discussions. This study investigates productive discussion in AI ethics dilemmas using a dialogue-centric learning analytics approach. We analyze small-group discussions among undergraduate students through a hybrid method that integrates expert-informed coding with data-driven topic modeling. This process identifies 14 discussion moves across five categories, including Elaborating Ideas, Position Taking, Reasoning & Justifications, Emotional Expression, and Discussion Management. We then examine how these moves relate to discussion quality and analyze sequential interaction patterns using Ordered Network Analysis. Results indicate that emotive and experiential arguments and explicit acknowledgment of ambiguity are strong positive predictors of discussion quality, whereas building on ideas is negatively associated. Ordered Network Analysis further reveals that productive discussions are characterized by interactional patterns that connect emotional expressions to evidence-based reasoning. These findings suggest that productive ethical discussion is grounded not only in reasoning and justification but also in the constructive integration of emotional expression.

**AI Summary:** This study explores productive discussion moves in small-group discussions on AI ethics dilemmas among undergraduate students. The research identifies 14 discussion moves across five categories and finds that emotive and experiential arguments, as well as acknowledgment of ambiguity, positively impact discussion quality. The study also highlights the importance of integrating emotional expression with evidence-based reasoning in productive ethical discussions.

---

## Secure Text Entry using a Virtual Radial Keyboard with Dynamically Resized Keys and Non-Intrusive Randomization
**URL:** https://arxiv.org/abs/2601.05516

**Abstract:** As virtual reality (VR) becomes more widely adopted, secure and efficient text entry is an increasingly critical need. In this paper, we identify a vulnerability in a state-of-the-art secure VR text entry method and introduce a novel virtual radial keyboard designed to achieve a balance between security with usability. Keys are arranged alphabetically in a circular layout, with each key selected by controller rotation and dynamically expanding to facilitate precise selection. A randomized rotation mechanism shifts the keyboard after each keystroke, preserving relative key positions while disrupting absolute spatial mappings to protect against inference attacks. We conducted a within-subject study (N=30) comparing our method with the prior secure technique and a standard QWERTY keyboard. Results showed that the radial keyboard significantly improves resistance to keystroke prediction attacks while incurring a tradeoff in entry speed and subjective workload due to the unfamiliar non-QWERTY layout. However, both quantitative trends and qualitative feedback indicate strong potential for performance improvements with practice. We also discuss design implications, possible interface refinements, and directions for future work, including layout variations and visual enhancements.

**AI Summary:** This research introduces a novel virtual radial keyboard for secure and efficient text entry in virtual reality environments. The keyboard features dynamically resized keys and non-intrusive randomization to enhance security while maintaining usability. Results from a user study show that the radial keyboard improves resistance to keystroke prediction attacks, although there is a tradeoff in entry speed and workload compared to traditional QWERTY keyboards. With further practice and refinement, the radial keyboard shows potential for improved performance in the future.

---

## Feedback Effects on Cognitive Dynamics: Network-Based Insights from EEG Patterns and Behavioral Performance
**URL:** https://arxiv.org/abs/2601.05450

**Abstract:** This study examines the impact of feedback on Electroencephalography (EEG) activity and performance during the Reading the Mind in the Eyes Test. In a within-subject design, eleven participants completed the test under Feedback and No-Feedback conditions. Using the principles of Epistemic Network Analysis (ENA) and Ordered Network Analysis (ONA), we extend these network-based models to explore the link between neural dynamics and task outcomes. ENA results showed that feedback is associated with stronger connections between higher frequency EEG bands (Beta and Gamma) and correct responses, while the absence of feedback activated lower frequency bands (Theta and Alpha). ONA further disclosed directional shifts toward higher frequency activity preceding correct answers in the Feedback condition, whereas the No-Feedback condition showed more self-connections in lower bands and a higher occurrence of wrong answers, suggesting less effective reasoning strategies without feedback. Both ENA and ONA revealed statistically significant differences between conditions (p = 0.01, Cohen's d > 2). This study highlights the methodological benefits of integrating EEG with ENA and ONA for network analysis, capturing both temporal and relational dynamics, as well as the practical insight that feedback can foster more effective reasoning processes and improve task performance.

**AI Summary:** This study investigates the impact of feedback on EEG activity and performance during a cognitive test. The results show that feedback is associated with stronger connections between higher frequency EEG bands and correct responses, while the absence of feedback activates lower frequency bands. The study suggests that feedback can enhance reasoning processes and improve task performance, highlighting the importance of integrating EEG with network-based models for analyzing cognitive dynamics.

---

## Protosampling: Enabling Free-Form Convergence of Sampling and Prototyping through Canvas-Driven Visual AI Generation
**URL:** https://arxiv.org/abs/2601.05401

**Abstract:** As an emergent process, creativity relies on explorations via sampling and prototyping for problem construction. These activities compile knowledge, provide a context enveloping the solution, and answer questions. With Generative AI, practitioners can go beyond sampling existing media towards instantly generating and remixing new ones. We refer to this convergence as 'protosampling'. Using existing literature we ground a definition for protosampling and operationalize it through Atelier, a canvas-like system that leverages a variety of generative image and video models for visual creation. Atelier: (1) blends the spaces for thinking and creation, where both references and generated assets co-exist in one space, (2) provides various encapsulated technical workflows that focus on the activity at hand, and (3) enables navigating emergence through interactive visualizations, smart search, and collections. Protosampling as a lens reframes creative work to emphasize the process itself and how seemingly disjointed thoughts can tightly interweave into a final solution.

**AI Summary:** The research introduces the concept of 'protosampling', a process that combines sampling and prototyping through Generative AI to enhance creativity and problem-solving. The Atelier system is developed to facilitate protosampling by integrating references and generated assets in a canvas-like space, providing technical workflows, and enabling interactive visualizations and smart search. This approach reframes creative work by emphasizing the process of exploration and generation, showing how seemingly unrelated ideas can come together to form a cohesive solution.

---

## Illusions of Confidence? Diagnosing LLM Truthfulness via Neighborhood Consistency
**URL:** https://arxiv.org/abs/2601.05905

**Abstract:** As Large Language Models (LLMs) are increasingly deployed in real-world settings, correctness alone is insufficient. Reliable deployment requires maintaining truthful beliefs under contextual perturbations. Existing evaluations largely rely on point-wise confidence like Self-Consistency, which can mask brittle belief. We show that even facts answered with perfect self-consistency can rapidly collapse under mild contextual interference. To address this gap, we propose Neighbor-Consistency Belief (NCB), a structural measure of belief robustness that evaluates response coherence across a conceptual neighborhood. To validate the efficiency of NCB, we introduce a new cognitive stress-testing protocol that probes outputs stability under contextual interference. Experiments across multiple LLMs show that the performance of high-NCB data is relatively more resistant to interference. Finally, we present Structure-Aware Training (SAT), which optimizes context-invariant belief structure and reduces long-tail knowledge brittleness by approximately 30%. Code will be available at this https URL.

**AI Summary:** This research highlights the importance of maintaining truthful beliefs in Large Language Models (LLMs) under contextual perturbations. The study introduces Neighbor-Consistency Belief (NCB) as a measure of belief robustness and shows that high-NCB data is more resistant to interference. The proposed Structure-Aware Training (SAT) optimizes context-invariant belief structure and reduces knowledge brittleness, providing a promising approach for improving the reliability of LLMs in real-world applications.

---

## The ICASSP 2026 HumDial Challenge: Benchmarking Human-like Spoken Dialogue Systems in the LLM Era
**URL:** https://arxiv.org/abs/2601.05564

**Abstract:** Driven by the rapid advancement of Large Language Models (LLMs), particularly Audio-LLMs and Omni-models, spoken dialogue systems have evolved significantly, progressively narrowing the gap between human-machine and human-human interactions. Achieving truly ``human-like'' communication necessitates a dual capability: emotional intelligence to perceive and resonate with users' emotional states, and robust interaction mechanisms to navigate the dynamic, natural flow of conversation, such as real-time turn-taking. Therefore, we launched the first Human-like Spoken Dialogue Systems Challenge (HumDial) at ICASSP 2026 to benchmark these dual capabilities. Anchored by a sizable dataset derived from authentic human conversations, this initiative establishes a fair evaluation platform across two tracks: (1) Emotional Intelligence, targeting long-term emotion understanding and empathetic generation; and (2) Full-Duplex Interaction, systematically evaluating real-time decision-making under `` listening-while-speaking'' conditions. This paper summarizes the dataset, track configurations, and the final results.

**AI Summary:** The research discusses the evolution of spoken dialogue systems with the advancement of Large Language Models (LLMs), focusing on emotional intelligence and robust interaction mechanisms to achieve human-like communication. The HumDial Challenge at ICASSP 2026 aims to benchmark these capabilities using a dataset derived from authentic human conversations, with tracks focusing on emotional intelligence and full-duplex interaction. This initiative provides a platform to evaluate the performance of spoken dialogue systems in mimicking human communication dynamics.

---

## Towards Valid Student Simulation with Large Language Models
**URL:** https://arxiv.org/abs/2601.05473

**Abstract:** This paper presents a conceptual and methodological framework for large language model (LLM) based student simulation in educational settings. The authors identify a core failure mode, termed the "competence paradox" in which broadly capable LLMs are asked to emulate partially knowledgeable learners, leading to unrealistic error patterns and learning dynamics. To address this, the paper reframes student simulation as a constrained generation problem governed by an explicit Epistemic State Specification (ESS), which defines what a simulated learner can access, how errors are structured, and how learner state evolves over time. The work further introduces a Goal-by-Environment framework to situate simulated student systems according to behavioral objectives and deployment contexts. Rather than proposing a new system or benchmark, the paper synthesizes prior literature, formalizes key design dimensions, and articulates open challenges related to validity, evaluation, and ethical risks. Overall, the paper argues for epistemic fidelity over surface realism as a prerequisite for using LLM-based simulated students as reliable scientific and pedagogical instruments.

**AI Summary:** This paper introduces a framework for using large language models (LLMs) to simulate student behavior in educational settings. The authors address the "competence paradox" where LLMs struggle to accurately emulate partially knowledgeable learners, proposing an Epistemic State Specification (ESS) to govern learner access, error patterns, and state evolution. The paper emphasizes the importance of epistemic fidelity over surface realism for creating reliable simulated student systems for scientific and pedagogical purposes.

---

## From Events to Trending: A Multi-Stage Hotspots Detection Method Based on Generative Query Indexing
**URL:** https://arxiv.org/abs/2601.05258

**Abstract:** LLM-based conversational systems have become a popular gateway for information access, yet most existing chatbots struggle to handle news-related trending queries effectively. To improve user experience, an effective trending query detection method is urgently needed to enable differentiated processing of such target traffic. However, current research on trending detection tailored to the dialogue system scenario remains largely unexplored, and methods designed for traditional search engines often underperform in conversational contexts due to radically distinct query distributions and expression patterns. To fill this gap, we propose a multi-stage framework for trending detection, which achieves systematic optimization from both offline generation and online identification perspectives. Specifically, our framework first exploits selected hot events to generate index queries, establishing a key bridge between static events and dynamic user queries. It then employs a retrieval matching mechanism for real-time online detection of trending queries, where we introduce a cascaded recall and ranking architecture to balance detection efficiency and accuracy. Furthermore, to better adapt to the practical application scenario, our framework adopts a single-recall module as a cold-start strategy to collect online data for fine-tuning the reranker. Extensive experiments demonstrate that our framework significantly outperforms baseline methods in both offline evaluations and online A/B tests, and user satisfaction is relatively improved by 27\% in terms of positive-negative feedback ratio.

**AI Summary:** This research proposes a multi-stage hotspots detection method for trending queries in conversational systems, addressing the limitations of existing chatbots in handling news-related queries effectively. The framework utilizes hot events to generate index queries and employs a retrieval matching mechanism for real-time detection of trending queries. Experimental results show that the proposed method outperforms baseline methods in offline evaluations and online tests, leading to a 27% improvement in user satisfaction.

---

## CourtNav: Voice-Guided, Anchor-Accurate Navigation of Long Legal Documents in Courtrooms
**URL:** https://arxiv.org/abs/2601.05255

**Abstract:** Judicial work depends on close reading of long records, charge sheets, pleadings, annexures, orders, often spanning hundreds of pages. With limited staff support, exhaustive reading during hearings is impractical. We present CourtNav, a voice-guided, anchor-first navigator for legal PDFs that maps a judge's spoken command (e.g., "go to paragraph 23", "highlight the contradiction in the cross-examination") directly to a highlighted paragraph in seconds. CourtNav transcribes the command, classifies intent with a grammar-first(Exact regex matching), LLM-backed router classifying the queries using few shot examples, retrieves over a layout-aware hybrid index, and auto-scrolls the viewer to the cited span while highlighting it and close alternates. By design, the interface shows only grounded passages, never free text, keeping evidence verifiable and auditable. This need is acute in India, where judgments and cross-examinations are notoriously this http URL a pilot on representative charge sheets, pleadings, and orders, median time-to-relevance drops from 3-5 minutes (manual navigation) to 10-15 seconds; with quick visual verification included, 30-45 seconds. Under fixed time budgets, this navigation-first design increases the breadth of the record actually consulted while preserving control and transparency.

**AI Summary:** CourtNav is a voice-guided navigation tool for legal PDFs that allows judges to quickly access specific sections of long documents during court hearings. The system uses a grammar-first approach to classify commands, retrieves information using a layout-aware hybrid index, and automatically scrolls to the cited section while highlighting it. This tool significantly reduces the time needed to find relevant information in legal documents, improving efficiency and accuracy in court proceedings.

---

## SP-Rank: A Dataset for Ranked Preferences with Secondary Information
**URL:** https://arxiv.org/abs/2601.05253

**Abstract:** We introduce $\mathbf{SP-Rank}$, the first large-scale, publicly available dataset for benchmarking algorithms that leverage both first-order preferences and second-order predictions in ranking tasks. Each datapoint includes a personal vote (first-order signal) and a meta-prediction of how others will vote (second-order signal), allowing richer modeling than traditional datasets that capture only individual preferences. SP-Rank contains over 12,000 human-generated datapoints across three domains -- geography, movies, and paintings, and spans nine elicitation formats with varying subset sizes. This structure enables empirical analysis of preference aggregation when expert identities are unknown but presumed to exist, and individual votes represent noisy estimates of a shared ground-truth ranking. We benchmark SP-Rank by comparing traditional aggregation methods that use only first-order votes against SP-Voting, a second-order method that jointly reasons over both signals to infer ground-truth rankings. While SP-Rank also supports models that rely solely on second-order predictions, our benchmarks emphasize the gains from combining both signals. We evaluate performance across three core tasks: (1) full ground-truth rank recovery, (2) subset-level rank recovery, and (3) probabilistic modeling of voter behavior. Results show that incorporating second-order signals substantially improves accuracy over vote-only methods. Beyond social choice, SP-Rank supports downstream applications in learning-to-rank, extracting expert knowledge from noisy crowds, and training reward models in preference-based fine-tuning pipelines. We release the dataset, code, and baseline evaluations (available at this https URL ) to foster research in human preference modeling, aggregation theory, and human-AI alignment.

**AI Summary:** The SP-Rank dataset is introduced as the first dataset that combines first-order preferences and second-order predictions in ranking tasks, allowing for richer modeling. The dataset contains over 12,000 human-generated datapoints across three domains and supports empirical analysis of preference aggregation. Benchmarking shows that incorporating second-order signals significantly improves accuracy over traditional methods, highlighting the importance of combining both signals in preference modeling and aggregation tasks.

---

## Driver-Intention Prediction with Deep Learning: Real-Time Brain-to-Vehicle Communication
**URL:** https://arxiv.org/abs/2601.05084

**Abstract:** Brain-computer interfaces (BCIs) allow direct communication between the brain and electronics without the need for speech or physical movement. Such interfaces can be particularly beneficial in applications requiring rapid response times, such as driving, where a vehicle's advanced driving assistance systems could benefit from immediate understanding of a driver's intentions. This study presents a novel method for predicting a driver's intention to steer using electroencephalography (EEG) signals through deep learning. A driving simulator created a controlled environment in which participants imagined controlling a vehicle during various driving scenarios, including left and right turns, as well as straight driving. A convolutional neural network (CNN) classified the detected EEG data with minimal pre-processing. Our model achieved an accuracy of 83.7% in distinguishing between the three steering intentions and demonstrated the ability of CNNs to process raw EEG data effectively. The classification accuracy was highest for right-turn segments, which suggests a potential spatial bias in brain activity. This study lays the foundation for more intuitive brain-to-vehicle communication systems.

**AI Summary:** This study explores the use of deep learning and EEG signals to predict a driver's intention to steer in real-time, potentially improving vehicle safety and performance. The research found that a CNN could accurately classify different steering intentions with an accuracy of 83.7%, indicating the potential for more intuitive brain-to-vehicle communication systems in the future. The study highlights the significance of BCIs in applications requiring rapid response times, such as driving, and the effectiveness of deep learning in processing raw EEG data for predictive purposes.

---

## OnomaCompass: A Texture Exploration Interface that Shuttles between Words and Images
**URL:** https://arxiv.org/abs/2601.04915

**Abstract:** Humans can finely perceive material textures, yet articulating such somatic impressions in words is a cognitive bottleneck in design ideation. We present OnomaCompass, a web-based exploration system that links sound-symbolic onomatopoeia and visual texture representations to support early-stage material discovery. Instead of requiring users to craft precise prompts for generative AI, OnomaCompass provides two coordinated latent-space maps--one for texture images and one for onomatopoeic term--built from an authored dataset of invented onomatopoeia and corresponding textures generated via Stable Diffusion. Users can navigate both spaces, trigger cross-modal highlighting, curate findings in a gallery, and preview textures applied to objects via an image-editing model. The system also supports video interpolation between selected textures and re-embedding of extracted frames to form an emergent exploration loop. We conducted a within-subjects study with 11 participants comparing OnomaCompass to a prompt-based image-generation workflow using Gemini 2.5 Flash Image ("Nano Banana"). OnomaCompass significantly reduced workload (NASA-TLX overall, mental demand, effort, and frustration; p < .05) and increased hedonic user experience (UEQ), while usability (SUS) favored the baseline. Qualitative findings indicate that OnomaCompass helps users externalize vague sensory expectations and promotes serendipitous discovery, but also reveals interaction challenges in spatial navigation. Overall, leveraging sound symbolism as a lightweight cue offers a complementary approach to Kansei-driven material ideation beyond prompt-centric generation.

**AI Summary:** The research introduces OnomaCompass, a web-based system that connects sound-symbolic onomatopoeia with visual texture representations to aid in material discovery during design ideation. The system allows users to navigate latent-space maps of textures and onomatopoeic terms, curate findings, and preview textures applied to objects. A study comparing OnomaCompass to a prompt-based image-generation workflow showed that OnomaCompass reduced workload and frustration while increasing hedonic user experience, demonstrating its potential to facilitate material ideation through serendipitous discovery.

---

## Dynamic Thermal Feedback in Highly Immersive VR Scenarios: a Multimodal Analysis of User Experience
**URL:** https://arxiv.org/abs/2601.04781

**Abstract:** Thermal feedback is critical to a range of Virtual Reality (VR) applications, such as firefighting training or thermal comfort simulation. Previous studies showed that adding congruent thermal feedback positively influences User eXperience (UX). However, existing work did not compare different levels of thermal feedback quality and mostly used less immersive virtual environments. To investigate these gaps in the scientific literature, we conducted a within-participant user study in two highly-immersive scenarios, Desert Island (n=25) and Snowy Mountains (n=24). Participants explored the scenarios in three conditions (Audio-Visual only, Static-Thermal Feedback, and Dynamic-Thermal Feedback). To assess the complex and subtle effects of thermal feedback on UX, we performed a multimodal analysis by crossing data from questionnaires, semi-structured interviews, and behavioral indicators. Our results show that despite an already high level of presence in the Audio-Visual only condition, adding thermal feedback increased presence further. Comparison between levels of thermal feedback quality showed no significant difference in UX questionnaires, however this result is nuanced according to participant profiles and interviews. Furthermore, we show that although the order of passage did not influence UX directly, it influenced user behavior. We propose guidelines for the use of thermal feedback in VR, and the design of studies in complex multisensory scenarios.

**AI Summary:** This study explores the impact of dynamic thermal feedback on user experience in highly immersive VR scenarios. The research found that adding thermal feedback increased the sense of presence for users, regardless of the quality of the feedback. The study also highlights the importance of considering user profiles and behaviors when implementing thermal feedback in VR applications, and provides guidelines for future research in complex multisensory environments.

---

## Leveraging LLMs for Efficient and Personalized Smart Home Automation
**URL:** https://arxiv.org/abs/2601.04680

**Abstract:** The proliferation of smart home devices has increased the complexity of controlling and managing them, leading to user fatigue. In this context, large language models (LLMs) offer a promising solution by enabling natural-language interfaces for Internet of Things (IoT) control. However, existing LLM-based approaches suffer from unreliable and inefficient device control due to the non-deterministic nature of LLMs, high inference latency and cost, and limited personalization. To address these challenges, we present IoTGPT, an LLM-based smart home agent designed to execute IoT commands in a reliable, efficient, and personalized manner. Inspired by how humans manage complex tasks, IoTGPT decomposes user instructions into subtasks and memorizes them. By reusing learned subtasks, subsequent instructions can be processed more efficiently with fewer LLM calls, improving reliability and reducing both latency and cost. IoTGPT also supports fine-grained personalization by adapting individual subtasks to user preferences. Our evaluation demonstrates that IoTGPT outperforms baselines in accuracy, latency/cost, and personalization, while reducing user workload.

**AI Summary:** This research introduces IoTGPT, an LLM-based smart home agent that aims to improve the efficiency and personalization of smart home automation. By decomposing user instructions into subtasks and memorizing them, IoTGPT can execute commands more reliably and efficiently, reducing latency and cost. The evaluation shows that IoTGPT outperforms existing approaches in accuracy, latency/cost, and personalization, offering a promising solution to the complexity and user fatigue associated with controlling smart home devices.

---

## RecruitScope: A Visual Analytics System for Multidimensional Recruitment Data Analysis
**URL:** https://arxiv.org/abs/2601.04630

**Abstract:** Online recruitment platforms have become the dominant channel for modern hiring, yet most platforms offer only basic filtering capabilities, such as job title, keyword, and salary range. This hinders comprehensive analysis of multi-attribute relationships and job market patterns across different scales. We present RecruitScope, a visual analytics system designed to support multidimensional and cross-level exploration of recruitment data for job seekers and employers, particularly HR specialists. Through coordinated visualizations, RecruitScope enables users to analyze job positions and salary patterns from multiple perspectives, interpret industry dynamics at the macro level, and identify emerging positions at the micro level. We demonstrate the effectiveness of RecruitScope through case studies that reveal regional salary distribution patterns, characterize industry growth trajectories, and discover high-demand emerging roles in the job market.

**AI Summary:** RecruitScope is a visual analytics system that allows for in-depth analysis of multidimensional recruitment data, enabling users to explore job market patterns and relationships across different scales. The system provides HR specialists, job seekers, and employers with the ability to analyze job positions, salary patterns, industry dynamics, and emerging roles through coordinated visualizations. Case studies demonstrate the effectiveness of RecruitScope in revealing regional salary distribution patterns, industry growth trajectories, and high-demand emerging roles in the job market.

---

## The UnScripted Trip: Fostering Policy Discussion on Future Human-Vehicle Collaboration in Autonomous Driving Through Design-Oriented Methods
**URL:** https://arxiv.org/abs/2601.04601

**Abstract:** The rapid advancement of autonomous vehicle (AV) technologies is fundamentally reshaping paradigms of human-vehicle collaboration, raising not only an urgent need for innovative design solutions but also for policies that address corresponding broader tensions in society. To bridge the gap between HCI research and policy making, this workshop will bring together researchers and practitioners in the automotive community to explore AV policy directions through collaborative speculation on the future of AVs. We designed The UnScripted Trip, a card game rooted in fictional narratives of autonomous mobility, to surface tensions around human-vehicle collaboration in future AV scenarios and to provoke critical reflections on design solutions and policy directions. Our goal is to provide an engaging, participatory space and method for automotive researchers, designers, and industry practitioners to collectively explore and shape the future of human-vehicle collaboration and its policy implications.

**AI Summary:** This research explores the impact of autonomous vehicle technologies on human-vehicle collaboration and the need for innovative design solutions and policies to address societal tensions. The study introduces The UnScripted Trip, a card game designed to facilitate discussions among researchers and practitioners in the automotive community about future AV scenarios and policy directions. The game aims to provoke critical reflections on design solutions and policy implications, providing a collaborative space for shaping the future of human-vehicle collaboration in autonomous driving.

---

## Feel the Presence: The Effects of Haptic Sensation on VR-Based Human-Robot Interaction
**URL:** https://arxiv.org/abs/2601.04596

**Abstract:** Virtual reality (VR) has been increasingly utilised as a simulation tool for human-robot interaction (HRI) studies due to its ability to facilitate fast and flexible prototyping. Despite efforts to achieve high validity in VR studies, haptic sensation, an essential sensory modality for perception and a critical factor in enhancing VR realism, is often absent from these experiments. Studying an interactive robot help-seeking scenario, we used a VR simulation with haptic gloves that provide highly realistic tactile and force feedback to examine the effects of haptic sensation on VR-based HRI. We compared participants' sense of presence and their assessments of the robot to a traditional setup using hand controllers. Our results indicate that haptic sensation enhanced participants' social and self-presence in VR and fostered more diverse and natural bodily engagement. Additionally, haptic sensations significantly influenced participants' affective-related perceptions of the robot. Our study provides insights to guide HRI researchers in building VR-based simulations that better align with their study contexts and objectives.

**AI Summary:** This research explores the impact of haptic sensation on virtual reality-based human-robot interaction studies. Using a VR simulation with haptic gloves, the study found that haptic sensation enhanced participants' sense of presence, social engagement, and affective perceptions of the robot. These findings suggest that incorporating haptic feedback in VR simulations can lead to more realistic and immersive human-robot interactions, providing valuable insights for researchers in designing VR-based studies.

---

## How Users Consider Web Tracking When Seeking Health Information Online
**URL:** https://arxiv.org/abs/2601.04485

**Abstract:** Health information websites offer instantaneous access to information, but have important privacy implications as they can associate a visitor with specific medical conditions. We interviewed 35 residents of Canada to better understand whether and how online health information seekers exercise three potential means of protection against surveillance: website selection, privacy-enhancing technologies, and self-censorship, as well as their understanding of web tracking. Our findings reveal how users' limited initiative and effectiveness in protecting their privacy could be associated with a missing or inaccurate understanding of how implicit data collection by third parties takes place on the web, and who collects the data. We conclude that to help Internet users achieve better self-data protection, we may need to shift privacy awareness efforts from what information is collected to how it is collected.

**AI Summary:** This study examines how online health information seekers in Canada protect their privacy when accessing health websites. The research found that users often lack awareness and understanding of how their data is collected and shared online, leading to limited privacy protection measures. The study suggests that efforts to improve privacy awareness should focus on educating users about how data is collected online, rather than just what information is collected.

---

## Human-in-the-Loop Testing of AI Agents for Air Traffic Control with a Regulated Assessment Framework
**URL:** https://arxiv.org/abs/2601.04288

**Abstract:** We present a rigorous, human-in-the-loop evaluation framework for assessing the performance of AI agents on the task of Air Traffic Control, grounded in a regulator-certified simulator-based curriculum used for training and testing real-world trainee controllers. By leveraging legally regulated assessments and involving expert human instructors in the evaluation process, our framework enables a more authentic and domain-accurate measurement of AI performance. This work addresses a critical gap in the existing literature: the frequent misalignment between academic representations of Air Traffic Control and the complexities of the actual operational environment. It also lays the foundations for effective future human-machine teaming paradigms by aligning machine performance with human assessment targets.

**AI Summary:** This research introduces a human-in-the-loop evaluation framework for testing AI agents in Air Traffic Control, using a regulator-certified simulator-based curriculum. By involving expert human instructors and leveraging legally regulated assessments, the framework provides a more authentic measurement of AI performance in a domain-accurate manner. This work addresses the gap between academic representations of Air Traffic Control and the complexities of the operational environment, laying the groundwork for effective human-machine teaming paradigms by aligning machine performance with human assessment targets.

---

## Exploring Student Expectations and Confidence in Learning Analytics
**URL:** https://arxiv.org/abs/2601.05082

**Abstract:** Learning Analytics (LA) is nowadays ubiquitous in many educational systems, providing the ability to collect and analyze student data in order to understand and optimize learning and the environments in which it occurs. On the other hand, the collection of data requires to comply with the growing demand regarding privacy legislation. In this paper, we use the Student Expectation of Learning Analytics Questionnaire (SELAQ) to analyze the expectations and confidence of students from different faculties regarding the processing of their data for Learning Analytics purposes. This allows us to identify four clusters of students through clustering algorithms: Enthusiasts, Realists, Cautious and Indifferents. This structured analysis provides valuable insights into the acceptance and criticism of Learning Analytics among students.

**AI Summary:** This research paper explores student expectations and confidence in Learning Analytics (LA) in educational systems. By using the Student Expectation of Learning Analytics Questionnaire (SELAQ), the study identifies four clusters of students with varying attitudes towards LA: Enthusiasts, Realists, Cautious, and Indifferents. This analysis provides valuable insights into student acceptance and criticism of LA, highlighting the importance of understanding student perspectives in implementing LA in educational settings.

---

## From Idea to Co-Creation: A Planner-Actor-Critic Framework for Agent Augmented 3D Modeling
**URL:** https://arxiv.org/abs/2601.05016

**Abstract:** We present a framework that extends the Actor-Critic architecture to creative 3D modeling through multi-agent self-reflection and human-in-the-loop supervision. While existing approaches rely on single-prompt agents that directly execute modeling commands via tools like Blender MCP, our approach introduces a Planner-Actor-Critic architecture. In this design, the Planner coordinates modeling steps, the Actor executes them, and the Critic provides iterative feedback, while human users act as supervisors and advisors throughout the process. Through systematic comparison between single-prompt modeling and our reflective multi-agent approach, we demonstrate improvements in geometric accuracy, aesthetic quality, and task completion rates across diverse 3D modeling scenarios. Our evaluation reveals that critic-guided reflection, combined with human supervisory input, reduces modeling errors and increases complexity and quality of the result compared to direct single-prompt execution. This work establishes that structured agent self-reflection, when augmented by human oversight and advisory guidance, produces higher-quality 3D models while maintaining efficient workflow integration through real-time Blender synchronization.

**AI Summary:** This research introduces a Planner-Actor-Critic framework for agent augmented 3D modeling, which improves geometric accuracy, aesthetic quality, and task completion rates compared to existing single-prompt approaches. By incorporating human supervision and feedback, the framework allows for structured agent self-reflection, reducing errors and increasing the complexity and quality of the resulting models. The study demonstrates the significance of combining AI with human oversight for enhancing 3D modeling outcomes.

---

## What Students Ask, How a Generative AI Assistant Responds: Exploring Higher Education Students' Dialogues on Learning Analytics Feedback
**URL:** https://arxiv.org/abs/2601.04919

**Abstract:** Learning analytics dashboards (LADs) aim to support students' regulation of learning by translating complex data into feedback. Yet students, especially those with lower self-regulated learning (SRL) competence, often struggle to engage with and interpret analytics feedback. Conversational generative artificial intelligence (GenAI) assistants have shown potential to scaffold this process through real-time, personalised, dialogue-based support. Further advancing this potential, we explored authentic dialogues between students and GenAI assistant integrated into LAD during a 10-week semester. The analysis focused on questions students with different SRL levels posed, the relevance and quality of the assistant's answers, and how students perceived the assistant's role in their learning. Findings revealed distinct query patterns. While low SRL students sought clarification and reassurance, high SRL students queried technical aspects and requested personalised strategies. The assistant provided clear and reliable explanations but limited in personalisation, handling emotionally charged queries, and integrating multiple data points for tailored responses. Findings further extend that GenAI interventions can be especially valuable for low SRL students, offering scaffolding that supports engagement with feedback and narrows gaps with their higher SRL peers. At the same time, students' reflections underscored the importance of trust, need for greater adaptivity, context-awareness, and technical refinement in future systems.

**AI Summary:** This research explores how conversational generative artificial intelligence (GenAI) assistants can support students in engaging with learning analytics feedback. The study found that students with lower self-regulated learning (SRL) competence sought clarification and reassurance from the assistant, while those with higher SRL levels asked more technical questions and requested personalized strategies. The findings suggest that GenAI interventions can be particularly beneficial for students with lower SRL levels, but improvements are needed in personalization, handling emotionally charged queries, and integrating multiple data points for tailored responses.

---

## Model of Spatial Human-Agent Interaction with Consideration for Others
**URL:** https://arxiv.org/abs/2601.04657

**Abstract:** Communication robots often need to initiate conversations with people in public spaces. At the same time, such robots must not disturb pedestrians. To handle these two requirements, an agent needs to estimate the communication desires of others based on their behavior and then adjust its own communication activities accordingly. In this study, we construct a computational spatial interaction model that considers others. Consideration is expressed as a quantitative parameter: the amount of adjustment of one's internal state to the estimated internal state of the other. To validate the model, we experimented with a human and a virtual robot interacting in a VR environment. The results show that when the participant moves to the target, a virtual robot with a low consideration value inhibits the participant's movement, while a robot with a higher consideration value did not inhibit the participant's movement. When the participant approached the robot, the robot also exhibited approaching behavior, regardless of the consideration value, thus decreasing the participant's movement. These results appear to verify the proposed model's ability to clarify interactions with consideration for others.

**AI Summary:** This research focuses on developing a computational model for communication robots to interact with pedestrians in public spaces while considering the desires and behaviors of others. The study introduces a quantitative parameter for consideration and validates the model through experiments in a VR environment. Results show that a robot with higher consideration values better accommodates the movements of participants, indicating the model's ability to improve interactions with consideration for others.

---

## Decision-Aware Trust Signal Alignment for SOC Alert Triage
**URL:** https://arxiv.org/abs/2601.04486

**Abstract:** Detection systems that utilize machine learning are progressively implemented at Security Operations Centers (SOCs) to help an analyst to filter through high volumes of security alerts. Practically, such systems tend to reveal probabilistic results or confidence scores which are ill-calibrated and hard to read when under pressure. Qualitative and survey based studies of SOC practice done before reveal that poor alert quality and alert overload greatly augment the burden on the analyst, especially when tool outputs are not coherent with decision requirements, or signal noise. One of the most significant limitations is that model confidence is usually shown without expressing that there are asymmetric costs in decision making where false alarms are much less harmful than missed attacks. The present paper presents a decision-sensitive trust signal correspondence scheme of SOC alert triage. The framework combines confidence that has been calibrated, lightweight uncertainty cues, and cost-sensitive decision thresholds into coherent decision-support layer, instead of making changes to detection models. To enhance probabilistic consistency, the calibration is done using the known post-hoc methods and the uncertainty cues give conservative protection in situations where model certainty is low. To measure the model-independent performance of the suggested model, we apply the Logistic Regression and the Random Forest classifiers to the UNSW-NB15 intrusion detection benchmark. According to simulation findings, false negatives are greatly amplified by the presence of misaligned displays of confidence, whereas cost weighted loss decreases by orders of magnitude between models with decision aligned trust signals. Lastly, we describe a human-in-the-loop study plan that would allow empirically assessing the decision-making of the analysts with aligned and misaligned trust interfaces.

**AI Summary:** This research focuses on improving the effectiveness of machine learning detection systems in Security Operations Centers (SOCs) by aligning trust signals with decision-making requirements. The study found that misaligned displays of confidence can greatly increase false negatives, while decision-aligned trust signals significantly reduce cost-weighted loss. The proposed framework combines calibrated confidence, uncertainty cues, and cost-sensitive decision thresholds to create a coherent decision-support layer for SOC alert triage, without changing the underlying detection models.

---

## Users Mispredict Their Own Preferences for AI Writing Assistance
**URL:** https://arxiv.org/abs/2601.04461

**Abstract:** Proactive AI writing assistants need to predict when users want drafting help, yet we lack empirical understanding of what drives preferences. Through a factorial vignette study with 50 participants making 750 pairwise comparisons, we find compositional effort dominates decisions ($\rho = 0.597$) while urgency shows no predictive power ($\rho \approx 0$). More critically, users exhibit a striking perception-behavior gap: they rank urgency first in self-reports despite it being the weakest behavioral driver, representing a complete preference inversion. This misalignment has measurable consequences. Systems designed from users' stated preferences achieve only 57.7\% accuracy, underperforming even naive baselines, while systems using behavioral patterns reach significantly higher 61.3\% ($p < 0.05$). These findings demonstrate that relying on user introspection for system design actively misleads optimization, with direct implications for proactive natural language generation (NLG) systems.

**AI Summary:** This research study found that users often mispredict their own preferences for AI writing assistance, with compositional effort being the main driver of decisions while urgency showed no predictive power. The study also revealed a significant perception-behavior gap, where users ranked urgency first in self-reports despite it being the weakest behavioral driver. The findings suggest that designing AI systems based on user introspection may lead to suboptimal performance, and that systems utilizing behavioral patterns can achieve higher accuracy in predicting user preferences for writing assistance.

---

## Balancing Usability and Compliance in AI Smart Devices: A Privacy-by-Design Audit of Google Home, Alexa, and Siri
**URL:** https://arxiv.org/abs/2601.04403

**Abstract:** This paper investigates the privacy and usability of AI-enabled smart devices commonly used by youth, focusing on Google Home Mini, Amazon Alexa, and Apple Siri. While these devices provide convenience and efficiency, they also raise privacy and transparency concerns due to their always-listening design and complex data management processes. The study proposes and applies a combined framework of Heuristic Evaluation, Personal Information Protection and Electronic Documents Act (PIPEDA) Compliance Assessment, and Youth-Centered Usability Testing to assess whether these devices align with Privacy-by-Design principles and support meaningful user control. Results show that Google Home achieved the highest usability score, while Siri scored highest in regulatory compliance, indicating a trade-off between user convenience and privacy protection. Alexa demonstrated clearer task navigation but weaker transparency in data retention. Findings suggest that although youth may feel capable of managing their data, their privacy self-efficacy remains limited by technical design, complex settings, and unclear data policies. The paper concludes that enhancing transparency, embedding privacy guidance during onboarding, and improving policy alignment are critical steps toward ensuring that smart devices are both usable and compliant with privacy standards that protect young users.

**AI Summary:** This research paper examines the privacy and usability of popular AI smart devices used by youth, such as Google Home Mini, Amazon Alexa, and Apple Siri. The study finds that while these devices offer convenience, they also pose privacy concerns due to their always-listening design and complex data management processes. The results show that there is a trade-off between user convenience and privacy protection, with Google Home scoring highest in usability, Siri in regulatory compliance, and Alexa in task navigation. The paper highlights the importance of enhancing transparency, providing privacy guidance during onboarding, and improving policy alignment to ensure that smart devices are both usable and compliant with privacy standards for young users.

---

## Convenience vs. Control: A Qualitative Study of Youth Privacy with Smart Voice Assistants
**URL:** https://arxiv.org/abs/2601.04399

**Abstract:** Smart voice assistants (SVAs) are embedded in the daily lives of youth, yet their privacy controls often remain opaque and difficult to manage. Through five semi-structured focus groups (N=26) with young Canadians (ages 16-24), we investigate how perceived privacy risks (PPR) and benefits (PPBf) intersect with algorithmic transparency and trust (ATT) and privacy self-efficacy (PSE) to shape privacy-protective behaviors (PPB). Our analysis reveals that policy overload, fragmented settings, and unclear data retention undermine self-efficacy and discourage protective actions. Conversely, simple transparency cues were associated with greater confidence without diminishing the utility of hands-free tasks and entertainment. We synthesize these findings into a qualitative model in which transparency friction erodes PSE, which in turn weakens PPB. From this model, we derive actionable design guidance for SVAs, including a unified privacy hub, plain-language "data nutrition" labels, clear retention defaults, and device-conditional micro-tutorials. This work foregrounds youth perspectives and offers a path for SVA governance and design that empowers young digital citizens while preserving convenience.

**AI Summary:** This study explores how youth in Canada perceive privacy risks and benefits associated with smart voice assistants (SVAs) and how these perceptions impact their privacy-protective behaviors. The research highlights the importance of algorithmic transparency, trust, and privacy self-efficacy in shaping privacy behaviors. The findings suggest that simple transparency cues and clear data retention policies can enhance user confidence and encourage privacy-protective actions, providing valuable insights for designing SVAs that empower young users while preserving convenience.

---

## Pilot Study on Student Public Opinion Regarding GAI
**URL:** https://arxiv.org/abs/2601.04336

**Abstract:** The emergence of generative AI (GAI) has sparked diverse opinions regarding its appropriate use across various domains, including education. This pilot study investigates university students' perceptions of GAI in higher education classrooms, aiming to lay the groundwork for understanding these attitudes. With a participation rate of approximately 4.4%, the study highlights the challenges of engaging students in GAI-related research and underscores the need for larger sample sizes in future studies. By gaining insights into student perspectives, instructors can better prepare to integrate discussions of GAI into their classrooms, fostering informed and critical engagement with this transformative technology.

**AI Summary:** This pilot study explores university students' opinions on the use of generative AI (GAI) in higher education classrooms. The study found a low participation rate of approximately 4.4%, indicating challenges in engaging students in GAI-related research. The findings emphasize the importance of understanding student perspectives to effectively integrate discussions of GAI into education and promote informed and critical engagement with this technology.

---

## ArtCognition: A Multimodal AI Framework for Affective State Sensing from Visual and Kinematic Drawing Cues
**URL:** https://arxiv.org/abs/2601.04297

**Abstract:** The objective assessment of human affective and psychological states presents a significant challenge, particularly through non-verbal channels. This paper introduces digital drawing as a rich and underexplored modality for affective sensing. We present a novel multimodal framework, named ArtCognition, for the automated analysis of the House-Tree-Person (HTP) test, a widely used psychological instrument. ArtCognition uniquely fuses two distinct data streams: static visual features from the final artwork, captured by computer vision models, and dynamic behavioral kinematic cues derived from the drawing process itself, such as stroke speed, pauses, and smoothness. To bridge the gap between low-level features and high-level psychological interpretation, we employ a Retrieval-Augmented Generation (RAG) architecture. This grounds the analysis in established psychological knowledge, enhancing explainability and reducing the potential for model hallucination. Our results demonstrate that the fusion of visual and behavioral kinematic cues provides a more nuanced assessment than either modality alone. We show significant correlations between the extracted multimodal features and standardized psychological metrics, validating the framework's potential as a scalable tool to support clinicians. This work contributes a new methodology for non-intrusive affective state assessment and opens new avenues for technology-assisted mental healthcare.

**AI Summary:** The paper introduces ArtCognition, a novel AI framework for analyzing the House-Tree-Person test using visual and kinematic drawing cues to assess affective and psychological states. By combining static visual features and dynamic behavioral cues, the framework provides a more nuanced assessment than using either modality alone. The results show significant correlations with standardized psychological metrics, indicating the potential for ArtCognition to support clinicians in non-intrusive affective state assessment and technology-assisted mental healthcare.

---

## A Future Capabilities Agent for Tactical Air Traffic Control
**URL:** https://arxiv.org/abs/2601.04285

**Abstract:** Escalating air traffic demand is driving the adoption of automation to support air traffic controllers, but existing approaches face a trade-off between safety assurance and interpretability. Optimisation-based methods such as reinforcement learning offer strong performance but are difficult to verify and explain, while rules-based systems are transparent yet rarely check safety under uncertainty. This paper outlines Agent Mallard, a forward-planning, rules-based agent for tactical control in systemised airspace that embeds a stochastic digital twin directly into its conflict-resolution loop. Mallard operates on predefined GPS-guided routes, reducing continuous 4D vectoring to discrete choices over lanes and levels, and constructs hierarchical plans from an expert-informed library of deconfliction strategies. A depth-limited backtracking search uses causal attribution, topological plan splicing, and monotonic axis constraints to seek a complete safe plan for all aircraft, validating each candidate manoeuvre against uncertain execution scenarios (e.g., wind variation, pilot response, communication loss) before commitment.
Preliminary walkthroughs with UK controllers and initial tests in the BluebirdDT airspace digital twin indicate that Mallard's behaviour aligns with expert reasoning and resolves conflicts in simplified scenarios. The architecture is intended to combine model-based safety assessment, interpretable decision logic, and tractable computational performance in future structured en-route environments.

**AI Summary:** This paper introduces Agent Mallard, a rules-based agent for tactical air traffic control that incorporates a stochastic digital twin to ensure safety under uncertainty. Mallard operates on predefined routes and uses expert-informed deconfliction strategies to plan aircraft movements. Initial tests show that Mallard aligns with expert reasoning and effectively resolves conflicts in simplified scenarios, offering a promising approach for future structured en-route environments.

---

## Using Grok to Avoid Personal Attacks While Correcting Misinformation on X
**URL:** https://arxiv.org/abs/2601.04251

**Abstract:** Correcting misinformation in public online spaces often exposes users to hostility and ad hominem attacks, discouraging participation in corrective discourse. This study presents empirical evidence that invoking Grok, the native large language model on X, rather than directly confronting other users, is associated with different social responses during misinformation correction. Using an observational design, 100 correction replies across five high-conflict misinformation topics were analyzed, with corrections balanced between Grok-mediated and direct human-issued responses. The primary outcome was whether a correction received at least one ad hominem attack within a 24-hour window. Ad hominem attacks occurred in 72 percent of human-issued corrections and in none of the Grok-mediated corrections. A chi-square test confirmed a statistically significant association with a large effect size. These findings suggest that AI-mediated correction may alter the social dynamics of public disagreement by reducing interpersonal hostility during misinformation responses.

**AI Summary:** This study found that using an AI model like Grok to correct misinformation on X resulted in significantly fewer ad hominem attacks compared to direct human responses. Ad hominem attacks occurred in 72 percent of human-issued corrections, but none of the Grok-mediated corrections. This suggests that AI-mediated corrections can help reduce interpersonal hostility during misinformation responses in public online spaces.

---

## Active Sensing Shapes Real-World Decision-Making through Dynamic Evidence Accumulation
**URL:** https://arxiv.org/abs/2601.04214

**Abstract:** Human decision-making heavily relies on active sensing, a well-documented cognitive behaviour for evidence gathering to accommodate ever-changing environments. However, its operational mechanism in the real world remains non-trivial. Currently, an in-laboratory paradigm, called evidence accumulation modelling (EAM), points out that human decision-making involves transforming external evidence into internal mental beliefs. However, the gap in evidence affordance between real-world contexts and laboratory settings hinders the effective application of EAM. Here we generalize EAM to the real world and conduct analysis in real-world driving scenarios. A cognitive scheme is proposed to formalize real-world evidence affordance and capture active sensing through eye movements. Empirically, our scheme can plausibly portray the accumulation of drivers' mental beliefs, explaining how active sensing transforms evidence into mental beliefs from the perspective of information utility. Also, our results demonstrate a negative correlation between evidence affordance and attention recruited by individuals, revealing how human drivers adapt their evidence-collection patterns across various contexts. Moreover, we reveal the positive influence of evidence affordance and attention distribution on decision-making propensity. In a nutshell, our computational scheme generalizes EAM to real-world contexts and provides a comprehensive account of how active sensing underlies real-world decision-making, unveiling multifactorial, integrated characteristics in real-world decision-making.

**AI Summary:** The research explores how active sensing, the process of gathering evidence in real time, influences human decision-making in real-world scenarios. By adapting evidence accumulation modelling to real-world contexts, the study demonstrates how drivers' mental beliefs are shaped through active sensing, as reflected in their eye movements. The findings show a correlation between evidence affordance, attention distribution, and decision-making propensity, highlighting the complex interplay of factors in real-world decision-making processes.

---

## Enhancing Admission Inquiry Responses with Fine-Tuned Models and Retrieval-Augmented Generation
**URL:** https://arxiv.org/abs/2601.04206

**Abstract:** University admissions offices face the significant challenge of managing high volumes of inquiries efficiently while maintaining response quality, which critically impacts prospective students' perceptions. This paper addresses the issues of response time and information accuracy by proposing an AI system integrating a fine-tuned language model with Retrieval-Augmented Generation (RAG). While RAG effectively retrieves relevant information from large datasets, its performance in narrow, complex domains like university admissions can be limited without adaptation, potentially leading to contextually inadequate responses due to the intricate rules and specific details involved. To overcome this, we fine-tuned the model on a curated dataset specific to admissions processes, enhancing its ability to interpret RAG-provided data accurately and generate domain-relevant outputs. This hybrid approach leverages RAG's ability to access up-to-date information and fine-tuning's capacity to embed nuanced domain understanding. We further explored optimization strategies for the response generation logic, experimenting with settings to balance response quality and speed, aiming for consistently high-quality outputs that meet the specific requirements of admissions communications.

**AI Summary:** This research proposes an AI system that integrates a fine-tuned language model with Retrieval-Augmented Generation (RAG) to improve university admissions inquiry responses. By fine-tuning the model on a specific admissions dataset, the system can accurately interpret information retrieved by RAG and generate relevant responses. The hybrid approach aims to balance response quality and speed, ultimately enhancing the efficiency and effectiveness of admissions communications.

---

## Generative Teaching via Code
**URL:** https://arxiv.org/abs/2601.04204

**Abstract:** The scalability of high-quality online education is hindered by the high costs and slow cycles of labor-intensive manual content creation. Despite advancements in video generation, current approaches often fail to ensure pedagogical structure and precise control due to their pixel-level, black-box nature. In this paper, we propose Generative Teaching, a novel paradigm that transitions educators from manual creators to high-level directors, allowing them to focus on pedagogical intent while autonomous agents handle the execution. To realize this vision, we introduce TeachMaster, a multi-agent framework that leverages code as an intermediate semantic medium. Unlike traditional video generation methods, TeachMaster orchestrates a collaborative team of agents--spanning planning, design, and rendering--to automate the production of interpretable, editable, and curriculum-ready educational videos. Experiments validate that TeachMaster significantly boosts production efficiency without compromising structural coherence or visual fidelity, providing a robust solution for scalable education.

**AI Summary:** This research introduces Generative Teaching, a new approach that allows educators to focus on pedagogical intent while autonomous agents handle the execution of creating educational videos. The framework, TeachMaster, uses code as an intermediate medium to automate the production of high-quality, curriculum-ready videos. Experiments show that TeachMaster significantly improves production efficiency without sacrificing structural coherence or visual fidelity, offering a scalable solution for online education.

---

## Collective Narrative Grounding: Community-Coordinated Data Contributions to Improve Local AI Systems
**URL:** https://arxiv.org/abs/2601.04201

**Abstract:** Large language model (LLM) question-answering systems often fail on community-specific queries, creating "knowledge blind spots" that marginalize local voices and reinforce epistemic injustice. We present Collective Narrative Grounding, a participatory protocol that transforms community stories into structured narrative units and integrates them into AI systems under community governance. Learning from three participatory mapping workshops with N=24 community members, we designed elicitation methods and a schema that retain narrative richness while enabling entity, time, and place extraction, validation, and provenance control. To scope the problem, we audit a county-level benchmark of 14,782 local information QA pairs, where factual gaps, cultural misunderstandings, geographic confusions, and temporal misalignments account for 76.7% of errors. On a participatory QA set derived from our workshops, a state-of-the-art LLM answered fewer than 21% of questions correctly without added context, underscoring the need for local grounding. The missing facts often appear in the collected narratives, suggesting a direct path to closing the dominant error modes for narrative items. Beyond the protocol and pilot, we articulate key design tensions, such as representation and power, governance and control, and privacy and consent, providing concrete requirements for retrieval-first, provenance-visible, locally governed QA systems. Together, our taxonomy, protocol, and participatory evaluation offer a rigorous foundation for building community-grounded AI that better answers local questions.

**AI Summary:** The research focuses on addressing the limitations of large language model question-answering systems in responding to community-specific queries, which can lead to knowledge blind spots and marginalize local voices. The study introduces Collective Narrative Grounding, a participatory protocol that integrates community stories into AI systems under community governance to improve accuracy. Through participatory workshops and audits, the researchers found that incorporating local narratives can help address errors in local information QA pairs, highlighting the importance of community-grounded AI systems for better answering local questions.

---

## Listen to Rhythm, Choose Movements: Autoregressive Multimodal Dance Generation via Diffusion and Mamba with Decoupled Dance Dataset
**URL:** https://arxiv.org/abs/2601.03323

**Abstract:** Advances in generative models and sequence learning have greatly promoted research in dance motion generation, yet current methods still suffer from coarse semantic control and poor coherence in long sequences. In this work, we present Listen to Rhythm, Choose Movements (LRCM), a multimodal-guided diffusion framework supporting both diverse input modalities and autoregressive dance motion generation. We explore a feature decoupling paradigm for dance datasets and generalize it to the Motorica Dance dataset, separating motion capture data, audio rhythm, and professionally annotated global and local text descriptions. Our diffusion architecture integrates an audio-latent Conformer and a text-latent Cross-Conformer, and incorporates a Motion Temporal Mamba Module (MTMM) to enable smooth, long-duration autoregressive synthesis. Experimental results indicate that LRCM delivers strong performance in both functional capability and quantitative metrics, demonstrating notable potential in multimodal input scenarios and extended sequence generation. We will release the full codebase, dataset, and pretrained models publicly upon acceptance.

**AI Summary:** The research introduces a new multimodal-guided diffusion framework called Listen to Rhythm, Choose Movements (LRCM) for generating dance motions. By decoupling features in the Motorica Dance dataset, including motion capture data, audio rhythm, and text descriptions, the model achieves improved semantic control and coherence in long dance sequences. Experimental results show that LRCM performs well in both functional capability and quantitative metrics, highlighting its potential for multimodal input scenarios and extended sequence generation.

---

## Beyond Physical Labels: Redefining Domains for Robust WiFi-based Gesture Recognition
**URL:** https://arxiv.org/abs/2601.03825

**Abstract:** In this paper, we propose GesFi, a novel WiFi-based gesture recognition system that introduces WiFi latent domain mining to redefine domains directly from the data itself. GesFi first processes raw sensing data collected from WiFi receivers using CSI-ratio denoising, Short-Time Fast Fourier Transform, and visualization techniques to generate standardized input representations. It then employs class-wise adversarial learning to suppress gesture semantic and leverages unsupervised clustering to automatically uncover latent domain factors responsible for distributional shifts. These latent domains are then aligned through adversarial learning to support robust cross-domain generalization. Finally, the system is applied to the target environment for robust gesture inference. We deployed GesFi under both single-pair and multi-pair settings using commodity WiFi transceivers, and evaluated it across multiple public datasets and real-world environments. Compared to state-of-the-art baselines, GesFi achieves up to 78% and 50% performance improvements over existing adversarial methods, and consistently outperforms prior generalization approaches across most cross-domain tasks.

**AI Summary:** This paper introduces GesFi, a WiFi-based gesture recognition system that utilizes latent domain mining to redefine domains from raw sensing data. By employing class-wise adversarial learning and unsupervised clustering, GesFi is able to achieve robust cross-domain generalization for gesture recognition. The system outperforms existing methods, achieving up to 78% and 50% performance improvements and consistently excelling in cross-domain tasks across various datasets and real-world environments.

---

## AR Object Layout Method Using Miniature Room Generated from Depth Data
**URL:** https://arxiv.org/abs/2601.03588

**Abstract:** In augmented reality (AR), users can place virtual objects anywhere in a real-world room, called AR layout. Although several object manipulation techniques have been proposed in AR, it is difficult to use them for AR layout owing to the difficulty in freely changing the position and size of virtual objects. In this study, we make the World-in-Miniature (WIM) technique available in AR to support AR layout. The WIM technique is a manipulation technique that uses miniatures, which has been proposed as a manipulation technique for virtual reality (VR). Our system uses the AR device's depth sensors to acquire a mesh of the room in real-time to create and update a miniature of a room in real-time. In our system, users can use miniature objects to move virtual objects to arbitrary positions and scale them to arbitrary sizes. In addition, because the miniature object can be manipulated instead of the real-scale object, we assumed that our system will shorten the placement time and reduce the workload of the user. In our previous study, we created a prototype and investigated the properties of manipulating miniature objects in AR. In this study, we conducted an experiment to evaluate how our system can support AR layout. To conduct a task close to the actual use, we used various objects and made the participants design an AR layout of their own will. The results showed that our system significantly reduced workload in physical and temporal demand. Although, there was no significant difference in the total manipulation time.

**AI Summary:** This study proposes a method for AR object layout using the World-in-Miniature technique, allowing users to freely change the position and size of virtual objects in a real-world room. By utilizing depth sensors to create and update a miniature of the room in real-time, users can manipulate miniature objects to move virtual objects to arbitrary positions and scale them to arbitrary sizes. The results of the experiment showed a significant reduction in workload in physical and temporal demand, indicating the potential of this system to improve AR layout efficiency.

---

## Dissolving a Digital Relationship: A Critical Examination of Digital Severance Behaviours in Close Relationships
**URL:** https://arxiv.org/abs/2601.03551

**Abstract:** Fulfilling social connections are crucial for human well-being and belonging, but not all relationships last forever. As interactions increasingly move online, the act of digitally severing a relationship - e.g. through blocking or unfriending - has become progressively more common as well. This study considers actions of "digital severance" through interviews with 30 participants with experience as the initiator and/or recipient of such situations. Through a critical interpretative lens, we explore how people perceive and interpret their severance experience and how the online setting of social media shapes these dynamics. We develop themes that position digital severance as being intertwined with power and control, and we highlight (im)balances between an individual's desires that can lead to feelings of disempowerment and ambiguous loss for both parties. We discuss the implications of our research, outlining three key tensions and four open questions regarding digital relationships, meaning-making, and design outcomes for future exploration.

**AI Summary:** This study investigates the phenomenon of "digital severance" in close relationships, such as blocking or unfriending someone online. Through interviews with 30 participants, the researchers found that digital severance is intertwined with power and control dynamics, leading to feelings of disempowerment and ambiguous loss for both parties involved. The study highlights the importance of understanding the implications of digital relationships and calls for further exploration into the design outcomes and meaning-making in online interactions.

---

## A Tool for Estimating Success Rates of Raycasting-Based Object Selection in Virtual Reality
**URL:** https://arxiv.org/abs/2601.03522

**Abstract:** As XR devices become widespread, 3D interaction has become commonplace, and UI developers are increasingly required to consider usability to deliver better user experiences. The HCI community has long studied target-pointing performance, and research on 3D environments has progressed substantially. However, for practitioners to directly leverage research findings in UI improvements, practical tools are needed. To bridge this gap between research and development in VR systems, we propose a system that estimates object selection success rates within a development tool (Unity). In this paper, we validate the underlying theory, describe the tool's functions, and report feedback from VR developers who tried the tool to assess its usefulness.

**AI Summary:** This research paper introduces a tool that can estimate object selection success rates in virtual reality environments, specifically within the Unity development platform. The tool aims to bridge the gap between research on 3D interaction and practical UI development, allowing developers to improve user experiences. The study validates the tool's underlying theory, describes its functions, and reports positive feedback from VR developers who found it useful for assessing object selection in their projects.

---

## Lightweight Test-Time Adaptation for EMG-Based Gesture Recognition
**URL:** https://arxiv.org/abs/2601.04181

**Abstract:** Reliable long-term decoding of surface electromyography (EMG) is hindered by signal drift caused by electrode shifts, muscle fatigue, and posture changes. While state-of-the-art models achieve high intra-session accuracy, their performance often degrades sharply. Existing solutions typically demand large datasets or high-compute pipelines that are impractical for energy-efficient wearables. We propose a lightweight framework for Test-Time Adaptation (TTA) using a Temporal Convolutional Network (TCN) backbone. We introduce three deployment-ready strategies: (i) causal adaptive batch normalization for real-time statistical alignment; (ii) a Gaussian Mixture Model (GMM) alignment with experience replay to prevent forgetting; and (iii) meta-learning for rapid, few-shot calibration. Evaluated on the NinaPro DB6 multi-session dataset, our framework significantly bridges the inter-session accuracy gap with minimal overhead. Our results show that experience-replay updates yield superior stability under limited data, while meta-learning achieves competitive performance in one- and two-shot regimes using only a fraction of the data required by current benchmarks. This work establishes a path toward robust, "plug-and-play" myoelectric control for long-term prosthetic use.

**AI Summary:** The research addresses the issue of signal drift in surface electromyography (EMG) for gesture recognition by proposing a lightweight Test-Time Adaptation framework using a Temporal Convolutional Network backbone. The framework includes strategies for real-time statistical alignment, preventing forgetting with experience replay, and rapid calibration through meta-learning. Results on the NinaPro DB6 dataset show that the framework significantly improves inter-session accuracy with minimal overhead, offering a promising solution for long-term prosthetic use.

---

## LLMberjack: Guided Trimming of Debate Trees for Multi-Party Conversation Creation
**URL:** https://arxiv.org/abs/2601.04135

**Abstract:** We present LLMberjack, a platform for creating multi-party conversations starting from existing debates, originally structured as reply trees. The system offers an interactive interface that visualizes discussion trees and enables users to construct coherent linearized dialogue sequences while preserving participant identity and discourse relations. It integrates optional large language model (LLM) assistance to support automatic editing of the messages and speakers' descriptions. We demonstrate the platform's utility by showing how tree visualization facilitates the creation of coherent, meaningful conversation threads and how LLM support enhances output quality while reducing human effort. The tool is open-source and designed to promote transparent and reproducible workflows to create multi-party conversations, addressing a lack of resources of this type.

**AI Summary:** LLMberjack is a platform that helps create multi-party conversations from existing debate trees, allowing users to construct coherent dialogue sequences while preserving participant identity and discourse relations. The system includes optional large language model (LLM) assistance to improve the quality of output and reduce human effort. This tool addresses the lack of resources for creating multi-party conversations and promotes transparent and reproducible workflows in this area.

---

## FocusUI: Efficient UI Grounding via Position-Preserving Visual Token Selection
**URL:** https://arxiv.org/abs/2601.03928

**Abstract:** Vision-Language Models (VLMs) have shown remarkable performance in User Interface (UI) grounding tasks, driven by their ability to process increasingly high-resolution screenshots. However, screenshots are tokenized into thousands of visual tokens (e.g., about 4700 for 2K resolution), incurring significant computational overhead and diluting attention. In contrast, humans typically focus on regions of interest when interacting with UI. In this work, we pioneer the task of efficient UI grounding. Guided by practical analysis of the task's characteristics and challenges, we propose FocusUI, an efficient UI grounding framework that selects patches most relevant to the instruction while preserving positional continuity for precise grounding. FocusUI addresses two key challenges: (1) Eliminating redundant tokens in visual encoding. We construct patch-level supervision by fusing an instruction-conditioned score with a rule-based UI-graph score that down-weights large homogeneous regions to select distinct and instruction-relevant visual tokens. (2) Preserving positional continuity during visual token selection. We find that general visual token pruning methods suffer from severe accuracy degradation on UI grounding tasks due to broken positional information. We introduce a novel PosPad strategy, which compresses each contiguous sequence of dropped visual tokens into a single special marker placed at the sequence's last index to preserve positional continuity. Comprehensive experiments on four grounding benchmarks demonstrate that FocusUI surpasses GUI-specific baselines. On the ScreenSpot-Pro benchmark, FocusUI-7B achieves a performance improvement of 3.7% over GUI-Actor-7B. Even with only 30% visual token retention, FocusUI-7B drops by only 3.2% while achieving up to 1.44x faster inference and 17% lower peak GPU memory.

**AI Summary:** FocusUI is a framework designed to improve the efficiency of UI grounding tasks by selecting the most relevant visual tokens while maintaining positional continuity. The framework addresses challenges such as eliminating redundant tokens and preserving positional information during token selection. Experimental results show that FocusUI outperforms GUI-specific baselines on multiple benchmarks, achieving faster inference and lower memory usage while maintaining high accuracy.

---

## Value-Action Alignment in Large Language Models under Privacy-Prosocial Conflict
**URL:** https://arxiv.org/abs/2601.03546

**Abstract:** Large language models (LLMs) are increasingly used to simulate decision-making tasks involving personal data sharing, where privacy concerns and prosocial motivations can push choices in opposite directions. Existing evaluations often measure privacy-related attitudes or sharing intentions in isolation, which makes it difficult to determine whether a model's expressed values jointly predict its downstream data-sharing actions as in real human behaviors. We introduce a context-based assessment protocol that sequentially administers standardized questionnaires for privacy attitudes, prosocialness, and acceptance of data sharing within a bounded, history-carrying session. To evaluate value-action alignments under competing attitudes, we use multi-group structural equation modeling (MGSEM) to identify relations from privacy concerns and prosocialness to data sharing. We propose Value-Action Alignment Rate (VAAR), a human-referenced directional agreement metric that aggregates path-level evidence for expected signs. Across multiple LLMs, we observe stable but model-specific Privacy-PSA-AoDS profiles, and substantial heterogeneity in value-action alignment.

**AI Summary:** This research focuses on the alignment between values expressed by large language models (LLMs) and their actual data-sharing actions in decision-making tasks involving privacy concerns and prosocial motivations. The study introduces a context-based assessment protocol to evaluate this alignment and uses multi-group structural equation modeling to identify relationships between privacy concerns, prosocialness, and data sharing. The findings show stable but model-specific profiles in terms of privacy concerns, prosocialness, and acceptance of data sharing, highlighting the importance of understanding and measuring value-action alignment in LLMs.

---

