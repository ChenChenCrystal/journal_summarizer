# arXiv cs.AI Summary â€“ 2025-12-08

## Eye of the Beholder: Towards Measuring Visualization Complexity
**URL:** https://arxiv.org/abs/2512.05536

**Abstract:** Constructing expressive and legible visualizations is a key activity for visualization designers. While numerous design guidelines exist, research on how specific graphical features affect perceived visual complexity remains limited. In this paper, we report on a crowdsourced study to collect human ratings of perceived complexity for diverse visualizations. Using these ratings as ground truth, we then evaluated three methods to estimate this perceived complexity: image analysis metrics, multilinear regression using manually coded visualization features, and automated feature extraction using a large language model (LLM). Image complexity metrics showed no correlation with human-perceived visualization complexity. Manual feature coding produced a reasonable predictive model but required substantial effort. In contrast, a zero-shot LLM (GPT-4o mini) demonstrated strong capabilities in both rating complexity and extracting relevant features. Our findings suggest that visualization complexity is truly in the eye of the beholder, yet can be effectively approximated using zero-shot LLM prompting, offering a scalable approach for evaluating the complexity of visualizations. The dataset and code for the study and data analysis can be found at this https URL

**AI Summary:** This research explores how different graphical features affect perceived visual complexity in visualizations. The study found that image complexity metrics did not correlate with human-perceived complexity, while manual feature coding was effective but time-consuming. However, using a zero-shot large language model (LLM) showed strong capabilities in rating complexity and extracting relevant features, offering a scalable approach for evaluating visualization complexity.

---

## User Negotiations of Authenticity, Ownership, and Governance on AI-Generated Video Platforms: Evidence from Sora
**URL:** https://arxiv.org/abs/2512.05519

**Abstract:** As AI-generated video platforms rapidly advance, ethical challenges such as copyright infringement emerge. This study examines how users make sense of AI-generated videos on OpenAI's Sora by conducting a qualitative content analysis of user comments. Through a thematic analysis, we identified four dynamics that characterize how users negotiate authenticity, authorship, and platform governance on Sora. First, users acted as critical evaluators of realism, assessing micro-details such as lighting, shadows, fluid motion, and physics to judge whether AI-generated scenes could plausibly exist. Second, users increasingly shifted from passive viewers to active creators, expressing curiosity about prompts, techniques, and creative processes. Text prompts were perceived as intellectual property, generating concerns about plagiarism and remixing norms. Third, users reported blurred boundaries between real and synthetic media, worried about misinformation, and even questioned the authenticity of other commenters, suspecting bot-generated engagement. Fourth, users contested platform governance: some perceived moderation as inconsistent or opaque, while others shared tactics for evading prompt censorship through misspellings, alternative phrasing, emojis, or other languages. Despite this, many users also enforced ethical norms by discouraging the misuse of real people's images or disrespectful content. Together, these patterns highlighted how AI-mediated platforms complicate notions of reality, creativity, and rule-making in emerging digital ecosystems. Based on the findings, we discuss governance challenges in Sora and how user negotiations inform future platform governance.

**AI Summary:** This study explores how users navigate authenticity, ownership, and governance issues on AI-generated video platform Sora. Users critically evaluate the realism of AI-generated content, shift from passive viewers to active creators, express concerns about plagiarism and misinformation, and question platform governance and moderation practices. The findings highlight the complexities of AI-mediated platforms and the need for thoughtful governance in emerging digital ecosystems.

---

## When Scaffolding Breaks: Investigating Student Interaction with LLM-Based Writing Support in Real-Time K-12 EFL Classrooms
**URL:** https://arxiv.org/abs/2512.05506

**Abstract:** Large language models (LLMs) are promising tools for scaffolding students' English writing skills, but their effectiveness in real-time K-12 classrooms remains underexplored. Addressing this gap, our study examines the benefits and limitations of using LLMs as real-time learning support, considering how classroom constraints, such as diverse proficiency levels and limited time, affect their effectiveness. We conducted a deployment study with 157 eighth-grade students in a South Korean middle school English class over six weeks. Our findings reveal that while scaffolding improved students' ability to compose grammatically correct sentences, this step-by-step approach demotivated lower-proficiency students and increased their system reliance. We also observed challenges to classroom dynamics, where extroverted students often dominated the teacher's attention, and the system's assistance made it difficult for teachers to identify struggling students. Based on these findings, we discuss design guidelines for integrating LLMs into real-time writing classes as inclusive educational tools.

**AI Summary:** This study explores the use of large language models (LLMs) as real-time support for English writing skills in K-12 classrooms. The research found that while LLMs improved students' ability to write grammatically correct sentences, lower-proficiency students became overly reliant on the system and felt demotivated. The study also identified challenges in classroom dynamics, such as extroverted students dominating teacher attention and difficulty in identifying struggling students. The findings suggest the need for design guidelines to effectively integrate LLMs into real-time writing classes as inclusive educational tools.

---

## Classification and taxonomy of mobile application usability issues
**URL:** https://arxiv.org/abs/2512.05450

**Abstract:** Despite years of research on testing the usability of mobile applications, our understanding of the issues their users experience still remains fragmented and underexplored. While most earlier studies has provided interesting insights, they have varying limitations in methodology, input diversity, and depth of this http URL the contrary, this study employs a triangulation strategy, using two research methods (systematic literature review and interview) and two data sources (scholarly literature and expert knowledge) to explore the traits underlying usability issues. Our study contributes to the field of human-computer interaction (HCI) by presenting a catalog of 16 usability issue categories, enriched with corresponding keywords and extended into a taxonomy, as well as a novel three-tier app-user-resource (AUR) classification system. At the first app level, usability issues arise from user interface design, as well as from efficiency, errors, and operability. At the second user level, they influence cognitive load, effectiveness, ease of use, learnability, memorability, and understandability. At the third resource level, usability issues stem from network quality and hardware, such as battery life, CPU speed, physical device button size and availability, RAM capacity, and screen size. The root cause of the usability issues is the user interface design. Detailed findings and takeaways for both researchers and practitioners are also discussed. Further research could focus on developing a measurement model for the identified variables to confirm the direction and strength of their relationships with perceived usability. Software vendors can also benefit by updating existing quality assurance programs, reviews and audits tools, as well as testing checklists.

**AI Summary:** This study addresses the fragmented understanding of mobile application usability issues by presenting a comprehensive catalog of 16 usability issue categories and a three-tier classification system. The study highlights the importance of user interface design in causing usability issues and provides insights for researchers and practitioners to improve mobile application usability. The findings suggest the need for further research to develop a measurement model for identified variables and for software vendors to update their quality assurance programs and testing tools.

---

## EXR: An Interactive Immersive EHR Visualization in Extended Reality
**URL:** https://arxiv.org/abs/2512.05438

**Abstract:** This paper presents the design and implementation of an Extended Reality (XR) platform for immersive, interactive visualization of Electronic Health Records (EHRs). The system extends beyond conventional 2D interfaces by visualizing both structured and unstructured patient data into a shared 3D environment, enabling intuitive exploration and real-time collaboration. The modular infrastructure integrates FHIR-based EHR data with volumetric medical imaging and AI-generated segmentation, ensuring interoperability with modern healthcare systems. The platform's capabilities are demonstrated using synthetic EHR datasets and computed tomography (CT)-derived spine models processed through an AI-powered segmentation pipeline. This work suggests that such integrated XR solutions could form the foundation for next-generation clinical decision-support tools, where advanced data infrastructures are directly accessible in an interactive and spatially rich environment.

**AI Summary:** This research introduces an Extended Reality (XR) platform for immersive visualization of Electronic Health Records (EHRs) in a 3D environment, allowing for intuitive exploration and collaboration. The system integrates structured EHR data, medical imaging, and AI-generated segmentation, demonstrating the potential for advanced clinical decision-support tools. This work highlights the importance of interactive and spatially rich environments in healthcare data visualization for future healthcare systems.

---

## From Vision to Touch: Bridging Visual and Tactile Principles for Accessible Data Representation
**URL:** https://arxiv.org/abs/2512.05433

**Abstract:** Tactile graphics are widely used to present maps and statistical diagrams to blind and low vision (BLV) people, with accessibility guidelines recommending their use for graphics where spatial relationships are important. Their use is expected to grow with the advent of commodity refreshable tactile displays. However, in stark contrast to visual information graphics, we lack a clear understanding of the benefits that well-designed tactile information graphics offer over text descriptions for BLV people. To address this gap, we introduce a framework considering the three components of encoding, perception and cognition to examine the known benefits for visual information graphics and explore their applicability to tactile information graphics. This work establishes a preliminary theoretical foundation for the tactile-first design of information graphics and identifies future research avenues.

**AI Summary:** This research explores the benefits of well-designed tactile information graphics for blind and low vision individuals compared to text descriptions. By examining the components of encoding, perception, and cognition, the study establishes a theoretical foundation for the tactile-first design of information graphics. This framework can help improve accessibility for BLV people and guide future research in this area.

---

## Simulating Life Paths with Digital Twins: AI-Generated Future Selves Influence Decision-Making and Expand Human Choice
**URL:** https://arxiv.org/abs/2512.05397

**Abstract:** Major life transitions demand high-stakes decisions, yet people often struggle to imagine how their future selves will live with the consequences. To support this limited capacity for mental time travel, we introduce AI-enabled digital twins that have ``lived through'' simulated life scenarios. Rather than predicting optimal outcomes, these simulations extend prospective cognition by making alternative futures vivid enough to support deliberation without assuming which path is best. We evaluate this idea in a randomized controlled study (N=192) using multimodal synthesis - facial age progression, voice cloning, and large language model dialogue - to create personalized avatars representing participants 30 years forward. Young adults 18 to 28 years old described pending binary decisions and were assigned to guided imagination or one of four avatar conditions: single-option, balanced dual-option, or expanded three-option with a system-generated novel alternative. Results showed asymmetric effects: single-sided avatars increased shifts toward the presented option, while balanced presentation produced movement toward both. Introducing a system-generated third option increased adoption of this new alternative compared to control, suggesting that AI-generated future selves can expand choice by surfacing paths that might otherwise go unnoticed. Participants rated evaluative reasoning and eudaimonic meaning-making as more important than emotional or visual vividness. Perceived persuasiveness and baseline agency predicted decision change. These findings advance understanding of AI-mediated episodic prospection and raise questions about autonomy in AI-augmented decisions.

**AI Summary:** This research introduces AI-enabled digital twins that simulate future selves to help individuals make high-stakes decisions. The study found that these simulations can expand human choice by making alternative futures vivid enough to support deliberation. Results showed that introducing a system-generated third option increased adoption of this new alternative, suggesting that AI-generated future selves can surface paths that might otherwise go unnoticed and influence decision-making.

---

## CLIO: A Tour Guide Robot with Co-speech Actions for Visual Attention Guidance and Enhanced User Engagement
**URL:** https://arxiv.org/abs/2512.05389

**Abstract:** While audio guides can offer rich information about an exhibit, it is challenging for visitors to focus on specific exhibit details based only on the verbal description. We present \textit{CLIO}, a tour guide robot with co-speech actions to direct visitors' visual attention and thus enhance the overall user engagement in a guided tour. \textit{CLIO} is equipped with designed actions to engage visitors. It builds eye contact with the visitor through tracking a visitor's face and blinking its eyes, or orient their attention by its head movement and laser pointer. We further use a Large Language Model (LLM) to coordinate the designed actions with a given narrative script for exhibition. We conducted a user study to evaluate the \textit{CLIO} system in a mock-up exhibition of historical photographs. We collected feedback from questionnaires and quantitative data from a mobile eye tracker. Experimental results validated that the engaging actions are well designed and demonstrated its efficacy in guiding visual attention of the visitors. It was evidenced that \textit{CLIO} achieved an enhanced engagement compared to the baseline system with only audio guidance.

**AI Summary:** The research presents CLIO, a tour guide robot with co-speech actions designed to enhance user engagement in guided tours by directing visitors' visual attention. CLIO uses eye contact, head movement, and a laser pointer to engage visitors and coordinate actions with a narrative script. A user study in a mock-up exhibition showed that CLIO's engaging actions effectively guided visual attention and significantly increased user engagement compared to a baseline system with only audio guidance.

---

## Systematically Evaluating Equivalent Purpose for Digital Maps
**URL:** https://arxiv.org/abs/2512.05310

**Abstract:** Digital geographic maps remain largely inaccessible to blind and low-vision individuals (BLVIs), despite global legislation adopting the Web Content Accessibility Guidelines (WCAG). A critical gap exists in defining "equivalent purpose" for maps under WCAG Success Criterion 1.1.1, which requires that non-text content provide a text alternative that serves the "equivalent purpose". This paper proposes a systematic framework for evaluating map accessibility, called the Map Equivalent-Purpose Framework (MEP Framework), defining purpose through three items (Generalized, Spatial Information, and Spatial Relationships), and establishing 15 measurable criteria for equivalent information communication. Eight text map representations were evaluated against visual map baselines using the proposed MEP Framework. Results show that legacy methods such as tables and turn-by-turn directions fail to meet the MEP Framework criteria, while Audiom Maps, Multi User Domain (MUD) Maps, and Audio Descriptions meet the criteria. The evaluation highlights the necessity of holistic, systematic approaches to ensure non-visual maps convey all generalized spatial information and relationships present in visual maps. The MEP Framework provides a replicable methodology for comprehensively assessing digital map accessibility, clarifying WCAG's "equivalent purpose", and guiding compliant and usable map creation. Compliant maps will support BLVIs' participation in map-dependent professions and civic engagement.

**AI Summary:** This research paper addresses the lack of accessibility for blind and low-vision individuals to digital maps, despite global legislation requiring accessibility. The authors propose a systematic framework called the Map Equivalent-Purpose Framework (MEP Framework) to evaluate map accessibility based on three defined purposes and 15 measurable criteria. The results show that traditional methods like tables and turn-by-turn directions fall short, while newer methods like Audiom Maps and Audio Descriptions meet the criteria, emphasizing the need for comprehensive approaches to ensure non-visual maps convey all necessary information. The MEP Framework provides a replicable methodology for creating compliant and usable maps that support blind and low-vision individuals in map-dependent professions and civic engagement.

---

## Knowing Your Uncertainty -- On the application of LLM in social sciences
**URL:** https://arxiv.org/abs/2512.05461

**Abstract:** Large language models (LLMs) are rapidly being integrated into computational social science research, yet their blackboxed training and designed stochastic elements in inference pose unique challenges for scientific inquiry. This article argues that applying LLMs to social scientific tasks requires explicit assessment of uncertainty-an expectation long established in both quantitative methodology in the social sciences and machine learning. We introduce a unified framework for evaluating LLM uncertainty along two dimensions: the task type (T), which distinguishes between classification, short-form, and long-form generation, and the validation type (V), which captures the availability of reference data or evaluative criteria. Drawing from both computer science and social science literature, we map existing uncertainty quantification (UQ) methods to this T-V typology and offer practical recommendations for researchers. Our framework provides both a methodological safeguard and a practical guide for integrating LLMs into rigorous social science research.

**AI Summary:** This research article discusses the challenges of using large language models (LLMs) in social science research due to their blackboxed training and stochastic elements. The authors propose a framework for evaluating uncertainty in LLMs based on task type and validation type, drawing from both computer science and social science literature. This framework serves as a methodological safeguard and practical guide for researchers looking to integrate LLMs into rigorous social science research.

---

## XR-DT: Extended Reality-Enhanced Digital Twin for Agentic Mobile Robots
**URL:** https://arxiv.org/abs/2512.05270

**Abstract:** As mobile robots increasingly operate alongside humans in shared workspaces, ensuring safe, efficient, and interpretable Human-Robot Interaction (HRI) has become a pressing challenge. While substantial progress has been devoted to human behavior prediction, limited attention has been paid to how humans perceive, interpret, and trust robots' inferences, impeding deployment in safety-critical and socially embedded environments. This paper presents XR-DT, an eXtended Reality-enhanced Digital Twin framework for agentic mobile robots, that bridges physical and virtual spaces to enable bi-directional understanding between humans and robots. Our hierarchical XR-DT architecture integrates virtual-, augmented-, and mixed-reality layers, fusing real-time sensor data, simulated environments in the Unity game engine, and human feedback captured through wearable AR devices. Within this framework, we design an agentic mobile robot system with a unified diffusion policy for context-aware task adaptation. We further propose a chain-of-thought prompting mechanism that allows multimodal large language models to reason over human instructions and environmental context, while leveraging an AutoGen-based multi-agent coordination layer to enhance robustness and collaboration in dynamic tasks. Initial experimental results demonstrate accurate human and robot trajectory prediction, validating the XR-DT framework's effectiveness in HRI tasks. By embedding human intention, environmental dynamics, and robot cognition into the XR-DT framework, our system enables interpretable, trustworthy, and adaptive HRI.

**AI Summary:** This research introduces XR-DT, a framework that combines extended reality technology with digital twin models to improve human-robot interaction in shared workspaces. The XR-DT architecture integrates virtual, augmented, and mixed reality layers to enhance communication between humans and robots, allowing for context-aware task adaptation. Experimental results show accurate human and robot trajectory prediction, demonstrating the effectiveness of the XR-DT framework in promoting interpretable, trustworthy, and adaptive human-robot interaction.

---

## Towards A Cultural Intelligence and Values Inferences Quality Benchmark for Community Values and Common Knowledge
**URL:** https://arxiv.org/abs/2512.05176

**Abstract:** Large language models (LLMs) have emerged as a powerful technology, and thus, we have seen widespread adoption and use on software engineering teams. Most often, LLMs are designed as "general purpose" technologies meant to represent the general population. Unfortunately, this often means alignment with predominantly Western Caucasian narratives and misalignment with other cultures and populations that engage in collaborative innovation. In response to this misalignment, there have been recent efforts centered on the development of "culturally-informed" LLMs, such as ChatBlackGPT, that are capable of better aligning with historically marginalized experiences and perspectives. Despite this progress, there has been little effort aimed at supporting our ability to develop and evaluate culturally-informed LLMs. A recent effort proposed an approach for developing a national alignment benchmark that emphasizes alignment with national social values and common knowledge. However, given the range of cultural identities present in the United States (U.S.), a national alignment benchmark is an ineffective goal for broader representation. To help fill this gap in this US context, we propose a replication study that translates the process used to develop KorNAT, a Korean National LLM alignment benchmark, to develop CIVIQ, a Cultural Intelligence and Values Inference Quality benchmark centered on alignment with community social values and common knowledge. Our work provides a critical foundation for research and development aimed at cultural alignment of AI technologies in practice.

**AI Summary:** This research focuses on the development of culturally-informed large language models (LLMs) to better align with diverse cultural perspectives and experiences. The study proposes the creation of a Cultural Intelligence and Values Inference Quality benchmark, CIVIQ, to evaluate the alignment of LLMs with community social values and common knowledge. This benchmark aims to support the development of AI technologies that are more inclusive and representative of a broader range of cultural identities.

---

## Perceptually-Minimal Color Optimization for Web Accessibility: A Multi-Phase Constrained Approach
**URL:** https://arxiv.org/abs/2512.05067

**Abstract:** Web accessibility guidelines require sufficient color contrast between text and backgrounds; yet, manually adjusting colors often necessitates significant visual deviation, compromising vital brand aesthetics. We present a novel, multi-phase optimization approach for automatically generating WCAG-compliant colors while minimizing perceptual change to original design choices.
Our method treats this as a constrained, non-linear optimization problem, utilizing the modern perceptually uniform OKLCH color space. Crucially, the optimization is constrained to preserve the original hue ($\text{H}$) of the color, ensuring that modifications are strictly limited to necessary adjustments in lightness ($\text{L}$) and chroma ($\text{C}$). This is achieved through a three-phase sequence: binary search, gradient descent, and progressive constraint relaxation.
Evaluation on a dataset of 10,000 procedurally generated color pairs demonstrates that the algorithm successfully resolves accessibility violations in $77.22\%$ of cases, with $88.51\%$ of successful corrections exhibiting imperceptible color difference ($\Delta E_{2000} < 2.0$) as defined by standard perceptibility thresholds. The median perceptual change for successful adjustments is only $0.76\ \Delta E_{2000}$, and the algorithm achieves this with a median processing time of $0.876\text{ms}$ per color pair.
The approach demonstrates that accessibility compliance and visual design integrity can be achieved simultaneously through a computationally efficient, perceptually-aware optimization that respects brand identity. The algorithm is publicly implemented in the open-source cm-colors Python library.

**AI Summary:** This research presents a novel approach to automatically generate web-accessible colors while minimizing perceptual changes to the original design. The algorithm successfully resolves accessibility violations in a majority of cases with imperceptible color differences, demonstrating that accessibility compliance and visual design integrity can be achieved simultaneously. The method is computationally efficient and respects brand identity, offering a valuable tool for web designers to ensure their content is accessible to all users.

---

## From Symptoms to Systems: An Expert-Guided Approach to Understanding Risks of Generative AI for Eating Disorders
**URL:** https://arxiv.org/abs/2512.04843

**Abstract:** Generative AI systems may pose serious risks to individuals vulnerable to eating disorders. Existing safeguards tend to overlook subtle but clinically significant cues, leaving many risks unaddressed. To better understand the nature of these risks, we conducted semi-structured interviews with 15 clinicians, researchers, and advocates with expertise in eating disorders. Using abductive qualitative analysis, we developed an expert-guided taxonomy of generative AI risks across seven categories: (1) providing generalized health advice; (2) encouraging disordered behaviors; (3) supporting symptom concealment; (4) creating thinspiration; (5) reinforcing negative self-beliefs; (6) promoting excessive focus on the body; and (7) perpetuating narrow views about eating disorders. Our results demonstrate how certain user interactions with generative AI systems intersect with clinical features of eating disorders in ways that may intensify risk. We discuss implications of our work, including approaches for risk assessment, safeguard design, and participatory evaluation practices with domain experts.

**AI Summary:** This research explores the risks posed by generative AI systems to individuals vulnerable to eating disorders, highlighting the importance of understanding subtle cues often overlooked by existing safeguards. Through interviews with experts in the field, a taxonomy of generative AI risks related to eating disorders was developed, including issues such as promoting disordered behaviors and negative self-beliefs. The study emphasizes the need for improved risk assessment, safeguard design, and collaboration with domain experts to address these potential harms.

---

## Interactive Communication -- cross-disciplinary perspectives from psychology, acoustics, and media technology
**URL:** https://arxiv.org/abs/2512.04692

**Abstract:** Interactive communication (IC), i.e., the reciprocal exchange of in- formation between two or more interactive partners, is a fundamental part of human nature. As such, it has been studied across multiple scientific disciplines with different goals and methods. This article pro- vides a cross-disciplinary primer on contemporary IC that integrates psy- chological mechanisms with acoustic and media-technological constraints across theory, measurement, and applications. First, we outline theoreti- cal frameworks that account for verbal, nonverbal and multimodal aspects of IC, including distinctions between face-to-face and computer-mediated communication. Second, we summarize key methodological approaches, including behavioral, cognitive, and experiential measures of communica- tive synchrony and acoustic signal quality. Third, we discuss selected applications, i.e. assistive listening technologies, conversational agents, alongside ethical considerations. Taken together, this review highlights how human capacities and technical systems jointly shape IC, consolidat- ing concepts, findings, and challenges that have often been discussed in separate lines of research.

**AI Summary:** The research article explores interactive communication (IC) from a cross-disciplinary perspective, integrating psychological mechanisms with acoustic and media-technological constraints. The study outlines theoretical frameworks, methodological approaches, and applications related to verbal, nonverbal, and multimodal aspects of IC. The review emphasizes the importance of understanding how human capacities and technical systems influence IC, consolidating concepts and challenges from various research fields.

---

## What is Beyond Presence? Dimensionality, Control, and Information Spaces
**URL:** https://arxiv.org/abs/2512.04398

**Abstract:** What is after presence? Spatial presence, the sense of "being there", is becoming less of a primary objective and more of a baseline expectation of virtual reality. More than six decades after its invention, VR is shifting from a technical system into a cultural, social, and phenomenological medium, offering experiences that function as distinct modes of reality. Existing theories that focus primarily on perceptual illusions are no longer sufficient to account for these emerging forms of experience. A new framework is needed to guide the design and evaluation of immersive environments by identifying the key technical and abstract dimensions afforded by virtual worlds. These dimensions include spatial, placeness, temporal, social, cultural, cognitive, and psychological parameters. The central argument is that immersive environments must move beyond the technical dimension to leverage richer information channels that shape user experience. This shift from presence to experience orchestration invites creators across disciplines to contribute to the design and assessment of meaningful immersive worlds.

**AI Summary:** The abstract explores the evolution of virtual reality beyond spatial presence, emphasizing the need for a new framework to guide the design and evaluation of immersive environments. The study highlights the importance of considering various dimensions such as spatial, social, cultural, cognitive, and psychological parameters in creating meaningful user experiences in virtual worlds. The shift from focusing solely on technical aspects to leveraging richer information channels is crucial for orchestrating immersive experiences that go beyond traditional notions of presence.

---

## Human-controllable AI: Meaningful Human Control
**URL:** https://arxiv.org/abs/2512.04334

**Abstract:** Developing human-controllable artificial intelligence (AI) and achieving meaningful human control (MHC) has become a vital principle to address these challenges, ensuring ethical alignment and effective governance in AI. MHC is also a critical focus in human-centered AI (HCAI) research and application. This chapter systematically examines MHC in AI, articulating its foundational principles and future trajectory. MHC is not simply the right to operate, but the unity of human understanding, intervention, and the traceablity of responsibility in AI decision-making, which requires technological design, AI governance, and humans to play a role together. MHC ensures AI autonomy serves humans without constraining technological progress. The mode of human control needs to match the levels of technology, and human supervision should balance the trust and doubt of AI. For future AI systems, MHC mandates human controllability as a prerequisite, requiring: (1) technical architectures with embedded mechanisms for human control; (2) human-AI interactions optimized for better access to human understanding; and (3) the evolution of AI systems harmonizing intelligence and human controllability. Governance must prioritize HCAI strategies: policies balancing innovation and risk mitigation, human-centered participatory frameworks transcending technical elite dominance, and global promotion of MHC as a universal governance paradigm to safeguard HCAI development. Looking ahead, there is a need to strengthen interdisciplinary research on the controllability of AI systems, enhance ethical and legal awareness among stakeholders, moving beyond simplistic technology design perspectives, focus on the knowledge construction, complexity interpretation, and influencing factors surrounding human control. By fostering MHC, the development of human-controllable AI can be further advanced, delivering HCAI systems.

**AI Summary:** The research focuses on the concept of meaningful human control (MHC) in artificial intelligence (AI) systems, emphasizing the importance of human understanding, intervention, and responsibility in AI decision-making. MHC ensures that AI serves humans without hindering technological progress, requiring a balance between human supervision and trust in AI. The study highlights the need for technical architectures with embedded mechanisms for human control, optimized human-AI interactions, and global governance strategies to promote human-centered AI development.

---

## ConsentDiff at Scale: Longitudinal Audits of Web Privacy Policy Changes and UI Frictions
**URL:** https://arxiv.org/abs/2512.04316

**Abstract:** Web privacy is experienced via two public artifacts: site utterances in policy texts, and the actions users are required to take during consent interfaces. In the extensive cross-section audits we've studied, there is a lack of longitudinal data detailing how these artifacts are changing together, and if interfaces are actually doing what they promise in policy. ConsentDiff provides that longitudinal view. We build a reproducible pipeline that snapshots sites every month, semantically aligns policy clauses to track clause-level churn, and classifies consent-UI patterns by pulling together DOM signals with cues provided by screenshots. We introduce a novel weighted claim-UI alignment score, connecting common policy claims to observable predicates, and enabling comparisons over time, regions, and verticals. Our measurements suggest continued policy churn, systematic changes to eliminate a higher-friction banner design, and significantly higher alignment where rejecting is visible and lower friction.

**AI Summary:** The research focuses on analyzing web privacy policy changes and user interface frictions over time using a tool called ConsentDiff. The study found that there is ongoing policy churn, efforts to reduce friction in consent interfaces, and improved alignment between policy claims and user interface elements, particularly in cases where users are given the option to reject consent. This research highlights the importance of monitoring and evaluating privacy policies and user interfaces to ensure transparency and user control in online data collection practices.

---

## The AI Consumer Index (ACE)
**URL:** https://arxiv.org/abs/2512.04921

**Abstract:** We introduce the first version of the AI Consumer Index (ACE), a benchmark for assessing whether frontier AI models can perform high-value consumer tasks. ACE contains a hidden heldout set of 400 test cases, split across four consumer activities: shopping, food, gaming, and DIY. We are also open sourcing 80 cases as a devset with a CC-BY license. For the ACE leaderboard we evaluated 10 frontier models (with websearch turned on) using a novel grading methodology that dynamically checks whether relevant parts of the response are grounded in the retrieved web sources. GPT 5 (Thinking = High) is the top-performing model, scoring 56.1%, followed by o3 Pro (Thinking = On) (55.2%) and GPT 5.1 (Thinking = High) (55.1%). Models differ across domains, and in Shopping the top model scores under 50%. For some requests (such as giving the correct price or providing working links), models are highly prone to hallucination. Overall, ACE shows a substantial gap between the performance of even the best models and consumers' AI needs.

**AI Summary:** The AI Consumer Index (ACE) is a benchmark for evaluating the performance of frontier AI models in completing high-value consumer tasks across various domains. The top-performing model, GPT 5, achieved a score of 56.1%, highlighting a substantial gap between the capabilities of AI models and consumers' needs. The study also revealed that models struggle with tasks such as providing accurate pricing information and functional links, indicating a need for further development in these areas.

---

## Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap
**URL:** https://arxiv.org/abs/2512.04680

**Abstract:** Self-adaptive systems (SASs) are designed to handle changes and uncertainties through a feedback loop with four core functionalities: monitoring, analyzing, planning, and execution. Recently, generative artificial intelligence (GenAI), especially the area of large language models, has shown impressive performance in data comprehension and logical reasoning. These capabilities are highly aligned with the functionalities required in SASs, suggesting a strong potential to employ GenAI to enhance SASs. However, the specific benefits and challenges of employing GenAI in SASs remain unclear. Yet, providing a comprehensive understanding of these benefits and challenges is complex due to several reasons: limited publications in the SAS field, the technological and application diversity within SASs, and the rapid evolution of GenAI technologies. To that end, this paper aims to provide researchers and practitioners a comprehensive snapshot that outlines the potential benefits and challenges of employing GenAI's within SAS. Specifically, we gather, filter, and analyze literature from four distinct research fields and organize them into two main categories to potential benefits: (i) enhancements to the autonomy of SASs centered around the specific functions of the MAPE-K feedback loop, and (ii) improvements in the interaction between humans and SASs within human-on-the-loop settings. From our study, we outline a research roadmap that highlights the challenges of integrating GenAI into SASs. The roadmap starts with outlining key research challenges that need to be tackled to exploit the potential for applying GenAI in the field of SAS. The roadmap concludes with a practical reflection, elaborating on current shortcomings of GenAI and proposing possible mitigation strategies.

**AI Summary:** This research paper explores the potential benefits and challenges of using generative artificial intelligence (GenAI) in self-adaptive systems (SASs), which are designed to handle changes and uncertainties through a feedback loop. The study suggests that GenAI, particularly in the area of large language models, could enhance the autonomy of SASs and improve the interaction between humans and SASs. However, there are challenges to integrating GenAI into SASs, and the research provides a roadmap outlining key research challenges and proposing mitigation strategies to exploit the potential of GenAI in SASs.

---

## A Modular Cognitive Architecture for Assisted Reasoning: The Nemosine Framework
**URL:** https://arxiv.org/abs/2512.04500

**Abstract:** This paper presents the Nemosine Framework, a modular cognitive architecture designed to support assisted reasoning, structured thinking, and systematic analysis. The model operates through functional cognitive modules ("personas") that organize tasks such as planning, evaluation, cross-checking, and narrative synthesis. The framework combines principles from metacognition, distributed cognition, and modular cognitive systems to offer an operational structure for assisted problem-solving and decision support. The architecture is documented through formal specification, internal consistency criteria, and reproducible structural components. The goal is to provide a clear conceptual basis for future computational implementations and to contribute to the study of symbolic-modular architectures for reasoning.

**AI Summary:** The Nemosine Framework is a modular cognitive architecture that supports assisted reasoning and structured thinking through functional cognitive modules. It combines principles from metacognition, distributed cognition, and modular cognitive systems to offer an operational structure for problem-solving and decision support. The framework provides a clear conceptual basis for future computational implementations and contributes to the study of symbolic-modular architectures for reasoning.

---

## Persona-based Multi-Agent Collaboration for Brainstorming
**URL:** https://arxiv.org/abs/2512.04488

**Abstract:** We demonstrate the importance of persona-based multi-agents brainstorming for both diverse topics and subject matter ideation. Prior work has shown that generalized multi-agent collaboration often provides better reasoning than a single agent alone. In this paper, we propose and develop a framework for persona-based agent selection, showing how persona domain curation can improve brainstorming outcomes. Using multiple experimental setups, we evaluate brainstorming outputs across different persona pairings (e.g., Doctor vs VR Engineer) and A2A (agent-to-agent) dynamics (separate, together, separate-then-together). Our results show that (1) persona choice shapes idea domains, (2) collaboration mode shifts diversity of idea generation, and (3) multi-agent persona-driven brainstorming produces idea depth and cross-domain coverage.

**AI Summary:** This research explores the impact of persona-based multi-agent collaboration on brainstorming outcomes, demonstrating that persona choice influences idea domains and collaboration mode affects the diversity of idea generation. The study shows that multi-agent persona-driven brainstorming leads to greater idea depth and cross-domain coverage, highlighting the significance of personalized agent selection in enhancing brainstorming processes.

---

## SmartAlert: Implementing Machine Learning-Driven Clinical Decision Support for Inpatient Lab Utilization Reduction
**URL:** https://arxiv.org/abs/2512.04354

**Abstract:** Repetitive laboratory testing unlikely to yield clinically useful information is a common practice that burdens patients and increases healthcare costs. Education and feedback interventions have limited success, while general test ordering restrictions and electronic alerts impede appropriate clinical care. We introduce and evaluate SmartAlert, a machine learning (ML)-driven clinical decision support (CDS) system integrated into the electronic health record that predicts stable laboratory results to reduce unnecessary repeat testing. This case study describes the implementation process, challenges, and lessons learned from deploying SmartAlert targeting complete blood count (CBC) utilization in a randomized controlled pilot across 9270 admissions in eight acute care units across two hospitals between August 15, 2024, and March 15, 2025. Results show significant decrease in number of CBC results within 52 hours of SmartAlert display (1.54 vs 1.82, p <0.01) without adverse effect on secondary safety outcomes, representing a 15% relative reduction in repetitive testing. Implementation lessons learned include interpretation of probabilistic model predictions in clinical contexts, stakeholder engagement to define acceptable model behavior, governance processes for deploying a complex model in a clinical environment, user interface design considerations, alignment with clinical operational priorities, and the value of qualitative feedback from end users. In conclusion, a machine learning-driven CDS system backed by a deliberate implementation and governance process can provide precision guidance on inpatient laboratory testing to safely reduce unnecessary repetitive testing.

**AI Summary:** The study introduces SmartAlert, a machine learning-driven clinical decision support system integrated into electronic health records to predict stable laboratory results and reduce unnecessary repeat testing. Results from a pilot study across two hospitals show a significant decrease in repeat complete blood count testing without adverse effects on safety outcomes, demonstrating a 15% relative reduction in repetitive testing. The study highlights the importance of stakeholder engagement, governance processes, user interface design, and qualitative feedback in implementing machine learning-driven clinical decision support systems to improve inpatient lab utilization.

---

## Mapping Data Labour Supply Chain in Africa in an Era of Digital Apartheid: a Struggle for Recognition
**URL:** https://arxiv.org/abs/2512.04269

**Abstract:** Content moderation and data labelling work has shifted to the Global South, particularly Africa, where workers operate under precarious conditions while remaining invisible to users. This study addresses the gap in understanding the scope of this industry and the working conditions of African content moderation workforce through a participatory approach. We collaborated with a union of content moderators to conduct desk research, deploy a questionnaire (n=81), and gather ethnographic observations across nine months that could answer their social needs. Our findings show that content moderation operations span 43 out of 55 African countries, involving 17 major firms serving predominantly North-American and European clients, with workers facing insecurity and inadequate psychological support. We contribute the first comprehensive map of Africa's content moderation industry, demonstrate a participatory methodology that centers workers' collective actions in documenting their conditions, and apply Honneth's ``struggle for recognition'' framework to understand data workers' demands for professional acknowledgement.

**AI Summary:** This study investigates the content moderation industry in Africa, revealing that workers in this sector face precarious conditions and lack visibility to users. The research involved collaboration with a union of content moderators to gather data on the working conditions and social needs of these workers. The findings highlight the widespread presence of content moderation operations across Africa, the challenges faced by workers, and the importance of recognizing data workers' demands for professional acknowledgment.

---

## Catching UX Flaws in Code: Leveraging LLMs to Identify Usability Flaws at the Development Stage
**URL:** https://arxiv.org/abs/2512.04262

**Abstract:** Usability evaluations are essential for ensuring that modern interfaces meet user needs, yet traditional heuristic evaluations by human experts can be time-consuming and subjective, especially early in development. This paper investigates whether large language models (LLMs) can provide reliable and consistent heuristic assessments at the development stage. By applying Jakob Nielsen's ten usability heuristics to thirty open-source websites, we generated over 850 heuristic evaluations in three independent evaluations per site using a pipeline of OpenAI's GPT-4o. For issue detection, the model demonstrated moderate consistency, with an average pairwise Cohen's Kappa of 0.50 and an exact agreement of 84%. Severity judgments showed more variability: weighted Cohen's Kappa averaged 0.63, but exact agreement was just 56%, and Krippendorff's Alpha was near zero. These results suggest that while GPT-4o can produce internally consistent evaluations, especially for identifying the presence of usability issues, its ability to judge severity varies and requires human oversight in practice. Our findings highlight the feasibility and limitations of using LLMs for early-stage, automated usability testing, and offer a foundation for improving consistency in automated User Experience (UX) evaluation. To the best of our knowledge, our work provides one of the first quantitative inter-rater reliability analyses of automated heuristic evaluation and highlights methods for improving model consistency.

**AI Summary:** This research explores the use of large language models (LLMs) to conduct heuristic evaluations of usability flaws in code during the development stage. The study found that LLMs, specifically GPT-4o, can provide consistent assessments of the presence of usability issues, but there is variability in judging severity. The results suggest that while LLMs can be useful for identifying flaws, human oversight is still necessary for accurate severity judgments, indicating the potential for automated usability testing in early-stage development with room for improvement in consistency.

---

## On the Role and Impact of GenAI Tools in Software Engineering Education
**URL:** https://arxiv.org/abs/2512.04256

**Abstract:** Context. The rise of generative AI (GenAI) tools like ChatGPT and GitHub Copilot has transformed how software is learned and written. In software engineering (SE) education, these tools offer new opportunities for support, but also raise concerns about over-reliance, ethical use, and impacts on learning. Objective. This study investigates how undergraduate SE students use GenAI tools, focusing on the benefits, challenges, ethical concerns, and instructional expectations that shape their experiences. Method. We conducted a survey with 130 undergraduate students from two universities. The survey combined structured Likert-scale items and open-ended questions to investigate five dimensions: usage context, perceived benefits, challenges, ethical and instructional perceptions. Results. Students most often use GenAI for incremental learning and advanced implementation, reporting benefits such as brainstorming support and confidence-building. At the same time, they face challenges including unclear rationales and difficulty adapting outputs. Students highlight ethical concerns around fairness and misconduct, and call for clearer instructional guidance. Conclusion. GenAI is reshaping SE education in nuanced ways. Our findings underscore the need for scaffolding, ethical policies, and adaptive instructional strategies to ensure that GenAI supports equitable and effective learning.

**AI Summary:** This study explores how undergraduate SE students use generative AI tools in their learning and writing processes, focusing on the benefits, challenges, ethical concerns, and instructional expectations that shape their experiences. The results show that students primarily use GenAI for incremental learning and advanced implementation, citing benefits such as brainstorming support and confidence-building. However, they also face challenges such as unclear rationales and ethical concerns around fairness and misconduct, indicating the need for clearer instructional guidance and ethical policies to ensure that GenAI supports equitable and effective learning in SE education.

---

## Artificial Intelligence Competence of K-12 Students Shapes Their AI Risk Perception: A Co-occurrence Network Analysis
**URL:** https://arxiv.org/abs/2512.04115

**Abstract:** As artificial intelligence (AI) becomes increasingly integrated into education, understanding how students perceive its risks is essential for supporting responsible and effective adoption. This research aimed to examine the relationships between perceived AI competence and risks among Finnish K-12 upper secondary students (n = 163) by utilizing a co-occurrence analysis. Students reported their self-perceived AI competence and concerns related to AI across systemic, institutional, and personal domains. The findings showed that students with lower competence emphasized personal and learning-related risks, such as reduced creativity, lack of critical thinking, and misuse, whereas higher-competence students focused more on systemic and institutional risks, including bias, inaccuracy, and cheating. These differences suggest that students' self-reported AI competence is related to how they evaluate both the risks and opportunities associated with artificial intelligence in education (AIED). The results of this study highlight the need for educational institutions to incorporate AI literacy into their curricula, provide teacher guidance, and inform policy development to ensure personalized opportunities for utilization and equitable integration of AI into K-12 education.

**AI Summary:** This study examined the relationship between perceived AI competence and risk perception among Finnish K-12 students. Findings showed that students with lower AI competence were more concerned about personal and learning-related risks, while higher-competence students focused on systemic and institutional risks. These results suggest the importance of incorporating AI literacy into education to ensure responsible and equitable integration of AI in K-12 settings.

---

## AI-Enabled grading with near-domain data for scaling feedback with human-level accuracy
**URL:** https://arxiv.org/abs/2512.04113

**Abstract:** Constructed-response questions are crucial to encourage generative processing and test a learner's understanding of core concepts. However, the limited availability of instructor time, large class sizes, and other resource constraints pose significant challenges in providing timely and detailed evaluation, which is crucial for a holistic educational experience. In addition, providing timely and frequent assessments is challenging since manual grading is labor intensive, and automated grading is complex to generalize to every possible response scenario. This paper proposes a novel and practical approach to grade short-answer constructed-response questions. We discuss why this problem is challenging, define the nature of questions on which our method works, and finally propose a framework that instructors can use to evaluate their students' open-responses, utilizing near-domain data like data from similar questions administered in previous years. The proposed method outperforms the state of the art machine learning models as well as non-fine-tuned large language models like GPT 3.5, GPT 4, and GPT 4o by a considerable margin of over 10-20% in some cases, even after providing the LLMs with reference/model answers. Our framework does not require pre-written grading rubrics and is designed explicitly with practical classroom settings in mind. Our results also reveal exciting insights about learning from near-domain data, including what we term as accuracy and data advantages using human-labeled data, and we believe this is the first work to formalize the problem of automated short answer grading based on the near-domain data.

**AI Summary:** This research paper introduces a novel approach to grading short-answer constructed-response questions using near-domain data, such as data from similar questions in previous years. The proposed method outperforms state-of-the-art machine learning models and large language models like GPT 3.5, GPT 4, and GPT 4o by a significant margin, even without pre-written grading rubrics. The findings highlight the advantages of learning from near-domain data and provide valuable insights for automated short answer grading in practical classroom settings.

---

## HAI-Eval: Measuring Human-AI Synergy in Collaborative Coding
**URL:** https://arxiv.org/abs/2512.04111

**Abstract:** LLM-powered coding agents are reshaping the development paradigm. However, existing evaluation systems, neither traditional tests for humans nor benchmarks for LLMs, fail to capture this shift. They remain focused on well-defined algorithmic problems, which excludes problems where success depends on human-AI collaboration. Such collaborative problems not only require human reasoning to interpret complex contexts and guide solution strategies, but also demand AI efficiency for implementation. To bridge this gap, we introduce HAI-Eval, a unified benchmark designed to measure the synergy of human-AI partnership in coding. HAI-Eval's core innovation is its "Collaboration-Necessary" problem templates, which are intractable for both standalone LLMs and unaided humans, but solvable through effective collaboration. Specifically, HAI-Eval uses 45 templates to dynamically create tasks. It also provides a standardized IDE for human participants and a reproducible toolkit with 450 task instances for LLMs, ensuring an ecologically valid evaluation. We conduct a within-subject study with 45 participants and benchmark their performance against 5 state-of-the-art LLMs under 4 different levels of human intervention. Results show that standalone LLMs and unaided participants achieve poor pass rates (0.67% and 18.89%), human-AI collaboration significantly improves performance to 31.11%. Our analysis reveals an emerging co-reasoning partnership. This finding challenges the traditional human-tool hierarchy by showing that strategic breakthroughs can originate from either humans or AI. HAI-Eval establishes not only a challenging benchmark for next-generation coding agents but also a grounded, scalable framework for assessing core developer competencies in the AI era. Our benchmark and interactive demo will be openly accessible.

**AI Summary:** The research introduces HAI-Eval, a benchmark designed to measure the synergy of human-AI partnership in coding. The study conducted with 45 participants and 5 state-of-the-art LLMs shows that human-AI collaboration significantly improves performance compared to standalone LLMs and unaided participants. The findings suggest an emerging co-reasoning partnership challenging the traditional human-tool hierarchy, providing a framework for assessing developer competencies in the AI era.

---

## Responsible LLM Deployment for High-Stake Decisions by Decentralized Technologies and Human-AI Interactions
**URL:** https://arxiv.org/abs/2512.04108

**Abstract:** High-stakes decision domains are increasingly exploring the potential of Large Language Models (LLMs) for complex decision-making tasks. However, LLM deployment in real-world settings presents challenges in data security, evaluation of its capabilities outside controlled environments, and accountability attribution in the event of adversarial decisions. This paper proposes a framework for responsible deployment of LLM-based decision-support systems through active human involvement. It integrates interactive collaboration between human experts and developers through multiple iterations at the pre-deployment stage to assess the uncertain samples and judge the stability of the explanation provided by post-hoc XAI techniques. Local LLM deployment within organizations and decentralized technologies, such as Blockchain and IPFS, are proposed to create immutable records of LLM activities for automated auditing to enhance security and trace back accountability. It was tested on Bert-large-uncased, Mistral, and LLaMA 2 and 3 models to assess the capability to support responsible financial decisions on business lending.

**AI Summary:** This paper addresses the challenges of deploying Large Language Models (LLMs) for high-stakes decision-making tasks, focusing on data security, evaluation of capabilities, and accountability attribution. The proposed framework emphasizes active human involvement in the deployment process to assess uncertain samples and ensure the stability of explanations provided by post-hoc eXplainable AI (XAI) techniques. The use of decentralized technologies like Blockchain and IPFS is suggested to create immutable records of LLM activities for automated auditing, enhancing security and accountability in decision-making processes.

---

## Rethinking AI Evaluation in Education: The TEACH-AI Framework and Benchmark for Generative AI Assistants
**URL:** https://arxiv.org/abs/2512.04107

**Abstract:** As generative artificial intelligence (AI) continues to transform education, most existing AI evaluations rely primarily on technical performance metrics such as accuracy or task efficiency while overlooking human identity, learner agency, contextual learning processes, and ethical considerations. In this paper, we present TEACH-AI (Trustworthy and Effective AI Classroom Heuristics), a domain-independent, pedagogically grounded, and stakeholder-aligned framework with measurable indicators and a practical toolkit for guiding the design, development, and evaluation of generative AI systems in educational contexts. Built on an extensive literature review and synthesis, the ten-component assessment framework and toolkit checklist provide a foundation for scalable, value-aligned AI evaluation in education. TEACH-AI rethinks "evaluation" through sociotechnical, educational, theoretical, and applied lenses, engaging designers, developers, researchers, and policymakers across AI and education. Our work invites the community to reconsider what constructs "effective" AI in education and to design model evaluation approaches that promote co-creation, inclusivity, and long-term human, social, and educational impact.

**AI Summary:** The paper introduces the TEACH-AI framework, which emphasizes the importance of considering human identity, learner agency, contextual learning processes, and ethical considerations in evaluating generative AI systems in education. The framework provides measurable indicators and a practical toolkit for designing and evaluating AI systems in educational contexts, promoting co-creation, inclusivity, and long-term impact. This research aims to shift the focus of AI evaluation in education from technical performance metrics to more holistic and stakeholder-aligned criteria, encouraging a more thoughtful and values-driven approach to AI development in educational settings.

---

## LegalWebAgent: Empowering Access to Justice via LLM-Based Web Agents
**URL:** https://arxiv.org/abs/2512.04105

**Abstract:** Access to justice remains a global challenge, with many citizens still finding it difficult to seek help from the justice system when facing legal issues. Although the internet provides abundant legal information and services, navigating complex websites, understanding legal terminology, and filling out procedural forms continue to pose barriers to accessing justice. This paper introduces the LegalWebAgent framework that employs a web agent powered by multimodal large language models to bridge the gap in access to justice for ordinary citizens. The framework combines the natural language understanding capabilities of large language models with multimodal perception, enabling a complete process from user query to concrete action. It operates in three stages: the Ask Module understands user needs through natural language processing; the Browse Module autonomously navigates webpages, interacts with page elements (including forms and calendars), and extracts information from HTML structures and webpage screenshots; the Act Module synthesizes information for users or performs direct actions like form completion and schedule booking. To evaluate its effectiveness, we designed a benchmark test covering 15 real-world tasks, simulating typical legal service processes relevant to QuÃ©bec civil law users, from problem identification to procedural operations. Evaluation results show LegalWebAgent achieved a peak success rate of 86.7%, with an average of 84.4% across all tested models, demonstrating high autonomy in complex real-world scenarios.

**AI Summary:** The LegalWebAgent framework utilizes a web agent powered by large language models to improve access to justice by helping users navigate complex legal websites, understand legal terminology, and fill out procedural forms. The framework operates in three stages - Ask, Browse, and Act - to understand user needs, autonomously navigate webpages, and perform actions like form completion. Evaluation results show that LegalWebAgent achieved a high success rate of 84.4% in completing real-world legal tasks, demonstrating its effectiveness in providing assistance to ordinary citizens seeking legal help.

---

## Human-Centred Evaluation of Text-to-Image Generation Models for Self-expression of Mental Distress: A Dataset Based on GPT-4o
**URL:** https://arxiv.org/abs/2512.04087

**Abstract:** Effective communication is central to achieving positive healthcare outcomes in mental health contexts, yet international students often face linguistic and cultural barriers that hinder their communication of mental distress. In this study, we evaluate the effectiveness of AI-generated images in supporting self-expression of mental distress. To achieve this, twenty Chinese international students studying at UK universities were invited to describe their personal experiences of mental distress. These descriptions were elaborated using GPT-4o with four persona-based prompt templates rooted in contemporary counselling practice to generate corresponding images. Participants then evaluated the helpfulness of generated images in facilitating the expression of their feelings based on their original descriptions. The resulting dataset comprises 100 textual descriptions of mental distress, 400 generated images, and corresponding human evaluation scores. Findings indicate that prompt design substantially affects perceived helpfulness, with the illustrator persona achieving the highest ratings. This work introduces the first publicly available text-to-image evaluation dataset with human judgment scores in the mental health domain, offering valuable resources for image evaluation, reinforcement learning with human feedback, and multi-modal research on mental health communication.

**AI Summary:** This study evaluates the use of AI-generated images to support the self-expression of mental distress in Chinese international students studying in the UK. The research found that the design of prompts significantly impacts the perceived helpfulness of the generated images, with the illustrator persona prompt receiving the highest ratings. The resulting dataset of 100 textual descriptions of mental distress and 400 generated images with human evaluation scores provides valuable resources for image evaluation and research on mental health communication.

---

## Affordances of Digital and Blockchain-based Community Currencies: The Case of Sarafu Network in Kenya
**URL:** https://arxiv.org/abs/2512.04030

**Abstract:** Community currencies (CCs) have been adopting innovative systems to overcome implementational hurdles from issuing paper currencies. Using a qualitative approach, this paper examined this digital transition of Sarafu Network in Kenya and its predecessor CCs as a case study. From the original vouchers launched in 2010, the foundation Grassroots Economics introduced a digital interface in 2016 that operates on a feature phone, and then integrated blockchain technology starting in 2018, undergoing several migrations before becoming settling on its current iteration called Community Asset Vouchers on the Celo blockchain since 2023. Using affordances from human-computer interaction, the research shows that digitalization and blockchain improved the facilitation of economic activities of the local communities, both their typical market transactions as well as traditional reciprocal labor exchanges, by offering more functionalities compared to the analog version of Sarafu. The unique contributions of blockchain include enabling automation of holding tax calculations and linking the vouchers to the mainstream monetary system via stablecoins facilitated by a series of smart contracts also known as the liquidity pool. The study also finds that there is an inherent trade-off between blockchain benefits and user interface complexity. Hence, balancing innovation and community needs remains a challenge.

**AI Summary:** This research paper explores the transition of the Sarafu Network in Kenya from paper vouchers to a digital and blockchain-based system, highlighting the improvements in economic activities for local communities. The introduction of digitalization and blockchain technology enhanced the functionality of the community currency, allowing for automation of tax calculations and integration with the mainstream monetary system. However, the study also notes a trade-off between the benefits of blockchain and the complexity of the user interface, emphasizing the need to balance innovation with community needs.

---

## When to Say "Hi" - Learn to Open a Conversation with an in-the-wild Dataset
**URL:** https://arxiv.org/abs/2512.03991

**Abstract:** The social capabilities of socially interactive agents (SIA) are a key to successful and smooth interactions between the user and the SIA. A successful start of the interaction is one of the essential factors for satisfying SIA interactions. For a service and information task in which the SIA helps with information, e.g. about the location, it is an important skill to master the opening of the conversation and to recognize which interlocutor opens the conversation and when. We are therefore investigating the extent to which the opening of the conversation can be trained using the user's body language as an input for machine learning to ensure smooth conversation starts for the interaction. In this paper we propose the Interaction Initiation System (IIS) which we developed, trained and validated using an in-the-wild data set. In a field test at the Deutsches Museum Bonn, a Furhat robot from Furhat Robotics was used as a service and information point. Over the period of use we collected the data of \textit{N} = 201 single user interactions for the training of the algorithms. We can show that the IIS, achieves a performance that allows the conclusion that this system is able to determine the greeting period and the opener of the interaction.

**AI Summary:** The research focuses on training socially interactive agents (SIAs) to open conversations effectively using the user's body language as input for machine learning. The Interaction Initiation System (IIS) developed and tested with an in-the-wild dataset showed promising results in determining the greeting period and opener of interactions, which is crucial for successful and satisfying SIA interactions. This study highlights the importance of mastering conversation openings for smooth interactions between users and SIAs in service and information tasks.

---

## HEART-Watch: A multimodal physiological dataset from a Google Pixel Watch across different physical states
**URL:** https://arxiv.org/abs/2512.03988

**Abstract:** Consumer-grade smartwatches offer a new personalized health monitoring option for general consumers globally as cardiovascular diseases continue to prevail as the leading cause of global mortality. The development and validation of reliable cardiovascular monitoring algorithms for these consumer-grade devices requires realistic biosignal data from diverse sets of participants. However, the availability of public consumer-grade smartwatch datasets with synchronized cardiovascular biosignals is limited, and existing datasets do not offer rich demographic diversity in their participant cohorts, leading to potentially biased algorithm development. This paper presents HEART-Watch, a multimodal physiological dataset collected from temporally synchronized wrist-worn Google Pixel Watch 2 electrocardiogram (ECG), photoplethysmography, and accelerometer signals from a diverse cohort of 40 healthy adults across three physical states - sitting, standing and walking with reference chest ECG. Intermittent upper arm blood pressure measurements and concurrent biosignals were collected as an additional biomarker for future research. The motivation, methodology, and initial analyses of results are presented. HEART-Watch is intended to support the development and benchmarking of robust algorithms for cardiovascular analyses on consumer-grade smartwatches across diverse populations.

**AI Summary:** The study introduces HEART-Watch, a dataset collected from a diverse group of healthy adults wearing a Google Pixel Watch 2, including ECG, photoplethysmography, and accelerometer signals in different physical states. This dataset aims to provide realistic biosignal data for the development and validation of cardiovascular monitoring algorithms on consumer-grade smartwatches, addressing the lack of diverse public datasets for this purpose. HEART-Watch can support future research in developing robust algorithms for cardiovascular analysis on smartwatches for a wider range of populations.

---

## Classification of User Satisfaction in HRI with Social Signals in the Wild
**URL:** https://arxiv.org/abs/2512.03945

**Abstract:** Socially interactive agents (SIAs) are being used in various scenarios and are nearing productive deployment. Evaluating user satisfaction with SIAs' performance is a key factor in designing the interaction between the user and SIA. Currently, subjective user satisfaction is primarily assessed manually through questionnaires or indirectly via system metrics. This study examines the automatic classification of user satisfaction through analysis of social signals, aiming to enhance both manual and autonomous evaluation methods for SIAs. During a field trial at the Deutsches Museum Bonn, a Furhat Robotics head was employed as a service and information hub, collecting an "in-the-wild" dataset. This dataset comprises 46 single-user interactions, including questionnaire responses and video data. Our method focuses on automatically classifying user satisfaction based on time series classification. We use time series of social signal metrics derived from the body pose, time series of facial expressions, and physical distance. This study compares three feature engineering approaches on different machine learning models. The results confirm the method's effectiveness in reliably identifying interactions with low user satisfaction without the need for manually annotated datasets. This approach offers significant potential for enhancing SIA performance and user experience through automated feedback mechanisms.

**AI Summary:** This study focuses on automatically classifying user satisfaction with socially interactive agents (SIAs) through analysis of social signals, aiming to improve evaluation methods for SIAs. Using data collected from a field trial at the Deutsches Museum Bonn, the study compares different feature engineering approaches and machine learning models to effectively identify interactions with low user satisfaction without the need for manual annotations. The results suggest that this approach has the potential to enhance SIA performance and user experience through automated feedback mechanisms.

---

## Adhera: A Human-Centered Health Informatics Solution for Reducing Informal Caregiver Burden through Improved Medication Adherence
**URL:** https://arxiv.org/abs/2512.03878

**Abstract:** The growing global population of older adults, combined with ongoing healthcare workforce shortages, has increased reliance on informal caregivers, including family members and friends who provide unpaid support to individuals with chronic illnesses. Among their daily responsibilities, medication management remains one of the most demanding and error-prone tasks. Non-adherence to prescribed regimens not only undermines patient outcomes but also intensifies caregiver stress, anxiety, and fatigue. Although digital health technologies have proliferated to address adherence, most solutions focus exclusively on patients and neglect the informational and emotional needs of caregivers. This paper introduces Adhera, a caregiver-inclusive health informatics system designed to support medication adherence while reducing caregiver burden. Using a mixed-methods research design that included fifteen semi-structured caregiver interviews, sixty-five survey responses, and five pharmacist consultations, this study identified three primary challenges: caregiver stress related to uncertainty about medication intake, fragmented communication with healthcare professionals, and distrust in existing digital tools. Informed by the CeHRes Roadmap 2.0 and the Triple Bottom Line by Design and Culture (TBLD+C) framework, as well as recent co-design studies involving caregivers, Adhera integrates a sensor-equipped smart pill organizer with a mobile companion application that records intake events, sends real-time reminders, and provides caregivers with synchronized adherence data. Preliminary evaluation suggests that Adhera enhances visibility, improves caregiver confidence, and streamlines medication routines. This study contributes to the field of health informatics by demonstrating how human-centered design and collaborative frameworks can align technical innovation with empathy-driven care.

**AI Summary:** This research paper introduces Adhera, a health informatics system designed to support medication adherence and reduce caregiver burden. The study identified challenges faced by caregivers, such as uncertainty about medication intake and distrust in existing digital tools. Adhera integrates a smart pill organizer with a mobile app to improve visibility, caregiver confidence, and streamline medication routines, highlighting the importance of human-centered design in healthcare technology.

---

## Sleep Modulation: The Challenge of Transitioning from Open Loop to Closed Loop
**URL:** https://arxiv.org/abs/2512.03784

**Abstract:** Sleep disorders have emerged as a critical global health issue, highlighting the urgent need for effective and widely accessible intervention technologies. Non-invasive brain stimulation has garnered attention as it enables direct or indirect modulation of neural activity, thereby promoting sleep enhancement in a safe and unobtrusive manner. This class of approaches is collectively referred to as sleep modulation. To date, the majority of sleep modulation research relies on open-loop paradigms with empirically determined parameters, while achieving individual adaptation and modulation accuracy remains a distant objective. The paradigm-specific constraints inherent to open-loop designs represent a major obstacle to clinical translation and large-scale deployment in home environments. In this paper, we delineate fundamental paradigms of sleep modulation, critically examine the intrinsic limitations of open-loop approaches, and formally conceptualize sleep closed-loop modulation. We further provide a comprehensive synthesis of prior studies involving five commonly employed modulation techniques, evaluating their potential integration within a closed-loop framework. Finally, we identify three primary challenges in constructing an effective sleep closed-loop modulation system: sensor solution selection, monitoring model design, and modulation strategy design, while also proposing potential solutions. Collectively, this work aims to advance the paradigm shift of sleep modulation from open-loop toward closed-loop systems.

**AI Summary:** This research paper explores the transition from open-loop to closed-loop sleep modulation systems, which have the potential to address the global health issue of sleep disorders. The study highlights the limitations of current open-loop approaches and proposes the development of closed-loop systems for more personalized and accurate sleep modulation. The paper identifies key challenges in constructing effective closed-loop systems and offers potential solutions, aiming to advance the field of sleep modulation towards more efficient and accessible interventions.

---

## Head, posture, and full-body gestures in dyadic conversations
**URL:** https://arxiv.org/abs/2512.03636

**Abstract:** When face-to-face communication becomes effortful due to background noise and interfering talkers, the role of visual cues becomes increasingly important for communication success. While previous research has selectively investigated head or hand movements, here we explore the combination of movements of head, hand and the whole body in acoustically adverse conditions. We hypothesize that with increasing background noise level, the frequency of typical conversational movements of hand, head, trunk, and legs increases to support the speakers role while the listeners support their role by increased use of confirmative head gestures and head and trunk movements to increase the signal-to-noise ratio. We conducted a dyadic conversation experiment in which (n=8) normal hearing participants stood freely in an audiovisual virtual environment. The conversational movements were described by a newly developed labeling system for typical conversational movements, and the frequency of individual types was analyzed. Increased levels of background noise led to increased hand-gesture complexity and modulation of head movements without a clear pattern. People leaned forward slightly more and used less head movements during listening than during speaking. Additional analysis of hand-speech synchrony with hypothesized loss of synchrony due to the background noise showed a modest decrease of synchrony in terms of increased standard deviation at moderate sound levels. The results support previous findings in terms of the gesturing frequency, and we found a limited support for the changes in speech-gesture synchrony. The work reveals communication patterns of the whole body and exemplifies interactive communication in context of multimodal adaptation to communication needs.

**AI Summary:** This research explores the role of head, hand, and full-body gestures in dyadic conversations in acoustically adverse conditions. The study found that as background noise levels increased, participants exhibited more complex hand gestures and modulated head movements to support communication. The findings highlight the importance of visual cues in aiding communication success when faced with challenging auditory conditions.

---

## Synthetic Cognitive Walkthrough: Aligning Large Language Model Performance with Human Cognitive Walkthrough
**URL:** https://arxiv.org/abs/2512.03568

**Abstract:** Conducting usability testing like cognitive walkthrough (CW) can be costly. Recent developments in large language models (LLMs), with visual reasoning and UI navigation capabilities, present opportunities to automate CW. We explored whether LLMs (GPT-4 and Gemini-2.5-pro) can simulate human behavior in CW by comparing their walkthroughs with human participants. While LLMs could navigate interfaces and provide reasonable rationales, their behavior differed from humans. LLM-prompted CW achieved higher task completion rates than humans and followed more optimal navigation paths, while identifying fewer potential failure points. However, follow-up studies demonstrated that with additional prompting, LLMs can predict human-identified failure points, aligning their performance with human participants. Our work highlights that while LLMs may not replicate human behaviors exactly, they can be leveraged for scaling usability walkthroughs and providing UI insights, offering a valuable complement to traditional usability testing.

**AI Summary:** The research explores using large language models (LLMs) to automate cognitive walkthroughs, a costly usability testing method. While LLMs differed from humans in behavior, they were able to achieve higher task completion rates and identify optimal navigation paths with fewer potential failure points. With additional prompting, LLMs were able to predict human-identified failure points, showing potential for scaling usability walkthroughs and providing valuable UI insights.

---

## Left shifting analysis of Human-Autonomous Team interactions to analyse risks of autonomy in high-stakes AI systems
**URL:** https://arxiv.org/abs/2512.03519

**Abstract:** Developing high-stakes autonomous systems that include Artificial Intelligence (AI) components is complex; the consequences of errors can be catastrophic, yet it is challenging to plan for all operational cases. In stressful scenarios for the human operator, such as short decision-making timescales, the risk of failures is exacerbated. A lack of understanding of AI failure modes obstructs this and so blocks the robust implementation of applications of AI in smart systems. This prevents early risk identification, leading to increased time, risk and cost of projects.
A key tenet of Systems Engineering and acquisition engineering is centred around a "left-shift" in test and evaluation activities to earlier in the system lifecycle, to allow for "accelerated delivery of [systems] that work". We argue it is therefore essential that this shift includes the analysis of AI failure cases as part of the design stages of the system life cycle. Our proposed framework enables the early characterisation of risks emerging from human-autonomy teaming (HAT) in operational contexts. The cornerstone of this is a new analysis of AI failure modes, built on the seminal modelling of human-autonomy teams laid out by LaMonica et al., 2022. Using the analysis of the interactions between human and autonomous systems and exploring the failure modes within each aspect, our approach provides a way to systematically identify human-AI interactions risks across the operational domain of the system of interest. The understanding of the emergent behaviour enables increased robustness of the system, for which the analysis should be undertaken over the whole scope of its operational design domain. This approach is illustrated through an example use case for an AI assistant supporting a Command & Control (C2) System.

**AI Summary:** The research focuses on analyzing the risks associated with autonomy in high-stakes AI systems, particularly in scenarios where human operators are under stress and decision-making timescales are short. The study emphasizes the importance of early identification of AI failure modes in the design stages of the system life cycle to mitigate risks and reduce project time, cost, and complexity. By developing a framework that analyzes human-autonomy team interactions and AI failure modes, the research aims to enhance the robustness of autonomous systems and improve their overall performance in operational contexts.

---

## EMINDS: Understanding User Behavior Progression for Mental Health Exploration on Social Media
**URL:** https://arxiv.org/abs/2512.03495

**Abstract:** Mental health is an urgent societal issue, and social scientists are increasingly turning to online mental health communities (OMHCs) to analyze user behavior data for early intervention. However, existing sequence mining techniques fall short of the urgent need to explore the behavior progression of different groups (e.g., recovery or deterioration groups) and track the potential long-term impact of behaviors on mental health status. To address this issue, we introduce EMINDS, a visual analytics system built on a novel automatic mining pipeline that extracts distinct behavior stages and assesses the potential impact of frequent stage patterns on mental health status over time. The system includes a set of interactive visualizations that summarize the meaning of each behavior stage and the evolution of different stage patterns. We feature a pattern-centric Sankey diagram to reveal contextual information about the impact of stage patterns on mental health, helping experts understand the specific changes in sequences before and after a stage pattern. We evaluated the effectiveness and usability of EMINDS through two case studies and expert interviews, which examined the potential stage patterns impacting long-term mental health by analyzing user behaviors on Reddit.

**AI Summary:** The study discusses the importance of analyzing user behavior data from online mental health communities for early intervention. The researchers introduce EMINDS, a visual analytics system that extracts distinct behavior stages and assesses the potential impact of frequent stage patterns on mental health status over time. The system includes interactive visualizations, such as a pattern-centric Sankey diagram, to help experts understand the specific changes in sequences before and after a stage pattern, ultimately aiding in the exploration of user behavior progression for mental health on social media.

---

## CellScout: Visual Analytics for Mining Biomarkers in Cell State Discovery
**URL:** https://arxiv.org/abs/2512.03485

**Abstract:** Cell state discovery is crucial for understanding biological systems and enhancing medical outcomes. A key aspect of this process is identifying distinct biomarkers that define specific cell states. However, difficulties arise from the co-discovery process of cell states and biomarkers: biologists often use dimensionality reduction to visualize cells in a two- dimensional space. Then they usually interpret visually clustered cells as distinct states, from which they seek to identify unique biomarkers. However, this assumption is often invalid due to internal inconsistencies in a cluster, making the process trial-and-error and highly uncertain. Therefore, biologists urgently need effective tools to help uncover the hidden association relationships between different cell populations and their potential biomarkers. To address this problem, we first designed a machine-learning algorithm based on the Mixture-of-Experts (MoE) technique to identify meaningful associations between cell populations and biomarkers. We further developed a visual analytics system, CellScout, in collaboration with biologists, to help them explore and refine these association relationships to advance cell state discovery. We validated our system through expert interviews, from which we further selected a representative case to demonstrate its effectiveness in discovering new cell states.

**AI Summary:** The research focuses on developing a visual analytics system called CellScout to aid biologists in mining biomarkers for cell state discovery. The study highlights the challenges in identifying distinct biomarkers and cell states, as well as the limitations of traditional methods like dimensionality reduction. By utilizing a machine-learning algorithm based on the Mixture-of-Experts technique, the researchers were able to uncover hidden association relationships between cell populations and biomarkers, ultimately leading to the discovery of new cell states. The validation of the system through expert interviews and a representative case study demonstrates its effectiveness in advancing biological research and medical outcomes.

---

## Why Some Seek AI, Others Seek Therapists: Mental Health in the Age of Generative AI
**URL:** https://arxiv.org/abs/2512.03406

**Abstract:** As generative artificial intelligence (GAI) enters the mental health landscape, questions arise about how individuals weigh AI tools against human therapists. Drawing on the Health Belief Model (HBM), this study examined belief-based predictors of intention to use GAI and therapists across two populations: a university sample (N = 1,155) and a nationally representative adult sample (N = 651). Using repeated-measures ANOVA and LASSO regression, we found that therapists were consistently valued for emotional, relational, and personalization benefits, while GAI was favored for accessibility and affordability. Yet structural advantages alone did not predict adoption; emotional benefit and personalization emerged as decisive factors. Adoption patterns diverged across groups: students treated GAI as a complement, whereas national adults approached it as a substitute. Concerns about privacy and reliability constrained GAI use in both groups. These findings extend HBM to multi-modality contexts and highlight design implications for trustworthy, emotionally resonant digital mental health tools.

**AI Summary:** This study explores the factors influencing individuals' intentions to use generative artificial intelligence (GAI) versus human therapists for mental health support. The research findings indicate that while GAI is preferred for its accessibility and affordability, therapists are valued for emotional, relational, and personalization benefits. Emotional benefit and personalization are crucial factors in adoption decisions, with different populations viewing GAI as either a complement or a substitute to traditional therapy. Concerns about privacy and reliability also impact the use of GAI in mental health settings, highlighting the need for trustworthy and emotionally resonant digital tools.

---

## Teacher, But Also Student: Challenges and Tech Needs of Adult Braille Learners with Sight
**URL:** https://arxiv.org/abs/2512.03398

**Abstract:** Braille literacy is critical for blind individuals' independence and quality of life, yet literacy rates continue to decline. Though braille instructors in integrated K-12 classrooms play a central role in literacy development in blind youth, prior research on braille learning almost exclusively focuses on blind adolescent students. As a result, we still know little about how sighted adult teachers learn braille. To address this, we interviewed 14 educators, including 13 certificated Teachers of Students with Visual Impairments (TVIs) and 1 paraeducator, who learned braille as adults. We found that they: (1) lack consistent braille exposure to reinforce knowledge and skill; (2) have limited time to practice due to myriad responsibilities of adulthood; and thus, (3) seek learning tools that are engaging and efficient. Our research draws attention to the needs of a group of braille learners who have been overlooked and identifies new design opportunities to facilitate braille literacy.

**AI Summary:** This research focuses on the challenges and technology needs of adult braille learners with sight, a group that has been largely overlooked in previous studies. The study interviewed 14 educators who learned braille as adults and found that they lack consistent exposure to braille, have limited time to practice, and seek engaging and efficient learning tools. The findings highlight the importance of addressing the needs of adult braille learners and suggest new design opportunities to facilitate braille literacy.

---

## DAWZY: A New Addition to AI powered "Human in the Loop" Music Co-creation
**URL:** https://arxiv.org/abs/2512.03289

**Abstract:** Digital Audio Workstations (DAWs) offer fine control, but mapping high-level intent (e.g., "warm the vocals") to low-level edits breaks creative flow. Existing artificial intelligence (AI) music generators are typically one-shot, limiting opportunities for iterative development and human contribution. We present DAWZY, an open-source assistant that turns natural-language (text/voice/hum) requests into reversible actions in REAPER. DAWZY keeps the DAW as the creative hub with a minimal GUI and voice-first interface. DAWZY uses LLM-based code generation as a novel way to significantly reduce the time users spend familiarizing themselves with large interfaces, replacing hundreds of buttons and drop-downs with a chat box. DAWZY also uses three Model Context Protocol tools for live state queries, parameter adjustment, and AI beat generation. It maintains grounding by refreshing state before mutation and ensures safety and reversibility with atomic scripts and undo. In evaluations, DAWZY performed reliably on common production tasks and was rated positively by users across Usability, Control, Learning, Collaboration, and Enjoyment.

**AI Summary:** The research introduces DAWZY, an AI-powered assistant for music co-creation in Digital Audio Workstations (DAWs) that translates natural language requests into reversible actions in REAPER. DAWZY streamlines the creative process by simplifying the interface and enhancing user control through voice-first interaction. The tool was found to be reliable and positively rated by users for usability, control, learning, collaboration, and enjoyment, highlighting its significance in facilitating iterative development and human contribution in music production.

---

## Smartphone Vibrometric Force Estimation for Grip Related Strength Measurements
**URL:** https://arxiv.org/abs/2512.03186

**Abstract:** Hand grip strength is a widely used clinical biomarker linked to mobility, frailty, surgical outcomes, and overall health. This work explores a novel, phone only approach for estimating grip related force using a smartphone's built in vibration motor and inertial measurement unit. When the phone vibrates, applied finger force modulates the amplitude of high frequency accelerometer and gyroscope signals through Vibrometric Force Estimation. We profiled a Google Pixel 4 using synchronized IMU data and ground truth force measurements across varied force trajectories, then trained ridge regression models for both absolute and relative force prediction. In 15 fold hold one out validation, absolute force estimation achieved a mean absolute error of 1.88 lbs, while relative force estimation achieved a mean error of 10.1%. Although the method captures pinch type force rather than standardized full hand HGS, the results demonstrate the feasibility of smartphone based strength assessment using only on device sensors. This approach may enable large scale, low burden functional health measurements once profiling is completed for major smartphone models.

**AI Summary:** This research explores a novel method for estimating grip related force using a smartphone's vibration motor and inertial measurement unit. The study found that the method achieved accurate absolute force estimation with a mean absolute error of 1.88 lbs and relative force estimation with a mean error of 10.1%. This approach could enable smartphone-based strength assessments for large-scale health measurements once profiling is completed for major smartphone models.

---

## Is Lying Only Sinful in Islam? Exploring Religious Bias in Multilingual Large Language Models Across Major Religions
**URL:** https://arxiv.org/abs/2512.03943

**Abstract:** While recent developments in large language models have improved bias detection and classification, sensitive subjects like religion still present challenges because even minor errors can result in severe misunderstandings. In particular, multilingual models often misrepresent religions and have difficulties being accurate in religious contexts. To address this, we introduce BRAND: Bilingual Religious Accountable Norm Dataset, which focuses on the four main religions of South Asia: Buddhism, Christianity, Hinduism, and Islam, containing over 2,400 entries, and we used three different types of prompts in both English and Bengali. Our results indicate that models perform better in English than in Bengali and consistently display bias toward Islam, even when answering religion-neutral questions. These findings highlight persistent bias in multilingual models when similar questions are asked in different languages. We further connect our findings to the broader issues in HCI regarding religion and spirituality.

**AI Summary:** This research explores bias in multilingual large language models when it comes to representing religions, specifically focusing on Buddhism, Christianity, Hinduism, and Islam. The study introduces a dataset called BRAND and finds that models perform better in English than in Bengali, displaying bias toward Islam even in religion-neutral questions. These findings underscore the ongoing challenges in addressing bias in multilingual models and have implications for the broader issues in human-computer interaction related to religion and spirituality.

---

## YOLOA: Real-Time Affordance Detection via LLM Adapter
**URL:** https://arxiv.org/abs/2512.03418

**Abstract:** Affordance detection aims to jointly address the fundamental "what-where-how" challenge in embodied AI by understanding "what" an object is, "where" the object is located, and "how" it can be used. However, most affordance learning methods focus solely on "how" objects can be used while neglecting the "what" and "where" aspects. Other affordance detection methods treat object detection and affordance learning as two independent tasks, lacking effective interaction and real-time capability. To overcome these limitations, we introduce YOLO Affordance (YOLOA), a real-time affordance detection model that jointly handles these two tasks via a large language model (LLM) adapter. Specifically, YOLOA employs a lightweight detector consisting of object detection and affordance learning branches refined through the LLM Adapter. During training, the LLM Adapter interacts with object and affordance preliminary predictions to refine both branches by generating more accurate class priors, box offsets, and affordance gates. Experiments on our relabeled ADG-Det and IIT-Heat benchmarks demonstrate that YOLOA achieves state-of-the-art accuracy (52.8 / 73.1 mAP on ADG-Det / IIT-Heat) while maintaining real-time performance (up to 89.77 FPS, and up to 846.24 FPS for the lightweight variant). This indicates that YOLOA achieves an excellent trade-off between accuracy and efficiency.

**AI Summary:** The research introduces YOLOA, a real-time affordance detection model that addresses the "what-where-how" challenge in embodied AI by simultaneously detecting objects, their locations, and how they can be used. YOLOA utilizes a large language model (LLM) adapter to refine object detection and affordance learning branches, achieving state-of-the-art accuracy while maintaining real-time performance. The model demonstrates an excellent trade-off between accuracy and efficiency, showcasing the significance of integrating object detection and affordance learning for more effective and efficient AI systems.

---

