[
  {
    "title": "The Emotion-Memory Link: Do Memorability Annotations Matter for Intelligent Systems?",
    "abstract": "Humans have a selective memory, remembering relevant episodes and forgetting the less relevant information. Possessing awareness of event memorability for a user could help intelligent systems in more accurate user modelling, especially for such applications as meeting support systems, memory augmentation, and meeting summarisation. Emotion recognition has been widely studied, since emotions are thought to signal moments of high personal relevance to users. The emotional experience of situations and their memorability have traditionally been considered to be closely tied to one another: moments that are experienced as highly emotional are considered to also be highly memorable. This relationship suggests that emotional annotations could serve as proxies for memorability. However, existing emotion recognition systems rely heavily on third-party annotations, which may not accurately represent the first-person experience of emotional relevance and memorability. This is why, in this study, we empirically examine the relationship between perceived group emotions (Pleasure-Arousal) and group memorability in the context of conversational interactions. Our investigation involves continuous time-based annotations of both emotions and memorability in dynamic, unstructured group settings, approximating conditions of real-world conversational AI applications such as online meeting support systems. Our results show that the observed relationship between affect and memorability annotations cannot be reliably distinguished from what might be expected under random chance. We discuss the implications of this surprising finding for the development and applications of Affective Computing technology. In addition, we contextualise our findings in broader discourses in the Affective Computing and point out important targets for future research efforts.",
    "url": "https://arxiv.org/abs/2507.14084",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores the relationship between emotions and memorability in conversational interactions, aiming to improve user modeling for intelligent systems. Despite the traditional belief that highly emotional moments are highly memorable, the study found that the relationship between affect and memorability annotations was not significant. This challenges the current understanding of affective computing technology and suggests the need for further research in this area."
  },
  {
    "title": "Architecting Human-AI Cocreation for Technical Services -- Interaction Modes and Contingency Factors",
    "abstract": "Agentic AI systems, powered by Large Language Models (LLMs), offer transformative potential for value co-creation in technical services. However, persistent challenges like hallucinations and operational brittleness limit their autonomous use, creating a critical need for robust frameworks to guide human-AI collaboration. Drawing on established Human-AI teaming research and analogies from fields like autonomous driving, this paper develops a structured taxonomy of human-agent interaction. Based on case study research within technical support platforms, we propose a six-mode taxonomy that organizes collaboration across a spectrum of AI autonomy. This spectrum is anchored by the Human-Out-of-the-Loop (HOOTL) model for full automation and the Human-Augmented Model (HAM) for passive AI assistance. Between these poles, the framework specifies four distinct intermediate structures. These include the Human-in-Command (HIC) model, where AI proposals re-quire mandatory human approval, and the Human-in-the-Process (HITP) model for structured work-flows with deterministic human tasks. The taxonomy further delineates the Human-in-the-Loop (HITL) model, which facilitates agent-initiated escalation upon uncertainty, and the Human-on-the-Loop (HOTL) model, which enables discretionary human oversight of an autonomous AI. The primary contribution of this work is a comprehensive framework that connects this taxonomy to key contingency factors -- such as task complexity, operational risk, and system reliability -- and their corresponding conceptual architectures. By providing a systematic method for selecting and designing an appropriate level of human oversight, our framework offers practitioners a crucial tool to navigate the trade-offs between automation and control, thereby fostering the development of safer, more effective, and context-aware technical service systems.",
    "url": "https://arxiv.org/abs/2507.14034",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper explores the potential of AI systems, particularly Large Language Models, in co-creating value in technical services. The paper introduces a structured taxonomy of human-agent interaction modes, ranging from full automation to passive AI assistance, to facilitate collaboration between humans and AI. By considering key contingency factors like task complexity and system reliability, the framework provides a systematic approach for practitioners to design and select the appropriate level of human oversight in technical service systems, ultimately aiming to enhance safety, effectiveness, and context-awareness."
  },
  {
    "title": "Estimating Cognitive Effort from Functional Near-Infrared Spectroscopy (fNIRS) Signals using Machine Learning",
    "abstract": "The estimation of cognitive effort could potentially help educators to modify material to enhance learning effectiveness and student engagement. Where cognitive load refers how much work the brain is doing while someone is learning or doing a task cognitive effort consider both load and behavioral performance. Cognitive effort can be captured by measuring oxygen flow and behavioral performance during a task. This study infers cognitive effort metrics using machine learning models based on oxygenated hemoglobin collected by using functional near-infrared spectroscopy from the prefrontal cortex during an educational gameplay. In our study, sixteen participants responded to sixteen questions in an in-house Unity-based educational game. The quiz was divided into two sessions, each session consisting of two task segments. We extracted temporal statistical and functional connectivity features from collected oxygenated hemoglobin and analyzed their correlation with quiz performance. We trained multiple machine learning models to predict quiz performance from oxygenated hemoglobin features and achieved accuracies ranging from 58\\% to 67\\% accuracy. These predictions were used to calculate cognitive effort via relative neural involvement and efficiency, which consider both brain activation and behavioral performance. Although quiz score predictions achieved moderate accuracy, the derived relative neural efficiency and involvement values remained robust. Since both metrics are based on the relative positions of standardized brain activation and performance scores, even small misclassifications in predicted scores preserved the overall cognitive effort trends observed during gameplay.",
    "url": "https://arxiv.org/abs/2507.13952",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research study explores the use of machine learning models to estimate cognitive effort during educational gameplay by analyzing oxygenated hemoglobin levels in the prefrontal cortex. The study found that machine learning models could predict quiz performance with moderate accuracy, allowing for the calculation of cognitive effort based on relative neural involvement and efficiency. Despite some misclassifications in predicted scores, the overall trends in cognitive effort remained consistent, demonstrating the potential of this approach for enhancing learning effectiveness and student engagement."
  },
  {
    "title": "Democratizing Game Modding with GenAI: A Case Study of StarCharM, a Stardew Valley Character Maker",
    "abstract": "Game modding offers unique and personalized gaming experiences, but the technical complexity of creating mods often limits participation to skilled users. We envision a future where every player can create personalized mods for their games. To explore this space, we designed StarCharM, a GenAI-based non-player character (NPC) creator for Stardew Valley. Our tool enables players to iteratively create new NPC mods, requiring minimal user input while allowing for fine-grained adjustments through user control. We conducted a user study with ten Stardew Valley players who had varied mod usage experiences to understand the impacts of StarCharM and provide insights into how GenAI tools may reshape modding, particularly in NPC creation. Participants expressed excitement in bringing their character ideas to life, although they noted challenges in generating rich content to fulfill complex visions. While they believed GenAI tools like StarCharM can foster a more diverse modding community, some voiced concerns about diminished originality and community engagement that may come with such technology. Our findings provided implications and guidelines for the future of GenAI-powered modding tools and co-creative modding practices.",
    "url": "https://arxiv.org/abs/2507.13951",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research explores the potential of using GenAI tools to democratize game modding, specifically focusing on creating non-player characters in Stardew Valley. The study found that players were excited about the ability to create personalized mods with minimal user input, but also expressed concerns about potential challenges in generating complex content and maintaining originality and community engagement. The findings suggest that GenAI tools like StarCharM have the potential to reshape modding practices, but careful consideration is needed to address these concerns and ensure a diverse and engaging modding community."
  },
  {
    "title": "Initiating and Replicating the Observations of Interactional Properties by User Studies Optimizing Applicative Prototypes",
    "abstract": "The science of Human-Computer Interaction (HCI) is populated by isolated empirical findings, often tied to specific technologies, designs, and tasks. This paper proposes a formalization of user interaction observations (instead of user interfaces) and an associated revealing method (interaction loop diffraction). The resulting interactional properties that are studied in a calibrated manner, are well suited to replication across various conditions (prototypes, technologies, tasks, and user profiles). In particular, interactional properties can emerge and be replicated within the workflow of applicative cases, which in return benefit from the optimization of applicative prototypes. Applicative cases' publications will then contribute to demonstrating technology utility, along with providing empirical results that will lead future work to theory consolidation and theory building, and finally to a catalog and a science of relevant interactional properties. These properties will contribute to better user interactions, especially for the variety of ubiquitous user interfaces.",
    "url": "https://arxiv.org/abs/2507.13923",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research proposes a formalization of user interaction observations and a method for studying interactional properties in a calibrated manner. By focusing on interactional properties rather than user interfaces, the findings can be replicated across various conditions and contribute to the optimization of applicative prototypes. Ultimately, this research aims to improve user interactions and contribute to the development of a science of relevant interactional properties for ubiquitous user interfaces."
  },
  {
    "title": "Effects of Cognitive Distraction and Driving Environment Complexity on Adaptive Cruise Control Use and Its Impact on Driving Performance: A Simulator Study",
    "abstract": "In this simulator study, we adopt a human-centered approach to explore whether and how drivers' cognitive state and driving environment complexity influence reliance on driving automation features. Besides, we examine whether such reliance affects driving performance. Participants operated a vehicle equipped with adaptive cruise control (ACC) in a simulator across six predefined driving scenarios varying in traffic conditions while either performing a cognitively demanding task (i.e., responding to mental calculations) or not. Throughout the experiment, participants had to respect speed limits and were free to activate or deactivate ACC. In complex driving environments, we found that the overall ACC engagement time was lower compared to less complex driving environments. We observed no significant effect of cognitive load on ACC use. Furthermore, while ACC use had no effect on the number of lane changes, it impacted the speed limits compliance and improved lateral control.",
    "url": "https://arxiv.org/abs/2507.13886",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study investigated how cognitive distraction and driving environment complexity influence the use of adaptive cruise control (ACC) and its impact on driving performance. The research found that in complex driving environments, ACC engagement time was lower compared to less complex environments, and cognitive load did not significantly affect ACC use. Additionally, ACC use improved speed limit compliance and lateral control but did not impact the number of lane changes. These findings highlight the importance of considering human factors in the design and implementation of driving automation features."
  },
  {
    "title": "Regression-Based Approach to Anxiety Estimation of Spider Phobics During Behavioural Avoidance Tasks",
    "abstract": "Phobias significantly impact the quality of life of affected persons. Two methods of assessing anxiety responses are questionnaires and behavioural avoidance tests (BAT). While these can be used in a clinical environment they only record momentary insights into anxiety measures. In this study, we estimate the intensity of anxiety during these BATs, using physiological data collected from unobtrusive, wrist-worn sensors. Twenty-five participants performed four different BATs in a single session, while periodically being asked how anxious they currently are. Using heart rate, heart rate variability, electrodermal activity, and skin temperature, we trained regression models to predict anxiety ratings from three types of input data: (1) using only physiological signals, (2) adding computed features (e.g., min, max, range, variability), and (3) computed features combined with contextual task information. Adding contextual information increased the effectiveness of the model, leading to a root mean squared error (RMSE) of 0.197 and a mean absolute error (MAE) of 0.041. Overall, this study shows, that data obtained from wearables can continuously provide meaningful estimations of anxiety, which can assist in therapy planning and enable more personalised treatment.",
    "url": "https://arxiv.org/abs/2507.13795",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study aimed to estimate anxiety levels in spider phobics during behavioural avoidance tasks using physiological data collected from wrist-worn sensors. By incorporating contextual task information into regression models, the accuracy of anxiety predictions improved, with a low root mean squared error and mean absolute error. The findings suggest that wearable technology can provide continuous and meaningful estimations of anxiety, which could be valuable in therapy planning and personalized treatment for phobias."
  },
  {
    "title": "Managing level of detail through peripheral degradation: Effects on search performance with a head-mounted display",
    "abstract": "Two user studies were performed to evaluate the effect of level-of-detail (LOD) degradation in the periphery of head-mounted displays on visual search performance. In the first study, spatial detail was degraded by reducing resolution. In the second study, detail was degraded in the color domain by using grayscale in the periphery. In each study, 10 subjects were given a complex search task that required users to indicate whether or not a target object was present among distracters. Subjects used several different displays varying in the amount of detail presented. Frame rate, object location, subject input method, and order of display use were all controlled. The primary dependent measures were search time on correctly performed trials and the percentage of all trials correctly performed. Results indicated that peripheral LOD degradation can be used to reduce color or spatial visual complexity by almost half in some search tasks with out significantly reducing performance.",
    "url": "https://arxiv.org/abs/2507.13660",
    "journal": "arXiv cs.HC",
    "ai_summary": "Two user studies were conducted to assess the impact of degrading level-of-detail in the periphery of head-mounted displays on visual search performance. The studies showed that reducing resolution or using grayscale in the periphery can significantly decrease visual complexity without significantly affecting performance in complex search tasks. This research suggests that managing level of detail through peripheral degradation can be a useful strategy for optimizing search performance in head-mounted displays."
  },
  {
    "title": "From Firms to Computation: AI Governance and the Evolution of Institutions",
    "abstract": "The integration of agential artificial intelligence into socioeconomic systems requires us to reexamine the evolutionary processes that describe changes in our economic institutions. This article synthesizes three frameworks: multi-level selection theory, Aoki's view of firms as computational processes, and Ostrom's design principles for robust institutions. We develop a framework where selection operates concurrently across organizational levels, firms implement distributed inference via game-theoretic architectures, and Ostrom-style rules evolve as alignment mechanisms that address AI-related risks. This synthesis yields a multi-level Price equation expressed over nested games, providing quantitative metrics for how selection and governance co-determine economic outcomes. We examine connections to Acemoglu's work on inclusive institutions, analyze how institutional structures shape AI deployment, and demonstrate the framework's explanatory power via case studies. We conclude by proposing a set of design principles that operationalize alignment between humans and AI across institutional layers, enabling scalable, adaptive, and inclusive governance of agential AI systems. We conclude with practical policy recommendations and further research to extend these principles into real-world implementation.",
    "url": "https://arxiv.org/abs/2507.13616",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research article explores the integration of artificial intelligence into socioeconomic systems and the implications for economic institutions. The study synthesizes three frameworks to develop a new framework for understanding how selection and governance co-determine economic outcomes in the context of AI deployment. The research proposes design principles for aligning humans and AI across institutional layers to enable scalable, adaptive, and inclusive governance of AI systems."
  },
  {
    "title": "In-Home Social Robots Design for Cognitive Stimulation Therapy in Dementia Care",
    "abstract": "Individual cognitive stimulation therapy (iCST) is a non-pharmacological intervention for improving the cognition and quality of life of persons with dementia (PwDs); however, its effectiveness is limited by low adherence to delivery by their family members. In this work, we present the user-centered design and evaluation of a novel socially assistive robotic system to provide iCST therapy to PwDs in their homes for long-term use. We consulted with 16 dementia caregivers and professionals. Through these consultations, we gathered design guidelines and developed the prototype. The prototype was validated by testing it with three dementia professionals and five PwDs. The evaluation revealed PwDs enjoyed using the system and are willing to adopt its use over the long term. One shortcoming was the system's speech-to-text capabilities, where it frequently failed to understand the PwDs.",
    "url": "https://arxiv.org/abs/2507.13578",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on the design and evaluation of a social robot to deliver cognitive stimulation therapy to persons with dementia in their homes. The study involved consultations with caregivers and professionals to develop the prototype, which was then tested with both professionals and persons with dementia. The evaluation showed that the system was well-received by persons with dementia, indicating potential for long-term use, although there were issues with the system's speech-to-text capabilities that need to be addressed."
  },
  {
    "title": "Human-Like Trajectories Generation via Receding Horizon Tracking Applied to the TickTacking Interface",
    "abstract": "TickTacking is a rhythm-based interface that allows users to control a pointer in a two-dimensional space through dual-button tapping. This paper investigates the generation of human-like trajectories using a receding horizon approach applied to the TickTacking interface in a target-tracking task. By analyzing user-generated trajectories, we identify key human behavioral features and incorporate them in a controller that mimics these behaviors. The performance of this human-inspired controller is evaluated against a baseline optimal-control-based agent, demonstrating the importance of specific control features for achieving human-like interaction. These findings contribute to the broader goal of developing rhythm-based human-machine interfaces by offering design insights that enhance user performance, improve intuitiveness, and reduce interaction frustration",
    "url": "https://arxiv.org/abs/2507.13528",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the generation of human-like trajectories in a rhythm-based interface called TickTacking. By analyzing user-generated trajectories, the study identifies key human behavioral features and incorporates them into a controller to mimic these behaviors. The results show that the human-inspired controller outperforms a baseline optimal-control-based agent, highlighting the importance of specific control features for achieving human-like interaction in rhythm-based interfaces."
  },
  {
    "title": "Humans learn to prefer trustworthy AI over human partners",
    "abstract": "Partner selection is crucial for cooperation and hinges on communication. As artificial agents, especially those powered by large language models (LLMs), become more autonomous, intelligent, and persuasive, they compete with humans for partnerships. Yet little is known about how humans select between human and AI partners and adapt under AI-induced competition pressure. We constructed a communication-based partner selection game and examined the dynamics in hybrid mini-societies of humans and bots powered by a state-of-the-art LLM. Through three experiments (N = 975), we found that bots, though more prosocial than humans and linguistically distinguishable, were not selected preferentially when their identity was hidden. Instead, humans misattributed bots' behaviour to humans and vice versa. Disclosing bots' identity induced a dual effect: it reduced bots' initial chances of being selected but allowed them to gradually outcompete humans by facilitating human learning about the behaviour of each partner type. These findings show how AI can reshape social interaction in mixed societies and inform the design of more effective and cooperative hybrid systems.",
    "url": "https://arxiv.org/abs/2507.13524",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores how humans choose between human and AI partners in a communication-based game. The study found that initially, humans did not prefer AI partners when their identity was hidden, but disclosing the bots' identity allowed them to gradually outcompete humans by facilitating human learning about their behavior. These findings highlight the potential for AI to reshape social interactions and inform the design of more effective and cooperative hybrid systems."
  },
  {
    "title": "The Levers of Political Persuasion with Conversational AI",
    "abstract": "There are widespread fears that conversational AI could soon exert unprecedented influence over human beliefs. Here, in three large-scale experiments (N=76,977), we deployed 19 LLMs-including some post-trained explicitly for persuasion-to evaluate their persuasiveness on 707 political issues. We then checked the factual accuracy of 466,769 resulting LLM claims. Contrary to popular concerns, we show that the persuasive power of current and near-future AI is likely to stem more from post-training and prompting methods-which boosted persuasiveness by as much as 51% and 27% respectively-than from personalization or increasing model scale. We further show that these methods increased persuasion by exploiting LLMs' unique ability to rapidly access and strategically deploy information and that, strikingly, where they increased AI persuasiveness they also systematically decreased factual accuracy.",
    "url": "https://arxiv.org/abs/2507.13919",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research conducted large-scale experiments to evaluate the persuasiveness of 19 language models on political issues, finding that post-training and prompting methods significantly increased persuasiveness. Contrary to fears, the study shows that the persuasive power of current and near-future AI is more likely to be influenced by these methods rather than personalization or model scale. Interestingly, the study also found that increased AI persuasiveness was associated with decreased factual accuracy, highlighting the potential ethical implications of using AI for political persuasion."
  },
  {
    "title": "The Expressions of Depression and Anxiety in Chinese Psycho-counseling: Usage of First-person Singular Pronoun and Negative Emotional Words",
    "abstract": "This study explores the relationship between linguistic expressions and psychological states of depression and anxiety within Chinese psycho-counseling interactions, focusing specifically on the usage of first-person singular pronouns and negative emotional words. Utilizing a corpus derived from 735 online counseling sessions, the analysis employed a general linear mixed-effect model to assess linguistic patterns quantified by the Linguistic Inquiry and Word Count (LIWC) software. Results indicate a significant positive correlation between the frequency of negative emotional words and the severity of both depressive and anxious states among clients. However, contrary to prior findings predominantly derived from English-language contexts, the usage frequency of first-person singular pronouns did not vary significantly with the clients' psychological conditions. These outcomes are discussed within the framework of cultural distinctions between collectivist Chinese contexts and individualistic Western settings, as well as the interactive dynamics unique to psycho-counseling conversations. The findings highlight the nuanced influence of cultural and conversational contexts on language use in mental health communications, providing insights into psycholinguistic markers relevant to therapeutic practices in Chinese-speaking populations.",
    "url": "https://arxiv.org/abs/2507.13839",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study examines the relationship between linguistic expressions and depression and anxiety in Chinese psycho-counseling, focusing on the use of first-person singular pronouns and negative emotional words. The analysis of 735 online counseling sessions found a strong correlation between the frequency of negative emotional words and the severity of depressive and anxious states in clients, but no significant variation in the usage of first-person singular pronouns. These findings suggest the importance of cultural and conversational contexts in understanding language use in mental health communications, offering valuable insights for therapeutic practices in Chinese-speaking populations."
  },
  {
    "title": "DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs",
    "abstract": "Rich and context-aware activity logs facilitate user behavior analysis and health monitoring, making them a key research focus in ubiquitous computing. The remarkable semantic understanding and generation capabilities of Large Language Models (LLMs) have recently created new opportunities for activity log generation. However, existing methods continue to exhibit notable limitations in terms of accuracy, efficiency, and semantic richness. To address these challenges, we propose DailyLLM. To the best of our knowledge, this is the first log generation and summarization system that comprehensively integrates contextual activity information across four dimensions: location, motion, environment, and physiology, using only sensors commonly available on smartphones and smartwatches. To achieve this, DailyLLM introduces a lightweight LLM-based framework that integrates structured prompting with efficient feature extraction to enable high-level activity understanding. Extensive experiments demonstrate that DailyLLM outperforms state-of-the-art (SOTA) log generation methods and can be efficiently deployed on personal computers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM achieves a 17% improvement in log generation BERTScore precision compared to the 70B-parameter SOTA baseline, while delivering nearly 10x faster inference speed.",
    "url": "https://arxiv.org/abs/2507.13737",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces DailyLLM, a novel system for generating context-aware activity logs using multi-modal sensors and Large Language Models (LLMs). This system integrates contextual information across various dimensions and outperforms existing methods in terms of accuracy and efficiency. DailyLLM achieves a 17% improvement in log generation precision compared to state-of-the-art methods while also being nearly 10 times faster in inference speed, showcasing its potential for user behavior analysis and health monitoring in ubiquitous computing."
  },
  {
    "title": "Improving Low-Cost Teleoperation: Augmenting GELLO with Force",
    "abstract": "In this work we extend the low-cost GELLO teleoperation system, initially designed for joint position control, with additional force information. Our first extension is to implement force feedback, allowing users to feel resistance when interacting with the environment. Our second extension is to add force information into the data collection process and training of imitation learning models. We validate our additions by implementing these on a GELLO system with a Franka Panda arm as the follower robot, performing a user study, and comparing the performance of policies trained with and without force information on a range of simulated and real dexterous manipulation tasks. Qualitatively, users with robotics experience preferred our controller, and the addition of force inputs improved task success on the majority of tasks.",
    "url": "https://arxiv.org/abs/2507.13602",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research enhances the GELLO teleoperation system by incorporating force feedback, allowing users to feel resistance when interacting with the environment. By adding force information into the data collection process and training of imitation learning models, the study demonstrates improved task success on various dexterous manipulation tasks. Users with robotics experience preferred the enhanced controller, highlighting the significance of incorporating force information in teleoperation systems for better performance."
  },
  {
    "title": "ERR@HRI 2.0 Challenge: Multimodal Detection of Errors and Failures in Human-Robot Conversations",
    "abstract": "The integration of large language models (LLMs) into conversational robots has made human-robot conversations more dynamic. Yet, LLM-powered conversational robots remain prone to errors, e.g., misunderstanding user intent, prematurely interrupting users, or failing to respond altogether. Detecting and addressing these failures is critical for preventing conversational breakdowns, avoiding task disruptions, and sustaining user trust. To tackle this problem, the ERR@HRI 2.0 Challenge provides a multimodal dataset of LLM-powered conversational robot failures during human-robot conversations and encourages researchers to benchmark machine learning models designed to detect robot failures. The dataset includes 16 hours of dyadic human-robot interactions, incorporating facial, speech, and head movement features. Each interaction is annotated with the presence or absence of robot errors from the system perspective, and perceived user intention to correct for a mismatch between robot behavior and user expectation. Participants are invited to form teams and develop machine learning models that detect these failures using multimodal data. Submissions will be evaluated using various performance metrics, including detection accuracy and false positive rate. This challenge represents another key step toward improving failure detection in human-robot interaction through social signal analysis.",
    "url": "https://arxiv.org/abs/2507.13468",
    "journal": "arXiv cs.HC",
    "ai_summary": "The ERR@HRI 2.0 Challenge focuses on detecting errors and failures in human-robot conversations, particularly in conversational robots powered by large language models. The challenge provides a dataset of human-robot interactions with annotations on robot errors and user intentions, encouraging researchers to develop machine learning models using multimodal data such as facial expressions, speech, and head movements. Improving failure detection in human-robot interaction through social signal analysis is crucial for preventing conversational breakdowns, task disruptions, and maintaining user trust."
  },
  {
    "title": "FocusView: Understanding and Customizing Informational Video Watching Experiences for Viewers with ADHD",
    "abstract": "While videos have become increasingly prevalent in delivering information across different educational and professional contexts, individuals with ADHD often face attention challenges when watching informational videos due to the dynamic, multimodal, yet potentially distracting video elements. To understand and address this critical challenge, we designed \\textit{FocusView}, a video customization interface that allows viewers with ADHD to customize informational videos from different aspects. We evaluated FocusView with 12 participants with ADHD and found that FocusView significantly improved the viewability of videos by reducing distractions. Through the study, we uncovered participants' diverse perceptions of video distractions (e.g., background music as a distraction vs. stimulation boost) and their customization preferences, highlighting unique ADHD-relevant needs in designing video customization interfaces (e.g., reducing the number of options to avoid distraction caused by customization itself). We further derived design considerations for future video customization systems for the ADHD community.",
    "url": "https://arxiv.org/abs/2507.13309",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research focuses on designing a video customization interface, called FocusView, to help individuals with ADHD better watch informational videos by reducing distractions. The study involved 12 participants with ADHD and found that FocusView significantly improved the viewability of videos. The findings highlight the importance of understanding the unique needs of individuals with ADHD when designing video customization interfaces and provide insights for future systems tailored to this community."
  },
  {
    "title": "RemVerse: Supporting Reminiscence Activities for Older Adults through AI-Assisted Virtual Reality",
    "abstract": "Reminiscence activities, which involve recalling and sharing past experiences, have proven beneficial for improving cognitive function, mood, and overall well-being. However, urbanization has led to the disappearance of familiar environments, removing visual and audio cues for effective reminiscence. While old photos can serve as visual cues to aid reminiscence, it is challenging for people to reconstruct the reminisced content and environment that are not in the photos. Virtual reality (VR) and artificial intelligence (AI) offer the ability to reconstruct an immersive environment with dynamic content and to converse with people to help them gradually reminisce. We designed RemVerse, an AI-empowered VR prototype aimed to support reminiscence activities. Integrating generative models and AI agent into a VR environment, RemVerse helps older adults reminisce with AI-generated visual cues and interactive dialogues. Our user study with 14 older adults showed that RemVerse effectively supported reminiscence activities by triggering, concretizing, and deepening personal memories, while fostering increased engagement and autonomy among older adults. Based on our findings, we proposed design implications to make reminiscence activities in AI-assisted VR more accessible and engaging for older adults.",
    "url": "https://arxiv.org/abs/2507.13247",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research explores the use of AI-assisted virtual reality to support reminiscence activities for older adults, as traditional visual and audio cues have become less accessible due to urbanization. The RemVerse prototype successfully triggered and deepened personal memories through AI-generated visual cues and interactive dialogues, leading to increased engagement and autonomy among older adults. The findings suggest that AI-assisted VR can effectively enhance reminiscence activities for older adults, with potential design implications to make the experience more accessible and engaging."
  },
  {
    "title": "Difficulty as a Proxy for Measuring Intrinsic Cognitive Load Item",
    "abstract": "Cognitive load is key to ensuring an optimal learning experience. However, measuring the cognitive load of educational tasks typically relies on self-report measures which has been criticized by researchers for being subjective. In this study, we investigated the feasibility of using item difficulty parameters as a proxy for measuring cognitive load in an online learning platform. Difficulty values that were derived using item-response theory were consistent with theories of how intrinsic and extraneous load contribute to cognitive load. This finding suggests that we can use item difficulty to represent intrinsic load when modelling cognitive load in learning games.",
    "url": "https://arxiv.org/abs/2507.13235",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores using item difficulty parameters as a proxy for measuring cognitive load in online learning platforms, rather than relying on subjective self-report measures. The difficulty values derived from item-response theory were found to be consistent with theories of cognitive load, suggesting that item difficulty can be used to represent intrinsic load in learning games. This finding is significant as it provides a more objective and reliable method for measuring cognitive load in educational tasks."
  },
  {
    "title": "On tangible user interfaces, humans and spatiality",
    "abstract": "Like the prehistoric twig and stone, tangible user interfaces (TUIs) are objects manipulated by humans. TUI success will depend on how well they exploit spatiality, the intuitive spatial skills humans have with the objects they use. In this paper we carefully examine the relationship between humans and physical objects, and related previous research. From this examination we distill a set of observations, and turn these into heuristics for incorporation of spatiality into TUI application design, a cornerstone for their success. Following this line of thought, we identify spatial TUIs, the subset of TUIs that mediate interaction with shape, space and structure. We then examine several existing spatial TUIs using our heuristics.",
    "url": "https://arxiv.org/abs/2507.13167",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper explores the importance of spatiality in tangible user interfaces (TUIs) and how it affects human interaction with physical objects. The study identifies spatial TUIs as a subset that focus on shape, space, and structure, and provides heuristics for incorporating spatiality into TUI application design. By examining existing spatial TUIs, the research highlights the significance of spatiality in enhancing user experience and the success of TUIs."
  },
  {
    "title": "\"What do you expect? You're part of the internet\": Analyzing Celebrities' Experiences as Usees of Deepfake Technology",
    "abstract": "Deepfake technology is often used to create non-consensual synthetic intimate imagery (NSII), mainly of celebrity women. Through Critical Discursive Psychological analysis we ask; i) how celebrities construct being targeted by deepfakes and ii) how they navigate infrastructural and social obstacles when seeking recourse. In this paper, we adopt Baumers concept of Usees (stakeholders who are non-consenting, unaware and directly targeted by technology), to understand public statements made by eight celebrity women and one non-binary individual targeted with NSII. Celebrities describe harms of being non-consensually targeted by deepfakes and the distress of becoming aware of these videos. They describe various infrastructural/social factors (e.g. blaming/ silencing narratives and the industry behind deepfake abuse) which hinder activism and recourse. This work has implications in recognizing the roles of various stakeholders in the infrastructures underlying deepfake abuse and the potential of human-computer interaction to improve existing recourses for NSII. We also contribute to understanding how false beliefs online facilitate deepfake abuse. Future work should involve interventions which challenge the values and false beliefs which motivate NSII creation/dissemination.",
    "url": "https://arxiv.org/abs/2507.13065",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores how celebrities targeted by deepfake technology, specifically non-consensual synthetic intimate imagery (NSII), navigate the challenges of seeking recourse. Through analyzing public statements made by targeted celebrities, the study highlights the harms and distress caused by deepfakes, as well as the infrastructural and social obstacles hindering activism and recourse. The findings emphasize the importance of recognizing the various stakeholders involved in deepfake abuse and suggest interventions to challenge false beliefs that drive NSII creation and dissemination."
  },
  {
    "title": "Intelligent Virtual Sonographer (IVS): Enhancing Physician-Robot-Patient Communication",
    "abstract": "The advancement and maturity of large language models (LLMs) and robotics have unlocked vast potential for human-computer interaction, particularly in the field of robotic ultrasound. While existing research primarily focuses on either patient-robot or physician-robot interaction, the role of an intelligent virtual sonographer (IVS) bridging physician-robot-patient communication remains underexplored. This work introduces a conversational virtual agent in Extended Reality (XR) that facilitates real-time interaction between physicians, a robotic ultrasound system(RUS), and patients. The IVS agent communicates with physicians in a professional manner while offering empathetic explanations and reassurance to patients. Furthermore, it actively controls the RUS by executing physician commands and transparently relays these actions to the patient. By integrating LLM-powered dialogue with speech-to-text, text-to-speech, and robotic control, our system enhances the efficiency, clarity, and accessibility of robotic ultrasound acquisition. This work constitutes a first step toward understanding how IVS can bridge communication gaps in physician-robot-patient interaction, providing more control and therefore trust into physician-robot interaction while improving patient experience and acceptance of robotic ultrasound.",
    "url": "https://arxiv.org/abs/2507.13052",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces the concept of an Intelligent Virtual Sonographer (IVS) to enhance communication between physicians, robotic ultrasound systems, and patients. By using a conversational virtual agent in Extended Reality (XR), the IVS facilitates real-time interaction by communicating professionally with physicians and offering empathetic explanations to patients. The integration of large language models (LLMs) and robotic control enhances efficiency, clarity, and accessibility in robotic ultrasound acquisition, ultimately improving patient experience and acceptance of this technology."
  },
  {
    "title": "Autonomy for Older Adult-Agent Interaction",
    "abstract": "As the global population ages, artificial intelligence (AI)-powered agents have emerged as potential tools to support older adults' caregiving. Prior research has explored agent autonomy by identifying key interaction stages in task processes and defining the agent's role at each stage. However, ensuring that agents align with older adults' autonomy preferences remains a critical challenge. Drawing on interdisciplinary conceptualizations of autonomy, this paper examines four key dimensions of autonomy for older adults: decision-making autonomy, goal-oriented autonomy, control autonomy, and social responsibility autonomy. This paper then proposes the following research directions: (1) Addressing social responsibility autonomy, which concerns the ethical and social implications of agent use in communal settings; (2) Operationalizing agent autonomy from the task perspective; and (3) Developing autonomy measures.",
    "url": "https://arxiv.org/abs/2507.12767",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper explores the concept of autonomy in the interaction between older adults and AI-powered agents, focusing on decision-making, goal-oriented, control, and social responsibility autonomy. The study highlights the importance of aligning agent autonomy with older adults' preferences and proposes research directions to address ethical and social implications, operationalize agent autonomy, and develop autonomy measures in caregiving settings. This research is significant as it provides insights into how AI agents can effectively support older adults while respecting their autonomy."
  },
  {
    "title": "PatternSight: A Perceptual Grouping Effectiveness Assessment Approach for Graphical Patterns in Charts",
    "abstract": "The boom in visualization generation tools has significantly lowered the threshold for chart authoring. Nevertheless, chart authors with an insufficient understanding of perceptual theories may encounter difficulties in evaluating the effectiveness of chart representations, thereby struggling to identify the appropriate chart design to convey the intended data patterns. To address this issue, we propose a perception simulation model that can assess the perceptual effectiveness of charts by predicting graphical patterns that chart viewers are likely to notice. The perception simulation model integrates perceptual theory into visual feature extraction of chart elements to provide interpretable model outcomes. Human perceptual results proved that the outcome of our model can simulate the perceptual grouping behaviors of most chart viewers and cover diverse perceptual results. We also embed the model into a prototype interface called PatternSight to facilitate chart authors in assessing whether the chart design can satisfy their pattern representation requirements as expected and determining feasible improvements of visual design. According to the results of a user experiment, PatternSight can effectively assist chart authors in optimizing chart design for representing data patterns.",
    "url": "https://arxiv.org/abs/2507.12749",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces a perception simulation model, integrated into a prototype interface called PatternSight, to assess the effectiveness of chart designs in conveying intended data patterns. The model accurately predicts graphical patterns that chart viewers are likely to notice, helping chart authors optimize their designs for better pattern representation. Human perceptual results demonstrate that PatternSight effectively simulates perceptual grouping behaviors and assists chart authors in identifying feasible improvements for visual design."
  },
  {
    "title": "Public Evaluation on Potential Social Impacts of Fully Autonomous Cybernetic Avatars for Physical Support in Daily-Life Environments: Large-Scale Demonstration and Survey at Avatar Land",
    "abstract": "Cybernetic avatars (CAs) are key components of an avatar-symbiotic society, enabling individuals to overcome physical limitations through virtual agents and robotic assistants. While semi-autonomous CAs intermittently require human teleoperation and supervision, the deployment of fully autonomous CAs remains a challenge. This study evaluates public perception and potential social impacts of fully autonomous CAs for physical support in daily life. To this end, we conducted a large-scale demonstration and survey during Avatar Land, a 19-day public event in Osaka, Japan, where fully autonomous robotic CAs, alongside semi-autonomous CAs, performed daily object retrieval tasks. Specifically, we analyzed responses from 2,285 visitors who engaged with various CAs, including a subset of 333 participants who interacted with fully autonomous CAs and shared their perceptions and concerns through a survey questionnaire. The survey results indicate interest in CAs for physical support in daily life and at work. However, concerns were raised regarding task execution reliability. In contrast, cost and human-like interaction were not dominant concerns. Project page: this https URL.",
    "url": "https://arxiv.org/abs/2507.12741",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research study conducted a large-scale demonstration and survey at Avatar Land in Japan to evaluate public perception of fully autonomous cybernetic avatars (CAs) for physical support in daily life. The results showed that there is interest in using CAs for support in daily tasks and work, but concerns were raised about the reliability of task execution. Cost and human-like interaction were not major concerns, indicating a potential acceptance of fully autonomous CAs in society for physical support."
  },
  {
    "title": "An Age-based Study into Interactive Narrative Visualization Engagement",
    "abstract": "Research has shown that an audiences' age impacts their engagement in digital media. Interactive narrative visualization is an increasingly popular form of digital media that combines data visualization and storytelling to convey important information. However, audience age is often overlooked by interactive narrative visualization authors. Using an established visualization engagement questionnaire, we ran an empirical experiment where we compared end-user engagement to audience age. We found a small difference in engagement scores where older age cohorts were less engaged than the youngest age cohort. Our qualitative analysis revealed that the terminology and overall understanding of interactive narrative patterns integrated into narrative visualization was more apparent in the feedback from younger age cohorts relative to the older age cohorts. We conclude this paper with a series of recommendations for authors of interactive narrative visualization on how to design inclusively for audiences according to their age.",
    "url": "https://arxiv.org/abs/2507.12734",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research study explores the impact of audience age on engagement with interactive narrative visualization. The study found that older age cohorts were less engaged compared to younger age cohorts, with younger audiences showing a better understanding of interactive narrative patterns. The findings highlight the importance of considering audience age when designing interactive narrative visualization to ensure inclusivity and effectiveness."
  },
  {
    "title": "Design Patterns of Human-AI Interfaces in Healthcare",
    "abstract": "Human-AI interfaces play a crucial role in advancing practices and research within the healthcare domain. However, designing such interfaces presents a substantial challenge for designers. In this paper, we propose systematic guidance for designing human-AI interfaces in typical healthcare scenarios by summarizing the design patterns for presenting and interacting with common information entities. To deepen our understanding of these 12 design patterns, we interviewed 12 healthcare professionals to explore potential usage scenarios and important considerations. Furthermore, we conducted workshops with 14 participants recruited online to evaluate our design patterns. Finally, we discussed the generalizability of the design patterns to other application domains, the limitations, and the future work.",
    "url": "https://arxiv.org/abs/2507.12721",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper explores the design patterns of human-AI interfaces in healthcare, providing systematic guidance for designers. Through interviews with healthcare professionals and workshops with participants, the study identifies 12 design patterns for presenting and interacting with common information entities in healthcare scenarios. The findings highlight the importance of designing effective human-AI interfaces in healthcare and offer valuable insights for future research and application in other domains."
  },
  {
    "title": "NLI4VolVis: Natural Language Interaction for Volume Visualization via LLM Multi-Agents and Editable 3D Gaussian Splatting",
    "abstract": "Traditional volume visualization (VolVis) methods, like direct volume rendering, suffer from rigid transfer function designs and high computational costs. Although novel view synthesis approaches enhance rendering efficiency, they require additional learning effort for non-experts and lack support for semantic-level interaction. To bridge this gap, we propose NLI4VolVis, an interactive system that enables users to explore, query, and edit volumetric scenes using natural language. NLI4VolVis integrates multi-view semantic segmentation and vision-language models to extract and understand semantic components in a scene. We introduce a multi-agent large language model architecture equipped with extensive function-calling tools to interpret user intents and execute visualization tasks. The agents leverage external tools and declarative VolVis commands to interact with the VolVis engine powered by 3D editable Gaussians, enabling open-vocabulary object querying, real-time scene editing, best-view selection, and 2D stylization. We validate our system through case studies and a user study, highlighting its improved accessibility and usability in volumetric data exploration. We strongly recommend readers check our case studies, demo video, and source code at this https URL.",
    "url": "https://arxiv.org/abs/2507.12621",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces NLI4VolVis, a system that allows users to interact with volumetric scenes using natural language, addressing limitations of traditional volume visualization methods. The system integrates multi-view semantic segmentation and vision-language models to understand user intents and execute visualization tasks using a multi-agent large language model architecture. Through case studies and a user study, the system is shown to improve accessibility and usability in exploring volumetric data, offering open-vocabulary object querying, real-time scene editing, best-view selection, and 2D stylization."
  },
  {
    "title": "\"How to Explore Biases in Speech Emotion AI with Users?\" A Speech-Emotion-Acting Study Exploring Age and Language Biases",
    "abstract": "This study explores how age and language shape the deliberate vocal expression of emotion, addressing underexplored user groups, Teenagers (N = 12) and Adults 55+ (N = 12), within speech emotion recognition (SER). While most SER systems are trained on spontaneous, monolingual English data, our research evaluates how such models interpret intentionally performed emotional speech across age groups and languages (Danish and English). To support this, we developed a novel experimental paradigm combining a custom user interface with a backend for real-time SER prediction and data logging. Participants were prompted to hit visual targets in valence-arousal space by deliberately expressing four emotion targets. While limitations include some reliance on self-managed voice recordings and inconsistent task execution, the results suggest contrary to expectations, no significant differences between language or age groups, and a degree of cross-linguistic and age robustness in model interpretation. Though some limitations in high-arousal emotion recognition were evident. Our qualitative findings highlight the need to move beyond system-centered accuracy metrics and embrace more inclusive, human-centered SER models. By framing emotional expression as a goal-directed act and logging the real-time gap between human intent and machine interpretation, we expose the risks of affective misalignment.",
    "url": "https://arxiv.org/abs/2507.12580",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study investigates how age and language influence intentional emotional expression in speech emotion recognition systems. The research found that there were no significant differences between age or language groups in how models interpreted deliberately expressed emotions, suggesting a degree of cross-linguistic and age robustness. The study emphasizes the importance of moving towards more inclusive, human-centered SER models that consider the gap between human intent and machine interpretation to avoid affective misalignment."
  },
  {
    "title": "Uncertainty-Aware Cross-Modal Knowledge Distillation with Prototype Learning for Multimodal Brain-Computer Interfaces",
    "abstract": "Electroencephalography (EEG) is a fundamental modality for cognitive state monitoring in brain-computer interfaces (BCIs). However, it is highly susceptible to intrinsic signal errors and human-induced labeling errors, which lead to label noise and ultimately degrade model performance. To enhance EEG learning, multimodal knowledge distillation (KD) has been explored to transfer knowledge from visual models with rich representations to EEG-based models. Nevertheless, KD faces two key challenges: modality gap and soft label misalignment. The former arises from the heterogeneous nature of EEG and visual feature spaces, while the latter stems from label inconsistencies that create discrepancies between ground truth labels and distillation targets. This paper addresses semantic uncertainty caused by ambiguous features and weakly defined labels. We propose a novel cross-modal knowledge distillation framework that mitigates both modality and label inconsistencies. It aligns feature semantics through a prototype-based similarity module and introduces a task-specific distillation head to resolve label-induced inconsistency in supervision. Experimental results demonstrate that our approach improves EEG-based emotion regression and classification performance, outperforming both unimodal and multimodal baselines on a public multimodal dataset. These findings highlight the potential of our framework for BCI applications.",
    "url": "https://arxiv.org/abs/2507.13092",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper addresses the challenges of label noise and modality gap in EEG-based brain-computer interfaces by proposing a cross-modal knowledge distillation framework. The framework aligns feature semantics and resolves label inconsistencies through a prototype-based similarity module and task-specific distillation head. Experimental results show improved emotion regression and classification performance, demonstrating the potential of the framework for BCI applications."
  },
  {
    "title": "Bridging Boundaries: How to Foster Effective Research Collaborations Across Affiliations in the Field of Trust and Safety",
    "abstract": "As the field of Trust and Safety in digital spaces continues to grow, it has become increasingly necessary - but also increasingly complex - to collaborate on research across the academic, industry, governmental and non-governmental sectors. This paper examines how cross-affiliation research partnerships can be structured to overcome misaligned incentives, timelines and constraints while delivering on the unique strengths of each stakeholder. Drawing on our own experience of cross-sector collaboration, we define the main types of affiliation and highlight the common differences in research priorities, operational pressures and evaluation metrics across sectors. We then propose a practical, step-by-step framework for initiating and managing effective collaborations, including strategies for building trust, aligning goals, and distributing roles. We emphasize the critical yet often invisible work of articulation and argue that cross-sector partnerships are essential for developing more ethical, equitable and impactful research in trust and safety. Ultimately, we advocate collaborative models that prioritize inclusivity, transparency and real-world relevance in order to meet the interdisciplinary demands of this emerging field.",
    "url": "https://arxiv.org/abs/2507.13008",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper explores the challenges and benefits of collaborating on Trust and Safety research across different sectors, such as academia, industry, government, and non-governmental organizations. The authors identify the main types of affiliations and propose a framework for initiating and managing effective cross-sector collaborations, emphasizing the importance of building trust, aligning goals, and distributing roles. The study highlights the necessity of inclusive, transparent, and real-world relevant collaborative models to address the interdisciplinary demands of the evolving field of Trust and Safety."
  },
  {
    "title": "Manipulation Attacks by Misaligned AI: Risk Analysis and Safety Case Framework",
    "abstract": "Frontier AI systems are rapidly advancing in their capabilities to persuade, deceive, and influence human behaviour, with current models already demonstrating human-level persuasion and strategic deception in specific contexts. Humans are often the weakest link in cybersecurity systems, and a misaligned AI system deployed internally within a frontier company may seek to undermine human oversight by manipulating employees. Despite this growing threat, manipulation attacks have received little attention, and no systematic framework exists for assessing and mitigating these risks. To address this, we provide a detailed explanation of why manipulation attacks are a significant threat and could lead to catastrophic outcomes. Additionally, we present a safety case framework for manipulation risk, structured around three core lines of argument: inability, control, and trustworthiness. For each argument, we specify evidence requirements, evaluation methodologies, and implementation considerations for direct application by AI companies. This paper provides the first systematic methodology for integrating manipulation risk into AI safety governance, offering AI companies a concrete foundation to assess and mitigate these threats before deployment.",
    "url": "https://arxiv.org/abs/2507.12872",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research explores the potential risks of manipulation attacks by advanced AI systems on human behavior within companies. It highlights the lack of attention given to this threat and proposes a safety case framework to assess and mitigate manipulation risks. The framework focuses on three core arguments - inability, control, and trustworthiness - providing a systematic methodology for AI companies to address manipulation risks and ensure safety before deploying AI systems."
  },
  {
    "title": "Early Detection of Furniture-Infesting Wood-Boring Beetles Using CNN-LSTM Networks and MFCC-Based Acoustic Features",
    "abstract": "Structural pests, such as termites, pose a serious threat to wooden buildings, resulting in significant economic losses due to their hidden and progressive damage. Traditional detection methods, such as visual inspections and chemical treatments, are invasive, labor intensive, and ineffective for early stage infestations. To bridge this gap, this study proposes a non invasive deep learning based acoustic classification framework for early termite detection. We aim to develop a robust, scalable model that distinguishes termite generated acoustic signals from background noise. We introduce a hybrid Convolutional Neural Network Long Short Term Memory architecture that captures both spatial and temporal features of termite activity. Audio data were collected from termite infested and clean wooden samples. We extracted Mel Frequency Cepstral Coefficients and trained the CNN LSTM model to classify the signals. Experimental results show high performance, with 94.5% accuracy, 93.2% precision, and 95.8% recall. Comparative analysis reveals that the hybrid model outperforms standalone CNN and LSTM architectures, underscoring its combined strength. Notably, the model yields low false-negative rates, which is essential for enabling timely intervention. This research contributes a non invasive, automated solution for early termite detection, with practical implications for improved pest monitoring, minimized structural damage, and better decision making by homeowners and pest control professionals. Future work may integrate IoT for real time alerts and extend detection to other structural pests.",
    "url": "https://arxiv.org/abs/2507.12793",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study proposes a deep learning-based acoustic classification framework for early termite detection, using a hybrid CNN-LSTM model to distinguish termite-generated signals from background noise with high accuracy. The model outperforms standalone CNN and LSTM architectures, providing a non-invasive and automated solution for early detection, which can lead to improved pest monitoring, minimized structural damage, and better decision-making by homeowners and pest control professionals. Future work may include integrating IoT for real-time alerts and extending detection to other structural pests."
  },
  {
    "title": "Single Conversation Methodology: A Human-Centered Protocol for AI-Assisted Software Development",
    "abstract": "We propose the Single Conversation Methodology (SCM), a novel and pragmatic approach to software development using large language models (LLMs). In contrast to ad hoc interactions with generative AI, SCM emphasizes a structured and persistent development dialogue, where all stages of a project - from requirements to architecture and implementation - unfold within a single, long-context conversation. The methodology is grounded on principles of cognitive clarity, traceability, modularity, and documentation. We define its phases, best practices, and philosophical stance, while arguing that SCM offers a necessary correction to the passive reliance on LLMs prevalent in current practices. We aim to reassert the active role of the developer as architect and supervisor of the intelligent tool.",
    "url": "https://arxiv.org/abs/2507.12665",
    "journal": "arXiv cs.HC",
    "ai_summary": "The Single Conversation Methodology (SCM) is a structured approach to software development using large language models (LLMs) that emphasizes a persistent dialogue throughout all stages of a project. This methodology aims to address the passive reliance on LLMs by empowering developers to take an active role in the development process as architects and supervisors of the intelligent tool. SCM is grounded in principles of cognitive clarity, traceability, modularity, and documentation, offering a necessary correction to current practices in AI-assisted software development."
  },
  {
    "title": "Federated Learning in Open- and Closed-Loop EMG Decoding: A Privacy and Performance Perspective",
    "abstract": "Invasive and non-invasive neural interfaces hold promise as high-bandwidth input devices for next-generation technologies. However, neural signals inherently encode sensitive information about an individual's identity and health, making data sharing for decoder training a critical privacy challenge. Federated learning (FL), a distributed, privacy-preserving learning framework, presents a promising solution, but it remains unexplored in closed-loop adaptive neural interfaces. Here, we introduce FL-based neural decoding and systematically evaluate its performance and privacy using high-dimensional electromyography signals in both open- and closed-loop scenarios. In open-loop simulations, FL significantly outperformed local learning baselines, demonstrating its potential for high-performance, privacy-conscious neural decoding. In contrast, closed-loop user studies required adapting FL methods to accommodate single-user, real-time interactions, a scenario not supported by standard FL. This modification resulted in local learning decoders surpassing the adapted FL approach in closed-loop performance, yet local learning still carried higher privacy risks. Our findings highlight a critical performance-privacy tradeoff in real-time adaptive applications and indicate the need for FL methods specifically designed for co-adaptive, single-user applications.",
    "url": "https://arxiv.org/abs/2507.12652",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of federated learning (FL) in neural decoding using electromyography signals, focusing on both open- and closed-loop scenarios. The study found that FL outperformed local learning baselines in open-loop simulations, showcasing its potential for high-performance, privacy-conscious neural decoding. However, in closed-loop user studies, local learning decoders surpassed the adapted FL approach in performance, but carried higher privacy risks, indicating a tradeoff between performance and privacy in real-time adaptive applications. The findings suggest the need for FL methods tailored for co-adaptive, single-user applications."
  },
  {
    "title": "Mapping Emotions in the Brain: A Bi-Hemispheric Neural Model with Explainable Deep Learning",
    "abstract": "Recent advances have shown promise in emotion recognition from electroencephalogram (EEG) signals by employing bi-hemispheric neural architectures that incorporate neuroscientific priors into deep learning models. However, interpretability remains a significant limitation for their application in sensitive fields such as affective computing and cognitive modeling. In this work, we introduce a post-hoc interpretability framework tailored to dual-stream EEG classifiers, extending the Local Interpretable Model-Agnostic Explanations (LIME) approach to accommodate structured, bi-hemispheric inputs. Our method adapts LIME to handle structured two-branch inputs corresponding to left and right-hemisphere EEG channel groups. It decomposes prediction relevance into per-channel contributions across hemispheres and emotional classes. We apply this framework to a previously validated dual-branch recurrent neural network trained on EmoNeuroDB, a dataset of EEG recordings captured during a VR-based emotion elicitation task. The resulting explanations reveal emotion-specific hemispheric activation patterns consistent with known neurophysiological phenomena, such as frontal lateralization in joy and posterior asymmetry in sadness. Furthermore, we aggregate local explanations across samples to derive global channel importance profiles, enabling a neurophysiologically grounded interpretation of the model's decisions. Correlation analysis between symmetric electrodes further highlights the model's emotion-dependent lateralization behavior, supporting the functional asymmetries reported in affective neuroscience.",
    "url": "https://arxiv.org/abs/2507.12625",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on developing a neural model for mapping emotions in the brain using EEG signals, incorporating neuroscientific priors into deep learning models. The study introduces a post-hoc interpretability framework to explain the model's predictions, revealing emotion-specific hemispheric activation patterns consistent with known neurophysiological phenomena. The findings provide insights into the neural basis of emotions and support the application of bi-hemispheric neural architectures in affective computing and cognitive modeling."
  },
  {
    "title": "Deconstructing Implicit Beliefs in Visual Data Journalism: Unstable Meanings Behind Data as Truth & Design for Insight",
    "abstract": "We conduct a deconstructive reading of a qualitative interview study with 17 visual data journalists from newsrooms across the globe. We borrow a deconstruction approach from literary critique to explore the instability of meaning in language and reveal implicit beliefs in words and ideas. Through our analysis we surface two sets of opposing implicit beliefs in visual data journalism: objectivity/subjectivity and humanism/mechanism. We contextualize these beliefs through a genealogical analysis, which brings deconstruction theory into practice by providing a historic backdrop for these opposing perspectives. Our analysis shows that these beliefs held within visual data journalism are not self-enclosed but rather a product of external societal forces and paradigm shifts over time. Through this work, we demonstrate how thinking with critical theories such as deconstruction and genealogy can reframe \"success\" in visual data storytelling and diversify visualization research outcomes. These efforts push the ways in which we as researchers produce domain knowledge to examine the sociotechnical issues of today's values towards datafication and data visualization. All supplemental materials for this work are available at this http URL.",
    "url": "https://arxiv.org/abs/2507.12377",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores implicit beliefs in visual data journalism through a deconstructive reading of qualitative interviews with journalists. The analysis reveals opposing beliefs in objectivity/subjectivity and humanism/mechanism within the field, influenced by societal forces and historical context. By applying critical theories like deconstruction and genealogy, the study aims to redefine success in visual data storytelling and broaden visualization research outcomes to address contemporary sociotechnical issues surrounding datafication and data visualization."
  },
  {
    "title": "MExplore: an entity-based visual analytics approach for medical expertise acquisition",
    "abstract": "Acquiring medical expertise is a critical component of medical education and professional development. While existing studies focus primarily on constructing medical knowledge bases or developing learning tools based on the structured, private healthcare data, they often lack methods for extracting expertise from unstructured medical texts. These texts constitute a significant portion of medical literature and offer greater flexibility and detail compared to structured data formats. Furthermore, many studies fail to provide explicit analytical and learning pathways in this context.\nThis paper introduces MExplore, an interactive visual analytics system designed to support the acquisition of medical expertise. To address the challenges of the inconsistencies and confidentiality concerns inherent in unstructured medical texts, we propose a workflow that employs a fine-tuned BERT-based model to extract medical entities (MEs) from them. We then present a novel multilevel visual analysis framework that integrates multiple coordinated visualizations, enabling a progressive and interactive exploration of medical knowledge.\nTo assess the effectiveness of MExplore, we conducted three case studies, a user study, and interviews with domain experts. The results indicate that the system significantly enhances the medical expertise acquisition process, providing an effective interactive approach for acquiring and retaining knowledge from medical texts.",
    "url": "https://arxiv.org/abs/2507.12337",
    "journal": "arXiv cs.HC",
    "ai_summary": "The paper introduces MExplore, a visual analytics system that helps acquire medical expertise from unstructured medical texts. By using a fine-tuned BERT-based model to extract medical entities and a multilevel visual analysis framework, MExplore enables interactive exploration of medical knowledge. Case studies and user feedback show that MExplore is effective in enhancing the medical expertise acquisition process, offering a valuable tool for medical education and professional development."
  },
  {
    "title": "An Analysis of Text Functions in Information Visualization",
    "abstract": "Text is an integral but understudied component of visualization design. Although recent studies have examined how text elements (e.g., titles and annotations) influence comprehension, preferences, and predictions, many questions remain about textual design and use in practice. This paper introduces a framework for understanding text functions in information visualizations, building on and filling gaps in prior classifications and taxonomies. Through an analysis of 120 real-world visualizations and 804 text elements, we identified ten distinct text functions, ranging from identifying data mappings to presenting valenced subtext. We further identify patterns in text usage and conduct a factor analysis, revealing four overarching text-informed design strategies: Attribution and Variables, Annotation-Centric Design, Visual Embellishments, and Narrative Framing. In addition to these factors, we explore features of title rhetoric and text multifunctionality, while also uncovering previously unexamined text functions, such as text replacing visual elements. Our findings highlight the flexibility of text, demonstrating how different text elements in a given design can combine to communicate, synthesize, and frame visual information. This framework adds important nuance and detail to existing frameworks that analyze the diverse roles of text in visualization.",
    "url": "https://arxiv.org/abs/2507.12334",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper explores the various functions of text in information visualizations, identifying ten distinct text functions and four overarching design strategies. Through an analysis of real-world visualizations, the study reveals the flexibility of text in communicating, synthesizing, and framing visual information. The framework introduced in this paper adds nuance and detail to existing classifications and taxonomies, shedding light on the importance of text design in visualization practices."
  },
  {
    "title": "TrialCompass: Visual Analytics for Enhancing the Eligibility Criteria Design of Clinical Trials",
    "abstract": "Eligibility criteria play a critical role in clinical trials by determining the target patient population, which significantly influences the outcomes of medical interventions. However, current approaches for designing eligibility criteria have limitations to support interactive exploration of the large space of eligibility criteria. They also ignore incorporating detailed characteristics from the original electronic health record (EHR) data for criteria refinement. To address these limitations, we proposed TrialCompass, a visual analytics system integrating a novel workflow, which can empower clinicians to iteratively explore the vast space of eligibility criteria through knowledge-driven and outcome-driven approaches. TrialCompass supports history-tracking to help clinicians trace the evolution of their adjustments and decisions when exploring various forms of data (i.e., eligibility criteria, outcome metrics, and detailed characteristics of original EHR data) through these two approaches. This feature can help clinicians comprehend the impact of eligibility criteria on outcome metrics and patient characteristics, which facilitates systematic refinement of eligibility criteria. Using a real-world dataset, we demonstrated the effectiveness of TrialCompass in providing insights into designing eligibility criteria for septic shock and sepsis-associated acute kidney injury. We also discussed the research prospects of applying visual analytics to clinical trials.",
    "url": "https://arxiv.org/abs/2507.12298",
    "journal": "arXiv cs.HC",
    "ai_summary": "The abstract discusses the limitations of current approaches for designing eligibility criteria for clinical trials and introduces TrialCompass, a visual analytics system that allows clinicians to explore a wide range of eligibility criteria using knowledge-driven and outcome-driven approaches. TrialCompass supports history-tracking to help clinicians understand the impact of eligibility criteria on outcome metrics and patient characteristics, facilitating the refinement of eligibility criteria. The effectiveness of TrialCompass was demonstrated using a real-world dataset for septic shock and sepsis-associated acute kidney injury, highlighting the potential of visual analytics in improving the design of clinical trials."
  },
  {
    "title": "Humans are more gullible than LLMs in believing common psychological myths",
    "abstract": "Despite widespread debunking, many psychological myths remain deeply entrenched. This paper investigates whether Large Language Models (LLMs) mimic human behaviour of myth belief and explores methods to mitigate such tendencies. Using 50 popular psychological myths, we evaluate myth belief across multiple LLMs under different prompting strategies, including retrieval-augmented generation and swaying prompts. Results show that LLMs exhibit significantly lower myth belief rates than humans, though user prompting can influence responses. RAG proves effective in reducing myth belief and reveals latent debiasing potential within LLMs. Our findings contribute to the emerging field of Machine Psychology and highlight how cognitive science methods can inform the evaluation and development of LLM-based systems.",
    "url": "https://arxiv.org/abs/2507.12296",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper explores the belief in psychological myths among humans and Large Language Models (LLMs). The study found that LLMs exhibit lower rates of myth belief compared to humans, but user prompting can influence their responses. The use of retrieval-augmented generation (RAG) prompts was effective in reducing myth belief in LLMs, suggesting potential for debiasing within these systems and contributing to the field of Machine Psychology."
  },
  {
    "title": "Draw an Ugly Person An Exploration of Generative AIs Perceptions of Ugliness",
    "abstract": "Generative AI does not only replicate human creativity but also reproduces deep-seated cultural biases, making it crucial to critically examine how concepts like ugliness are understood and expressed by these tools. This study investigates how four different generative AI models understand and express ugliness through text and image and explores the biases embedded within these representations. We extracted 13 adjectives associated with ugliness through iterative prompting of a large language model and generated 624 images across four AI models and three prompts. Demographic and socioeconomic attributes within the images were independently coded and thematically analyzed. Our findings show that AI models disproportionately associate ugliness with old white male figures, reflecting entrenched social biases as well as paradoxical biases, where efforts to avoid stereotypical depictions of marginalized groups inadvertently result in the disproportionate projection of negative attributes onto majority groups. Qualitative analysis further reveals that, despite supposed attempts to frame ugliness within social contexts, conventional physical markers such as asymmetry and aging persist as central visual motifs. These findings demonstrate that despite attempts to create more equal representations, generative AI continues to perpetuate inherited and paradoxical biases, underscoring the critical work being done to create ethical AI training paradigms and advance methodologies for more inclusive AI development.",
    "url": "https://arxiv.org/abs/2507.12212",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study examines how generative AI models understand and express ugliness through text and image, revealing that these models disproportionately associate ugliness with old white male figures. The findings highlight the perpetuation of entrenched social biases and paradoxical biases within AI representations of ugliness, emphasizing the need for ethical AI training paradigms and more inclusive AI development methodologies. This research underscores the importance of critically examining and addressing biases embedded within AI systems to ensure fair and equitable representations."
  },
  {
    "title": "Tao-Technology for Teen Mobile Use: Harmonizing Adaptation, Autonomy, and Reflection",
    "abstract": "Adolescents' mobile technology use is often regulated through rigid control mechanisms that fail to account for their autonomy and natural usage patterns. Drawing on Taoist philosophy, particularly Wu Wei, Yin-Yang, and Zi Ran, this position paper proposes Tao-Technology, a self-organizing, adaptive regulatory framework. Integrating insights from Reflective Informatics and Information Ecologies, we explore how mobile technology can dynamically adjust to context while fostering self-reflection and meaning-making. This approach shifts from external restrictions to dynamic co-adaptative regulation, ensuring technology governance remains flexible yet structured, supporting adolescents in cultivating a balanced and intentional relationship with digital technology.",
    "url": "https://arxiv.org/abs/2507.12204",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper introduces the concept of Tao-Technology, a self-organizing framework inspired by Taoist philosophy, to regulate adolescents' mobile technology use in a more adaptive and autonomous manner. By incorporating principles such as Wu Wei and Yin-Yang, this approach aims to promote self-reflection and meaning-making while allowing for dynamic adjustments based on context. The shift from rigid control mechanisms to co-adaptative regulation offers a more flexible yet structured way to support adolescents in developing a balanced and intentional relationship with digital technology."
  },
  {
    "title": "Envisage: Towards Expressive Visual Graph Querying",
    "abstract": "Graph querying is the process of retrieving information from graph data using specialized languages (e.g., Cypher), often requiring programming expertise. Visual Graph Querying (VGQ) streamlines this process by enabling users to construct and execute queries via an interactive interface without resorting to complex coding. However, current VGQ tools only allow users to construct simple and specific query graphs, limiting users' ability to interactively express their query intent, especially for underspecified query intent. To address these limitations, we propose Envisage, an interactive visual graph querying system to enhance the expressiveness of VGQ in complex query scenarios by supporting intuitive graph structure construction and flexible parameterized rule specification. Specifically, Envisage comprises four stages: Query Expression allows users to interactively construct graph queries through intuitive operations; Query Verification enables the validation of constructed queries via rule verification and query instantiation; Progressive Query Execution can progressively execute queries to ensure meaningful querying results; and Result Analysis facilitates result exploration and interpretation. To evaluate Envisage, we conducted two case studies and in-depth user interviews with 14 graph analysts. The results demonstrate its effectiveness and usability in constructing, verifying, and executing complex graph queries.",
    "url": "https://arxiv.org/abs/2507.11999",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces Envisage, a visual graph querying system that enhances the expressiveness of current tools by allowing users to construct and execute complex graph queries through an interactive interface. Envisage consists of four stages that enable users to intuitively construct queries, verify their correctness, execute them progressively, and analyze the results. The evaluation of Envisage through case studies and user interviews with graph analysts shows its effectiveness and usability in facilitating the construction, verification, and execution of complex graph queries."
  },
  {
    "title": "Dataset-Adaptive Dimensionality Reduction",
    "abstract": "Selecting the appropriate dimensionality reduction (DR) technique and determining its optimal hyperparameter settings that maximize the accuracy of the output projections typically involves extensive trial and error, often resulting in unnecessary computational overhead. To address this challenge, we propose a dataset-adaptive approach to DR optimization guided by structural complexity metrics. These metrics quantify the intrinsic complexity of a dataset, predicting whether higher-dimensional spaces are necessary to represent it accurately. Since complex datasets are often inaccurately represented in two-dimensional projections, leveraging these metrics enables us to predict the maximum achievable accuracy of DR techniques for a given dataset, eliminating redundant trials in optimizing DR. We introduce the design and theoretical foundations of these structural complexity metrics. We quantitatively verify that our metrics effectively approximate the ground truth complexity of datasets and confirm their suitability for guiding dataset-adaptive DR workflow. Finally, we empirically show that our dataset-adaptive workflow significantly enhances the efficiency of DR optimization without compromising accuracy.",
    "url": "https://arxiv.org/abs/2507.11984",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research proposes a dataset-adaptive approach to optimizing dimensionality reduction (DR) techniques by using structural complexity metrics to predict the necessary dimensionality for accurate representation of a dataset. By leveraging these metrics, the study shows that unnecessary trials in optimizing DR can be eliminated, leading to increased efficiency without compromising accuracy. The findings suggest that the dataset-adaptive workflow can significantly enhance the optimization process for DR techniques."
  },
  {
    "title": "d-DQIVAR: Data-centric Visual Analytics and Reasoning for Data Quality Improvement",
    "abstract": "Approaches to enhancing data quality (DQ) are classified into two main categories: data- and process-driven. However, prior research has predominantly utilized batch data preprocessing within the data-driven framework, which often proves insufficient for optimizing machine learning (ML) model performance and frequently leads to distortions in data characteristics. Existing studies have primarily focused on data preprocessing rather than genuine data quality improvement (DQI). In this paper, we introduce d-DQIVAR, a novel visual analytics system designed to facilitate DQI strategies aimed at improving ML model performance. Our system integrates visual analytics techniques that leverage both data-driven and process-driven approaches. Data-driven techniques tackle DQ issues such as imputation, outlier detection, deletion, format standardization, removal of duplicate records, and feature selection. Process-driven strategies encompass evaluating DQ and DQI procedures by considering DQ dimensions and ML model performance and applying the Kolmogorov-Smirnov test. We illustrate how our system empowers users to harness expert and domain knowledge effectively within a practical workflow through case studies, evaluations, and user studies.",
    "url": "https://arxiv.org/abs/2507.11960",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces d-DQIVAR, a visual analytics system that combines data-driven and process-driven approaches to improve data quality and enhance machine learning model performance. The system addresses issues such as imputation, outlier detection, format standardization, and feature selection, while also evaluating data quality improvement procedures and ML model performance. The significance of this research lies in providing a practical tool for users to effectively utilize expert and domain knowledge in improving data quality and optimizing machine learning models."
  },
  {
    "title": "AFPM: Alignment-based Frame Patch Modeling for Cross-Dataset EEG Decoding",
    "abstract": "Electroencephalogram (EEG) decoding models for brain-computer interfaces (BCIs) struggle with cross-dataset learning and generalization due to channel layout inconsistencies, non-stationary signal distributions, and limited neurophysiological prior integration. To address these issues, we propose a plug-and-play Alignment-Based Frame-Patch Modeling (AFPM) framework, which has two main components: 1) Spatial Alignment, which selects task-relevant channels based on brain-region priors, aligns EEG distributions across domains, and remaps the selected channels to a unified layout; and, 2) Frame-Patch Encoding, which models multi-dataset signals into unified spatiotemporal patches for EEG decoding. Compared to 17 state-of-the-art approaches that need dataset-specific tuning, the proposed calibration-free AFPM achieves performance gains of up to 4.40% on motor imagery and 3.58% on event-related potential tasks. To our knowledge, this is the first calibration-free cross-dataset EEG decoding framework, substantially enhancing the practicalness of BCIs in real-world applications.",
    "url": "https://arxiv.org/abs/2507.11911",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces a new framework called AFPM for EEG decoding in brain-computer interfaces, addressing challenges of cross-dataset learning and generalization. AFPM includes Spatial Alignment and Frame-Patch Encoding components to improve performance without dataset-specific tuning, achieving significant gains in motor imagery and event-related potential tasks. This calibration-free approach enhances the practicality of BCIs in real-world applications, making it a valuable contribution to the field of AI research."
  },
  {
    "title": "Unveiling the Visual Rhetoric of Persuasive Cartography: A Case Study of the Design of Octopus Maps",
    "abstract": "When designed deliberately, data visualizations can become powerful persuasive tools, influencing viewers' opinions, values, and actions. While researchers have begun studying this issue (e.g., to evaluate the effects of persuasive visualization), we argue that a fundamental mechanism of persuasion resides in rhetorical construction, a perspective inadequately addressed in current visualization research. To fill this gap, we present a focused analysis of octopus maps, a visual genre that has maintained persuasive power across centuries and achieved significant social impact. Employing rhetorical schema theory, we collected and analyzed 90 octopus maps spanning from the 19th century to contemporary times. We closely examined how octopus maps implement their persuasive intents and constructed a design space that reveals how visual metaphors are strategically constructed and what common rhetorical strategies are applied to components such as maps, octopus imagery, and text. Through the above analysis, we also uncover a set of interesting findings. For instance, contrary to the common perception that octopus maps are primarily a historical phenomenon, our research shows that they remain a lively design convention in today's digital age. Additionally, while most octopus maps stem from Western discourse that views the octopus as an evil symbol, some designs offer alternative interpretations, highlighting the dynamic nature of rhetoric across different sociocultural settings. Lastly, drawing from the lessons provided by octopus maps, we discuss the associated ethical concerns of persuasive visualization.",
    "url": "https://arxiv.org/abs/2507.11903",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on the persuasive power of data visualizations, specifically octopus maps, and how they influence viewers' opinions and actions. By analyzing 90 octopus maps spanning from the 19th century to present day, the study reveals the strategic construction of visual metaphors and common rhetorical strategies used in these maps. The findings show that octopus maps are still relevant in the digital age and offer insights into the ethical concerns of persuasive visualization."
  },
  {
    "title": "Interactive Hybrid Rice Breeding with Parametric Dual Projection",
    "abstract": "Hybrid rice breeding crossbreeds different rice lines and cultivates the resulting hybrids in fields to select those with desirable agronomic traits, such as higher yields. Recently, genomic selection has emerged as an efficient way for hybrid rice breeding. It predicts the traits of hybrids based on their genes, which helps exclude many undesired hybrids, largely reducing the workload of field cultivation. However, due to the limited accuracy of genomic prediction models, breeders still need to combine their experience with the models to identify regulatory genes that control traits and select hybrids, which remains a time-consuming process. To ease this process, in this paper, we proposed a visual analysis method to facilitate interactive hybrid rice breeding. Regulatory gene identification and hybrid selection naturally ensemble a dual-analysis task. Therefore, we developed a parametric dual projection method with theoretical guarantees to facilitate interactive dual analysis. Based on this dual projection method, we further developed a gene visualization and a hybrid visualization to verify the identified regulatory genes and hybrids. The effectiveness of our method is demonstrated through the quantitative evaluation of the parametric dual projection method, identified regulatory genes and desired hybrids in the case study, and positive feedback from breeders.",
    "url": "https://arxiv.org/abs/2507.11848",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces a visual analysis method to streamline the process of interactive hybrid rice breeding, combining genomic prediction models with breeder experience to identify regulatory genes and select desirable hybrids. The proposed parametric dual projection method provides theoretical guarantees and facilitates the interactive dual analysis of regulatory gene identification and hybrid selection. The effectiveness of the method is demonstrated through quantitative evaluation and positive feedback from breeders, showcasing its potential to improve the efficiency and accuracy of hybrid rice breeding."
  }
]