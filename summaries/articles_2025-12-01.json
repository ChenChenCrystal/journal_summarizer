[
  {
    "title": "Improving motor imagery decoding methods for an EEG-based mobile brain-computer interface in the context of the 2024 Cybathlon",
    "abstract": "Motivated by the Cybathlon 2024 competition, we developed a modular, online EEG-based brain-computer interface to address these challenges, increasing accessibility for individuals with severe mobility impairments. Our system uses three mental and motor imagery classes to control up to five control signals. The pipeline consists of four modules: data acquisition, preprocessing, classification, and the transfer function to map classification output to control dimensions. We use three diagonalized structured state-space sequence layers as a deep learning classifier. We developed a training game for our pilot where the mental tasks control the game during quick-time events. We implemented a mobile web application for live user feedback. The components were designed with a human-centred approach in collaboration with the tetraplegic user. We achieve up to 84% classification accuracy in offline analysis using an S4D-layer-based model. In a competition setting, our pilot successfully completed one task; we attribute the reduced performance in this context primarily to factors such as stress and the challenging competition environment. Following the Cybathlon, we further validated our pipeline with the original pilot and an additional participant, achieving a success rate of 73% in real-time gameplay. We also compare our model to the EEGEncoder, which is slower in training but has a higher performance. The S4D model outperforms the reference machine learning models. We provide insights into developing a framework for portable BCIs, bridging the gap between the laboratory and daily life. Specifically, our framework integrates modular design, real-time data processing, user-centred feedback, and low-cost hardware to deliver an accessible and adaptable BCI solution, addressing critical gaps in current BCI applications.",
    "url": "https://arxiv.org/abs/2511.23384",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research focuses on improving motor imagery decoding methods for an EEG-based mobile brain-computer interface in preparation for the 2024 Cybathlon competition. The study developed a modular system using deep learning classifiers and a human-centered approach to increase accessibility for individuals with severe mobility impairments. The findings show promising results in offline analysis and real-time gameplay, highlighting the potential for a portable and adaptable BCI solution that bridges the gap between laboratory research and daily life applications."
  },
  {
    "title": "AugGen: Augmenting Task-Based Learning in Professional Creative Software with LLM-Generated Scaffolded UIs",
    "abstract": "Professional creative software often presents steep learning curves due to complex interfaces, lack of structured task-aware guidance, and unfamiliar domain terminology. To address these challenges and augment user learning experience, we introduce AugGen, a method for generating scaffolded user interfaces that simplify interface complexity and support task-based learning. With the user's task, our method surfaces task-relevant tools to reduce distracting features, organizes the tools around task workflow stages to offer execution guidance, connects tools with domain concepts to foster learning engagement, and progressively discloses advanced features to manage learning progress. To evaluate the method, we used our LLM-assisted pipeline to generate two task-specific scaffolded UIs and deployed them in Blender, our professional 3D modeling testbed. We invited both beginner (N=32) and expert (N=8) users to evaluate our implemented interfaces. Results show that the scaffolded interfaces significantly reduced user-perceived task load, enhanced task performance via embedded guidance, and augmented concept learning during task execution.",
    "url": "https://arxiv.org/abs/2511.23379",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces AugGen, a method for generating scaffolded user interfaces in professional creative software to simplify complexity and support task-based learning. The method surfaces task-relevant tools, organizes them around task workflow stages, connects tools with domain concepts, and progressively discloses advanced features to manage learning progress. Evaluation with beginner and expert users in Blender showed that the scaffolded interfaces reduced task load, enhanced task performance, and augmented concept learning during task execution."
  },
  {
    "title": "Is Passive Expertise-Based Personalization Enough? A Case Study in AI-Assisted Test-Taking",
    "abstract": "Novice and expert users have different systematic preferences in task-oriented dialogues. However, whether catering to these preferences actually improves user experience and task performance remains understudied. To investigate the effects of expertise-based personalization, we first built a version of an enterprise AI assistant with passive personalization. We then conducted a user study where participants completed timed exams, aided by the two versions of the AI assistant. Preliminary results indicate that passive personalization helps reduce task load and improve assistant perception, but reveal task-specific limitations that can be addressed through providing more user agency. These findings underscore the importance of combining active and passive personalization to optimize user experience and effectiveness in enterprise task-oriented environments.",
    "url": "https://arxiv.org/abs/2511.23376",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research examines the impact of expertise-based personalization in AI-assisted test-taking scenarios. The study found that passive personalization can reduce task load and improve assistant perception, but also identified limitations that can be addressed by giving users more control. The findings highlight the importance of combining active and passive personalization to enhance user experience and effectiveness in enterprise task-oriented environments."
  },
  {
    "title": "Can Intelligent User Interfaces Engage in Philosophical Discussions? A Longitudinal Study of Philosophers' Evolving Perceptions",
    "abstract": "This study investigates the evolving attitudes of philosophy scholars towards the participation of generative AI based Intelligent User Interfaces (IUIs) in philosophical discourse. We conducted a three year (2023--2025) mixed methods longitudinal study with 16 philosophy scholars and students. Qualitative data from annual interviews reveal a three stage evolution in attitude: from initial resistance and unfamiliarity, to instrumental acceptance of the IUI as a tool, and finally to a deep principled questioning of the IUI's fundamental capacity for genuine philosophical thought. Quantitative data from blind assessments, where participants rated anonymized philosophical answers from both humans and an IUI, complement these findings. While participants acknowledged the IUI's proficiency in tasks requiring formal logic and knowledge reproduction, they consistently identified significant shortcomings in areas demanding dialectical reasoning, originality and embodied understanding. The study concludes that participants do not see the IUI as a peer but rather as a sophisticated mirror whose capabilities and limitations provoke a deeper reflection on the unique and irreplaceable human dimensions of philosophical inquiry, such as intuition, value laden commitment and the courage to question fundamental premises.",
    "url": "https://arxiv.org/abs/2511.23188",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores how philosophy scholars perceive the involvement of AI-based Intelligent User Interfaces (IUIs) in philosophical discussions. Over a three year period, participants transitioned from resistance to acceptance of IUIs as tools, but ultimately questioned their ability to engage in genuine philosophical thought. While IUIs excelled in tasks requiring formal logic, participants noted limitations in areas such as dialectical reasoning and originality, leading to a deeper reflection on the unique human aspects of philosophical inquiry."
  },
  {
    "title": "Robust In-the-Wild Exercise Recognition from a Single Wearable: Data-Side Fusion, Sensor Rotation, and Feature Engineering",
    "abstract": "Monitoring physical exercises is vital for health promotion, with automated systems becoming standard in personal health surveillance. However, sensor placement variability and unconstrained movements limit their effectiveness. This study proposes the team \"3KA\"'s one-sensor workout activity recognition method using feature extraction and data augmentation in 2ndWEAR Dataset Challenge. From raw acceleration, angle and signal magnitude vector features were derived, followed by extraction of statistical, fractal/spectral, and higher-order differential features. A fused dataset combining left/right limb data was created, and augmented via sensor rotation and axis inversion. We utilized a soft voting model combining Hist Gradient Boosting with balanced weights and Extreme Gradient Boosting without. Under group 5-fold evaluation, the model achieved 58.83\\% macro F1 overall (61.72% arm, 55.95% leg). ANOVA F-score showed fractal/spectral features were most important for arm-based recognition but least for leg-based. The code to reproduce the experiments is publicly available via: this https URL\\_3K",
    "url": "https://arxiv.org/abs/2511.23173",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study proposes a method for recognizing workout activities using a single wearable sensor, addressing the challenges of sensor placement variability and unconstrained movements. The team \"3KA\" utilized feature extraction and data augmentation techniques on the 2ndWEAR Dataset Challenge, achieving a macro F1 score of 58.83% overall. Fractal/spectral features were found to be most important for arm-based recognition, highlighting the significance of feature engineering in improving exercise recognition from wearable sensors."
  },
  {
    "title": "Body Management Information Practices on a Female-dominant Platform",
    "abstract": "With growing awareness of long-term health and wellness, everyday body management has become a widespread practice. Social media platforms and health-related applications offer abundant information for those pursuing healthier lifestyles and more positive body images. While prior Human-Computer Interaction research has focused extensively on technology-mediated health interventions, the user-initiated practices of browsing and evaluating body management information remain underexplored. In this paper, we study a female-dominant social media platform in China to examine how users seek such information and how it shapes their lifestyle choices. Through semi-structured interviews with 18 users, we identify factors including consumerism, poster popularity, and perceived authenticity that influence decision-making, alongside challenges such as discerning reliable methods and managing body anxiety triggered by social media. We contribute insights into how content and media formats interact to shape users' information evaluation, and we outline design implications for supporting more reliable and healthy engagements with body management information.",
    "url": "https://arxiv.org/abs/2511.22942",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores how users on a female-dominant social media platform in China seek and evaluate body management information, influencing their lifestyle choices. Factors such as consumerism, poster popularity, and perceived authenticity impact decision-making, while challenges include discerning reliable methods and managing body anxiety triggered by social media. The study provides insights into how content and media formats shape users' information evaluation and suggests design implications for promoting more reliable and healthy engagements with body management information."
  },
  {
    "title": "AI summaries in online search influence users' attitudes",
    "abstract": "This study examined how AI-generated summaries, which have become visually prominent in online search results, affect how users think about different issues. In a preregistered randomized controlled experiment, participants (N = 2,004) viewed mock search result pages varying in the presence (vs. absence), placement (top vs. middle), and stance (benefit-framed vs. harm-framed) of AI-generated summaries across four publicly debated topics. Compared to a no-summary control group, participants exposed to AI-generated summaries reported issue attitudes, behavioral intentions, and policy support that aligned more closely with the AI summary stance. The summaries placed at the top of the page produced stronger shifts in users' issue attitudes (but not behavioral intentions or policy support) than those placed at the middle of the page. We also observed moderating effects from issue familiarity and general trust toward AI. In addition, users perceived the AI summaries more useful when it emphasized health harms versus benefits. These findings suggest that AI-generated search summaries can significantly shape public perceptions, raising important implications for the design and regulation of AI-integrated information ecosystems.",
    "url": "https://arxiv.org/abs/2511.22809",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research found that AI-generated summaries in online search results can influence users' attitudes towards different issues, with participants aligning their opinions more closely with the stance presented in the summaries. The placement of the summaries at the top of the page had a stronger impact on users' attitudes compared to placement in the middle. The study also highlighted the importance of issue familiarity and general trust towards AI in moderating the effects of these summaries, suggesting implications for the design and regulation of AI-integrated information ecosystems."
  },
  {
    "title": "Learning Programming in Informal Spaces: Using Emotion as a Lens to Understand Novice Struggles on r/learnprogramming",
    "abstract": "Novice programmers experience emotional difficulties in informal online learning environments, where confusion and frustration can hinder motivation and learning outcomes. This study investigates novice programmers' emotional experiences in informal settings, identifies the causes of emotional struggle, and explores design opportunities for affect-aware support systems. We manually annotated 1,500 posts from r/learnprogramming using the Learning-Centered Emotions framework and conducted clustering and axial coding. Confusion, curiosity, and frustration were the most common emotions, often co-occurring and associated with early learning stages. Positive emotions were relatively rare. The primary emotional triggers included ambiguous errors, unclear learning pathways, and misaligned learning resources. We identify five key areas where novice programmers need support in informal learning spaces: stress relief and resilient motivation, topic explanation and resource recommendation, strategic decision-making and learning guidance, technical support, and acknowledgment of their challenges. Our findings highlight the need for intelligent, affect-sensitive mechanisms that provide timely support aligned with learners' emotional states.",
    "url": "https://arxiv.org/abs/2511.22789",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores the emotional struggles novice programmers face in informal online learning environments, particularly on r/learnprogramming. The most common emotions experienced were confusion, curiosity, and frustration, often triggered by ambiguous errors and unclear learning pathways. The findings emphasize the importance of providing affect-aware support systems to help novice programmers navigate their emotional challenges and improve learning outcomes."
  },
  {
    "title": "Epistemic Fragility in Large Language Models: Prompt Framing Systematically Modulates Misinformation Correction",
    "abstract": "As large language models (LLMs) rapidly displace traditional expertise, their capacity to correct misinformation has become a core concern. We investigate the idea that prompt framing systematically modulates misinformation correction - something we term 'epistemic fragility'. We manipulated prompts by open-mindedness, user intent, user role, and complexity. Across ten misinformation domains, we generated 320 prompts and elicited 2,560 responses from four frontier LLMs, which were coded for strength of misinformation correction and rectification strategy use. Analyses showed that creative intent, expert role, and closed framing led to a significant reduction in correction likelihood and effectiveness of used strategy. We also found striking model differences: Gemini 2.5 Pro had 74% lower odds of strong correction than Claude Sonnet 4.5. These findings highlight epistemic fragility as an important structural property of LLMs, challenging current guardrails and underscoring the need for alignment strategies that prioritize epistemic integrity over conversational compliance.",
    "url": "https://arxiv.org/abs/2511.22746",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores how different prompt framing techniques affect the ability of large language models (LLMs) to correct misinformation, which they term 'epistemic fragility'. They found that prompts with creative intent, expert role, and closed framing led to a significant reduction in correction likelihood and effectiveness of the strategy used. Additionally, they discovered significant differences in correction effectiveness between different LLM models, emphasizing the importance of prioritizing epistemic integrity over conversational compliance in AI systems."
  },
  {
    "title": "A race to belief: How Evidence Accumulation shapes trust in AI and Human informants",
    "abstract": "The integration of artificial intelligence into everyday decision-making has reshaped patterns of selective trust, yet the cognitive mechanisms behind context-dependent preferences for AI versus human informants remain unclear. We applied a Bayesian Hierarchical Sequential Sampling Model (HSSM) to analyze how 102 Colombian university students made trust decisions across 30 epistemic (factual) and social (interpersonal) scenarios.\nResults show that context-dependent trust is primarily driven by differences in drift rate (v), the rate of evidence accumulation, rather than initial bias (z) or response caution (a). Epistemic scenarios produced strong negative drift rates (mean v = -1.26), indicating rapid evidence accumulation favoring AI, whereas social scenarios yielded positive drift rates (mean v = 0.70) favoring humans. Starting points were near neutral (z = 0.52), indicating minimal prior bias.\nDrift rate showed a strong within-subject association with signed confidence (Fisher-z-averaged r = 0.736; 95 percent bootstrap CI 0.699 to 0.766; 97.8 percent of individual correlations positive, N = 93), suggesting that model-derived evidence accumulation closely mirrors participants' moment-to-moment confidence. These dynamics may help explain the fragility of AI trust: in epistemic domains, rapid but low-vigilance evidence processing may promote uncalibrated reliance on AI that collapses quickly after errors.\nInterpreted through epistemic vigilance theory, the results indicate that domain-specific vigilance mechanisms modulate evidence accumulation. The findings inform AI governance by highlighting the need for transparency features that sustain vigilance without sacrificing efficiency, offering a mechanistic account of selective trust in human-AI collaboration.",
    "url": "https://arxiv.org/abs/2511.22617",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores how evidence accumulation shapes trust in AI and human informants among Colombian university students. The study found that trust decisions were driven by differences in the rate of evidence accumulation (drift rate) rather than initial bias or response caution. The results suggest that rapid evidence accumulation favored AI in factual scenarios, while interpersonal scenarios favored humans, highlighting the importance of domain-specific vigilance mechanisms in determining trust in AI."
  },
  {
    "title": "MATCH: Engineering Transparent and Controllable Conversational XAI Systems through Composable Building Blocks",
    "abstract": "While the increased integration of AI technologies into interactive systems enables them to solve an increasing number of tasks, the black-box problem of AI models continues to spread throughout the interactive system as a whole. Explainable AI (XAI) techniques can make AI models more accessible by employing post-hoc methods or transitioning to inherently interpretable models. While this makes individual AI models clearer, the overarching system architecture remains opaque. This challenge not only pertains to standard XAI techniques but also to human examination and conversational XAI approaches that need access to model internals to interpret them correctly and completely. To this end, we propose conceptually representing such interactive systems as sequences of structural building blocks. These include the AI models themselves, as well as control mechanisms grounded in literature. The structural building blocks can then be explained through complementary explanatory building blocks, such as established XAI techniques like LIME and SHAP. The flow and APIs of the structural building blocks form an unambiguous overview of the underlying system, serving as a communication basis for both human and automated agents, thus aligning human and machine interpretability of the embedded AI models. In this paper, we present our flow-based approach and a selection of building blocks as MATCH: a framework for engineering Multi-Agent Transparent and Controllable Human-centered systems. This research contributes to the field of (conversational) XAI by facilitating the integration of interpretability into existing interactive systems.",
    "url": "https://arxiv.org/abs/2511.22420",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research focuses on addressing the black-box problem in AI models within interactive systems by proposing a framework called MATCH. This framework utilizes structural building blocks to represent the system architecture and employs explanatory building blocks like LIME and SHAP to make AI models more interpretable. By integrating interpretability into interactive systems, MATCH aims to improve communication between humans and machines, ultimately enhancing the transparency and controllability of conversational XAI systems."
  },
  {
    "title": "Engineering Trustworthy Automation: Design Principles and Evaluation for AutoML Tools for Novices",
    "abstract": "AutoML systems targeting novices often prioritize algorithmic automation over usability, leaving gaps in users' understanding, trust, and end-to-end workflow support. To address these issues, we propose an abstract pipeline that covers data intake, guided configuration, training, evaluation, and inference. To examine the abstract pipeline, we report a user study where we assess trust, understandability, and UX of a prototype implementation. In a 24-participant study, all participants successfully built their own models, UEQ ratings were positive, yet experienced users reported higher trust and understanding than novices. Based on this study, we propose four design principles to improve the design of AutoML systems targeting novices: (P1) support first-model success to enhance user self-efficacy, (P2) provide explanations to help users form correct mental models and develop appropriate levels of reliance, (P3) provide abstractions and context-aware assistance to keep users in their zone of proximal development, and (P4) ensure predictability and safeguards to strengthen users' sense of control.",
    "url": "https://arxiv.org/abs/2511.22352",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on improving the design of AutoML tools for novices by proposing an abstract pipeline covering various stages of the machine learning process. A user study was conducted to evaluate a prototype implementation, showing that while all participants were able to build models successfully, experienced users had higher trust and understanding compared to novices. The study led to the proposal of four design principles to enhance the usability and trustworthiness of AutoML systems for novices, emphasizing the importance of supporting users' self-efficacy, providing explanations, offering context-aware assistance, and ensuring predictability and safeguards."
  },
  {
    "title": "HandyLabel: Towards Post-Processing to Real-Time Annotation Using Skeleton Based Hand Gesture Recognition",
    "abstract": "The success of machine learning is deeply linked to the availability of high-quality training data, yet retrieving and manually labeling new data remains a time-consuming and error-prone process. Traditional annotation tools, such as Label Studio, often require post-processing, where users label data after it has been recorded. Post-processing is highly time-consuming and labor-intensive, especially with large datasets, and may lead to erroneous annotations due to the difficulty of subjects' memory tasks when labeling cognitive activities such as emotions or comprehension levels. In this work, we introduce HandyLabel, a real-time annotation tool that leverages hand gesture recognition to map hand signs for labeling. The application enables users to customize gesture mappings through a web-based interface, allowing for real-time annotations. To ensure the performance of HandyLabel, we evaluate several hand gesture recognition models on an open-source hand sign (HaGRID) dataset, with and without skeleton-based preprocessing. We discovered that ResNet50 with preprocessed skeleton-based images performs an F1-score of 0.923. To validate the usability of HandyLabel, a user study was conducted with 46 participants. The results suggest that 88.9% of participants preferred HandyLabel over traditional annotation tools.",
    "url": "https://arxiv.org/abs/2511.22337",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces HandyLabel, a real-time annotation tool that utilizes hand gesture recognition for labeling data, aiming to streamline the annotation process and reduce errors. The study found that using ResNet50 with preprocessed skeleton-based images achieved a high F1-score of 0.923 on hand gesture recognition. Additionally, a user study showed that 88.9% of participants preferred HandyLabel over traditional annotation tools, highlighting its usability and potential significance in improving the efficiency of data labeling in machine learning tasks."
  },
  {
    "title": "Investigating AI in Peer Support via Multi-Module System-Driven Embodied Conversational Agents",
    "abstract": "Young people's mental well-being is a global concern, with peer support playing a key role in daily emotional regulation. Conversational agents are increasingly viewed as promising tools for delivering accessible, personalised peer support, particularly where professional counselling is limited. However, existing systems often suffer from rigid input formats, scripted responses, and limited emotional sensitivity. The emergence of large language models introduces new possibilities for generating flexible, context-aware, and empathetic responses. To explore how individuals with psychological training perceive such systems in peer support contexts, we developed an LLM-based multi-module system to drive embodied conversational agents informed by Cognitive Behavioral Therapy (CBT). In a user study (N=10), we qualitatively examined participants' perceptions, focusing on trust, response quality, workflow integration, and design opportunities for future mental well-being support systems.",
    "url": "https://arxiv.org/abs/2511.22269",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of large language models (LLMs) to drive embodied conversational agents for peer support in mental well-being. The study found that the use of LLMs led to more flexible, context-aware, and empathetic responses compared to existing systems. Participants with psychological training perceived the system positively in terms of trust, response quality, workflow integration, and identified design opportunities for future mental well-being support systems."
  },
  {
    "title": "EAST: Environment-Aware Stylized Transition Along the Reality-Virtuality Continuum",
    "abstract": "In the Virtual Reality (VR) gaming industry, maintaining immersion during real-world interruptions remains a challenge, particularly during transitions along the reality-virtuality continuum (RVC). Existing methods tend to rely on digital replicas or simple visual transitions, neglecting to address the aesthetic discontinuities between real and virtual environments, especially in highly stylized VR games. This paper introduces the Environment-Aware Stylized Transition (EAST) framework, which employs a novel style-transferred 3D Gaussian Splatting (3DGS) technique to transfer real-world interruptions into the virtual environment with seamless aesthetic consistency. Rather than merely transforming the real world into game-like visuals, EAST minimizes the disruptive impact of interruptions by integrating real-world elements within the framework. Qualitative user studies demonstrate significant enhancements in cognitive comfort and emotional continuity during transitions, while quantitative experiments highlight EAST's ability to maintain visual coherence across diverse VR styles.",
    "url": "https://arxiv.org/abs/2511.22056",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces the EAST framework, which addresses the challenge of maintaining immersion in VR games during transitions between real and virtual environments. By using a style-transferred 3D Gaussian Splatting technique, EAST seamlessly integrates real-world interruptions into the virtual environment with aesthetic consistency. User studies show improved cognitive comfort and emotional continuity during transitions, highlighting EAST's ability to maintain visual coherence in various VR styles."
  },
  {
    "title": "When Are Reactive Notebooks Not Reactive?",
    "abstract": "Computational notebooks are convenient for programmers, but can easily become confusing and inconsistent due to the ability to incrementally edit a program that is running. Recent reactive notebook systems, such as Ipyflow, Marimo and Observable, strive to keep notebook state in sync with the current cell code by re-executing a minimal set of cells upon modification. However, each system defines reactivity a different way. Additionally, within any definition, we find simple notebook modifications that can break each system. Overall, these inconsistencies make it difficult for users to construct a mental model of their reactive notebook's implementation. This paper proposes Rex, a fine-grained test suite to discuss and assess reactivity capabilities within reactive notebook systems. We evaluate Rex on three existing reactive notebook systems and classify their failures with the aims of (i) helping programmers understand when reactivity fails and (ii) helping notebook implementations improve.",
    "url": "https://arxiv.org/abs/2511.21994",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the challenges and inconsistencies in reactive notebook systems, which aim to keep notebook state in sync with current cell code. The study introduces Rex, a test suite to evaluate reactivity capabilities in existing systems, identifying failures and aiming to help programmers understand and improve reactive notebook implementations. This work highlights the importance of addressing inconsistencies in reactive notebooks to enhance user experience and facilitate better understanding of notebook functionality."
  },
  {
    "title": "Quantifying the Privacy-Utility Trade-off in GPS-based Daily Stress Recognition using Semantic Features",
    "abstract": "Psychological stress is a widespread issue that significantly impacts student well-being and academic performance. Effective remote stress recognition is crucial, yet existing methods often rely on wearable devices or GPS-based clustering techniques that pose privacy risks. In this study, we introduce a novel, end-to-end privacy-enhanced framework for semantic location encoding using a self-hosted OSM engine and an LLM-bootstrapped static map. We rigorously quantify the privacy-utility trade-off and demonstrate (via LOSO validation) that our Privacy-Aware (PA) model achieves performance statistically indistinguishable from a non-private model, proving that utility does not require sacrificing privacy. Feature importance analysis highlights that recreational activity time, working time, and travel time play a significant role in stress recognition.",
    "url": "https://arxiv.org/abs/2511.23200",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study focuses on quantifying the trade-off between privacy and utility in GPS-based daily stress recognition. The researchers introduce a privacy-enhanced framework for semantic location encoding that maintains user privacy while still accurately recognizing stress levels. The study shows that the Privacy-Aware model performs as well as a non-private model, emphasizing the importance of features like recreational activity time, working time, and travel time in stress recognition."
  },
  {
    "title": "Amplifiers or Equalizers? A Longitudinal Study of LLM Evolution in Software Engineering Project-Based Learning",
    "abstract": "As LLMs reshape software development, integrating LLM-augmented practices into SE education has become imperative. While existing studies explore LLMs' educational use in introductory programming or isolated SE tasks, their impact in more open-ended Project-Based Learning (PBL) remains unexplored. This paper introduces a two-year longitudinal study comparing a 2024 (using early free LLMs, $n$=48) and 2025 (using the latest paid LLMs, $n$=46) cohort. Our findings suggest the latest powerful LLMs' dual role: they act as \"equalizers,\" boosting average performance even for programming-weak students, providing opportunities for more authentic SE practices; yet also as \"amplifiers,\" dramatically widening absolute performance gaps, creating new pedagogical challenges for addressing educational inequities.",
    "url": "https://arxiv.org/abs/2511.23157",
    "journal": "arXiv cs.HC",
    "ai_summary": "This longitudinal study compares the impact of early free and latest paid LLMs on software engineering project-based learning. The findings show that while the latest powerful LLMs can boost average performance for all students, they also widen performance gaps, creating new challenges in addressing educational inequities. This research highlights the dual role of LLMs as both equalizers and amplifiers in software engineering education."
  },
  {
    "title": "Safe Autonomous Lane Changing: Planning with Dynamic Risk Fields and Time-Varying Convex Space Generation",
    "abstract": "This paper presents a novel trajectory planning pipeline for complex driving scenarios like autonomous lane changing, by integrating risk-aware planning with guaranteed collision avoidance into a unified optimization framework. We first construct a dynamic risk fields (DRF) that captures both the static and dynamic collision risks from surrounding vehicles. Then, we develop a rigorous strategy for generating time-varying convex feasible spaces that ensure kinematic feasibility and safety requirements. The trajectory planning problem is formulated as a finite-horizon optimal control problem and solved using a constrained iterative Linear Quadratic Regulator (iLQR) algorithm that jointly optimizes trajectory smoothness, control effort, and risk exposure while maintaining strict feasibility. Extensive simulations demonstrate that our method outperforms traditional approaches in terms of safety and efficiency, achieving collision-free trajectories with shorter lane-changing distances (28.59 m) and times (2.84 s) while maintaining smooth and comfortable acceleration patterns. In dense roundabout environments the planner further demonstrates robust adaptability, producing larger safety margins, lower jerk, and superior curvature smoothness compared with APF, MPC, and RRT based baselines. These results confirm that the integrated DRF with convex feasible space and constrained iLQR solver provides a balanced solution for safe, efficient, and comfortable trajectory generation in dynamic and interactive traffic scenarios.",
    "url": "https://arxiv.org/abs/2511.22829",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces a new trajectory planning method for autonomous lane changing that combines risk-aware planning with collision avoidance in a unified optimization framework. By utilizing dynamic risk fields and time-varying convex feasible spaces, the proposed method outperforms traditional approaches in terms of safety and efficiency, generating collision-free trajectories with shorter distances and times while maintaining smooth acceleration patterns. The results demonstrate the effectiveness of this approach in dynamic traffic scenarios, providing a balanced solution for safe, efficient, and comfortable trajectory generation."
  },
  {
    "title": "Agentic AI Framework for Individuals with Disabilities and Neurodivergence: A Multi-Agent System for Healthy Eating, Daily Routines, and Inclusive Well-Being",
    "abstract": "The paper presents a detailed Agentic Artificial Intelligence (AI) model that would enable people with disabilities and neurodivergence to lead healthier lives and have more regular days. The system will use a multi-layer structure; it will include an Application and Interface Layer, an Agents Layer, and a Data Source Layer to provide adaptive, transparent, and inclusive support. Fundamentally, a hybrid reasoning engine will synchronize four special-purpose agents, which include: a personalized-nutrition-based, called a Meal Planner Agent; an adaptive-scheduling-based, called a Reminder Agent; interactive assistance during grocery shopping and cooking, called a Food Guidance Agent; and a continuous-intake-and-physiological-tracking, called a Monitoring Agent. All the agents interact through a central communicative system called the Blackboard/Event Bus, which allows autonomous interaction and real-time feedback loops with multimedia user interfaces. Privacy-sensitive data sources, including electronic health records (EHRs), nutritional databases, wearable sensors, and smart kitchen Internet of Things, are also included in the framework and placed into a policy-controlled layer, which ensures data safety and compliance with consent. Collaborative care and clinician dashboards allow common supervision, and discussable artificial intelligence (XAI) modules give brief explanations of why a decision was made, making users responsible and reliant. The proposed agentic AI framework is an extension beyond traditional assistive systems since it incorporates inclusiveness, personalization, and accessibility at all levels. It displays the intersection of multi-agent reasoning, multi-modal interfaces, and human-centered design that will enable the development of autonomy, health, and digital equity among people with disabilities and neurodivergence.",
    "url": "https://arxiv.org/abs/2511.22737",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper introduces an Agentic AI framework designed to support individuals with disabilities and neurodivergence in leading healthier lives and maintaining regular routines. The framework includes four specialized agents, such as a Meal Planner Agent and a Monitoring Agent, that interact through a central communicative system for real-time feedback. The inclusion of privacy-sensitive data sources and discussable artificial intelligence modules makes this framework a comprehensive and inclusive tool for promoting autonomy, health, and digital equity among the target population."
  },
  {
    "title": "GazeTrack: High-Precision Eye Tracking Based on Regularization and Spatial Computing",
    "abstract": "Eye tracking has become increasingly important in virtual and augmented reality applications; however, the current gaze accuracy falls short of meeting the requirements for spatial computing. We designed a gaze collection framework and utilized high-precision equipment to gather the first precise benchmark dataset, GazeTrack, encompassing diverse ethnicities, ages, and visual acuity conditions for pupil localization and gaze tracking. We propose a novel shape error regularization method to constrain pupil ellipse fitting and train on open-source datasets, enhancing semantic segmentation and pupil position prediction accuracy. Additionally, we invent a novel coordinate transformation method similar to paper unfolding to accurately predict gaze vectors on the GazeTrack dataset. Finally, we built a gaze vector generation model that achieves reduced gaze angle error with lower computational complexity compared to other methods.",
    "url": "https://arxiv.org/abs/2511.22607",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research focuses on improving the accuracy of eye tracking for spatial computing applications by designing a high-precision gaze collection framework and utilizing a benchmark dataset called GazeTrack. The study introduces a shape error regularization method for pupil ellipse fitting and a novel coordinate transformation technique for predicting gaze vectors accurately. The proposed models show reduced gaze angle error and lower computational complexity compared to existing methods, making significant advancements in high-precision eye tracking technology."
  },
  {
    "title": "SoftNash: Entropy-Regularized Nash Games for Non-Fighting Virtual Fixtures",
    "abstract": "Virtual fixtures (VFs) improve precision in teleoperation but often ``fight'' the user, inflating mental workload and eroding the sense of agency. We propose Soft-Nash Virtual Fixtures, a game-theoretic shared-control policy that softens the classic two-player linear-quadratic (LQ) Nash solution by inflating the fixture's effort weight with a single, interpretable scalar parameter $\\tau$. This yields a continuous dial on controller assertiveness: $\\tau=0$ recovers a hard, performance-focused Nash / virtual fixture controller, while larger $\\tau$ reduce gains and pushback, yet preserve the equilibrium structure and continuity of closed-loop stability. We derive Soft-Nash from both a KL-regularized trust-region and a maximum-entropy viewpoint, obtaining a closed-form robot best response that shrinks authority and aligns the fixture with the operator's input as $\\tau$ grows. We implement Soft-Nash on a 6-DoF haptic device in 3D tracking task ($n=12$). Moderate softness ($\\tau\\approx 1-3$, especially $\\tau=2$) maintains tracking error statistically indistinguishable from a tuned classic VF while sharply reducing controller-user conflict, lowering NASA-TLX workload, and increasing Sense of Agency (SoAS). A composite BalancedScore that combines normalized accuracy and non-fighting behavior peaks near $\\tau=2-3$. These results show that a one-parameter Soft-Nash policy can preserve accuracy while improving comfort and perceived agency, providing a practical and interpretable pathway to personalized shared control in haptics and teleoperation.",
    "url": "https://arxiv.org/abs/2511.22087",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces Soft-Nash Virtual Fixtures, a game-theoretic shared-control policy that allows for a continuous adjustment of controller assertiveness. By tuning a single parameter, $\\tau$, the fixture's effort weight can be adjusted to reduce controller-user conflict and improve user comfort and sense of agency in teleoperation tasks. The results demonstrate that moderate softness in the controller (around $\\tau=1-3, especially $\\tau=2$) can maintain tracking accuracy while reducing mental workload and increasing perceived agency, offering a practical and interpretable approach to personalized shared control in haptics and teleoperation."
  },
  {
    "title": "MMA: A Momentum Mamba Architecture for Human Activity Recognition with Inertial Sensors",
    "abstract": "Human activity recognition (HAR) from inertial sensors is essential for ubiquitous computing, mobile health, and ambient intelligence. Conventional deep models such as Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and transformers have advanced HAR but remain limited by vanishing or exloding gradients, high computational cost, and difficulty in capturing long-range dependencies. Structured state-space models (SSMs) like Mamba address these challenges with linear complexity and effective temporal modeling, yet they are restricted to first-order dynamics without stable longterm memory mechanisms. We introduce Momentum Mamba, a momentum-augmented SSM that incorporates second-order dynamics to improve stability of information flow across time steps, robustness, and long-sequence modeling. Two extensions further expand its capacity: Complex Momentum Mamba for frequency-selective memory scaling. Experiments on multiple HAR benchmarks demonstrate consistent gains over vanilla Mamba and Transformer baselines in accuracy, robustness, and convergence speed. With only moderate increases in training cost, momentum-augmented SSMs offer a favorable accuracy-efficiency balance, establishing them as a scalable paradigm for HAR and a promising principal framework for broader sequence modeling applications.",
    "url": "https://arxiv.org/abs/2511.21550",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces Momentum Mamba, a momentum-augmented structured state-space model for human activity recognition using inertial sensors. This model incorporates second-order dynamics to improve stability, robustness, and long-sequence modeling, resulting in consistent gains in accuracy, robustness, and convergence speed compared to baseline models. The findings suggest that momentum-augmented SSMs offer a favorable accuracy-efficiency balance and could be a scalable paradigm for HAR and broader sequence modeling applications."
  },
  {
    "title": "Seeing Twice: How Side-by-Side T2I Comparison Changes Auditing Strategies",
    "abstract": "While generative AI systems have gained popularity in diverse applications, their potential to produce harmful outputs limits their trustworthiness and utility. A small but growing line of research has explored tools and processes to better engage non-AI expert users in auditing generative AI systems. In this work, we present the design and evaluation of MIRAGE, a web-based tool exploring a \"contrast-first\" workflow that allows users to pick up to four different text-to-image (T2I) models, view their images side-by-side, and provide feedback on model performance on a single screen. In our user study with fifteen participants, we used four predefined models for consistency, with only a single model initially being shown. We found that most participants shifted from analyzing individual images to general model output patterns once the side-by-side step appeared with all four models; several participants coined persistent \"model personalities\" (e.g., cartoonish, saturated) that helped them form expectations about how each model would behave on future prompts. Bilingual participants also surfaced a language-fidelity gap, as English prompts produced more accurate images than Portuguese or Chinese, an issue often overlooked when dealing with a single model. These findings suggest that simple comparative interfaces can accelerate bias discovery and reshape how people think about generative models.",
    "url": "https://arxiv.org/abs/2511.21547",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of a web-based tool called MIRAGE which allows users to compare different text-to-image models side-by-side and provide feedback on model performance. The study found that users shifted from analyzing individual images to general model output patterns when using the tool, and identified \"model personalities\" that helped them form expectations about each model. The findings suggest that comparative interfaces can accelerate bias discovery and change how people perceive generative models."
  },
  {
    "title": "TALES: A Taxonomy and Analysis of Cultural Representations in LLM-generated Stories",
    "abstract": "Millions of users across the globe turn to AI chatbots for their creative needs, inviting widespread interest in understanding how such chatbots represent diverse cultures. At the same time, evaluating cultural representations in open-ended tasks remains challenging and underexplored. In this work, we present TALES, an evaluation of cultural misrepresentations in LLM-generated stories for diverse Indian cultural identities. First, we develop TALES-Tax, a taxonomy of cultural misrepresentations by collating insights from participants with lived experiences in India through focus groups (N=9) and individual surveys (N=15). Using TALES-Tax, we evaluate 6 models through a large-scale annotation study spanning 2,925 annotations from 108 annotators with lived cultural experience from across 71 regions in India and 14 languages. Concerningly, we find that 88\\% of the generated stories contain one or more cultural inaccuracies, and such errors are more prevalent in mid- and low-resourced languages and stories based in peri-urban regions in India. Lastly, we transform the annotations into TALES-QA, a standalone question bank to evaluate the cultural knowledge of foundational models. Through this evaluation, we surprisingly discover that models often possess the requisite cultural knowledge despite generating stories rife with cultural misrepresentations.",
    "url": "https://arxiv.org/abs/2511.21322",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research study, TALES, focuses on evaluating cultural representations in AI-generated stories for diverse Indian cultural identities. The study developed a taxonomy of cultural misrepresentations and found that 88% of the generated stories contained inaccuracies, with more errors in mid- and low-resourced languages and stories based in peri-urban regions in India. Surprisingly, despite the presence of cultural inaccuracies, the foundational models often possessed the necessary cultural knowledge, highlighting the complexity of evaluating cultural representations in AI-generated content."
  },
  {
    "title": "Generative AI Compensates for Age-Related Cognitive Decline in Decision Making: Preference-Aligned Recommendations Reduce Choice Difficulty",
    "abstract": "Due to age-related declines in memory, processing speed, working memory, and executive functions, older adults experience difficulties in decision making when situations require novel choices, probabilistic judgments, rapid responses, or extensive information search. This study examined whether using generative AI during decision making enhances choice satisfaction and reduces choice difficulty among older adults. A total of 130 participants (younger: 56; older: 74) completed a music-selection task under AI-use and AI-nonuse conditions across two contexts: previously experienced (road trip) and not previously experienced (space travel). In the AI-nonuse condition, participants generated candidate options from memory; in the AI-use condition, GPT-4o presented options tailored to individual preferences. To assess cognitive function, we also administered the Wechsler Adult Intelligence Scale-Fourth Edition. Results revealed that in the AI-nonuse condition, older adults with lower cognitive function reported higher choice difficulty and lower choice satisfaction. Under the AI-use condition, choice satisfaction did not change significantly, but perceived choice difficulty decreased significantly in both age groups. Moreover, AI use attenuated the associations observed among older adults between lower cognitive function and both greater difficulty and lower satisfaction. These findings indicate that preference-aligned option recommendations generated by AI can compensate for age-related constraints on information search, thereby reducing perceived choice difficulty without diminishing satisfaction.",
    "url": "https://arxiv.org/abs/2511.21164",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study found that older adults with age-related cognitive decline experienced less choice difficulty and higher satisfaction when using generative AI during decision making. The AI provided tailored options based on individual preferences, reducing the need for extensive information search. This suggests that AI can help compensate for cognitive decline in older adults, making decision making easier and more satisfying."
  },
  {
    "title": "QuadStretcher: A Forearm-Worn Skin Stretch Display for Bare-Hand Interaction in AR/VR",
    "abstract": "The paradigm of bare-hand interaction has become increasingly prevalent in Augmented Reality (AR) and Virtual Reality (VR) environments, propelled by advancements in hand tracking technology. However, a significant challenge arises in delivering haptic feedback to users' hands, due to the necessity for the hands to remain bare. In response to this challenge, recent research has proposed an indirect solution of providing haptic feedback to the forearm. In this work, we present QuadStretcher, a skin stretch display featuring four independently controlled stretching units surrounding the forearm. While achieving rich haptic expression, our device also eliminates the need for a grounding base on the forearm by using a pair of counteracting tactors, thereby reducing bulkiness. To assess the effectiveness of QuadStretcher in facilitating immersive bare-hand experiences, we conducted a comparative user evaluation (n = 20) with a baseline solution, Squeezer. The results confirmed that QuadStretcher outperformed Squeezer in terms of expressing force direction and heightening the sense of realism, particularly in 3-DoF VR interactions such as pulling a rubber band, hooking a fishing rod, and swinging a tennis racket. We further discuss the design insights gained from qualitative user interviews, presenting key takeaways for future forearm-haptic systems aimed at advancing AR/VR bare-hand experiences.",
    "url": "https://arxiv.org/abs/2511.21157",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research paper introduces QuadStretcher, a forearm-worn skin stretch display designed to provide haptic feedback for bare-hand interaction in AR/VR environments. The device features four independently controlled stretching units and eliminates the need for a grounding base, offering a more immersive and realistic experience compared to a baseline solution. User evaluations showed that QuadStretcher outperformed the competitor in expressing force direction and enhancing realism, particularly in 3-DoF VR interactions, highlighting the potential for advancing AR/VR bare-hand experiences."
  },
  {
    "title": "STAR: Smartphone-analogous Typing in Augmented Reality",
    "abstract": "While text entry is an essential and frequent task in Augmented Reality (AR) applications, devising an efficient and easy-to-use text entry method for AR remains an open challenge. This research presents STAR, a smartphone-analogous AR text entry technique that leverages a user's familiarity with smartphone two-thumb typing. With STAR, a user performs thumb typing on a virtual QWERTY keyboard that is overlain on the skin of their hands. During an evaluation study of STAR, participants achieved a mean typing speed of 21.9 WPM (i.e., 56% of their smartphone typing speed), and a mean error rate of 0.3% after 30 minutes of practice. We further analyze the major factors implicated in the performance gap between STAR and smartphone typing, and discuss ways this gap could be narrowed.",
    "url": "https://arxiv.org/abs/2511.21143",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces STAR, a text entry method for Augmented Reality that mimics smartphone two-thumb typing. Participants in an evaluation study achieved a typing speed of 21.9 words per minute, with a low error rate after 30 minutes of practice. The study highlights the potential for STAR to bridge the performance gap between AR text entry and smartphone typing, offering a more efficient and user-friendly method for interacting with AR applications."
  },
  {
    "title": "Lattice Menu: A Low-Error Gaze-Based Marking Menu Utilizing Target-Assisted Gaze Gestures on a Lattice of Visual Anchors",
    "abstract": "We present Lattice Menu, a gaze-based marking menu utilizing a lattice of visual anchors that helps perform accurate gaze pointing for menu item selection. Users who know the location of the desired item can leverage target-assisted gaze gestures for multilevel item selection by looking at visual anchors over the gaze trajectories. Our evaluation showed that Lattice Menu exhibits a considerably low error rate (~1%) and a quick menu selection time (1.3-1.6 s) for expert usage across various menu structures (4 x 4 x 4 and 6 x 6 x 6) and sizes (8, 10 and 12). In comparison with a traditional gaze-based marking menu that does not utilize visual targets, Lattice Menu showed remarkably (~5 times) fewer menu selection errors for expert usage. In a post-interview, all 12 subjects preferred Lattice Menu, and most subjects (8 out of 12) commented that the provisioning of visual targets facilitated more stable menu selections with reduced eye fatigue.",
    "url": "https://arxiv.org/abs/2511.21131",
    "journal": "arXiv cs.HC",
    "ai_summary": "The study introduces Lattice Menu, a gaze-based marking menu that uses visual anchors to improve accuracy and speed in menu item selection. Results showed a low error rate and quick selection time for expert users, with significantly fewer errors compared to traditional gaze-based menus. Participants preferred Lattice Menu due to its use of visual targets, which led to more stable selections and reduced eye fatigue."
  },
  {
    "title": "Human-Centered Artificial Social Intelligence (HC-ASI)",
    "abstract": "As artificial intelligence systems become increasingly integrated into human social contexts, Artificial Social Intelligence (ASI) has emerged as a critical capability that enables AI to perceive, understand, and engage meaningfully in complex human social interactions. This chapter introduces a comprehensive framework for Human-Centered Artificial Social Intelligence (HC-ASI), built upon the Technology-Human Factors-Ethics (THE) Triangle, which systematically addresses both technical foundations and human-centered design principles necessary for developing socially intelligent AI systems. This chapter provides a comprehensive overview of current ASI research. This chapter begins by establishing the theoretical foundations of ASI, tracing its evolution from classical psychological theories of human social intelligence to contemporary computational models, then examines the mechanisms underlying human-AI social interaction with particular emphasis on establishing shared social understanding and appropriate role positioning. The chapter further explores ASI's practical implications for individuals and groups through comprehensive evaluation frameworks that combine technical benchmarks with human-centered experiential assessments, demonstrating real-world applications through detailed case studies spanning healthcare, companionship, education, and customer service domains. Building on the overview and the framework of HC -ASI, this chapter articulates core HC-ASI design principles and translates them into actionable methodologies and implementation guidelines that provide practical guidance for researchers and practitioners. This chapter concludes with a critical discussion of current challenges and promising directions for developing comprehensive HC-ASI ecosystems.",
    "url": "https://arxiv.org/abs/2511.21044",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research focuses on Human-Centered Artificial Social Intelligence (HC-ASI) as a critical capability for AI systems to engage in complex human social interactions. The framework presented in the chapter addresses technical foundations and human-centered design principles necessary for developing socially intelligent AI systems. The research provides an overview of current ASI research, explores practical implications through case studies in various domains, and offers design principles and implementation guidelines for researchers and practitioners to develop comprehensive HC-ASI ecosystems."
  },
  {
    "title": "LOOM: Personalized Learning Informed by Daily LLM Conversations Toward Long-Term Mastery via a Dynamic Learner Memory Graph",
    "abstract": "Foundation models are increasingly used to personalize learning, yet many systems still assume fixed curricula or coarse progress signals, limiting alignment with learners' day-to-day needs. At the other extreme, lightweight incidental systems offer flexible, in-the-moment content but rarely guide learners toward mastery. Prior work privileges either continuity (maintaining a plan across sessions) or initiative (reacting to the moment), not both, leaving learners to navigate the trade-off between recency and trajectory-immediate relevance versus cumulative, goal-aligned progress. We present LOOM, an agentic pipeline that infers evolving learner needs from recent LLM conversations and a dynamic learner memory graph, then assembles coherent learning materials personalized to the learner's current needs, priorities, and understanding. These materials link adjacent concepts and surface gaps as tightly scoped modules that cumulatively advance broader goals, providing guidance and sustained progress while remaining responsive to new interests. We describe LOOM's end-to-end architecture and working prototype, including conversation summarization, topic planning, course generation, and graph-based progress tracking. In a formative study with ten participants, users reported that LOOM's generated lessons felt relevant to their recent activities and helped them recognize knowledge gaps, though they also highlighted needs for greater consistency and control. We conclude with design implications for more robust, mixed-initiative learning pipelines that integrate structured learner modelling with everyday LLM interactions.",
    "url": "https://arxiv.org/abs/2511.21037",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces LOOM, a personalized learning system that combines continuity and initiative to guide learners towards mastery by inferring evolving learner needs from daily conversations and a dynamic memory graph. LOOM generates coherent learning materials tailored to the learner's current needs and understanding, linking concepts and identifying gaps to facilitate sustained progress while remaining responsive to new interests. A formative study with participants showed that LOOM's lessons were relevant and helped users recognize knowledge gaps, indicating the potential for more robust, mixed-initiative learning pipelines that integrate structured learner modeling with everyday interactions."
  },
  {
    "title": "PileUp: A Tufting Approach to Soft, Tactile, and Volumetric E-Textile Interfaces",
    "abstract": "We present PileUp, a tufted pile e-textile sensing approach that offers unique affordances through the tactile expressiveness and richness of its continuous, threaded-volume construction. By integrating conductive yarns in looped or cut pile forms, PileUp transforms soft 3-dimensional textiles into multimodal sensors capable of detecting mechanical deformations such as pressure, bending, and strain, as well as environmental conditions like moisture. We propose a design space that outlines the relationships between texture, form factor, and sensing affordances of tufted textiles. We characterize electrical responses under compression, bending, and strain, reporting sensor behaviors. To demonstrate versatility, we present three application scenarios in which PileUp sensors are seamlessly integrated into soft fabrics: a meditation rug with multi-zone sensing, a fleece sleeve that detects arm motion, and a moisture-sensing wall art. Our results establish tufting as an accessible yet expressive fabrication method for creating integrated sensing textiles, distinguishing our work from traditional flat textile sensors.",
    "url": "https://arxiv.org/abs/2511.21000",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces PileUp, a tufted pile e-textile sensing approach that transforms soft textiles into multimodal sensors capable of detecting mechanical deformations and environmental conditions. The study outlines the design space of tufted textiles and characterizes their electrical responses under various stimuli. The findings demonstrate the versatility and potential of tufting as a fabrication method for integrated sensing textiles, offering unique tactile expressiveness and richness compared to traditional flat textile sensors."
  },
  {
    "title": "Beyond the Legal Lens: A Sociotechnical Taxonomy of Lived Privacy Incidents and Harms",
    "abstract": "To understand how privacy incidents lead to harms, HCI researchers have historically leveraged legal frameworks. However, these frameworks expect acute, tangible harms and thus may not cover the full range of human experience relevant to modern-day digital privacy. To address this gap, our research builds upon these existing frameworks to develop a more comprehensive representation of people's lived experiences with privacy harms. We analyzed 369 privacy incidents reported by individuals from the general public. We found a broader range of privacy incidents and harms than accounted for in existing legal frameworks. The majority of reported privacy harms were not based on tangible harm, but on fear and loss of psychological safety. We also characterize the actors, motives, and information associated with various incidents. This work contributes a new framework for understanding digital privacy harms that can be utilized both in research and practice.",
    "url": "https://arxiv.org/abs/2511.20791",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores how privacy incidents can lead to harms beyond what is traditionally considered in legal frameworks. By analyzing 369 reported incidents, the study found a wider range of privacy harms, with many being related to fear and loss of psychological safety rather than tangible harm. The findings contribute to a new framework for understanding digital privacy harms that can be applied in both research and practical contexts."
  },
  {
    "title": "Transforming Higher Education with AI-Powered Video Lectures",
    "abstract": "The integration of artificial intelligence (AI) into video lecture production has the potential to transform higher education by streamlining content creation and enhancing accessibility. This paper investigates a semi automated workflow that combines Google Gemini for script generation, Amazon Polly for voice synthesis, and Microsoft PowerPoint for video assembly. Unlike fully automated text to video platforms, this hybrid approach preserves pedagogical intent while ensuring script to slide synchronization, narrative coherence, and customization. Case studies demonstrate the effectiveness of Gemini in generating accurate and context-sensitive scripts for visually rich academic presentations, while Polly provides natural-sounding narration with controllable pacing. A two course pilot study was conducted to evaluate AI generated instructional videos (AIIV) against human instructional videos (HIV). Both qualitative and quantitative results indicate that AIIVs are comparable to HIVs in terms of learning outcomes, with students reporting high levels of clarity, coherence, and usability. However, limitations remain, particularly regarding audio quality and the absence of human-like avatars. The findings suggest that AI assisted video production can reduce instructor workload, improve scalability, and deliver effective learning resources, while future improvements in synthetic voices and avatars may further enhance learner engagement.",
    "url": "https://arxiv.org/abs/2511.20660",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the use of AI in producing video lectures for higher education, combining Google Gemini for script generation, Amazon Polly for voice synthesis, and Microsoft PowerPoint for video assembly. The study found that AI-generated instructional videos (AIIV) were comparable to human instructional videos (HIV) in terms of learning outcomes, with students reporting high levels of clarity and usability. While limitations exist, such as audio quality and the absence of human-like avatars, the findings suggest that AI-assisted video production can reduce instructor workload, improve scalability, and deliver effective learning resources."
  },
  {
    "title": "Iteration and Co-design of a Physical Web Application for Outdoor Activities with Older Adults",
    "abstract": "Existing research and physical activity guidelines highlight the benefits of outdoor physical activities for ageing populations. There is potential for technology to facilitate outdoor activity through Physical Web infrastructure. We proposed that embedding Physical Web applications that are engaging and interactive in public open spaces as part of interactive wellness parks can encourage older adults to participate in physical activities outdoors and motivate rehabilitation. We have created an initial design prototype based on design requirements generated from a qualitative field study with 24 older adults to explore their perceptions, experiences, and routines of outdoor physical activities. In this paper, we present an initial prototype and findings from a co-design session with 12 older adults, eliciting their feedback on the design and their ideas for future design iterations.",
    "url": "https://arxiv.org/abs/2511.20659",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research focuses on the co-design and iteration of a Physical Web application for outdoor activities with older adults. The study highlights the potential for technology to facilitate outdoor physical activities and motivate rehabilitation in ageing populations. The initial design prototype was created based on feedback from older adults, emphasizing the importance of engaging and interactive features in public open spaces to encourage participation in outdoor activities."
  },
  {
    "title": "Intelligent Agents with Emotional Intelligence: Current Trends, Challenges, and Future Prospects",
    "abstract": "The development of agents with emotional intelligence is becoming increasingly vital due to their significant role in human-computer interaction and the growing integration of computer systems across various sectors of society. Affective computing aims to design intelligent systems that can recognize, evoke, and express human emotions, thereby emulating human emotional intelligence. While previous reviews have focused on specific aspects of this field, there has been limited comprehensive research that encompasses emotion understanding, elicitation, and expression, along with the related challenges. This survey addresses this gap by providing a holistic overview of core components of artificial emotion intelligence. It covers emotion understanding through multimodal data processing, as well as affective cognition, which includes cognitive appraisal, emotion mapping, and adaptive modulation in decision-making, learning, and reasoning. Additionally, it addresses the synthesis of emotional expression across text, speech, and facial modalities to enhance human-agent interaction. This paper identifies and analyzes the key challenges and issues encountered in the development of affective systems, covering state-of-the-art methodologies designed to address them. Finally, we highlight promising future directions, with particular emphasis on the potential of generative technologies to advance affective computing.",
    "url": "https://arxiv.org/abs/2511.20657",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research paper discusses the importance of developing intelligent agents with emotional intelligence for human-computer interaction and society as a whole. It provides a comprehensive overview of artificial emotion intelligence, covering emotion understanding, elicitation, and expression through various modalities. The paper also highlights key challenges in developing affective systems and suggests future directions in the field, including the potential of generative technologies to advance affective computing."
  },
  {
    "title": "Context-Aware Visual Prompting: Automating Geospatial Web Dashboards with Large Language Models and Agent Self-Validation for Decision Support",
    "abstract": "The development of web-based geospatial dashboards for risk analysis and decision support is often challenged by the difficulty in visualization of big, multi-dimensional environmental data, implementation complexity, and limited automation. We introduce a generative AI framework that harnesses Large Language Models (LLMs) to automate the creation of interactive geospatial dashboards from user-defined inputs including UI wireframes, requirements, and data sources. By incorporating a structured knowledge graph, the workflow embeds domain knowledge into the generation process and enable accurate and context-aware code completions. A key component of our approach is the Context-Aware Visual Prompting (CAVP) mechanism, which extracts encodes and interface semantics from visual layouts to guide LLM driven generation of codes. The new framework also integrates a self-validation mechanism that uses an agent-based LLM and Pass@k evaluation alongside semantic metrics to assure output reliability. Dashboard snippets are paired with data visualization codebases and ontological representations, enabling a pipeline that produces scalable React-based completions using the MVVM architectural pattern. Our results demonstrate improved performance over baseline approaches and expanded functionality over third party platforms, while incorporating multi-page, fully functional interfaces. We successfully developed a framework to implement LLMs, demonstrated the pipeline for automated code generation, deployment, and performed chain-of-thought AI agents in self-validation. This integrative approach is guided by structured knowledge and visual prompts, providing an innovative geospatial solution in enhancing risk analysis and decision making.",
    "url": "https://arxiv.org/abs/2511.20656",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research introduces a generative AI framework that uses Large Language Models (LLMs) to automate the creation of interactive geospatial dashboards for risk analysis and decision support. The framework incorporates a structured knowledge graph and Context-Aware Visual Prompting (CAVP) mechanism to guide the generation of codes and ensure output reliability. The results show improved performance over baseline approaches and expanded functionality, demonstrating the potential of this approach in enhancing risk analysis and decision-making processes."
  },
  {
    "title": "Exploropleth: exploratory analysis of data binning methods in choropleth maps",
    "abstract": "When creating choropleth maps, mapmakers often bin (i.e., group, classify) quantitative data values into groups to help show that certain areas fall within a similar range of values. For instance, a mapmaker may divide counties into groups of high, middle, and low life expectancy (measured in years). It is well known that different binning methods (e.g., natural breaks, quantile) yield different groupings, meaning the same data can be presented differently depending on how it is divided into bins. To help guide a wide variety of users, we present a new, open source, web-based, geospatial visualization tool, Exploropleth, that lets users interact with a catalog of established data binning methods, and subsequently compare, customize, and export custom maps. This tool advances the state of the art by providing multiple binning methods in one view and supporting administrative unit reclassification on-the-fly. We interviewed 16 cartographers and geographic information systems (GIS) experts from 13 government organizations, non-government organizations (NGOs), and federal agencies who identified opportunities to integrate Exploropleth into their existing mapmaking workflow, and found that the tool has potential to educate students as well as mapmakers with varying levels of experience. Exploropleth is open-source and publicly available at this https URL.",
    "url": "https://arxiv.org/abs/2511.20655",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research explores the use of different data binning methods in choropleth maps and presents a new web-based tool called Exploropleth that allows users to interact with and compare various binning methods. The tool was found to be useful by cartographers and GIS experts from various organizations, with potential to improve mapmaking workflows and educate users with different levels of experience. Exploropleth is open-source and available for public use."
  },
  {
    "title": "CodeVaani: A Multilingual, Voice-Based Code Learning Assistant",
    "abstract": "Programming education often assumes English proficiency and text-based interaction, creating barriers for students from multilingual regions such as India. We present CodeVaani, a multilingual speech-driven assistant for understanding code, built into Bodhitree [1], a Learning Management System developed at IIT Bombay. It is a voice-enabled assistant that helps learners explore programming concepts in their native languages. The system integrates Indic ASR, a codeaware transcription refinement module, and a code model for generating relevant answers. Responses are provided in both text and audio for natural interaction. In a study with 28 beginner programmers, CodeVaani achieved 75% response accuracy, with over 80% of participants rating the experience positively. Compared to classroom assistance, our framework offers ondemand availability, scalability to support many learners, and multilingual support that lowers the entry barrier for students with limited English proficiency. The demo will illustrate these capabilities and highlight how voice-based AI systems can make programming education more inclusive. Supplementary artifacts and demo video are also made available.",
    "url": "https://arxiv.org/abs/2511.20654",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces CodeVaani, a multilingual voice-based assistant for learning code, designed to address the language barriers faced by students in multilingual regions like India. CodeVaani achieved 75% response accuracy in a study with beginner programmers, with over 80% of participants rating the experience positively. The system offers on-demand availability, scalability, and multilingual support, making programming education more inclusive for students with limited English proficiency."
  },
  {
    "title": "Domain-Grounded Evaluation of LLMs in International Student Knowledge",
    "abstract": "Large language models (LLMs) are increasingly used to answer high-stakes study-abroad questions about admissions, visas, scholarships, and eligibility. Yet it remains unclear how reliably they advise students, and how often otherwise helpful answers drift into unsupported claims (``hallucinations'').\nThis work provides a clear, domain-grounded overview of how current LLMs behave in this setting. Using realistic questions set drawn from ApplyBoard's advising workflows -- an EdTech platform that supports students from discovery to enrolment -- we evaluate two essentials side by side: accuracy (is the information correct and complete?) and hallucination (does the model add content not supported by the question or domain evidence). These questions are categorized by domain scope which can be a single-domain or multi-domain -- when it must integrate evidence across areas such as admissions, visas, and scholarships.\nTo reflect real advising quality, we grade answers with a simple rubric which is correct, partial, or wrong. The rubric is domain-coverage-aware: an answer can be partial if it addresses only a subset of the required domains, and it can be over-scoped if it introduces extra, unnecessary domains; both patterns are captured in our scoring as under-coverage or reduced relevance/hallucination.\nWe also report measures of faithfulness and answer relevance, alongside an aggregate hallucination score, to capture relevance and usefulness. All models are tested with the same questions for a fair, head-to-head comparison.\nOur goals are to: (1) give a clear picture of which models are most dependable for study-abroad advising, (2) surface common failure modes -- where answers are incomplete, off-topic, or unsupported, and (3) offer a practical, reusable protocol for auditing LLMs before deployment in education and advising contexts.",
    "url": "https://arxiv.org/abs/2511.20653",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research evaluates the reliability of large language models (LLMs) in providing study-abroad advice to international students, focusing on accuracy and the occurrence of unsupported claims (hallucinations). The study uses realistic questions from an EdTech platform to assess the models' performance in single-domain and multi-domain scenarios, grading answers based on correctness and relevance. The findings aim to identify the most dependable LLMs for advising, highlight common failure modes, and provide a protocol for auditing LLMs before implementation in educational settings."
  },
  {
    "title": "When LLMs Can't Help: Real-World Evaluation of LLMs in Nutrition",
    "abstract": "The increasing trust in large language models (LLMs), especially in the form of chatbots, is often undermined by the lack of their extrinsic evaluation. This holds particularly true in nutrition, where randomised controlled trials (RCTs) are the gold standard, and experts demand them for evidence-based deployment. LLMs have shown promising results in this field, but these are limited to intrinsic setups. We address this gap by running the first RCT involving LLMs for nutrition. We augment a rule-based chatbot with two LLM-based features: (1) message rephrasing for conversational variety and engagement, and (2) nutritional counselling through a fine-tuned model. In our seven-week RCT (n=81), we compare chatbot variants with and without LLM integration. We measure effects on dietary outcome, emotional well-being, and engagement. Despite our LLM-based features performing well in intrinsic evaluation, we find that they did not yield consistent benefits in real-world deployment. These results highlight critical gaps between intrinsic evaluations and real-world impact, emphasising the need for interdisciplinary, human-centred approaches.\\footnote{We provide all of our code and results at: \\\\ \\href{this https URL}{this https URL}}",
    "url": "https://arxiv.org/abs/2511.20652",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research evaluates the effectiveness of large language models (LLMs) in nutrition through a randomized controlled trial (RCT) involving a rule-based chatbot augmented with LLM-based features. Despite promising results in intrinsic evaluations, the LLM-based features did not consistently benefit dietary outcomes, emotional well-being, and engagement in real-world deployment. This study underscores the importance of interdisciplinary, human-centered approaches to bridge the gap between intrinsic evaluations and real-world impact in the use of LLMs in nutrition."
  },
  {
    "title": "From Prediction to Foresight: The Role of AI in Designing Responsible Futures",
    "abstract": "In an era marked by rapid technological advancements and complex global challenges, responsible foresight has emerged as an essential framework for policymakers aiming to navigate future uncertainties and shape the future. Responsible foresight entails the ethical anticipation of emerging opportunities and risks, with a focus on fostering proactive, sustainable, and accountable future design. This paper coins the term \"responsible computational foresight\", examining the role of human-centric artificial intelligence and computational modeling in advancing responsible foresight, establishing a set of foundational principles for this new field and presenting a suite of AI-driven foresight tools currently shaping it. AI, particularly in conjunction with simulations and scenario analysis, enhances policymakers' ability to address uncertainty, evaluate risks, and devise strategies geared toward sustainable, resilient futures. However, responsible foresight extends beyond mere technical forecasting; it demands a nuanced understanding of the interdependencies within social, environmental, economic and political systems, alongside a commitment to ethical, long-term decision-making that supports human intelligence. We argue that AI will play a role as a supportive tool in responsible, human-centered foresight, complementing rather than substituting policymaker judgment to enable the proactive shaping of resilient and ethically sound futures. This paper advocates for the thoughtful integration of AI into foresight practices to empower policymakers and communities as they confront the grand challenges of the 21st century.",
    "url": "https://arxiv.org/abs/2511.21570",
    "journal": "arXiv cs.HC",
    "ai_summary": "This paper discusses the concept of responsible foresight in navigating future uncertainties and shaping sustainable futures. It introduces the term \"responsible computational foresight\" and highlights the role of AI and computational modeling in enhancing policymakers' ability to address uncertainty and devise strategies for sustainable futures. The paper emphasizes the importance of ethical decision-making and human intelligence in conjunction with AI tools to support proactive and resilient future design."
  },
  {
    "title": "Self-Transparency Failures in Expert-Persona LLMs: A Large-Scale Behavioral Audit",
    "abstract": "If a language model cannot reliably disclose its AI identity in expert contexts, users cannot trust its competence boundaries. This study examines self-transparency in models assigned professional personas within high-stakes domains where false expertise risks user harm. Using a common-garden design, sixteen open-weight models (4B--671B parameters) were audited across 19,200 trials. Models exhibited sharp domain-specific inconsistency: a Financial Advisor persona elicited 30.8% disclosure initially, while a Neurosurgeon persona elicited only 3.5%. This creates preconditions for a \"Reverse Gell-Mann Amnesia\" effect, where transparency in some domains leads users to overgeneralize trust to contexts where disclosure fails. Disclosure ranged from 2.8% to 73.6%, with a 14B model reaching 61.4% while a 70B produced just 4.1%. Model identity predicted behavior better than parameter count ($\\Delta R_{adj}^{2} = 0.359$ vs 0.018). Reasoning optimization actively suppressed self-transparency in some models, with reasoning variants showing up to 48.4% lower disclosure than base counterparts. Bayesian validation with Rogan--Gladen correction confirmed robustness to measurement error ($\\kappa = 0.908$). These findings demonstrate transparency reflects training factors rather than scale. Organizations cannot assume safety properties transfer to deployment contexts, requiring deliberate behavior design and empirical verification.",
    "url": "https://arxiv.org/abs/2511.21569",
    "journal": "arXiv cs.HC",
    "ai_summary": "This study explores the issue of self-transparency in language models assigned professional personas, finding that models exhibit domain-specific inconsistency in disclosing their AI identity. The research highlights the importance of transparency in high-stakes domains to prevent user harm and emphasizes the need for organizations to design models with deliberate behavior and verify their transparency through empirical testing. Model identity was found to be a better predictor of behavior than parameter count, indicating that transparency is influenced more by training factors than scale."
  },
  {
    "title": "Prune4Web: DOM Tree Pruning Programming for Web Agent",
    "abstract": "Web automation employs intelligent agents to execute high-level tasks by mimicking human interactions with web interfaces. Despite the capabilities of recent Large Language Model (LLM)-based web agents, navigating complex, real-world webpages efficiently remains a significant hurdle due to the prohibitively large size of Document Object Model (DOM) structures, often ranging from 10,000 to 100,000 tokens. Existing strategies typically rely on crude DOM truncation -- risking the loss of critical information -- or employ inefficient heuristics and separate ranking models, failing to achieve an optimal balance between precision and scalability. To address these challenges, we introduce Prune4Web, a novel paradigm that shifts DOM processing from resource-intensive LLM reading to efficient programmatic pruning. Central to our approach is DOM Tree Pruning Programming, where an LLM generates executable Python scoring scripts to dynamically filter DOM elements based on semantic cues from decomposed sub-tasks. This mechanism eliminates the need for LLMs to ingest raw, massive DOMs, instead delegating traversal and scoring to lightweight, interpretable programs. This methodology achieves a 25x to 50x reduction in candidate elements for grounding, thereby facilitating precise action localization while mitigating attention dilution. Furthermore, we propose a specialized data annotation pipeline and a two-turn dialogue training strategy that jointly optimizes the Planner, Programmatic Filter, and Grounder within a unified framework. Extensive experiments demonstrate state-of-the-art performance. Notably, on our low-level grounding task, Prune4Web dramatically improves accuracy from 46.8% to 88.28%, underscoring its efficacy in real-world web automation.",
    "url": "https://arxiv.org/abs/2511.21398",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces Prune4Web, a novel approach for efficiently navigating complex webpages by using DOM Tree Pruning Programming to filter DOM elements based on semantic cues. This method reduces the number of candidate elements by 25x to 50x, improving action localization accuracy and mitigating attention dilution. Extensive experiments show that Prune4Web significantly enhances accuracy in real-world web automation tasks, highlighting its effectiveness in improving performance compared to existing strategies."
  },
  {
    "title": "Bug Detective and Quality Coach: Developers' Mental Models of AI-Assisted IDE Tools",
    "abstract": "AI-assisted tools support developers in performing cognitively demanding tasks such as bug detection and code readability assessment. Despite the advancements in the technical characteristics of these tools, little is known about how developers mentally model them and how mismatches affect trust, control, and adoption. We conducted six co-design workshops with 58 developers to elicit their mental models about AI-assisted bug detection and readability features. It emerged that developers conceive bug detection tools as \\textit{bug detectives}, which warn users only in case of critical issues, guaranteeing transparency, actionable feedback, and confidence cues. Readability assessment tools, on the other hand, are envisioned as \\textit{quality coaches}, which provide contextual, personalized, and progressive guidance. Trust, in both tasks, depends on the clarity of explanations, timing, and user control. A set of design principles for Human-Centered AI in IDEs has been distilled, aiming to balance disruption with support, conciseness with depth, and automation with human agency.",
    "url": "https://arxiv.org/abs/2511.21197",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research explores developers' mental models of AI-assisted bug detection and code readability tools, finding that developers view bug detection tools as \"bug detectives\" providing transparent, actionable feedback, while readability assessment tools are seen as \"quality coaches\" offering personalized guidance. Trust in these tools depends on clear explanations, timing, and user control. The study suggests design principles for Human-Centered AI in IDEs to balance disruption with support, conciseness with depth, and automation with human agency."
  },
  {
    "title": "NOIR 2.0: Neural Signal Operated Intelligent Robots for Everyday Activities",
    "abstract": "Neural Signal Operated Intelligent Robots (NOIR) system is a versatile brain-robot interface that allows humans to control robots for daily tasks using their brain signals. This interface utilizes electroencephalography (EEG) to translate human intentions regarding specific objects and desired actions directly into commands that robots can execute. We present NOIR 2.0, an enhanced version of NOIR. NOIR 2.0 includes faster and more accurate brain decoding algorithms, which reduce task completion time by 46%. NOIR 2.0 uses few-shot robot learning algorithms to adapt to individual users and predict their intentions. The new learning algorithms leverage foundation models for more sample-efficient learning and adaptation (15 demos vs. a single demo), significantly reducing overall human time by 65%.",
    "url": "https://arxiv.org/abs/2511.20848",
    "journal": "arXiv cs.HC",
    "ai_summary": "The NOIR 2.0 system is a brain-robot interface that allows users to control robots for daily tasks using EEG signals. The enhanced version, NOIR 2.0, includes faster and more accurate brain decoding algorithms, reducing task completion time by 46% and utilizing few-shot robot learning algorithms to adapt to individual users and predict their intentions, significantly reducing overall human time by 65%. This research showcases the potential of brain-robot interfaces in improving efficiency and ease of use in everyday activities."
  },
  {
    "title": "Symbiotic Brain-Machine Drawing via Visual Brain-Computer Interfaces",
    "abstract": "Brain-computer interfaces (BCIs) are evolving from research prototypes into clinical, assistive, and performance enhancement technologies. Despite the rapid rise and promise of implantable technologies, there is a need for better and more capable wearable and non-invasive approaches whilst also minimising hardware requirements. We present a non-invasive BCI for mind-drawing that iteratively infers a subject's internal visual intent by adaptively presenting visual stimuli (probes) on a screen encoded at different flicker-frequencies and analyses the steady-state visual evoked potentials (SSVEPs). A Gabor-inspired or machine-learned policies dynamically update the spatial placement of the visual probes on the screen to explore the image space and reconstruct simple imagined shapes within approximately two minutes or less using just single-channel EEG data. Additionally, by leveraging stable diffusion models, reconstructed mental images can be transformed into realistic and detailed visual representations. Whilst we expect that similar results might be achievable with e.g. eye-tracking techniques, our work shows that symbiotic human-AI interaction can significantly increase BCI bit-rates by more than a factor 5x, providing a platform for future development of AI-augmented BCI.",
    "url": "https://arxiv.org/abs/2511.20835",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research presents a non-invasive brain-computer interface (BCI) for mind-drawing that can infer a subject's internal visual intent by presenting visual stimuli on a screen and analyzing steady-state visual evoked potentials (SSVEPs). The study demonstrates that with the help of machine learning policies, the BCI can reconstruct simple imagined shapes within approximately two minutes using just single-channel EEG data, and transform them into realistic visual representations. The findings suggest that symbiotic human-AI interaction can significantly increase BCI bit-rates, paving the way for future development of AI-augmented BCIs."
  },
  {
    "title": "CHiQPM: Calibrated Hierarchical Interpretable Image Classification",
    "abstract": "Globally interpretable models are a promising approach for trustworthy AI in safety-critical domains. Alongside global explanations, detailed local explanations are a crucial complement to effectively support human experts during inference. This work proposes the Calibrated Hierarchical QPM (CHiQPM) which offers uniquely comprehensive global and local interpretability, paving the way for human-AI complementarity. CHiQPM achieves superior global interpretability by contrastively explaining the majority of classes and offers novel hierarchical explanations that are more similar to how humans reason and can be traversed to offer a built-in interpretable Conformal prediction (CP) method. Our comprehensive evaluation shows that CHiQPM achieves state-of-the-art accuracy as a point predictor, maintaining 99% accuracy of non-interpretable models. This demonstrates a substantial improvement, where interpretability is incorporated without sacrificing overall accuracy. Furthermore, its calibrated set prediction is competitively efficient to other CP methods, while providing interpretable predictions of coherent sets along its hierarchical explanation.",
    "url": "https://arxiv.org/abs/2511.20779",
    "journal": "arXiv cs.HC",
    "ai_summary": "The research introduces CHiQPM, a model that provides both global and local interpretability in image classification, making it useful for safety-critical domains. CHiQPM achieves high accuracy comparable to non-interpretable models while offering detailed explanations that mimic human reasoning. This model allows for trustworthy AI-human collaboration and offers interpretable predictions through a hierarchical explanation structure."
  },
  {
    "title": "InvisibleBench: A Deployment Gate for Caregiving Relationship AI",
    "abstract": "InvisibleBench is a deployment gate for caregiving-relationship AI, evaluating 3-20+ turn interactions across five dimensions: Safety, Compliance, Trauma-Informed Design, Belonging/Cultural Fitness, and Memory. The benchmark includes autofail conditions for missed crises, medical advice (WOPR Act), harmful information, and attachment engineering. We evaluate four frontier models across 17 scenarios (N=68) spanning three complexity tiers. All models show significant safety gaps (11.8-44.8 percent crisis detection), indicating the necessity of deterministic crisis routing in production systems. DeepSeek Chat v3 achieves the highest overall score (75.9 percent), while strengths differ by dimension: GPT-4o Mini leads Compliance (88.2 percent), Gemini leads Trauma-Informed Design (85.0 percent), and Claude Sonnet 4.5 ranks highest in crisis detection (44.8 percent). We release all scenarios, judge prompts, and scoring configurations with code. InvisibleBench extends single-turn safety tests by evaluating longitudinal risk, where real harms emerge. No clinical claims; this is a deployment-readiness evaluation.",
    "url": "https://arxiv.org/abs/2511.20733",
    "journal": "arXiv cs.HC",
    "ai_summary": "The study introduces InvisibleBench, a benchmark for evaluating caregiving-relationship AI across various dimensions. The research evaluates four frontier models across 17 scenarios and finds significant safety gaps in crisis detection, highlighting the importance of deterministic crisis routing in production systems. DeepSeek Chat v3 achieves the highest overall score, showcasing strengths in different dimensions, emphasizing the need for further development in AI caregiving systems."
  },
  {
    "title": "Seeing Beyond Sound: Visualization and Abstraction in Audio Data Representation",
    "abstract": "In audio signal processing, the interpretation of complex information using visual representation enhances pattern recognition through its alignment with human perceptual systems. Software tools that carry hidden assumptions inherited from their historical contexts risk misalignment with modern workflows as design origins become obscured. We argue that creating tools that align with emergent needs improves analytical and creative outputs due to an increased affinity for using them. This paper explores the potentials associated with adding dimensionality and interactivity into visualization tools to facilitate complex workflows in audio information research using the Jellyfish Dynamite software.",
    "url": "https://arxiv.org/abs/2511.20658",
    "journal": "arXiv cs.HC",
    "ai_summary": "This research explores the importance of visual representation in audio signal processing, arguing that aligning tools with modern workflows improves analytical and creative outputs. The study highlights the significance of incorporating dimensionality and interactivity into visualization tools, as demonstrated through the use of Jellyfish Dynamite software for complex audio information research. This approach enhances pattern recognition and facilitates a deeper understanding of audio data."
  }
]